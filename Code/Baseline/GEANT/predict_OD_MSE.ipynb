{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "from torch.autograd import *\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from utils import * \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Geant Dataset\n",
    "data = read_geant_data()\n",
    "start_idx = 0 \n",
    "end_idx = int((60/15)*24*21) # three weeks of data (same number of samples as abilene for 1 week)\n",
    "data = data[start_idx:end_idx]\n",
    "\n",
    "# Train Test Split \n",
    "train_data, test_data = train_test_split(data, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-wise min-max normalization (normalize each element over time)\n",
    "min_vals_train = train_data.min(axis=0)  # Shape (144,)\n",
    "max_vals_train = train_data.max(axis=0)  # Shape (144,)\n",
    "train_data_norm = (train_data - min_vals_train) / (max_vals_train - min_vals_train + 1e-8)  # Avoid division by zero\n",
    "\n",
    "# Feature-wise min-max normalization (normalize each element over time)\n",
    "min_vals_test = test_data.min(axis=0)  # Shape (144,)\n",
    "max_vals_test = test_data.max(axis=0)  # Shape (144,)\n",
    "test_data_norm = (test_data - min_vals_test) / (max_vals_test - min_vals_test + 1e-8)  # Avoid division by zero\n",
    "\n",
    "# Window the dataset\n",
    "trainX, trainY= create_dataset(train_data_norm, 10) \n",
    "testX, testY = create_dataset(test_data_norm, 10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyper parameters \n",
    "input_size = 1  # Each feature is treated as an individual time series\n",
    "hidden_size = 30\n",
    "num_layers = 1\n",
    "learn_rate = 0.001 \n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "num_features = 23 * 23  # Total number of features in the flattened traffic matrix\n",
    "shuffle = False #don't want to lose the time dependency\n",
    "num_workers = 0  # Number of subprocesses to use for data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a separate model for each feature in the traffic matrix\n",
    "models = [RNN(input_size, hidden_size, num_layers) for _ in range(num_features)]\n",
    "optimizers = [optim.Adam(model.parameters(), lr=learn_rate) for model in models]\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####--training model 0--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2278e-04\n",
      "Epoch [20/100], Loss: 1.4211e-03\n",
      "Epoch [30/100], Loss: 1.9306e-03\n",
      "Epoch [40/100], Loss: 2.7916e-03\n",
      "Epoch [50/100], Loss: 3.6398e-03\n",
      "Epoch [60/100], Loss: 4.0653e-03\n",
      "Epoch [70/100], Loss: 3.6213e-03\n",
      "Epoch [80/100], Loss: 3.1896e-03\n",
      "Epoch [90/100], Loss: 3.0066e-03\n",
      "Epoch [100/100], Loss: 2.9712e-03\n",
      "#####--training model 1--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3607e-02\n",
      "Epoch [20/100], Loss: 1.7870e-02\n",
      "Epoch [30/100], Loss: 1.1440e-02\n",
      "Epoch [40/100], Loss: 6.9626e-03\n",
      "Epoch [50/100], Loss: 5.3262e-03\n",
      "Epoch [60/100], Loss: 4.7486e-03\n",
      "Epoch [70/100], Loss: 4.4519e-03\n",
      "Epoch [80/100], Loss: 4.2378e-03\n",
      "Epoch [90/100], Loss: 4.0588e-03\n",
      "Epoch [100/100], Loss: 3.8988e-03\n",
      "#####--training model 2--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0468e-03\n",
      "Epoch [20/100], Loss: 1.0840e-03\n",
      "Epoch [30/100], Loss: 1.0944e-03\n",
      "Epoch [40/100], Loss: 1.0948e-03\n",
      "Epoch [50/100], Loss: 1.7449e-03\n",
      "Epoch [60/100], Loss: 1.5267e-03\n",
      "Epoch [70/100], Loss: 1.2161e-03\n",
      "Epoch [80/100], Loss: 1.8150e-03\n",
      "Epoch [90/100], Loss: 2.1555e-03\n",
      "Epoch [100/100], Loss: 2.1387e-03\n",
      "#####--training model 3--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.5954e-03\n",
      "Epoch [20/100], Loss: 1.0643e-02\n",
      "Epoch [30/100], Loss: 1.8442e-02\n",
      "Epoch [40/100], Loss: 2.5388e-02\n",
      "Epoch [50/100], Loss: 2.8953e-02\n",
      "Epoch [60/100], Loss: 3.0627e-02\n",
      "Epoch [70/100], Loss: 3.1279e-02\n",
      "Epoch [80/100], Loss: 3.0953e-02\n",
      "Epoch [90/100], Loss: 2.9507e-02\n",
      "Epoch [100/100], Loss: 2.7613e-02\n",
      "#####--training model 4--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3026e-03\n",
      "Epoch [20/100], Loss: 4.0047e-04\n",
      "Epoch [30/100], Loss: 2.6752e-04\n",
      "Epoch [40/100], Loss: 2.0802e-04\n",
      "Epoch [50/100], Loss: 1.6362e-04\n",
      "Epoch [60/100], Loss: 1.2172e-04\n",
      "Epoch [70/100], Loss: 7.9438e-05\n",
      "Epoch [80/100], Loss: 4.7655e-05\n",
      "Epoch [90/100], Loss: 2.9931e-05\n",
      "Epoch [100/100], Loss: 2.2775e-05\n",
      "#####--training model 5--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4886e-03\n",
      "Epoch [20/100], Loss: 7.0949e-04\n",
      "Epoch [30/100], Loss: 2.1309e-04\n",
      "Epoch [40/100], Loss: 7.4687e-05\n",
      "Epoch [50/100], Loss: 4.0092e-05\n",
      "Epoch [60/100], Loss: 2.6039e-05\n",
      "Epoch [70/100], Loss: 1.8922e-05\n",
      "Epoch [80/100], Loss: 1.4454e-05\n",
      "Epoch [90/100], Loss: 1.1001e-05\n",
      "Epoch [100/100], Loss: 8.2648e-06\n",
      "#####--training model 6--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2902e-03\n",
      "Epoch [20/100], Loss: 1.5101e-03\n",
      "Epoch [30/100], Loss: 2.2317e-03\n",
      "Epoch [40/100], Loss: 3.0599e-03\n",
      "Epoch [50/100], Loss: 3.6754e-03\n",
      "Epoch [60/100], Loss: 4.0792e-03\n",
      "Epoch [70/100], Loss: 4.3629e-03\n",
      "Epoch [80/100], Loss: 4.5696e-03\n",
      "Epoch [90/100], Loss: 4.7094e-03\n",
      "Epoch [100/100], Loss: 4.8011e-03\n",
      "#####--training model 7--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3058e-03\n",
      "Epoch [20/100], Loss: 1.3747e-03\n",
      "Epoch [30/100], Loss: 2.8348e-04\n",
      "Epoch [40/100], Loss: 1.1807e-04\n",
      "Epoch [50/100], Loss: 7.3242e-05\n",
      "Epoch [60/100], Loss: 5.0132e-05\n",
      "Epoch [70/100], Loss: 3.5393e-05\n",
      "Epoch [80/100], Loss: 2.2299e-05\n",
      "Epoch [90/100], Loss: 1.2432e-05\n",
      "Epoch [100/100], Loss: 7.4553e-06\n",
      "#####--training model 8--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.8673e-03\n",
      "Epoch [20/100], Loss: 4.5963e-04\n",
      "Epoch [30/100], Loss: 1.9496e-04\n",
      "Epoch [40/100], Loss: 1.3502e-04\n",
      "Epoch [50/100], Loss: 9.2059e-05\n",
      "Epoch [60/100], Loss: 6.5756e-05\n",
      "Epoch [70/100], Loss: 4.5960e-05\n",
      "Epoch [80/100], Loss: 3.1127e-05\n",
      "Epoch [90/100], Loss: 2.1200e-05\n",
      "Epoch [100/100], Loss: 1.5080e-05\n",
      "#####--training model 9--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3760e-02\n",
      "Epoch [20/100], Loss: 3.4408e-02\n",
      "Epoch [30/100], Loss: 3.3966e-02\n",
      "Epoch [40/100], Loss: 9.8968e-03\n",
      "Epoch [50/100], Loss: 1.7386e-02\n",
      "Epoch [60/100], Loss: 1.7168e-02\n",
      "Epoch [70/100], Loss: 2.0334e-02\n",
      "Epoch [80/100], Loss: 1.8967e-02\n",
      "Epoch [90/100], Loss: 1.5279e-02\n",
      "Epoch [100/100], Loss: 1.4948e-02\n",
      "#####--training model 10--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6708e-04\n",
      "Epoch [20/100], Loss: 1.9468e-04\n",
      "Epoch [30/100], Loss: 1.8939e-04\n",
      "Epoch [40/100], Loss: 1.9119e-04\n",
      "Epoch [50/100], Loss: 1.9372e-04\n",
      "Epoch [60/100], Loss: 1.9666e-04\n",
      "Epoch [70/100], Loss: 1.9995e-04\n",
      "Epoch [80/100], Loss: 2.0347e-04\n",
      "Epoch [90/100], Loss: 2.0704e-04\n",
      "Epoch [100/100], Loss: 2.1045e-04\n",
      "#####--training model 11--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.0212e-03\n",
      "Epoch [20/100], Loss: 1.2733e-03\n",
      "Epoch [30/100], Loss: 1.0176e-03\n",
      "Epoch [40/100], Loss: 6.6122e-04\n",
      "Epoch [50/100], Loss: 5.2207e-04\n",
      "Epoch [60/100], Loss: 5.4650e-04\n",
      "Epoch [70/100], Loss: 5.7407e-04\n",
      "Epoch [80/100], Loss: 5.8057e-04\n",
      "Epoch [90/100], Loss: 5.7521e-04\n",
      "Epoch [100/100], Loss: 5.7681e-04\n",
      "#####--training model 12--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1909e-03\n",
      "Epoch [20/100], Loss: 3.6783e-04\n",
      "Epoch [30/100], Loss: 1.2190e-03\n",
      "Epoch [40/100], Loss: 1.0781e-03\n",
      "Epoch [50/100], Loss: 9.4851e-04\n",
      "Epoch [60/100], Loss: 8.3569e-04\n",
      "Epoch [70/100], Loss: 7.4226e-04\n",
      "Epoch [80/100], Loss: 6.8118e-04\n",
      "Epoch [90/100], Loss: 6.4466e-04\n",
      "Epoch [100/100], Loss: 6.0292e-04\n",
      "#####--training model 13--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7024e-04\n",
      "Epoch [20/100], Loss: 7.2905e-05\n",
      "Epoch [30/100], Loss: 4.7832e-05\n",
      "Epoch [40/100], Loss: 3.8495e-05\n",
      "Epoch [50/100], Loss: 3.4810e-05\n",
      "Epoch [60/100], Loss: 3.3523e-05\n",
      "Epoch [70/100], Loss: 3.3179e-05\n",
      "Epoch [80/100], Loss: 3.3113e-05\n",
      "Epoch [90/100], Loss: 3.3097e-05\n",
      "Epoch [100/100], Loss: 3.3085e-05\n",
      "#####--training model 14--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.2280e-03\n",
      "Epoch [20/100], Loss: 4.1722e-03\n",
      "Epoch [30/100], Loss: 4.2174e-03\n",
      "Epoch [40/100], Loss: 4.2764e-03\n",
      "Epoch [50/100], Loss: 4.6004e-03\n",
      "Epoch [60/100], Loss: 4.7679e-03\n",
      "Epoch [70/100], Loss: 4.8049e-03\n",
      "Epoch [80/100], Loss: 4.8178e-03\n",
      "Epoch [90/100], Loss: 4.8153e-03\n",
      "Epoch [100/100], Loss: 4.8193e-03\n",
      "#####--training model 15--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7537e-01\n",
      "Epoch [20/100], Loss: 2.2536e-02\n",
      "Epoch [30/100], Loss: 2.3221e-02\n",
      "Epoch [40/100], Loss: 2.4015e-02\n",
      "Epoch [50/100], Loss: 2.4679e-02\n",
      "Epoch [60/100], Loss: 2.5126e-02\n",
      "Epoch [70/100], Loss: 2.5267e-02\n",
      "Epoch [80/100], Loss: 2.5111e-02\n",
      "Epoch [90/100], Loss: 2.4809e-02\n",
      "Epoch [100/100], Loss: 2.4502e-02\n",
      "#####--training model 16--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.5100e-03\n",
      "Epoch [20/100], Loss: 3.9318e-03\n",
      "Epoch [30/100], Loss: 3.6421e-03\n",
      "Epoch [40/100], Loss: 3.0338e-03\n",
      "Epoch [50/100], Loss: 2.5578e-03\n",
      "Epoch [60/100], Loss: 2.2273e-03\n",
      "Epoch [70/100], Loss: 2.0045e-03\n",
      "Epoch [80/100], Loss: 1.8605e-03\n",
      "Epoch [90/100], Loss: 1.7565e-03\n",
      "Epoch [100/100], Loss: 1.6695e-03\n",
      "#####--training model 17--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6472e-03\n",
      "Epoch [20/100], Loss: 1.1001e-03\n",
      "Epoch [30/100], Loss: 7.5551e-04\n",
      "Epoch [40/100], Loss: 4.9987e-04\n",
      "Epoch [50/100], Loss: 4.1468e-04\n",
      "Epoch [60/100], Loss: 4.6037e-04\n",
      "Epoch [70/100], Loss: 5.3589e-04\n",
      "Epoch [80/100], Loss: 5.8444e-04\n",
      "Epoch [90/100], Loss: 6.1276e-04\n",
      "Epoch [100/100], Loss: 6.3303e-04\n",
      "#####--training model 18--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.0356e-04\n",
      "Epoch [20/100], Loss: 1.0113e-03\n",
      "Epoch [30/100], Loss: 1.1126e-03\n",
      "Epoch [40/100], Loss: 2.2086e-03\n",
      "Epoch [50/100], Loss: 2.9084e-03\n",
      "Epoch [60/100], Loss: 2.8086e-03\n",
      "Epoch [70/100], Loss: 2.3687e-03\n",
      "Epoch [80/100], Loss: 2.0138e-03\n",
      "Epoch [90/100], Loss: 1.7931e-03\n",
      "Epoch [100/100], Loss: 1.6449e-03\n",
      "#####--training model 19--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0323e-03\n",
      "Epoch [20/100], Loss: 1.9973e-03\n",
      "Epoch [30/100], Loss: 1.9508e-03\n",
      "Epoch [40/100], Loss: 1.8870e-03\n",
      "Epoch [50/100], Loss: 1.7557e-03\n",
      "Epoch [60/100], Loss: 1.4735e-03\n",
      "Epoch [70/100], Loss: 1.5497e-03\n",
      "Epoch [80/100], Loss: 2.7472e-03\n",
      "Epoch [90/100], Loss: 3.6050e-03\n",
      "Epoch [100/100], Loss: 4.1101e-03\n",
      "#####--training model 20--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0966e-01\n",
      "Epoch [20/100], Loss: 8.8058e-02\n",
      "Epoch [30/100], Loss: 5.3443e-02\n",
      "Epoch [40/100], Loss: 2.5083e-02\n",
      "Epoch [50/100], Loss: 1.0565e-02\n",
      "Epoch [60/100], Loss: 6.4646e-03\n",
      "Epoch [70/100], Loss: 5.7342e-03\n",
      "Epoch [80/100], Loss: 5.1329e-03\n",
      "Epoch [90/100], Loss: 4.3899e-03\n",
      "Epoch [100/100], Loss: 3.7271e-03\n",
      "#####--training model 21--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1314e-02\n",
      "Epoch [20/100], Loss: 1.0599e-02\n",
      "Epoch [30/100], Loss: 1.0967e-02\n",
      "Epoch [40/100], Loss: 1.1991e-02\n",
      "Epoch [50/100], Loss: 1.2827e-02\n",
      "Epoch [60/100], Loss: 1.3287e-02\n",
      "Epoch [70/100], Loss: 1.3434e-02\n",
      "Epoch [80/100], Loss: 1.3375e-02\n",
      "Epoch [90/100], Loss: 1.3198e-02\n",
      "Epoch [100/100], Loss: 1.2960e-02\n",
      "#####--training model 22--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2982e-04\n",
      "Epoch [20/100], Loss: 1.7427e-04\n",
      "Epoch [30/100], Loss: 1.7518e-04\n",
      "Epoch [40/100], Loss: 1.8270e-04\n",
      "Epoch [50/100], Loss: 1.9852e-04\n",
      "Epoch [60/100], Loss: 2.5727e-04\n",
      "Epoch [70/100], Loss: 4.1781e-04\n",
      "Epoch [80/100], Loss: 3.5726e-04\n",
      "Epoch [90/100], Loss: 3.2080e-04\n",
      "Epoch [100/100], Loss: 2.2631e-04\n",
      "#####--training model 23--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.0857e-02\n",
      "Epoch [20/100], Loss: 1.5306e-02\n",
      "Epoch [30/100], Loss: 7.8942e-03\n",
      "Epoch [40/100], Loss: 3.9692e-03\n",
      "Epoch [50/100], Loss: 3.1343e-03\n",
      "Epoch [60/100], Loss: 2.7541e-03\n",
      "Epoch [70/100], Loss: 2.5154e-03\n",
      "Epoch [80/100], Loss: 2.3998e-03\n",
      "Epoch [90/100], Loss: 2.3438e-03\n",
      "Epoch [100/100], Loss: 2.3135e-03\n",
      "#####--training model 24--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.6651e-03\n",
      "Epoch [20/100], Loss: 5.4766e-03\n",
      "Epoch [30/100], Loss: 5.1761e-03\n",
      "Epoch [40/100], Loss: 3.9664e-03\n",
      "Epoch [50/100], Loss: 2.4442e-03\n",
      "Epoch [60/100], Loss: 1.8627e-03\n",
      "Epoch [70/100], Loss: 1.3534e-03\n",
      "Epoch [80/100], Loss: 9.8974e-04\n",
      "Epoch [90/100], Loss: 1.0162e-03\n",
      "Epoch [100/100], Loss: 1.0543e-03\n",
      "#####--training model 25--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.4077e-04\n",
      "Epoch [20/100], Loss: 6.8315e-04\n",
      "Epoch [30/100], Loss: 1.6635e-04\n",
      "Epoch [40/100], Loss: 1.3088e-04\n",
      "Epoch [50/100], Loss: 1.1227e-04\n",
      "Epoch [60/100], Loss: 1.0190e-04\n",
      "Epoch [70/100], Loss: 9.5667e-05\n",
      "Epoch [80/100], Loss: 8.4606e-05\n",
      "Epoch [90/100], Loss: 7.2035e-05\n",
      "Epoch [100/100], Loss: 6.1173e-05\n",
      "#####--training model 26--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.8294e-04\n",
      "Epoch [20/100], Loss: 3.8911e-04\n",
      "Epoch [30/100], Loss: 5.3260e-04\n",
      "Epoch [40/100], Loss: 3.0387e-04\n",
      "Epoch [50/100], Loss: 8.0735e-05\n",
      "Epoch [60/100], Loss: 9.8910e-06\n",
      "Epoch [70/100], Loss: 2.6215e-05\n",
      "Epoch [80/100], Loss: 6.6331e-05\n",
      "Epoch [90/100], Loss: 9.3177e-05\n",
      "Epoch [100/100], Loss: 1.0497e-04\n",
      "#####--training model 27--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.4336e-03\n",
      "Epoch [20/100], Loss: 4.4749e-03\n",
      "Epoch [30/100], Loss: 4.5172e-03\n",
      "Epoch [40/100], Loss: 4.6256e-03\n",
      "Epoch [50/100], Loss: 5.3244e-03\n",
      "Epoch [60/100], Loss: 5.6757e-03\n",
      "Epoch [70/100], Loss: 5.8743e-03\n",
      "Epoch [80/100], Loss: 6.0200e-03\n",
      "Epoch [90/100], Loss: 6.0663e-03\n",
      "Epoch [100/100], Loss: 6.0585e-03\n",
      "#####--training model 28--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.9768e-04\n",
      "Epoch [20/100], Loss: 2.2899e-04\n",
      "Epoch [30/100], Loss: 1.1134e-04\n",
      "Epoch [40/100], Loss: 5.5307e-05\n",
      "Epoch [50/100], Loss: 1.6357e-05\n",
      "Epoch [60/100], Loss: 8.8829e-06\n",
      "Epoch [70/100], Loss: 6.3659e-06\n",
      "Epoch [80/100], Loss: 5.0488e-06\n",
      "Epoch [90/100], Loss: 4.1680e-06\n",
      "Epoch [100/100], Loss: 3.4701e-06\n",
      "#####--training model 29--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.2827e-03\n",
      "Epoch [20/100], Loss: 4.8028e-03\n",
      "Epoch [30/100], Loss: 3.3674e-03\n",
      "Epoch [40/100], Loss: 2.2398e-03\n",
      "Epoch [50/100], Loss: 1.9212e-03\n",
      "Epoch [60/100], Loss: 1.8253e-03\n",
      "Epoch [70/100], Loss: 1.7781e-03\n",
      "Epoch [80/100], Loss: 1.7436e-03\n",
      "Epoch [90/100], Loss: 1.7119e-03\n",
      "Epoch [100/100], Loss: 1.6804e-03\n",
      "#####--training model 30--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.2681e-03\n",
      "Epoch [20/100], Loss: 1.8060e-02\n",
      "Epoch [30/100], Loss: 1.0343e-02\n",
      "Epoch [40/100], Loss: 5.2168e-03\n",
      "Epoch [50/100], Loss: 3.5622e-03\n",
      "Epoch [60/100], Loss: 2.8639e-03\n",
      "Epoch [70/100], Loss: 2.4740e-03\n",
      "Epoch [80/100], Loss: 2.3888e-03\n",
      "Epoch [90/100], Loss: 2.4288e-03\n",
      "Epoch [100/100], Loss: 2.5041e-03\n",
      "#####--training model 31--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5267e-03\n",
      "Epoch [20/100], Loss: 1.0561e-03\n",
      "Epoch [30/100], Loss: 8.3487e-04\n",
      "Epoch [40/100], Loss: 8.8052e-04\n",
      "Epoch [50/100], Loss: 8.7496e-04\n",
      "Epoch [60/100], Loss: 8.8423e-04\n",
      "Epoch [70/100], Loss: 8.7712e-04\n",
      "Epoch [80/100], Loss: 8.6746e-04\n",
      "Epoch [90/100], Loss: 8.4907e-04\n",
      "Epoch [100/100], Loss: 8.1490e-04\n",
      "#####--training model 32--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0035e-04\n",
      "Epoch [20/100], Loss: 3.2077e-02\n",
      "Epoch [30/100], Loss: 2.3143e-02\n",
      "Epoch [40/100], Loss: 1.8264e-02\n",
      "Epoch [50/100], Loss: 1.4805e-02\n",
      "Epoch [60/100], Loss: 1.2343e-02\n",
      "Epoch [70/100], Loss: 1.0054e-02\n",
      "Epoch [80/100], Loss: 8.5669e-03\n",
      "Epoch [90/100], Loss: 7.6943e-03\n",
      "Epoch [100/100], Loss: 7.1034e-03\n",
      "#####--training model 33--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.3384e-03\n",
      "Epoch [20/100], Loss: 3.3979e-03\n",
      "Epoch [30/100], Loss: 1.8023e-03\n",
      "Epoch [40/100], Loss: 1.1719e-03\n",
      "Epoch [50/100], Loss: 8.9112e-04\n",
      "Epoch [60/100], Loss: 7.5160e-04\n",
      "Epoch [70/100], Loss: 6.6094e-04\n",
      "Epoch [80/100], Loss: 5.8756e-04\n",
      "Epoch [90/100], Loss: 5.2140e-04\n",
      "Epoch [100/100], Loss: 4.6542e-04\n",
      "#####--training model 34--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.6988e-04\n",
      "Epoch [20/100], Loss: 1.5467e-03\n",
      "Epoch [30/100], Loss: 1.5026e-03\n",
      "Epoch [40/100], Loss: 1.3477e-03\n",
      "Epoch [50/100], Loss: 1.2623e-03\n",
      "Epoch [60/100], Loss: 1.2450e-03\n",
      "Epoch [70/100], Loss: 1.2587e-03\n",
      "Epoch [80/100], Loss: 1.2820e-03\n",
      "Epoch [90/100], Loss: 1.3051e-03\n",
      "Epoch [100/100], Loss: 1.3223e-03\n",
      "#####--training model 35--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.2777e-04\n",
      "Epoch [20/100], Loss: 4.1809e-04\n",
      "Epoch [30/100], Loss: 2.0806e-04\n",
      "Epoch [40/100], Loss: 1.2999e-04\n",
      "Epoch [50/100], Loss: 1.0492e-04\n",
      "Epoch [60/100], Loss: 9.1371e-05\n",
      "Epoch [70/100], Loss: 8.3216e-05\n",
      "Epoch [80/100], Loss: 8.1707e-05\n",
      "Epoch [90/100], Loss: 7.8396e-05\n",
      "Epoch [100/100], Loss: 7.7153e-05\n",
      "#####--training model 36--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3216e-03\n",
      "Epoch [20/100], Loss: 2.7069e-03\n",
      "Epoch [30/100], Loss: 1.8792e-03\n",
      "Epoch [40/100], Loss: 1.2250e-03\n",
      "Epoch [50/100], Loss: 8.9519e-04\n",
      "Epoch [60/100], Loss: 7.3307e-04\n",
      "Epoch [70/100], Loss: 6.4204e-04\n",
      "Epoch [80/100], Loss: 5.6983e-04\n",
      "Epoch [90/100], Loss: 5.0705e-04\n",
      "Epoch [100/100], Loss: 4.5549e-04\n",
      "#####--training model 37--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.0390e-03\n",
      "Epoch [20/100], Loss: 1.0935e-03\n",
      "Epoch [30/100], Loss: 6.3996e-04\n",
      "Epoch [40/100], Loss: 5.9427e-04\n",
      "Epoch [50/100], Loss: 4.9766e-04\n",
      "Epoch [60/100], Loss: 4.4046e-04\n",
      "Epoch [70/100], Loss: 4.6191e-04\n",
      "Epoch [80/100], Loss: 5.0410e-04\n",
      "Epoch [90/100], Loss: 4.7316e-04\n",
      "Epoch [100/100], Loss: 4.1336e-04\n",
      "#####--training model 38--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.5323e-03\n",
      "Epoch [20/100], Loss: 3.2572e-03\n",
      "Epoch [30/100], Loss: 1.1839e-03\n",
      "Epoch [40/100], Loss: 8.8516e-04\n",
      "Epoch [50/100], Loss: 9.8157e-04\n",
      "Epoch [60/100], Loss: 1.1092e-03\n",
      "Epoch [70/100], Loss: 1.2123e-03\n",
      "Epoch [80/100], Loss: 1.2750e-03\n",
      "Epoch [90/100], Loss: 1.2931e-03\n",
      "Epoch [100/100], Loss: 1.2755e-03\n",
      "#####--training model 39--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.5504e-03\n",
      "Epoch [20/100], Loss: 1.0490e-02\n",
      "Epoch [30/100], Loss: 9.4731e-03\n",
      "Epoch [40/100], Loss: 9.0588e-03\n",
      "Epoch [50/100], Loss: 8.8480e-03\n",
      "Epoch [60/100], Loss: 8.7106e-03\n",
      "Epoch [70/100], Loss: 8.6165e-03\n",
      "Epoch [80/100], Loss: 8.5650e-03\n",
      "Epoch [90/100], Loss: 8.5675e-03\n",
      "Epoch [100/100], Loss: 8.5535e-03\n",
      "#####--training model 40--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3710e-04\n",
      "Epoch [20/100], Loss: 8.5743e-04\n",
      "Epoch [30/100], Loss: 8.6100e-04\n",
      "Epoch [40/100], Loss: 7.1475e-04\n",
      "Epoch [50/100], Loss: 6.5509e-04\n",
      "Epoch [60/100], Loss: 6.3164e-04\n",
      "Epoch [70/100], Loss: 6.1695e-04\n",
      "Epoch [80/100], Loss: 6.0360e-04\n",
      "Epoch [90/100], Loss: 5.9197e-04\n",
      "Epoch [100/100], Loss: 5.8183e-04\n",
      "#####--training model 41--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2653e-03\n",
      "Epoch [20/100], Loss: 6.5700e-04\n",
      "Epoch [30/100], Loss: 3.9610e-04\n",
      "Epoch [40/100], Loss: 2.7541e-04\n",
      "Epoch [50/100], Loss: 2.0848e-04\n",
      "Epoch [60/100], Loss: 1.4822e-04\n",
      "Epoch [70/100], Loss: 1.1251e-04\n",
      "Epoch [80/100], Loss: 9.5346e-05\n",
      "Epoch [90/100], Loss: 8.3124e-05\n",
      "Epoch [100/100], Loss: 7.3599e-05\n",
      "#####--training model 42--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4477e-03\n",
      "Epoch [20/100], Loss: 1.6271e-03\n",
      "Epoch [30/100], Loss: 6.1254e-04\n",
      "Epoch [40/100], Loss: 6.4639e-04\n",
      "Epoch [50/100], Loss: 7.5076e-04\n",
      "Epoch [60/100], Loss: 8.4681e-04\n",
      "Epoch [70/100], Loss: 9.0200e-04\n",
      "Epoch [80/100], Loss: 9.2394e-04\n",
      "Epoch [90/100], Loss: 9.2622e-04\n",
      "Epoch [100/100], Loss: 9.0872e-04\n",
      "#####--training model 43--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.1455e-02\n",
      "Epoch [20/100], Loss: 4.5498e-03\n",
      "Epoch [30/100], Loss: 3.2899e-03\n",
      "Epoch [40/100], Loss: 2.6471e-03\n",
      "Epoch [50/100], Loss: 2.2169e-03\n",
      "Epoch [60/100], Loss: 1.9400e-03\n",
      "Epoch [70/100], Loss: 1.7686e-03\n",
      "Epoch [80/100], Loss: 1.6814e-03\n",
      "Epoch [90/100], Loss: 1.6476e-03\n",
      "Epoch [100/100], Loss: 1.6335e-03\n",
      "#####--training model 44--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.3258e-03\n",
      "Epoch [20/100], Loss: 2.6306e-02\n",
      "Epoch [30/100], Loss: 2.6002e-02\n",
      "Epoch [40/100], Loss: 2.0767e-02\n",
      "Epoch [50/100], Loss: 1.3627e-02\n",
      "Epoch [60/100], Loss: 8.2050e-03\n",
      "Epoch [70/100], Loss: 5.2948e-03\n",
      "Epoch [80/100], Loss: 4.0490e-03\n",
      "Epoch [90/100], Loss: 3.4376e-03\n",
      "Epoch [100/100], Loss: 3.0609e-03\n",
      "#####--training model 45--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9261e-04\n",
      "Epoch [20/100], Loss: 1.7196e-04\n",
      "Epoch [30/100], Loss: 1.7095e-04\n",
      "Epoch [40/100], Loss: 1.7106e-04\n",
      "Epoch [50/100], Loss: 1.7122e-04\n",
      "Epoch [60/100], Loss: 1.7143e-04\n",
      "Epoch [70/100], Loss: 1.7171e-04\n",
      "Epoch [80/100], Loss: 1.7217e-04\n",
      "Epoch [90/100], Loss: 1.7300e-04\n",
      "Epoch [100/100], Loss: 1.7487e-04\n",
      "#####--training model 46--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6396e-03\n",
      "Epoch [20/100], Loss: 2.5561e-03\n",
      "Epoch [30/100], Loss: 3.2319e-03\n",
      "Epoch [40/100], Loss: 3.5278e-03\n",
      "Epoch [50/100], Loss: 3.6623e-03\n",
      "Epoch [60/100], Loss: 3.6538e-03\n",
      "Epoch [70/100], Loss: 3.5068e-03\n",
      "Epoch [80/100], Loss: 3.3263e-03\n",
      "Epoch [90/100], Loss: 3.1677e-03\n",
      "Epoch [100/100], Loss: 3.0443e-03\n",
      "#####--training model 47--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8758e-03\n",
      "Epoch [20/100], Loss: 2.4800e-03\n",
      "Epoch [30/100], Loss: 2.1221e-03\n",
      "Epoch [40/100], Loss: 1.6882e-03\n",
      "Epoch [50/100], Loss: 1.3464e-03\n",
      "Epoch [60/100], Loss: 1.1896e-03\n",
      "Epoch [70/100], Loss: 1.0939e-03\n",
      "Epoch [80/100], Loss: 1.0235e-03\n",
      "Epoch [90/100], Loss: 9.7052e-04\n",
      "Epoch [100/100], Loss: 9.2419e-04\n",
      "#####--training model 48--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4993e-03\n",
      "Epoch [20/100], Loss: 3.8290e-04\n",
      "Epoch [30/100], Loss: 2.0820e-04\n",
      "Epoch [40/100], Loss: 1.2801e-04\n",
      "Epoch [50/100], Loss: 8.0997e-05\n",
      "Epoch [60/100], Loss: 4.8782e-05\n",
      "Epoch [70/100], Loss: 2.9525e-05\n",
      "Epoch [80/100], Loss: 1.8199e-05\n",
      "Epoch [90/100], Loss: 1.1802e-05\n",
      "Epoch [100/100], Loss: 8.3700e-06\n",
      "#####--training model 49--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9659e-04\n",
      "Epoch [20/100], Loss: 1.3852e-04\n",
      "Epoch [30/100], Loss: 1.3722e-04\n",
      "Epoch [40/100], Loss: 1.4958e-04\n",
      "Epoch [50/100], Loss: 1.6252e-04\n",
      "Epoch [60/100], Loss: 1.7242e-04\n",
      "Epoch [70/100], Loss: 1.8107e-04\n",
      "Epoch [80/100], Loss: 5.4763e-05\n",
      "Epoch [90/100], Loss: 1.9443e-05\n",
      "Epoch [100/100], Loss: 9.7783e-06\n",
      "#####--training model 50--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.1813e-03\n",
      "Epoch [20/100], Loss: 2.3124e-03\n",
      "Epoch [30/100], Loss: 2.4266e-03\n",
      "Epoch [40/100], Loss: 1.0137e-03\n",
      "Epoch [50/100], Loss: 9.1146e-04\n",
      "Epoch [60/100], Loss: 7.6724e-04\n",
      "Epoch [70/100], Loss: 5.4658e-04\n",
      "Epoch [80/100], Loss: 3.7456e-04\n",
      "Epoch [90/100], Loss: 3.0626e-04\n",
      "Epoch [100/100], Loss: 2.7493e-04\n",
      "#####--training model 51--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6936e-04\n",
      "Epoch [20/100], Loss: 2.1585e-04\n",
      "Epoch [30/100], Loss: 2.0840e-04\n",
      "Epoch [40/100], Loss: 2.0611e-04\n",
      "Epoch [50/100], Loss: 2.0396e-04\n",
      "Epoch [60/100], Loss: 2.0156e-04\n",
      "Epoch [70/100], Loss: 1.9900e-04\n",
      "Epoch [80/100], Loss: 1.9677e-04\n",
      "Epoch [90/100], Loss: 1.7286e-04\n",
      "Epoch [100/100], Loss: 1.6506e-04\n",
      "#####--training model 52--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3927e-01\n",
      "Epoch [20/100], Loss: 1.7914e-01\n",
      "Epoch [30/100], Loss: 1.0090e-01\n",
      "Epoch [40/100], Loss: 4.9178e-02\n",
      "Epoch [50/100], Loss: 2.1137e-02\n",
      "Epoch [60/100], Loss: 1.3504e-02\n",
      "Epoch [70/100], Loss: 1.0669e-02\n",
      "Epoch [80/100], Loss: 8.5668e-03\n",
      "Epoch [90/100], Loss: 6.9608e-03\n",
      "Epoch [100/100], Loss: 5.8378e-03\n",
      "#####--training model 53--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4657e-03\n",
      "Epoch [20/100], Loss: 1.5777e-03\n",
      "Epoch [30/100], Loss: 2.7491e-03\n",
      "Epoch [40/100], Loss: 1.9682e-03\n",
      "Epoch [50/100], Loss: 1.3962e-03\n",
      "Epoch [60/100], Loss: 1.2373e-03\n",
      "Epoch [70/100], Loss: 1.1258e-03\n",
      "Epoch [80/100], Loss: 1.0188e-03\n",
      "Epoch [90/100], Loss: 9.0946e-04\n",
      "Epoch [100/100], Loss: 8.1392e-04\n",
      "#####--training model 54--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.5235e-04\n",
      "Epoch [20/100], Loss: 7.0736e-04\n",
      "Epoch [30/100], Loss: 8.3161e-04\n",
      "Epoch [40/100], Loss: 1.8957e-03\n",
      "Epoch [50/100], Loss: 1.3278e-03\n",
      "Epoch [60/100], Loss: 9.0627e-04\n",
      "Epoch [70/100], Loss: 6.6568e-04\n",
      "Epoch [80/100], Loss: 5.3712e-04\n",
      "Epoch [90/100], Loss: 4.4758e-04\n",
      "Epoch [100/100], Loss: 3.7175e-04\n",
      "#####--training model 55--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.0992e-02\n",
      "Epoch [20/100], Loss: 7.6806e-02\n",
      "Epoch [30/100], Loss: 5.7960e-02\n",
      "Epoch [40/100], Loss: 2.4715e-02\n",
      "Epoch [50/100], Loss: 1.4521e-02\n",
      "Epoch [60/100], Loss: 1.0824e-02\n",
      "Epoch [70/100], Loss: 8.5444e-03\n",
      "Epoch [80/100], Loss: 7.0501e-03\n",
      "Epoch [90/100], Loss: 6.1532e-03\n",
      "Epoch [100/100], Loss: 5.4723e-03\n",
      "#####--training model 56--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4238e-03\n",
      "Epoch [20/100], Loss: 6.4149e-04\n",
      "Epoch [30/100], Loss: 2.8076e-04\n",
      "Epoch [40/100], Loss: 1.7983e-04\n",
      "Epoch [50/100], Loss: 1.2150e-04\n",
      "Epoch [60/100], Loss: 8.7664e-05\n",
      "Epoch [70/100], Loss: 6.3388e-05\n",
      "Epoch [80/100], Loss: 4.3022e-05\n",
      "Epoch [90/100], Loss: 2.6102e-05\n",
      "Epoch [100/100], Loss: 1.6644e-05\n",
      "#####--training model 57--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1077e-02\n",
      "Epoch [20/100], Loss: 1.3663e-03\n",
      "Epoch [30/100], Loss: 1.0039e-03\n",
      "Epoch [40/100], Loss: 1.0902e-03\n",
      "Epoch [50/100], Loss: 1.2675e-03\n",
      "Epoch [60/100], Loss: 1.3271e-03\n",
      "Epoch [70/100], Loss: 1.3507e-03\n",
      "Epoch [80/100], Loss: 1.3358e-03\n",
      "Epoch [90/100], Loss: 1.2815e-03\n",
      "Epoch [100/100], Loss: 1.1834e-03\n",
      "#####--training model 58--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.9698e-03\n",
      "Epoch [20/100], Loss: 7.3585e-03\n",
      "Epoch [30/100], Loss: 5.8092e-03\n",
      "Epoch [40/100], Loss: 5.8166e-03\n",
      "Epoch [50/100], Loss: 6.1583e-03\n",
      "Epoch [60/100], Loss: 6.5272e-03\n",
      "Epoch [70/100], Loss: 6.8987e-03\n",
      "Epoch [80/100], Loss: 7.3086e-03\n",
      "Epoch [90/100], Loss: 7.6821e-03\n",
      "Epoch [100/100], Loss: 7.9660e-03\n",
      "#####--training model 59--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.7711e-03\n",
      "Epoch [20/100], Loss: 1.6629e-03\n",
      "Epoch [30/100], Loss: 5.3724e-04\n",
      "Epoch [40/100], Loss: 2.1040e-04\n",
      "Epoch [50/100], Loss: 1.0257e-04\n",
      "Epoch [60/100], Loss: 6.3541e-05\n",
      "Epoch [70/100], Loss: 4.6806e-05\n",
      "Epoch [80/100], Loss: 3.1618e-05\n",
      "Epoch [90/100], Loss: 1.8741e-05\n",
      "Epoch [100/100], Loss: 1.2515e-05\n",
      "#####--training model 60--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.3793e-03\n",
      "Epoch [20/100], Loss: 4.9639e-03\n",
      "Epoch [30/100], Loss: 5.1390e-03\n",
      "Epoch [40/100], Loss: 5.3216e-03\n",
      "Epoch [50/100], Loss: 5.4632e-03\n",
      "Epoch [60/100], Loss: 5.6049e-03\n",
      "Epoch [70/100], Loss: 5.7083e-03\n",
      "Epoch [80/100], Loss: 5.7488e-03\n",
      "Epoch [90/100], Loss: 5.7498e-03\n",
      "Epoch [100/100], Loss: 5.7161e-03\n",
      "#####--training model 61--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.7496e-04\n",
      "Epoch [20/100], Loss: 1.8794e-03\n",
      "Epoch [30/100], Loss: 2.2516e-03\n",
      "Epoch [40/100], Loss: 2.4913e-03\n",
      "Epoch [50/100], Loss: 2.7366e-03\n",
      "Epoch [60/100], Loss: 2.9211e-03\n",
      "Epoch [70/100], Loss: 3.0186e-03\n",
      "Epoch [80/100], Loss: 3.0791e-03\n",
      "Epoch [90/100], Loss: 3.1277e-03\n",
      "Epoch [100/100], Loss: 3.1821e-03\n",
      "#####--training model 62--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3190e-03\n",
      "Epoch [20/100], Loss: 3.1935e-03\n",
      "Epoch [30/100], Loss: 3.4838e-03\n",
      "Epoch [40/100], Loss: 3.4850e-03\n",
      "Epoch [50/100], Loss: 3.4234e-03\n",
      "Epoch [60/100], Loss: 3.3566e-03\n",
      "Epoch [70/100], Loss: 3.2832e-03\n",
      "Epoch [80/100], Loss: 3.2008e-03\n",
      "Epoch [90/100], Loss: 3.1121e-03\n",
      "Epoch [100/100], Loss: 3.0220e-03\n",
      "#####--training model 63--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0030e-03\n",
      "Epoch [20/100], Loss: 4.5840e-04\n",
      "Epoch [30/100], Loss: 1.4501e-04\n",
      "Epoch [40/100], Loss: 4.7039e-05\n",
      "Epoch [50/100], Loss: 1.5585e-05\n",
      "Epoch [60/100], Loss: 1.7903e-05\n",
      "Epoch [70/100], Loss: 2.6604e-05\n",
      "Epoch [80/100], Loss: 3.1784e-05\n",
      "Epoch [90/100], Loss: 3.4040e-05\n",
      "Epoch [100/100], Loss: 4.0262e-05\n",
      "#####--training model 64--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4765e-03\n",
      "Epoch [20/100], Loss: 4.5490e-03\n",
      "Epoch [30/100], Loss: 5.9340e-03\n",
      "Epoch [40/100], Loss: 6.6304e-03\n",
      "Epoch [50/100], Loss: 6.9688e-03\n",
      "Epoch [60/100], Loss: 7.1005e-03\n",
      "Epoch [70/100], Loss: 7.1098e-03\n",
      "Epoch [80/100], Loss: 7.1025e-03\n",
      "Epoch [90/100], Loss: 7.1152e-03\n",
      "Epoch [100/100], Loss: 7.1397e-03\n",
      "#####--training model 65--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.8580e-02\n",
      "Epoch [20/100], Loss: 8.2012e-02\n",
      "Epoch [30/100], Loss: 7.9561e-02\n",
      "Epoch [40/100], Loss: 7.5597e-02\n",
      "Epoch [50/100], Loss: 7.1903e-02\n",
      "Epoch [60/100], Loss: 6.9518e-02\n",
      "Epoch [70/100], Loss: 6.8567e-02\n",
      "Epoch [80/100], Loss: 6.8237e-02\n",
      "Epoch [90/100], Loss: 6.7885e-02\n",
      "Epoch [100/100], Loss: 6.7238e-02\n",
      "#####--training model 66--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.2891e-03\n",
      "Epoch [20/100], Loss: 4.5106e-03\n",
      "Epoch [30/100], Loss: 4.2416e-03\n",
      "Epoch [40/100], Loss: 4.4918e-03\n",
      "Epoch [50/100], Loss: 5.1982e-03\n",
      "Epoch [60/100], Loss: 5.9348e-03\n",
      "Epoch [70/100], Loss: 6.4824e-03\n",
      "Epoch [80/100], Loss: 6.7924e-03\n",
      "Epoch [90/100], Loss: 6.8925e-03\n",
      "Epoch [100/100], Loss: 6.8399e-03\n",
      "#####--training model 67--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.5376e-02\n",
      "Epoch [20/100], Loss: 5.4182e-03\n",
      "Epoch [30/100], Loss: 5.6987e-03\n",
      "Epoch [40/100], Loss: 5.7395e-03\n",
      "Epoch [50/100], Loss: 5.8421e-03\n",
      "Epoch [60/100], Loss: 6.5567e-03\n",
      "Epoch [70/100], Loss: 6.9538e-03\n",
      "Epoch [80/100], Loss: 6.8902e-03\n",
      "Epoch [90/100], Loss: 6.6956e-03\n",
      "Epoch [100/100], Loss: 6.4439e-03\n",
      "#####--training model 68--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.7291e-02\n",
      "Epoch [20/100], Loss: 2.6447e-02\n",
      "Epoch [30/100], Loss: 1.3981e-02\n",
      "Epoch [40/100], Loss: 1.0970e-02\n",
      "Epoch [50/100], Loss: 1.0624e-02\n",
      "Epoch [60/100], Loss: 1.1322e-02\n",
      "Epoch [70/100], Loss: 1.2440e-02\n",
      "Epoch [80/100], Loss: 1.3868e-02\n",
      "Epoch [90/100], Loss: 1.4114e-02\n",
      "Epoch [100/100], Loss: 1.3461e-02\n",
      "#####--training model 69--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0427e-02\n",
      "Epoch [20/100], Loss: 2.5838e-03\n",
      "Epoch [30/100], Loss: 1.4314e-03\n",
      "Epoch [40/100], Loss: 1.1234e-03\n",
      "Epoch [50/100], Loss: 7.3037e-04\n",
      "Epoch [60/100], Loss: 3.8049e-04\n",
      "Epoch [70/100], Loss: 2.1661e-04\n",
      "Epoch [80/100], Loss: 1.5031e-04\n",
      "Epoch [90/100], Loss: 1.9668e-04\n",
      "Epoch [100/100], Loss: 2.0368e-04\n",
      "#####--training model 70--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5606e-03\n",
      "Epoch [20/100], Loss: 6.6952e-04\n",
      "Epoch [30/100], Loss: 4.8883e-04\n",
      "Epoch [40/100], Loss: 3.7863e-04\n",
      "Epoch [50/100], Loss: 2.9950e-04\n",
      "Epoch [60/100], Loss: 2.3917e-04\n",
      "Epoch [70/100], Loss: 1.9553e-04\n",
      "Epoch [80/100], Loss: 1.6665e-04\n",
      "Epoch [90/100], Loss: 1.4790e-04\n",
      "Epoch [100/100], Loss: 1.3590e-04\n",
      "#####--training model 71--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8129e-04\n",
      "Epoch [20/100], Loss: 2.8648e-04\n",
      "Epoch [30/100], Loss: 2.8447e-04\n",
      "Epoch [40/100], Loss: 1.0780e-04\n",
      "Epoch [50/100], Loss: 5.0767e-05\n",
      "Epoch [60/100], Loss: 2.6149e-05\n",
      "Epoch [70/100], Loss: 1.3980e-05\n",
      "Epoch [80/100], Loss: 9.7596e-06\n",
      "Epoch [90/100], Loss: 4.7384e-06\n",
      "Epoch [100/100], Loss: 1.6429e-05\n",
      "#####--training model 72--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.9742e-03\n",
      "Epoch [20/100], Loss: 9.7537e-03\n",
      "Epoch [30/100], Loss: 1.0033e-02\n",
      "Epoch [40/100], Loss: 1.0150e-02\n",
      "Epoch [50/100], Loss: 1.0197e-02\n",
      "Epoch [60/100], Loss: 1.0216e-02\n",
      "Epoch [70/100], Loss: 1.0226e-02\n",
      "Epoch [80/100], Loss: 1.0236e-02\n",
      "Epoch [90/100], Loss: 1.0247e-02\n",
      "Epoch [100/100], Loss: 1.0258e-02\n",
      "#####--training model 73--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0549e-02\n",
      "Epoch [20/100], Loss: 6.3070e-03\n",
      "Epoch [30/100], Loss: 4.8194e-03\n",
      "Epoch [40/100], Loss: 3.2955e-03\n",
      "Epoch [50/100], Loss: 2.3255e-03\n",
      "Epoch [60/100], Loss: 1.8162e-03\n",
      "Epoch [70/100], Loss: 1.5226e-03\n",
      "Epoch [80/100], Loss: 1.3447e-03\n",
      "Epoch [90/100], Loss: 1.2403e-03\n",
      "Epoch [100/100], Loss: 1.1775e-03\n",
      "#####--training model 74--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.3827e-04\n",
      "Epoch [20/100], Loss: 7.4176e-04\n",
      "Epoch [30/100], Loss: 7.4644e-04\n",
      "Epoch [40/100], Loss: 6.3771e-04\n",
      "Epoch [50/100], Loss: 5.5403e-04\n",
      "Epoch [60/100], Loss: 4.5646e-04\n",
      "Epoch [70/100], Loss: 2.9060e-04\n",
      "Epoch [80/100], Loss: 1.6260e-04\n",
      "Epoch [90/100], Loss: 1.2293e-04\n",
      "Epoch [100/100], Loss: 9.3638e-05\n",
      "#####--training model 75--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.5036e-05\n",
      "Epoch [20/100], Loss: 9.1780e-05\n",
      "Epoch [30/100], Loss: 1.4608e-04\n",
      "Epoch [40/100], Loss: 2.1739e-04\n",
      "Epoch [50/100], Loss: 2.7870e-04\n",
      "Epoch [60/100], Loss: 3.5127e-04\n",
      "Epoch [70/100], Loss: 4.5646e-04\n",
      "Epoch [80/100], Loss: 6.4770e-04\n",
      "Epoch [90/100], Loss: 9.4998e-04\n",
      "Epoch [100/100], Loss: 1.2879e-03\n",
      "#####--training model 76--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0417e-03\n",
      "Epoch [20/100], Loss: 2.2470e-03\n",
      "Epoch [30/100], Loss: 1.5451e-03\n",
      "Epoch [40/100], Loss: 1.1450e-03\n",
      "Epoch [50/100], Loss: 9.2712e-04\n",
      "Epoch [60/100], Loss: 7.8520e-04\n",
      "Epoch [70/100], Loss: 6.9816e-04\n",
      "Epoch [80/100], Loss: 6.4579e-04\n",
      "Epoch [90/100], Loss: 6.1077e-04\n",
      "Epoch [100/100], Loss: 5.8494e-04\n",
      "#####--training model 77--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6589e-03\n",
      "Epoch [20/100], Loss: 9.0264e-04\n",
      "Epoch [30/100], Loss: 5.2091e-04\n",
      "Epoch [40/100], Loss: 3.1298e-04\n",
      "Epoch [50/100], Loss: 2.3368e-04\n",
      "Epoch [60/100], Loss: 2.0357e-04\n",
      "Epoch [70/100], Loss: 1.8265e-04\n",
      "Epoch [80/100], Loss: 1.5377e-04\n",
      "Epoch [90/100], Loss: 1.3955e-04\n",
      "Epoch [100/100], Loss: 1.2999e-04\n",
      "#####--training model 78--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2644e-04\n",
      "Epoch [20/100], Loss: 4.6649e-05\n",
      "Epoch [30/100], Loss: 2.4444e-05\n",
      "Epoch [40/100], Loss: 1.4809e-05\n",
      "Epoch [50/100], Loss: 9.7096e-06\n",
      "Epoch [60/100], Loss: 6.6852e-06\n",
      "Epoch [70/100], Loss: 4.7544e-06\n",
      "Epoch [80/100], Loss: 3.4581e-06\n",
      "Epoch [90/100], Loss: 2.5558e-06\n",
      "Epoch [100/100], Loss: 1.9112e-06\n",
      "#####--training model 79--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.9519e-03\n",
      "Epoch [20/100], Loss: 1.7074e-03\n",
      "Epoch [30/100], Loss: 1.2338e-03\n",
      "Epoch [40/100], Loss: 8.0118e-04\n",
      "Epoch [50/100], Loss: 5.5301e-04\n",
      "Epoch [60/100], Loss: 4.0075e-04\n",
      "Epoch [70/100], Loss: 3.1700e-04\n",
      "Epoch [80/100], Loss: 2.7341e-04\n",
      "Epoch [90/100], Loss: 2.5109e-04\n",
      "Epoch [100/100], Loss: 2.3764e-04\n",
      "#####--training model 80--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3733e-04\n",
      "Epoch [20/100], Loss: 1.2925e-04\n",
      "Epoch [30/100], Loss: 4.4718e-05\n",
      "Epoch [40/100], Loss: 5.4124e-05\n",
      "Epoch [50/100], Loss: 4.0937e-05\n",
      "Epoch [60/100], Loss: 2.6838e-05\n",
      "Epoch [70/100], Loss: 2.2902e-05\n",
      "Epoch [80/100], Loss: 2.1957e-05\n",
      "Epoch [90/100], Loss: 2.0923e-05\n",
      "Epoch [100/100], Loss: 2.0421e-05\n",
      "#####--training model 81--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4382e-04\n",
      "Epoch [20/100], Loss: 1.3642e-04\n",
      "Epoch [30/100], Loss: 1.0778e-04\n",
      "Epoch [40/100], Loss: 9.7898e-05\n",
      "Epoch [50/100], Loss: 9.5178e-05\n",
      "Epoch [60/100], Loss: 1.0031e-04\n",
      "Epoch [70/100], Loss: 1.0327e-04\n",
      "Epoch [80/100], Loss: 3.2084e-05\n",
      "Epoch [90/100], Loss: 2.0833e-05\n",
      "Epoch [100/100], Loss: 1.6272e-05\n",
      "#####--training model 82--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3590e-03\n",
      "Epoch [20/100], Loss: 1.7250e-03\n",
      "Epoch [30/100], Loss: 1.2583e-03\n",
      "Epoch [40/100], Loss: 8.1033e-04\n",
      "Epoch [50/100], Loss: 5.9746e-04\n",
      "Epoch [60/100], Loss: 5.0521e-04\n",
      "Epoch [70/100], Loss: 4.2376e-04\n",
      "Epoch [80/100], Loss: 3.6073e-04\n",
      "Epoch [90/100], Loss: 3.2177e-04\n",
      "Epoch [100/100], Loss: 3.0046e-04\n",
      "#####--training model 83--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.8041e-03\n",
      "Epoch [20/100], Loss: 5.8931e-03\n",
      "Epoch [30/100], Loss: 4.8094e-03\n",
      "Epoch [40/100], Loss: 4.0083e-03\n",
      "Epoch [50/100], Loss: 3.2447e-03\n",
      "Epoch [60/100], Loss: 2.7012e-03\n",
      "Epoch [70/100], Loss: 2.4850e-03\n",
      "Epoch [80/100], Loss: 2.4363e-03\n",
      "Epoch [90/100], Loss: 2.4503e-03\n",
      "Epoch [100/100], Loss: 2.4754e-03\n",
      "#####--training model 84--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.3104e-03\n",
      "Epoch [20/100], Loss: 2.7733e-03\n",
      "Epoch [30/100], Loss: 2.5742e-03\n",
      "Epoch [40/100], Loss: 2.0772e-03\n",
      "Epoch [50/100], Loss: 1.5531e-03\n",
      "Epoch [60/100], Loss: 1.2356e-03\n",
      "Epoch [70/100], Loss: 1.0598e-03\n",
      "Epoch [80/100], Loss: 9.3303e-04\n",
      "Epoch [90/100], Loss: 8.3789e-04\n",
      "Epoch [100/100], Loss: 7.8096e-04\n",
      "#####--training model 85--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.4459e-03\n",
      "Epoch [20/100], Loss: 2.6735e-03\n",
      "Epoch [30/100], Loss: 1.9791e-03\n",
      "Epoch [40/100], Loss: 1.7689e-03\n",
      "Epoch [50/100], Loss: 1.6864e-03\n",
      "Epoch [60/100], Loss: 1.6434e-03\n",
      "Epoch [70/100], Loss: 1.3714e-03\n",
      "Epoch [80/100], Loss: 1.2039e-03\n",
      "Epoch [90/100], Loss: 1.2893e-03\n",
      "Epoch [100/100], Loss: 1.3971e-03\n",
      "#####--training model 86--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.6009e-03\n",
      "Epoch [20/100], Loss: 9.4430e-04\n",
      "Epoch [30/100], Loss: 3.7380e-04\n",
      "Epoch [40/100], Loss: 3.0614e-04\n",
      "Epoch [50/100], Loss: 4.0494e-04\n",
      "Epoch [60/100], Loss: 4.8366e-04\n",
      "Epoch [70/100], Loss: 5.4873e-04\n",
      "Epoch [80/100], Loss: 6.2158e-04\n",
      "Epoch [90/100], Loss: 7.1276e-04\n",
      "Epoch [100/100], Loss: 8.0709e-04\n",
      "#####--training model 87--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.8962e-03\n",
      "Epoch [20/100], Loss: 3.6678e-03\n",
      "Epoch [30/100], Loss: 2.1419e-03\n",
      "Epoch [40/100], Loss: 1.2193e-03\n",
      "Epoch [50/100], Loss: 8.2724e-04\n",
      "Epoch [60/100], Loss: 6.8212e-04\n",
      "Epoch [70/100], Loss: 6.0718e-04\n",
      "Epoch [80/100], Loss: 5.6445e-04\n",
      "Epoch [90/100], Loss: 5.4053e-04\n",
      "Epoch [100/100], Loss: 5.3295e-04\n",
      "#####--training model 88--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.6583e-04\n",
      "Epoch [20/100], Loss: 6.8572e-04\n",
      "Epoch [30/100], Loss: 8.6742e-04\n",
      "Epoch [40/100], Loss: 7.3268e-04\n",
      "Epoch [50/100], Loss: 6.5262e-04\n",
      "Epoch [60/100], Loss: 6.5772e-04\n",
      "Epoch [70/100], Loss: 6.6131e-04\n",
      "Epoch [80/100], Loss: 6.5326e-04\n",
      "Epoch [90/100], Loss: 6.2623e-04\n",
      "Epoch [100/100], Loss: 5.7012e-04\n",
      "#####--training model 89--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0752e-03\n",
      "Epoch [20/100], Loss: 5.4201e-03\n",
      "Epoch [30/100], Loss: 8.0559e-03\n",
      "Epoch [40/100], Loss: 9.9597e-03\n",
      "Epoch [50/100], Loss: 1.1601e-02\n",
      "Epoch [60/100], Loss: 1.2794e-02\n",
      "Epoch [70/100], Loss: 1.3352e-02\n",
      "Epoch [80/100], Loss: 1.3415e-02\n",
      "Epoch [90/100], Loss: 1.3184e-02\n",
      "Epoch [100/100], Loss: 1.2793e-02\n",
      "#####--training model 90--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.9895e-04\n",
      "Epoch [20/100], Loss: 8.7863e-04\n",
      "Epoch [30/100], Loss: 6.4455e-04\n",
      "Epoch [40/100], Loss: 2.8454e-04\n",
      "Epoch [50/100], Loss: 1.0001e-04\n",
      "Epoch [60/100], Loss: 6.4577e-05\n",
      "Epoch [70/100], Loss: 4.9475e-05\n",
      "Epoch [80/100], Loss: 4.2631e-05\n",
      "Epoch [90/100], Loss: 3.9699e-05\n",
      "Epoch [100/100], Loss: 3.9730e-05\n",
      "#####--training model 91--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.2971e-05\n",
      "Epoch [20/100], Loss: 2.1287e-05\n",
      "Epoch [30/100], Loss: 1.4544e-05\n",
      "Epoch [40/100], Loss: 1.3498e-05\n",
      "Epoch [50/100], Loss: 1.3667e-05\n",
      "Epoch [60/100], Loss: 1.3978e-05\n",
      "Epoch [70/100], Loss: 1.4188e-05\n",
      "Epoch [80/100], Loss: 1.4288e-05\n",
      "Epoch [90/100], Loss: 1.4326e-05\n",
      "Epoch [100/100], Loss: 1.4342e-05\n",
      "#####--training model 92--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.4410e-03\n",
      "Epoch [20/100], Loss: 1.2985e-03\n",
      "Epoch [30/100], Loss: 7.3853e-04\n",
      "Epoch [40/100], Loss: 5.1102e-04\n",
      "Epoch [50/100], Loss: 4.0117e-04\n",
      "Epoch [60/100], Loss: 3.4491e-04\n",
      "Epoch [70/100], Loss: 3.2022e-04\n",
      "Epoch [80/100], Loss: 3.1041e-04\n",
      "Epoch [90/100], Loss: 2.8901e-04\n",
      "Epoch [100/100], Loss: 2.6492e-04\n",
      "#####--training model 93--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3002e-04\n",
      "Epoch [20/100], Loss: 2.2175e-04\n",
      "Epoch [30/100], Loss: 1.5017e-04\n",
      "Epoch [40/100], Loss: 1.0236e-04\n",
      "Epoch [50/100], Loss: 9.2457e-05\n",
      "Epoch [60/100], Loss: 9.1052e-05\n",
      "Epoch [70/100], Loss: 8.9215e-05\n",
      "Epoch [80/100], Loss: 8.6803e-05\n",
      "Epoch [90/100], Loss: 8.4229e-05\n",
      "Epoch [100/100], Loss: 8.1737e-05\n",
      "#####--training model 94--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9637e-04\n",
      "Epoch [20/100], Loss: 1.2054e-04\n",
      "Epoch [30/100], Loss: 1.0405e-04\n",
      "Epoch [40/100], Loss: 9.9663e-05\n",
      "Epoch [50/100], Loss: 9.7582e-05\n",
      "Epoch [60/100], Loss: 9.5687e-05\n",
      "Epoch [70/100], Loss: 9.3755e-05\n",
      "Epoch [80/100], Loss: 9.1864e-05\n",
      "Epoch [90/100], Loss: 8.9894e-05\n",
      "Epoch [100/100], Loss: 8.2337e-05\n",
      "#####--training model 95--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1331e-05\n",
      "Epoch [20/100], Loss: 1.1041e-04\n",
      "Epoch [30/100], Loss: 6.2250e-05\n",
      "Epoch [40/100], Loss: 1.5697e-05\n",
      "Epoch [50/100], Loss: 2.2740e-05\n",
      "Epoch [60/100], Loss: 2.1969e-05\n",
      "Epoch [70/100], Loss: 2.2352e-05\n",
      "Epoch [80/100], Loss: 2.5556e-05\n",
      "Epoch [90/100], Loss: 3.1211e-05\n",
      "Epoch [100/100], Loss: 3.8829e-05\n",
      "#####--training model 96--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1423e-04\n",
      "Epoch [20/100], Loss: 4.2960e-05\n",
      "Epoch [30/100], Loss: 2.2446e-05\n",
      "Epoch [40/100], Loss: 1.3548e-05\n",
      "Epoch [50/100], Loss: 8.8573e-06\n",
      "Epoch [60/100], Loss: 6.0842e-06\n",
      "Epoch [70/100], Loss: 4.3189e-06\n",
      "Epoch [80/100], Loss: 3.1365e-06\n",
      "Epoch [90/100], Loss: 2.3153e-06\n",
      "Epoch [100/100], Loss: 1.7295e-06\n",
      "#####--training model 97--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9730e-03\n",
      "Epoch [20/100], Loss: 3.0630e-03\n",
      "Epoch [30/100], Loss: 2.8333e-03\n",
      "Epoch [40/100], Loss: 1.5830e-03\n",
      "Epoch [50/100], Loss: 1.3110e-03\n",
      "Epoch [60/100], Loss: 1.1371e-03\n",
      "Epoch [70/100], Loss: 9.1083e-04\n",
      "Epoch [80/100], Loss: 4.7638e-04\n",
      "Epoch [90/100], Loss: 2.3298e-04\n",
      "Epoch [100/100], Loss: 1.6696e-04\n",
      "#####--training model 98--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6961e-03\n",
      "Epoch [20/100], Loss: 1.8018e-03\n",
      "Epoch [30/100], Loss: 2.0958e-03\n",
      "Epoch [40/100], Loss: 2.4085e-03\n",
      "Epoch [50/100], Loss: 2.6258e-03\n",
      "Epoch [60/100], Loss: 2.7373e-03\n",
      "Epoch [70/100], Loss: 2.7199e-03\n",
      "Epoch [80/100], Loss: 2.6602e-03\n",
      "Epoch [90/100], Loss: 2.6455e-03\n",
      "Epoch [100/100], Loss: 2.6706e-03\n",
      "#####--training model 99--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4638e-03\n",
      "Epoch [20/100], Loss: 7.2214e-04\n",
      "Epoch [30/100], Loss: 6.9775e-04\n",
      "Epoch [40/100], Loss: 7.5277e-04\n",
      "Epoch [50/100], Loss: 7.6638e-04\n",
      "Epoch [60/100], Loss: 7.2182e-04\n",
      "Epoch [70/100], Loss: 6.6576e-04\n",
      "Epoch [80/100], Loss: 6.2016e-04\n",
      "Epoch [90/100], Loss: 5.7667e-04\n",
      "Epoch [100/100], Loss: 5.3430e-04\n",
      "#####--training model 100--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3222e-04\n",
      "Epoch [20/100], Loss: 2.6127e-04\n",
      "Epoch [30/100], Loss: 2.8611e-04\n",
      "Epoch [40/100], Loss: 3.0872e-04\n",
      "Epoch [50/100], Loss: 3.2413e-04\n",
      "Epoch [60/100], Loss: 3.2914e-04\n",
      "Epoch [70/100], Loss: 3.3239e-04\n",
      "Epoch [80/100], Loss: 3.3637e-04\n",
      "Epoch [90/100], Loss: 3.4143e-04\n",
      "Epoch [100/100], Loss: 3.4730e-04\n",
      "#####--training model 101--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.7521e-03\n",
      "Epoch [20/100], Loss: 4.9562e-03\n",
      "Epoch [30/100], Loss: 3.9020e-03\n",
      "Epoch [40/100], Loss: 3.7763e-03\n",
      "Epoch [50/100], Loss: 2.9747e-03\n",
      "Epoch [60/100], Loss: 1.6841e-03\n",
      "Epoch [70/100], Loss: 7.5622e-04\n",
      "Epoch [80/100], Loss: 1.1192e-03\n",
      "Epoch [90/100], Loss: 1.2416e-03\n",
      "Epoch [100/100], Loss: 1.3096e-03\n",
      "#####--training model 102--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2390e-03\n",
      "Epoch [20/100], Loss: 9.7513e-04\n",
      "Epoch [30/100], Loss: 1.1528e-03\n",
      "Epoch [40/100], Loss: 1.4098e-03\n",
      "Epoch [50/100], Loss: 1.5398e-03\n",
      "Epoch [60/100], Loss: 1.6670e-03\n",
      "Epoch [70/100], Loss: 1.5992e-03\n",
      "Epoch [80/100], Loss: 1.5120e-03\n",
      "Epoch [90/100], Loss: 1.4538e-03\n",
      "Epoch [100/100], Loss: 1.4151e-03\n",
      "#####--training model 103--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9825e-04\n",
      "Epoch [20/100], Loss: 4.3263e-05\n",
      "Epoch [30/100], Loss: 2.5593e-05\n",
      "Epoch [40/100], Loss: 2.7428e-05\n",
      "Epoch [50/100], Loss: 2.8727e-05\n",
      "Epoch [60/100], Loss: 2.9834e-05\n",
      "Epoch [70/100], Loss: 3.0578e-05\n",
      "Epoch [80/100], Loss: 3.0536e-05\n",
      "Epoch [90/100], Loss: 2.9588e-05\n",
      "Epoch [100/100], Loss: 2.8404e-05\n",
      "#####--training model 104--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.6947e-03\n",
      "Epoch [20/100], Loss: 2.4758e-03\n",
      "Epoch [30/100], Loss: 2.1022e-03\n",
      "Epoch [40/100], Loss: 1.7629e-03\n",
      "Epoch [50/100], Loss: 1.5894e-03\n",
      "Epoch [60/100], Loss: 1.6176e-03\n",
      "Epoch [70/100], Loss: 1.7648e-03\n",
      "Epoch [80/100], Loss: 1.9145e-03\n",
      "Epoch [90/100], Loss: 2.0201e-03\n",
      "Epoch [100/100], Loss: 2.1033e-03\n",
      "#####--training model 105--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5556e-03\n",
      "Epoch [20/100], Loss: 1.5550e-03\n",
      "Epoch [30/100], Loss: 1.5529e-03\n",
      "Epoch [40/100], Loss: 1.5487e-03\n",
      "Epoch [50/100], Loss: 1.5635e-03\n",
      "Epoch [60/100], Loss: 1.5883e-03\n",
      "Epoch [70/100], Loss: 1.6149e-03\n",
      "Epoch [80/100], Loss: 1.6276e-03\n",
      "Epoch [90/100], Loss: 1.6454e-03\n",
      "Epoch [100/100], Loss: 1.6883e-03\n",
      "#####--training model 106--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8515e-03\n",
      "Epoch [20/100], Loss: 3.0025e-03\n",
      "Epoch [30/100], Loss: 1.5369e-03\n",
      "Epoch [40/100], Loss: 1.2733e-03\n",
      "Epoch [50/100], Loss: 1.1497e-03\n",
      "Epoch [60/100], Loss: 9.1845e-04\n",
      "Epoch [70/100], Loss: 7.6165e-04\n",
      "Epoch [80/100], Loss: 6.7160e-04\n",
      "Epoch [90/100], Loss: 6.1438e-04\n",
      "Epoch [100/100], Loss: 5.7035e-04\n",
      "#####--training model 107--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5859e-03\n",
      "Epoch [20/100], Loss: 2.9053e-03\n",
      "Epoch [30/100], Loss: 6.7129e-04\n",
      "Epoch [40/100], Loss: 2.9844e-04\n",
      "Epoch [50/100], Loss: 8.4969e-05\n",
      "Epoch [60/100], Loss: 2.4681e-05\n",
      "Epoch [70/100], Loss: 1.1208e-05\n",
      "Epoch [80/100], Loss: 9.0307e-06\n",
      "Epoch [90/100], Loss: 1.0150e-05\n",
      "Epoch [100/100], Loss: 1.1733e-05\n",
      "#####--training model 108--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2782e-05\n",
      "Epoch [20/100], Loss: 1.3266e-04\n",
      "Epoch [30/100], Loss: 1.3872e-04\n",
      "Epoch [40/100], Loss: 1.2135e-04\n",
      "Epoch [50/100], Loss: 1.0750e-04\n",
      "Epoch [60/100], Loss: 9.7174e-05\n",
      "Epoch [70/100], Loss: 8.5737e-05\n",
      "Epoch [80/100], Loss: 7.1081e-05\n",
      "Epoch [90/100], Loss: 5.6854e-05\n",
      "Epoch [100/100], Loss: 4.2850e-05\n",
      "#####--training model 109--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3066e-03\n",
      "Epoch [20/100], Loss: 3.0029e-03\n",
      "Epoch [30/100], Loss: 1.0861e-03\n",
      "Epoch [40/100], Loss: 7.8082e-04\n",
      "Epoch [50/100], Loss: 6.1181e-04\n",
      "Epoch [60/100], Loss: 4.8778e-04\n",
      "Epoch [70/100], Loss: 3.5491e-04\n",
      "Epoch [80/100], Loss: 3.0506e-04\n",
      "Epoch [90/100], Loss: 3.0174e-04\n",
      "Epoch [100/100], Loss: 3.1838e-04\n",
      "#####--training model 110--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2467e-03\n",
      "Epoch [20/100], Loss: 3.3953e-03\n",
      "Epoch [30/100], Loss: 2.2139e-03\n",
      "Epoch [40/100], Loss: 1.8239e-03\n",
      "Epoch [50/100], Loss: 1.3768e-03\n",
      "Epoch [60/100], Loss: 1.1190e-03\n",
      "Epoch [70/100], Loss: 9.6531e-04\n",
      "Epoch [80/100], Loss: 8.5814e-04\n",
      "Epoch [90/100], Loss: 7.7771e-04\n",
      "Epoch [100/100], Loss: 7.2110e-04\n",
      "#####--training model 111--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.8386e-03\n",
      "Epoch [20/100], Loss: 8.0110e-04\n",
      "Epoch [30/100], Loss: 1.1519e-03\n",
      "Epoch [40/100], Loss: 1.0142e-03\n",
      "Epoch [50/100], Loss: 8.2317e-04\n",
      "Epoch [60/100], Loss: 7.6827e-04\n",
      "Epoch [70/100], Loss: 8.4619e-04\n",
      "Epoch [80/100], Loss: 8.6021e-04\n",
      "Epoch [90/100], Loss: 8.2625e-04\n",
      "Epoch [100/100], Loss: 7.6377e-04\n",
      "#####--training model 112--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8912e-03\n",
      "Epoch [20/100], Loss: 4.2496e-03\n",
      "Epoch [30/100], Loss: 2.1810e-03\n",
      "Epoch [40/100], Loss: 1.4736e-03\n",
      "Epoch [50/100], Loss: 1.0156e-03\n",
      "Epoch [60/100], Loss: 8.1812e-04\n",
      "Epoch [70/100], Loss: 6.4159e-04\n",
      "Epoch [80/100], Loss: 4.5781e-04\n",
      "Epoch [90/100], Loss: 3.4343e-04\n",
      "Epoch [100/100], Loss: 2.9428e-04\n",
      "#####--training model 113--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.3184e-03\n",
      "Epoch [20/100], Loss: 2.8728e-03\n",
      "Epoch [30/100], Loss: 1.9148e-03\n",
      "Epoch [40/100], Loss: 1.4593e-03\n",
      "Epoch [50/100], Loss: 1.2117e-03\n",
      "Epoch [60/100], Loss: 1.1665e-03\n",
      "Epoch [70/100], Loss: 1.0899e-03\n",
      "Epoch [80/100], Loss: 1.0028e-03\n",
      "Epoch [90/100], Loss: 9.2372e-04\n",
      "Epoch [100/100], Loss: 8.6171e-04\n",
      "#####--training model 114--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4929e-04\n",
      "Epoch [20/100], Loss: 2.1353e-04\n",
      "Epoch [30/100], Loss: 1.8453e-04\n",
      "Epoch [40/100], Loss: 1.7877e-04\n",
      "Epoch [50/100], Loss: 1.7899e-04\n",
      "Epoch [60/100], Loss: 1.8190e-04\n",
      "Epoch [70/100], Loss: 1.9292e-04\n",
      "Epoch [80/100], Loss: 2.4404e-04\n",
      "Epoch [90/100], Loss: 1.8935e-04\n",
      "Epoch [100/100], Loss: 2.1487e-04\n",
      "#####--training model 115--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4310e-03\n",
      "Epoch [20/100], Loss: 6.9667e-04\n",
      "Epoch [30/100], Loss: 1.6422e-03\n",
      "Epoch [40/100], Loss: 1.0072e-03\n",
      "Epoch [50/100], Loss: 6.7516e-04\n",
      "Epoch [60/100], Loss: 7.0702e-04\n",
      "Epoch [70/100], Loss: 7.1202e-04\n",
      "Epoch [80/100], Loss: 7.1343e-04\n",
      "Epoch [90/100], Loss: 7.1785e-04\n",
      "Epoch [100/100], Loss: 7.2575e-04\n",
      "#####--training model 116--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2366e-04\n",
      "Epoch [20/100], Loss: 6.8132e-04\n",
      "Epoch [30/100], Loss: 1.1273e-03\n",
      "Epoch [40/100], Loss: 1.2961e-03\n",
      "Epoch [50/100], Loss: 1.3896e-03\n",
      "Epoch [60/100], Loss: 1.4413e-03\n",
      "Epoch [70/100], Loss: 1.4790e-03\n",
      "Epoch [80/100], Loss: 1.5132e-03\n",
      "Epoch [90/100], Loss: 1.5398e-03\n",
      "Epoch [100/100], Loss: 1.5558e-03\n",
      "#####--training model 117--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.8731e-04\n",
      "Epoch [20/100], Loss: 7.8712e-04\n",
      "Epoch [30/100], Loss: 4.1262e-04\n",
      "Epoch [40/100], Loss: 3.8863e-04\n",
      "Epoch [50/100], Loss: 3.5701e-04\n",
      "Epoch [60/100], Loss: 3.2427e-04\n",
      "Epoch [70/100], Loss: 2.8892e-04\n",
      "Epoch [80/100], Loss: 2.5189e-04\n",
      "Epoch [90/100], Loss: 2.1847e-04\n",
      "Epoch [100/100], Loss: 1.9589e-04\n",
      "#####--training model 118--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3068e-03\n",
      "Epoch [20/100], Loss: 2.5439e-03\n",
      "Epoch [30/100], Loss: 1.6977e-03\n",
      "Epoch [40/100], Loss: 1.0669e-03\n",
      "Epoch [50/100], Loss: 6.8155e-04\n",
      "Epoch [60/100], Loss: 4.5054e-04\n",
      "Epoch [70/100], Loss: 2.9912e-04\n",
      "Epoch [80/100], Loss: 2.1835e-04\n",
      "Epoch [90/100], Loss: 1.8518e-04\n",
      "Epoch [100/100], Loss: 1.6790e-04\n",
      "#####--training model 119--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.2427e-03\n",
      "Epoch [20/100], Loss: 6.5551e-03\n",
      "Epoch [30/100], Loss: 4.5681e-03\n",
      "Epoch [40/100], Loss: 3.6617e-03\n",
      "Epoch [50/100], Loss: 3.3937e-03\n",
      "Epoch [60/100], Loss: 3.3235e-03\n",
      "Epoch [70/100], Loss: 3.2667e-03\n",
      "Epoch [80/100], Loss: 3.1903e-03\n",
      "Epoch [90/100], Loss: 3.1023e-03\n",
      "Epoch [100/100], Loss: 3.0124e-03\n",
      "#####--training model 120--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1909e-04\n",
      "Epoch [20/100], Loss: 4.5975e-05\n",
      "Epoch [30/100], Loss: 2.4379e-05\n",
      "Epoch [40/100], Loss: 1.4850e-05\n",
      "Epoch [50/100], Loss: 9.7685e-06\n",
      "Epoch [60/100], Loss: 6.7408e-06\n",
      "Epoch [70/100], Loss: 4.8019e-06\n",
      "Epoch [80/100], Loss: 3.4970e-06\n",
      "Epoch [90/100], Loss: 2.5871e-06\n",
      "Epoch [100/100], Loss: 1.9360e-06\n",
      "#####--training model 121--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4215e-04\n",
      "Epoch [20/100], Loss: 3.4199e-04\n",
      "Epoch [30/100], Loss: 3.5399e-04\n",
      "Epoch [40/100], Loss: 3.7468e-04\n",
      "Epoch [50/100], Loss: 4.5188e-04\n",
      "Epoch [60/100], Loss: 2.2034e-04\n",
      "Epoch [70/100], Loss: 1.5232e-04\n",
      "Epoch [80/100], Loss: 7.7812e-05\n",
      "Epoch [90/100], Loss: 3.3187e-05\n",
      "Epoch [100/100], Loss: 1.2778e-05\n",
      "#####--training model 122--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0661e-03\n",
      "Epoch [20/100], Loss: 1.0589e-03\n",
      "Epoch [30/100], Loss: 1.0645e-03\n",
      "Epoch [40/100], Loss: 1.0748e-03\n",
      "Epoch [50/100], Loss: 1.0997e-03\n",
      "Epoch [60/100], Loss: 1.1335e-03\n",
      "Epoch [70/100], Loss: 8.4803e-04\n",
      "Epoch [80/100], Loss: 6.6147e-04\n",
      "Epoch [90/100], Loss: 5.2277e-04\n",
      "Epoch [100/100], Loss: 4.1855e-04\n",
      "#####--training model 123--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6216e-04\n",
      "Epoch [20/100], Loss: 1.0381e-04\n",
      "Epoch [30/100], Loss: 9.4645e-05\n",
      "Epoch [40/100], Loss: 9.4076e-05\n",
      "Epoch [50/100], Loss: 9.4786e-05\n",
      "Epoch [60/100], Loss: 9.5718e-05\n",
      "Epoch [70/100], Loss: 9.6820e-05\n",
      "Epoch [80/100], Loss: 9.8106e-05\n",
      "Epoch [90/100], Loss: 9.9599e-05\n",
      "Epoch [100/100], Loss: 1.0136e-04\n",
      "#####--training model 124--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.9989e-04\n",
      "Epoch [20/100], Loss: 9.7108e-04\n",
      "Epoch [30/100], Loss: 1.0432e-03\n",
      "Epoch [40/100], Loss: 1.0780e-03\n",
      "Epoch [50/100], Loss: 1.0951e-03\n",
      "Epoch [60/100], Loss: 1.1034e-03\n",
      "Epoch [70/100], Loss: 1.1080e-03\n",
      "Epoch [80/100], Loss: 1.1105e-03\n",
      "Epoch [90/100], Loss: 1.1104e-03\n",
      "Epoch [100/100], Loss: 1.1052e-03\n",
      "#####--training model 125--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5775e-04\n",
      "Epoch [20/100], Loss: 1.7704e-04\n",
      "Epoch [30/100], Loss: 1.6586e-04\n",
      "Epoch [40/100], Loss: 1.6410e-04\n",
      "Epoch [50/100], Loss: 1.6317e-04\n",
      "Epoch [60/100], Loss: 1.6216e-04\n",
      "Epoch [70/100], Loss: 1.6107e-04\n",
      "Epoch [80/100], Loss: 1.5983e-04\n",
      "Epoch [90/100], Loss: 1.5748e-04\n",
      "Epoch [100/100], Loss: 1.5218e-04\n",
      "#####--training model 126--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3358e-03\n",
      "Epoch [20/100], Loss: 1.2072e-03\n",
      "Epoch [30/100], Loss: 1.1259e-04\n",
      "Epoch [40/100], Loss: 3.4789e-05\n",
      "Epoch [50/100], Loss: 1.5673e-05\n",
      "Epoch [60/100], Loss: 1.3711e-05\n",
      "Epoch [70/100], Loss: 2.2079e-05\n",
      "Epoch [80/100], Loss: 3.4567e-05\n",
      "Epoch [90/100], Loss: 5.7440e-05\n",
      "Epoch [100/100], Loss: 8.6609e-05\n",
      "#####--training model 127--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4721e-04\n",
      "Epoch [20/100], Loss: 8.0882e-05\n",
      "Epoch [30/100], Loss: 3.6806e-05\n",
      "Epoch [40/100], Loss: 2.7116e-05\n",
      "Epoch [50/100], Loss: 2.4067e-05\n",
      "Epoch [60/100], Loss: 2.2025e-05\n",
      "Epoch [70/100], Loss: 2.7304e-05\n",
      "Epoch [80/100], Loss: 4.4139e-05\n",
      "Epoch [90/100], Loss: 7.3585e-05\n",
      "Epoch [100/100], Loss: 1.0940e-04\n",
      "#####--training model 128--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.1703e-03\n",
      "Epoch [20/100], Loss: 5.5834e-03\n",
      "Epoch [30/100], Loss: 5.7361e-03\n",
      "Epoch [40/100], Loss: 5.8002e-03\n",
      "Epoch [50/100], Loss: 5.8254e-03\n",
      "Epoch [60/100], Loss: 5.8340e-03\n",
      "Epoch [70/100], Loss: 5.8372e-03\n",
      "Epoch [80/100], Loss: 5.8396e-03\n",
      "Epoch [90/100], Loss: 5.8422e-03\n",
      "Epoch [100/100], Loss: 5.8453e-03\n",
      "#####--training model 129--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5992e-04\n",
      "Epoch [20/100], Loss: 2.2282e-04\n",
      "Epoch [30/100], Loss: 2.2258e-04\n",
      "Epoch [40/100], Loss: 2.2444e-04\n",
      "Epoch [50/100], Loss: 2.2693e-04\n",
      "Epoch [60/100], Loss: 2.3067e-04\n",
      "Epoch [70/100], Loss: 2.3798e-04\n",
      "Epoch [80/100], Loss: 2.5889e-04\n",
      "Epoch [90/100], Loss: 3.5524e-04\n",
      "Epoch [100/100], Loss: 4.4512e-04\n",
      "#####--training model 130--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3502e-02\n",
      "Epoch [20/100], Loss: 1.3732e-02\n",
      "Epoch [30/100], Loss: 1.3732e-02\n",
      "Epoch [40/100], Loss: 1.3719e-02\n",
      "Epoch [50/100], Loss: 1.3690e-02\n",
      "Epoch [60/100], Loss: 1.3596e-02\n",
      "Epoch [70/100], Loss: 1.3338e-02\n",
      "Epoch [80/100], Loss: 1.2697e-02\n",
      "Epoch [90/100], Loss: 1.1694e-02\n",
      "Epoch [100/100], Loss: 1.1601e-02\n",
      "#####--training model 131--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.5904e-03\n",
      "Epoch [20/100], Loss: 4.4892e-03\n",
      "Epoch [30/100], Loss: 3.5628e-03\n",
      "Epoch [40/100], Loss: 2.8654e-03\n",
      "Epoch [50/100], Loss: 2.2448e-03\n",
      "Epoch [60/100], Loss: 1.7586e-03\n",
      "Epoch [70/100], Loss: 1.4671e-03\n",
      "Epoch [80/100], Loss: 1.3906e-03\n",
      "Epoch [90/100], Loss: 1.4616e-03\n",
      "Epoch [100/100], Loss: 1.5745e-03\n",
      "#####--training model 132--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.8760e-04\n",
      "Epoch [20/100], Loss: 4.9353e-04\n",
      "Epoch [30/100], Loss: 5.0297e-04\n",
      "Epoch [40/100], Loss: 5.3004e-04\n",
      "Epoch [50/100], Loss: 4.5277e-04\n",
      "Epoch [60/100], Loss: 4.4546e-04\n",
      "Epoch [70/100], Loss: 4.4825e-04\n",
      "Epoch [80/100], Loss: 4.5603e-04\n",
      "Epoch [90/100], Loss: 4.7201e-04\n",
      "Epoch [100/100], Loss: 4.9050e-04\n",
      "#####--training model 133--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.0963e-04\n",
      "Epoch [20/100], Loss: 5.9081e-04\n",
      "Epoch [30/100], Loss: 5.9849e-04\n",
      "Epoch [40/100], Loss: 6.0600e-04\n",
      "Epoch [50/100], Loss: 6.1334e-04\n",
      "Epoch [60/100], Loss: 6.2061e-04\n",
      "Epoch [70/100], Loss: 6.2851e-04\n",
      "Epoch [80/100], Loss: 6.3878e-04\n",
      "Epoch [90/100], Loss: 6.5576e-04\n",
      "Epoch [100/100], Loss: 6.9853e-04\n",
      "#####--training model 134--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5946e-04\n",
      "Epoch [20/100], Loss: 1.3269e-04\n",
      "Epoch [30/100], Loss: 9.8703e-05\n",
      "Epoch [40/100], Loss: 8.6965e-05\n",
      "Epoch [50/100], Loss: 8.3307e-05\n",
      "Epoch [60/100], Loss: 8.2622e-05\n",
      "Epoch [70/100], Loss: 8.2808e-05\n",
      "Epoch [80/100], Loss: 8.3207e-05\n",
      "Epoch [90/100], Loss: 8.3696e-05\n",
      "Epoch [100/100], Loss: 8.4268e-05\n",
      "#####--training model 135--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.7539e-04\n",
      "Epoch [20/100], Loss: 4.7199e-04\n",
      "Epoch [30/100], Loss: 4.7558e-04\n",
      "Epoch [40/100], Loss: 4.8030e-04\n",
      "Epoch [50/100], Loss: 4.8803e-04\n",
      "Epoch [60/100], Loss: 5.0346e-04\n",
      "Epoch [70/100], Loss: 5.5127e-04\n",
      "Epoch [80/100], Loss: 4.1123e-04\n",
      "Epoch [90/100], Loss: 2.7719e-04\n",
      "Epoch [100/100], Loss: 2.3419e-04\n",
      "#####--training model 136--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.3839e-04\n",
      "Epoch [20/100], Loss: 9.9462e-04\n",
      "Epoch [30/100], Loss: 1.2880e-03\n",
      "Epoch [40/100], Loss: 9.6724e-04\n",
      "Epoch [50/100], Loss: 8.9737e-04\n",
      "Epoch [60/100], Loss: 8.8478e-04\n",
      "Epoch [70/100], Loss: 9.1509e-04\n",
      "Epoch [80/100], Loss: 9.4042e-04\n",
      "Epoch [90/100], Loss: 9.1852e-04\n",
      "Epoch [100/100], Loss: 8.5673e-04\n",
      "#####--training model 137--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5858e-02\n",
      "Epoch [20/100], Loss: 1.5871e-02\n",
      "Epoch [30/100], Loss: 1.5862e-02\n",
      "Epoch [40/100], Loss: 1.5824e-02\n",
      "Epoch [50/100], Loss: 1.5737e-02\n",
      "Epoch [60/100], Loss: 1.6881e-02\n",
      "Epoch [70/100], Loss: 1.7080e-02\n",
      "Epoch [80/100], Loss: 1.7251e-02\n",
      "Epoch [90/100], Loss: 1.7450e-02\n",
      "Epoch [100/100], Loss: 1.7613e-02\n",
      "#####--training model 138--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.5678e-04\n",
      "Epoch [20/100], Loss: 6.3803e-04\n",
      "Epoch [30/100], Loss: 6.0932e-04\n",
      "Epoch [40/100], Loss: 6.5257e-04\n",
      "Epoch [50/100], Loss: 8.0501e-04\n",
      "Epoch [60/100], Loss: 7.6224e-04\n",
      "Epoch [70/100], Loss: 7.4211e-04\n",
      "Epoch [80/100], Loss: 7.3419e-04\n",
      "Epoch [90/100], Loss: 7.3051e-04\n",
      "Epoch [100/100], Loss: 7.2796e-04\n",
      "#####--training model 139--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1129e-03\n",
      "Epoch [20/100], Loss: 1.1614e-03\n",
      "Epoch [30/100], Loss: 1.1955e-03\n",
      "Epoch [40/100], Loss: 1.2433e-03\n",
      "Epoch [50/100], Loss: 1.3856e-03\n",
      "Epoch [60/100], Loss: 6.9012e-04\n",
      "Epoch [70/100], Loss: 3.4713e-04\n",
      "Epoch [80/100], Loss: 1.8471e-04\n",
      "Epoch [90/100], Loss: 1.5531e-04\n",
      "Epoch [100/100], Loss: 1.5446e-04\n",
      "#####--training model 140--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3158e-03\n",
      "Epoch [20/100], Loss: 8.1738e-04\n",
      "Epoch [30/100], Loss: 8.1908e-04\n",
      "Epoch [40/100], Loss: 5.3678e-04\n",
      "Epoch [50/100], Loss: 3.4574e-04\n",
      "Epoch [60/100], Loss: 2.5816e-04\n",
      "Epoch [70/100], Loss: 2.1002e-04\n",
      "Epoch [80/100], Loss: 1.7596e-04\n",
      "Epoch [90/100], Loss: 1.5040e-04\n",
      "Epoch [100/100], Loss: 1.3115e-04\n",
      "#####--training model 141--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.4577e-03\n",
      "Epoch [20/100], Loss: 5.1937e-03\n",
      "Epoch [30/100], Loss: 5.6381e-03\n",
      "Epoch [40/100], Loss: 5.9121e-03\n",
      "Epoch [50/100], Loss: 5.9896e-03\n",
      "Epoch [60/100], Loss: 6.0337e-03\n",
      "Epoch [70/100], Loss: 6.0577e-03\n",
      "Epoch [80/100], Loss: 6.0330e-03\n",
      "Epoch [90/100], Loss: 5.8787e-03\n",
      "Epoch [100/100], Loss: 5.4892e-03\n",
      "#####--training model 142--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8246e-04\n",
      "Epoch [20/100], Loss: 3.0263e-04\n",
      "Epoch [30/100], Loss: 2.0601e-04\n",
      "Epoch [40/100], Loss: 1.9466e-04\n",
      "Epoch [50/100], Loss: 1.8307e-04\n",
      "Epoch [60/100], Loss: 1.5616e-04\n",
      "Epoch [70/100], Loss: 1.2865e-04\n",
      "Epoch [80/100], Loss: 1.1962e-04\n",
      "Epoch [90/100], Loss: 1.2060e-04\n",
      "Epoch [100/100], Loss: 1.2830e-04\n",
      "#####--training model 143--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.6748e-04\n",
      "Epoch [20/100], Loss: 8.8611e-04\n",
      "Epoch [30/100], Loss: 3.2237e-04\n",
      "Epoch [40/100], Loss: 1.5890e-04\n",
      "Epoch [50/100], Loss: 7.5844e-05\n",
      "Epoch [60/100], Loss: 3.5709e-05\n",
      "Epoch [70/100], Loss: 2.2077e-05\n",
      "Epoch [80/100], Loss: 1.5122e-05\n",
      "Epoch [90/100], Loss: 1.0570e-05\n",
      "Epoch [100/100], Loss: 7.5424e-06\n",
      "#####--training model 144--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7123e-03\n",
      "Epoch [20/100], Loss: 1.7199e-03\n",
      "Epoch [30/100], Loss: 1.7518e-03\n",
      "Epoch [40/100], Loss: 1.8010e-03\n",
      "Epoch [50/100], Loss: 1.8552e-03\n",
      "Epoch [60/100], Loss: 1.9020e-03\n",
      "Epoch [70/100], Loss: 1.9329e-03\n",
      "Epoch [80/100], Loss: 1.9483e-03\n",
      "Epoch [90/100], Loss: 1.9612e-03\n",
      "Epoch [100/100], Loss: 1.9774e-03\n",
      "#####--training model 145--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4964e-03\n",
      "Epoch [20/100], Loss: 1.4428e-03\n",
      "Epoch [30/100], Loss: 1.3129e-03\n",
      "Epoch [40/100], Loss: 1.0919e-03\n",
      "Epoch [50/100], Loss: 8.6560e-04\n",
      "Epoch [60/100], Loss: 7.2812e-04\n",
      "Epoch [70/100], Loss: 5.3618e-04\n",
      "Epoch [80/100], Loss: 3.5560e-04\n",
      "Epoch [90/100], Loss: 2.4080e-04\n",
      "Epoch [100/100], Loss: 1.8125e-04\n",
      "#####--training model 146--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4997e-02\n",
      "Epoch [20/100], Loss: 1.2429e-02\n",
      "Epoch [30/100], Loss: 9.9000e-03\n",
      "Epoch [40/100], Loss: 5.8493e-03\n",
      "Epoch [50/100], Loss: 2.9178e-03\n",
      "Epoch [60/100], Loss: 1.9187e-03\n",
      "Epoch [70/100], Loss: 1.5840e-03\n",
      "Epoch [80/100], Loss: 1.4131e-03\n",
      "Epoch [90/100], Loss: 1.2810e-03\n",
      "Epoch [100/100], Loss: 1.1416e-03\n",
      "#####--training model 147--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0750e-01\n",
      "Epoch [20/100], Loss: 1.0675e-01\n",
      "Epoch [30/100], Loss: 1.3513e-02\n",
      "Epoch [40/100], Loss: 1.0174e-02\n",
      "Epoch [50/100], Loss: 1.0491e-02\n",
      "Epoch [60/100], Loss: 1.1191e-02\n",
      "Epoch [70/100], Loss: 1.1558e-02\n",
      "Epoch [80/100], Loss: 1.1530e-02\n",
      "Epoch [90/100], Loss: 1.1355e-02\n",
      "Epoch [100/100], Loss: 1.1103e-02\n",
      "#####--training model 148--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4800e-04\n",
      "Epoch [20/100], Loss: 1.2853e-04\n",
      "Epoch [30/100], Loss: 1.0499e-04\n",
      "Epoch [40/100], Loss: 9.9465e-05\n",
      "Epoch [50/100], Loss: 9.8342e-05\n",
      "Epoch [60/100], Loss: 9.7947e-05\n",
      "Epoch [70/100], Loss: 9.7548e-05\n",
      "Epoch [80/100], Loss: 9.7049e-05\n",
      "Epoch [90/100], Loss: 9.6431e-05\n",
      "Epoch [100/100], Loss: 9.5689e-05\n",
      "#####--training model 149--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.1719e-03\n",
      "Epoch [20/100], Loss: 3.3863e-03\n",
      "Epoch [30/100], Loss: 3.6470e-03\n",
      "Epoch [40/100], Loss: 4.1367e-03\n",
      "Epoch [50/100], Loss: 4.4017e-03\n",
      "Epoch [60/100], Loss: 4.5013e-03\n",
      "Epoch [70/100], Loss: 4.5156e-03\n",
      "Epoch [80/100], Loss: 4.4793e-03\n",
      "Epoch [90/100], Loss: 4.4255e-03\n",
      "Epoch [100/100], Loss: 4.4179e-03\n",
      "#####--training model 150--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.0937e-03\n",
      "Epoch [20/100], Loss: 7.5687e-03\n",
      "Epoch [30/100], Loss: 9.4908e-03\n",
      "Epoch [40/100], Loss: 9.2631e-03\n",
      "Epoch [50/100], Loss: 8.4220e-03\n",
      "Epoch [60/100], Loss: 7.8845e-03\n",
      "Epoch [70/100], Loss: 7.5979e-03\n",
      "Epoch [80/100], Loss: 7.4041e-03\n",
      "Epoch [90/100], Loss: 7.2747e-03\n",
      "Epoch [100/100], Loss: 7.2065e-03\n",
      "#####--training model 151--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.7311e-04\n",
      "Epoch [20/100], Loss: 1.0321e-03\n",
      "Epoch [30/100], Loss: 1.2089e-03\n",
      "Epoch [40/100], Loss: 6.5908e-04\n",
      "Epoch [50/100], Loss: 5.2508e-04\n",
      "Epoch [60/100], Loss: 4.8468e-04\n",
      "Epoch [70/100], Loss: 4.5711e-04\n",
      "Epoch [80/100], Loss: 4.3845e-04\n",
      "Epoch [90/100], Loss: 4.2381e-04\n",
      "Epoch [100/100], Loss: 4.0876e-04\n",
      "#####--training model 152--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.3945e-04\n",
      "Epoch [20/100], Loss: 5.2392e-04\n",
      "Epoch [30/100], Loss: 5.0979e-04\n",
      "Epoch [40/100], Loss: 4.8781e-04\n",
      "Epoch [50/100], Loss: 4.3636e-04\n",
      "Epoch [60/100], Loss: 2.7007e-04\n",
      "Epoch [70/100], Loss: 1.8982e-04\n",
      "Epoch [80/100], Loss: 1.7736e-04\n",
      "Epoch [90/100], Loss: 1.8236e-04\n",
      "Epoch [100/100], Loss: 1.8891e-04\n",
      "#####--training model 153--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.9363e-04\n",
      "Epoch [20/100], Loss: 4.6998e-04\n",
      "Epoch [30/100], Loss: 8.5708e-05\n",
      "Epoch [40/100], Loss: 4.6366e-05\n",
      "Epoch [50/100], Loss: 1.7359e-05\n",
      "Epoch [60/100], Loss: 1.2087e-05\n",
      "Epoch [70/100], Loss: 1.2445e-05\n",
      "Epoch [80/100], Loss: 1.2836e-05\n",
      "Epoch [90/100], Loss: 1.3221e-05\n",
      "Epoch [100/100], Loss: 1.3548e-05\n",
      "#####--training model 154--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1395e-03\n",
      "Epoch [20/100], Loss: 2.2148e-03\n",
      "Epoch [30/100], Loss: 2.8597e-03\n",
      "Epoch [40/100], Loss: 2.8625e-03\n",
      "Epoch [50/100], Loss: 2.6840e-03\n",
      "Epoch [60/100], Loss: 2.3811e-03\n",
      "Epoch [70/100], Loss: 2.1444e-03\n",
      "Epoch [80/100], Loss: 2.0882e-03\n",
      "Epoch [90/100], Loss: 2.0987e-03\n",
      "Epoch [100/100], Loss: 2.0697e-03\n",
      "#####--training model 155--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.5411e-04\n",
      "Epoch [20/100], Loss: 1.5571e-03\n",
      "Epoch [30/100], Loss: 1.8258e-03\n",
      "Epoch [40/100], Loss: 1.1385e-03\n",
      "Epoch [50/100], Loss: 6.1896e-04\n",
      "Epoch [60/100], Loss: 4.3981e-04\n",
      "Epoch [70/100], Loss: 3.8478e-04\n",
      "Epoch [80/100], Loss: 3.6322e-04\n",
      "Epoch [90/100], Loss: 3.5219e-04\n",
      "Epoch [100/100], Loss: 3.4548e-04\n",
      "#####--training model 156--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0311e-03\n",
      "Epoch [20/100], Loss: 4.5926e-04\n",
      "Epoch [30/100], Loss: 1.5578e-04\n",
      "Epoch [40/100], Loss: 1.3441e-04\n",
      "Epoch [50/100], Loss: 1.2999e-04\n",
      "Epoch [60/100], Loss: 1.2514e-04\n",
      "Epoch [70/100], Loss: 1.2106e-04\n",
      "Epoch [80/100], Loss: 1.1750e-04\n",
      "Epoch [90/100], Loss: 1.1371e-04\n",
      "Epoch [100/100], Loss: 1.0924e-04\n",
      "#####--training model 157--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.8866e-05\n",
      "Epoch [20/100], Loss: 5.7161e-05\n",
      "Epoch [30/100], Loss: 5.7804e-05\n",
      "Epoch [40/100], Loss: 5.8664e-05\n",
      "Epoch [50/100], Loss: 6.0058e-05\n",
      "Epoch [60/100], Loss: 6.3434e-05\n",
      "Epoch [70/100], Loss: 6.8899e-05\n",
      "Epoch [80/100], Loss: 2.9432e-05\n",
      "Epoch [90/100], Loss: 4.2981e-05\n",
      "Epoch [100/100], Loss: 5.2277e-05\n",
      "#####--training model 158--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4637e-02\n",
      "Epoch [20/100], Loss: 8.2018e-03\n",
      "Epoch [30/100], Loss: 5.1844e-03\n",
      "Epoch [40/100], Loss: 3.0435e-03\n",
      "Epoch [50/100], Loss: 2.5653e-03\n",
      "Epoch [60/100], Loss: 2.9053e-03\n",
      "Epoch [70/100], Loss: 3.2938e-03\n",
      "Epoch [80/100], Loss: 3.5958e-03\n",
      "Epoch [90/100], Loss: 3.6786e-03\n",
      "Epoch [100/100], Loss: 3.6328e-03\n",
      "#####--training model 159--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.1170e-03\n",
      "Epoch [20/100], Loss: 3.0855e-03\n",
      "Epoch [30/100], Loss: 3.4766e-03\n",
      "Epoch [40/100], Loss: 3.7189e-03\n",
      "Epoch [50/100], Loss: 3.5771e-03\n",
      "Epoch [60/100], Loss: 3.3935e-03\n",
      "Epoch [70/100], Loss: 3.1630e-03\n",
      "Epoch [80/100], Loss: 2.9486e-03\n",
      "Epoch [90/100], Loss: 2.8332e-03\n",
      "Epoch [100/100], Loss: 2.7850e-03\n",
      "#####--training model 160--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1206e-03\n",
      "Epoch [20/100], Loss: 1.1719e-03\n",
      "Epoch [30/100], Loss: 1.2539e-03\n",
      "Epoch [40/100], Loss: 2.0690e-03\n",
      "Epoch [50/100], Loss: 1.3487e-03\n",
      "Epoch [60/100], Loss: 1.3588e-03\n",
      "Epoch [70/100], Loss: 1.4530e-03\n",
      "Epoch [80/100], Loss: 1.5300e-03\n",
      "Epoch [90/100], Loss: 1.5679e-03\n",
      "Epoch [100/100], Loss: 1.5520e-03\n",
      "#####--training model 161--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.1362e-02\n",
      "Epoch [20/100], Loss: 1.9213e-02\n",
      "Epoch [30/100], Loss: 1.3314e-02\n",
      "Epoch [40/100], Loss: 1.0241e-02\n",
      "Epoch [50/100], Loss: 5.2752e-03\n",
      "Epoch [60/100], Loss: 2.5120e-03\n",
      "Epoch [70/100], Loss: 1.8727e-03\n",
      "Epoch [80/100], Loss: 1.7568e-03\n",
      "Epoch [90/100], Loss: 1.7323e-03\n",
      "Epoch [100/100], Loss: 1.6728e-03\n",
      "#####--training model 162--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.2906e-04\n",
      "Epoch [20/100], Loss: 1.6774e-04\n",
      "Epoch [30/100], Loss: 1.0456e-04\n",
      "Epoch [40/100], Loss: 6.0794e-05\n",
      "Epoch [50/100], Loss: 2.6090e-05\n",
      "Epoch [60/100], Loss: 1.4654e-05\n",
      "Epoch [70/100], Loss: 1.3275e-05\n",
      "Epoch [80/100], Loss: 1.1739e-05\n",
      "Epoch [90/100], Loss: 1.0103e-05\n",
      "Epoch [100/100], Loss: 8.8971e-06\n",
      "#####--training model 163--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7901e-04\n",
      "Epoch [20/100], Loss: 8.9443e-05\n",
      "Epoch [30/100], Loss: 6.3166e-05\n",
      "Epoch [40/100], Loss: 5.2806e-05\n",
      "Epoch [50/100], Loss: 4.8491e-05\n",
      "Epoch [60/100], Loss: 4.6698e-05\n",
      "Epoch [70/100], Loss: 4.5797e-05\n",
      "Epoch [80/100], Loss: 4.5088e-05\n",
      "Epoch [90/100], Loss: 4.4379e-05\n",
      "Epoch [100/100], Loss: 4.3693e-05\n",
      "#####--training model 164--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.0279e-03\n",
      "Epoch [20/100], Loss: 9.3100e-03\n",
      "Epoch [30/100], Loss: 7.9555e-03\n",
      "Epoch [40/100], Loss: 6.6263e-03\n",
      "Epoch [50/100], Loss: 6.3850e-03\n",
      "Epoch [60/100], Loss: 6.5457e-03\n",
      "Epoch [70/100], Loss: 6.6709e-03\n",
      "Epoch [80/100], Loss: 6.7867e-03\n",
      "Epoch [90/100], Loss: 6.8837e-03\n",
      "Epoch [100/100], Loss: 6.9438e-03\n",
      "#####--training model 165--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.7111e-03\n",
      "Epoch [20/100], Loss: 1.2065e-03\n",
      "Epoch [30/100], Loss: 1.0954e-03\n",
      "Epoch [40/100], Loss: 1.0146e-03\n",
      "Epoch [50/100], Loss: 9.5964e-04\n",
      "Epoch [60/100], Loss: 9.3267e-04\n",
      "Epoch [70/100], Loss: 9.1925e-04\n",
      "Epoch [80/100], Loss: 9.0561e-04\n",
      "Epoch [90/100], Loss: 8.8056e-04\n",
      "Epoch [100/100], Loss: 8.6312e-04\n",
      "#####--training model 166--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0076e-04\n",
      "Epoch [20/100], Loss: 1.1842e-04\n",
      "Epoch [30/100], Loss: 9.7146e-05\n",
      "Epoch [40/100], Loss: 9.1577e-05\n",
      "Epoch [50/100], Loss: 9.4642e-05\n",
      "Epoch [60/100], Loss: 1.0618e-04\n",
      "Epoch [70/100], Loss: 1.3818e-04\n",
      "Epoch [80/100], Loss: 1.4951e-04\n",
      "Epoch [90/100], Loss: 9.0087e-05\n",
      "Epoch [100/100], Loss: 7.0433e-05\n",
      "#####--training model 167--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.3647e-04\n",
      "Epoch [20/100], Loss: 9.8651e-04\n",
      "Epoch [30/100], Loss: 7.7043e-04\n",
      "Epoch [40/100], Loss: 5.5399e-04\n",
      "Epoch [50/100], Loss: 4.5439e-04\n",
      "Epoch [60/100], Loss: 4.2495e-04\n",
      "Epoch [70/100], Loss: 4.5143e-04\n",
      "Epoch [80/100], Loss: 4.5764e-04\n",
      "Epoch [90/100], Loss: 4.3719e-04\n",
      "Epoch [100/100], Loss: 4.0391e-04\n",
      "#####--training model 168--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3764e-04\n",
      "Epoch [20/100], Loss: 4.9910e-05\n",
      "Epoch [30/100], Loss: 2.5720e-05\n",
      "Epoch [40/100], Loss: 1.5401e-05\n",
      "Epoch [50/100], Loss: 1.0009e-05\n",
      "Epoch [60/100], Loss: 6.8410e-06\n",
      "Epoch [70/100], Loss: 4.8336e-06\n",
      "Epoch [80/100], Loss: 3.4948e-06\n",
      "Epoch [90/100], Loss: 2.5690e-06\n",
      "Epoch [100/100], Loss: 1.9116e-06\n",
      "#####--training model 169--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1722e-04\n",
      "Epoch [20/100], Loss: 8.0551e-05\n",
      "Epoch [30/100], Loss: 4.2769e-04\n",
      "Epoch [40/100], Loss: 6.6434e-04\n",
      "Epoch [50/100], Loss: 6.1493e-04\n",
      "Epoch [60/100], Loss: 5.4348e-04\n",
      "Epoch [70/100], Loss: 4.8153e-04\n",
      "Epoch [80/100], Loss: 4.3438e-04\n",
      "Epoch [90/100], Loss: 3.9933e-04\n",
      "Epoch [100/100], Loss: 3.7240e-04\n",
      "#####--training model 170--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.8322e-05\n",
      "Epoch [20/100], Loss: 4.2822e-05\n",
      "Epoch [30/100], Loss: 3.4928e-05\n",
      "Epoch [40/100], Loss: 3.6651e-05\n",
      "Epoch [50/100], Loss: 7.5580e-04\n",
      "Epoch [60/100], Loss: 5.4611e-03\n",
      "Epoch [70/100], Loss: 4.4693e-03\n",
      "Epoch [80/100], Loss: 5.2270e-03\n",
      "Epoch [90/100], Loss: 3.5503e-03\n",
      "Epoch [100/100], Loss: 3.5453e-03\n",
      "#####--training model 171--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.1711e-04\n",
      "Epoch [20/100], Loss: 4.2700e-04\n",
      "Epoch [30/100], Loss: 3.7713e-04\n",
      "Epoch [40/100], Loss: 1.8654e-04\n",
      "Epoch [50/100], Loss: 1.0323e-04\n",
      "Epoch [60/100], Loss: 9.0181e-05\n",
      "Epoch [70/100], Loss: 8.5795e-05\n",
      "Epoch [80/100], Loss: 8.0113e-05\n",
      "Epoch [90/100], Loss: 7.4639e-05\n",
      "Epoch [100/100], Loss: 7.0968e-05\n",
      "#####--training model 172--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4689e-04\n",
      "Epoch [20/100], Loss: 1.1037e-05\n",
      "Epoch [30/100], Loss: 5.3876e-06\n",
      "Epoch [40/100], Loss: 1.8321e-05\n",
      "Epoch [50/100], Loss: 2.7303e-05\n",
      "Epoch [60/100], Loss: 3.9800e-05\n",
      "Epoch [70/100], Loss: 5.4828e-05\n",
      "Epoch [80/100], Loss: 6.7056e-05\n",
      "Epoch [90/100], Loss: 7.4092e-05\n",
      "Epoch [100/100], Loss: 7.6776e-05\n",
      "#####--training model 173--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0229e-03\n",
      "Epoch [20/100], Loss: 1.0344e-03\n",
      "Epoch [30/100], Loss: 1.0447e-03\n",
      "Epoch [40/100], Loss: 1.0511e-03\n",
      "Epoch [50/100], Loss: 6.0365e-04\n",
      "Epoch [60/100], Loss: 4.3540e-04\n",
      "Epoch [70/100], Loss: 2.5974e-04\n",
      "Epoch [80/100], Loss: 1.7757e-04\n",
      "Epoch [90/100], Loss: 1.3647e-04\n",
      "Epoch [100/100], Loss: 1.1611e-04\n",
      "#####--training model 174--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.6930e-04\n",
      "Epoch [20/100], Loss: 8.2894e-04\n",
      "Epoch [30/100], Loss: 1.2227e-03\n",
      "Epoch [40/100], Loss: 8.7938e-04\n",
      "Epoch [50/100], Loss: 6.5563e-04\n",
      "Epoch [60/100], Loss: 5.0369e-04\n",
      "Epoch [70/100], Loss: 4.2054e-04\n",
      "Epoch [80/100], Loss: 3.7740e-04\n",
      "Epoch [90/100], Loss: 3.5450e-04\n",
      "Epoch [100/100], Loss: 3.4110e-04\n",
      "#####--training model 175--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2434e-03\n",
      "Epoch [20/100], Loss: 1.2525e-03\n",
      "Epoch [30/100], Loss: 1.2846e-03\n",
      "Epoch [40/100], Loss: 1.3379e-03\n",
      "Epoch [50/100], Loss: 1.1823e-03\n",
      "Epoch [60/100], Loss: 1.0109e-03\n",
      "Epoch [70/100], Loss: 9.6886e-04\n",
      "Epoch [80/100], Loss: 9.3220e-04\n",
      "Epoch [90/100], Loss: 8.8266e-04\n",
      "Epoch [100/100], Loss: 8.1256e-04\n",
      "#####--training model 176--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4986e-03\n",
      "Epoch [20/100], Loss: 1.4352e-03\n",
      "Epoch [30/100], Loss: 5.4628e-04\n",
      "Epoch [40/100], Loss: 4.8132e-04\n",
      "Epoch [50/100], Loss: 3.8677e-04\n",
      "Epoch [60/100], Loss: 3.2299e-04\n",
      "Epoch [70/100], Loss: 2.7945e-04\n",
      "Epoch [80/100], Loss: 2.5330e-04\n",
      "Epoch [90/100], Loss: 2.3763e-04\n",
      "Epoch [100/100], Loss: 2.2518e-04\n",
      "#####--training model 177--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.6990e-05\n",
      "Epoch [20/100], Loss: 1.5154e-04\n",
      "Epoch [30/100], Loss: 1.6138e-04\n",
      "Epoch [40/100], Loss: 1.3472e-04\n",
      "Epoch [50/100], Loss: 9.6898e-05\n",
      "Epoch [60/100], Loss: 6.0471e-05\n",
      "Epoch [70/100], Loss: 3.1934e-05\n",
      "Epoch [80/100], Loss: 1.4334e-05\n",
      "Epoch [90/100], Loss: 5.9278e-06\n",
      "Epoch [100/100], Loss: 4.3433e-06\n",
      "#####--training model 178--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9352e-04\n",
      "Epoch [20/100], Loss: 2.9458e-04\n",
      "Epoch [30/100], Loss: 1.8032e-04\n",
      "Epoch [40/100], Loss: 7.3770e-05\n",
      "Epoch [50/100], Loss: 9.8654e-05\n",
      "Epoch [60/100], Loss: 4.1116e-05\n",
      "Epoch [70/100], Loss: 1.6468e-05\n",
      "Epoch [80/100], Loss: 6.2881e-06\n",
      "Epoch [90/100], Loss: 2.2898e-06\n",
      "Epoch [100/100], Loss: 1.2971e-06\n",
      "#####--training model 179--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.7570e-04\n",
      "Epoch [20/100], Loss: 2.4488e-04\n",
      "Epoch [30/100], Loss: 2.4704e-04\n",
      "Epoch [40/100], Loss: 2.5332e-04\n",
      "Epoch [50/100], Loss: 2.6832e-04\n",
      "Epoch [60/100], Loss: 2.9698e-04\n",
      "Epoch [70/100], Loss: 2.1585e-04\n",
      "Epoch [80/100], Loss: 2.5352e-04\n",
      "Epoch [90/100], Loss: 2.5761e-04\n",
      "Epoch [100/100], Loss: 2.5450e-04\n",
      "#####--training model 180--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3636e-03\n",
      "Epoch [20/100], Loss: 2.1941e-03\n",
      "Epoch [30/100], Loss: 2.7954e-03\n",
      "Epoch [40/100], Loss: 2.7670e-03\n",
      "Epoch [50/100], Loss: 2.9103e-03\n",
      "Epoch [60/100], Loss: 3.0870e-03\n",
      "Epoch [70/100], Loss: 3.3215e-03\n",
      "Epoch [80/100], Loss: 3.6072e-03\n",
      "Epoch [90/100], Loss: 3.9037e-03\n",
      "Epoch [100/100], Loss: 4.2148e-03\n",
      "#####--training model 181--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0412e-03\n",
      "Epoch [20/100], Loss: 1.0710e-03\n",
      "Epoch [30/100], Loss: 1.1379e-03\n",
      "Epoch [40/100], Loss: 1.3582e-03\n",
      "Epoch [50/100], Loss: 2.0096e-03\n",
      "Epoch [60/100], Loss: 2.4422e-03\n",
      "Epoch [70/100], Loss: 2.5443e-03\n",
      "Epoch [80/100], Loss: 2.5214e-03\n",
      "Epoch [90/100], Loss: 2.4267e-03\n",
      "Epoch [100/100], Loss: 2.4250e-03\n",
      "#####--training model 182--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7892e-02\n",
      "Epoch [20/100], Loss: 2.0131e-02\n",
      "Epoch [30/100], Loss: 2.5722e-02\n",
      "Epoch [40/100], Loss: 2.8811e-02\n",
      "Epoch [50/100], Loss: 2.9620e-02\n",
      "Epoch [60/100], Loss: 2.9538e-02\n",
      "Epoch [70/100], Loss: 2.9176e-02\n",
      "Epoch [80/100], Loss: 2.8768e-02\n",
      "Epoch [90/100], Loss: 2.8345e-02\n",
      "Epoch [100/100], Loss: 2.7889e-02\n",
      "#####--training model 183--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8575e-04\n",
      "Epoch [20/100], Loss: 1.9368e-04\n",
      "Epoch [30/100], Loss: 1.8257e-04\n",
      "Epoch [40/100], Loss: 1.8699e-04\n",
      "Epoch [50/100], Loss: 1.8860e-04\n",
      "Epoch [60/100], Loss: 2.0269e-04\n",
      "Epoch [70/100], Loss: 2.4443e-04\n",
      "Epoch [80/100], Loss: 2.2864e-04\n",
      "Epoch [90/100], Loss: 2.4850e-04\n",
      "Epoch [100/100], Loss: 2.7498e-04\n",
      "#####--training model 184--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.7123e-03\n",
      "Epoch [20/100], Loss: 5.4314e-05\n",
      "Epoch [30/100], Loss: 4.2624e-05\n",
      "Epoch [40/100], Loss: 1.9880e-04\n",
      "Epoch [50/100], Loss: 1.6357e-04\n",
      "Epoch [60/100], Loss: 1.5431e-04\n",
      "Epoch [70/100], Loss: 1.6244e-04\n",
      "Epoch [80/100], Loss: 1.7409e-04\n",
      "Epoch [90/100], Loss: 1.8593e-04\n",
      "Epoch [100/100], Loss: 1.9695e-04\n",
      "#####--training model 185--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.4955e-06\n",
      "Epoch [20/100], Loss: 6.2588e-06\n",
      "Epoch [30/100], Loss: 1.1530e-05\n",
      "Epoch [40/100], Loss: 1.7439e-05\n",
      "Epoch [50/100], Loss: 1.4586e-05\n",
      "Epoch [60/100], Loss: 1.6980e-05\n",
      "Epoch [70/100], Loss: 1.8625e-05\n",
      "Epoch [80/100], Loss: 1.8282e-05\n",
      "Epoch [90/100], Loss: 1.4949e-05\n",
      "Epoch [100/100], Loss: 1.2524e-05\n",
      "#####--training model 186--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.6811e-06\n",
      "Epoch [20/100], Loss: 7.0362e-06\n",
      "Epoch [30/100], Loss: 7.0435e-06\n",
      "Epoch [40/100], Loss: 7.0869e-06\n",
      "Epoch [50/100], Loss: 7.1543e-06\n",
      "Epoch [60/100], Loss: 7.2523e-06\n",
      "Epoch [70/100], Loss: 7.3975e-06\n",
      "Epoch [80/100], Loss: 7.7823e-06\n",
      "Epoch [90/100], Loss: 1.1660e-05\n",
      "Epoch [100/100], Loss: 1.7513e-05\n",
      "#####--training model 187--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9269e-02\n",
      "Epoch [20/100], Loss: 2.8337e-03\n",
      "Epoch [30/100], Loss: 1.0767e-03\n",
      "Epoch [40/100], Loss: 3.1138e-04\n",
      "Epoch [50/100], Loss: 2.0022e-04\n",
      "Epoch [60/100], Loss: 1.9525e-04\n",
      "Epoch [70/100], Loss: 2.0487e-04\n",
      "Epoch [80/100], Loss: 2.1525e-04\n",
      "Epoch [90/100], Loss: 2.2342e-04\n",
      "Epoch [100/100], Loss: 2.2843e-04\n",
      "#####--training model 188--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.6545e-03\n",
      "Epoch [20/100], Loss: 1.6818e-03\n",
      "Epoch [30/100], Loss: 1.4436e-03\n",
      "Epoch [40/100], Loss: 1.2549e-03\n",
      "Epoch [50/100], Loss: 1.1094e-03\n",
      "Epoch [60/100], Loss: 1.0465e-03\n",
      "Epoch [70/100], Loss: 1.0103e-03\n",
      "Epoch [80/100], Loss: 1.0032e-03\n",
      "Epoch [90/100], Loss: 1.0132e-03\n",
      "Epoch [100/100], Loss: 6.8769e-04\n",
      "#####--training model 189--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3652e-04\n",
      "Epoch [20/100], Loss: 9.5320e-05\n",
      "Epoch [30/100], Loss: 5.7932e-05\n",
      "Epoch [40/100], Loss: 4.2095e-05\n",
      "Epoch [50/100], Loss: 3.3945e-05\n",
      "Epoch [60/100], Loss: 2.9393e-05\n",
      "Epoch [70/100], Loss: 2.6821e-05\n",
      "Epoch [80/100], Loss: 2.5434e-05\n",
      "Epoch [90/100], Loss: 2.4762e-05\n",
      "Epoch [100/100], Loss: 2.4510e-05\n",
      "#####--training model 190--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9158e-04\n",
      "Epoch [20/100], Loss: 2.2179e-04\n",
      "Epoch [30/100], Loss: 3.2128e-04\n",
      "Epoch [40/100], Loss: 1.4349e-04\n",
      "Epoch [50/100], Loss: 7.4390e-05\n",
      "Epoch [60/100], Loss: 1.7521e-04\n",
      "Epoch [70/100], Loss: 3.8641e-04\n",
      "Epoch [80/100], Loss: 5.4057e-04\n",
      "Epoch [90/100], Loss: 6.2366e-04\n",
      "Epoch [100/100], Loss: 6.6957e-04\n",
      "#####--training model 191--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6508e-03\n",
      "Epoch [20/100], Loss: 9.6275e-04\n",
      "Epoch [30/100], Loss: 1.8099e-04\n",
      "Epoch [40/100], Loss: 1.9564e-04\n",
      "Epoch [50/100], Loss: 2.5716e-04\n",
      "Epoch [60/100], Loss: 3.0046e-04\n",
      "Epoch [70/100], Loss: 3.3299e-04\n",
      "Epoch [80/100], Loss: 3.5211e-04\n",
      "Epoch [90/100], Loss: 3.6659e-04\n",
      "Epoch [100/100], Loss: 3.7931e-04\n",
      "#####--training model 192--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.8078e-04\n",
      "Epoch [20/100], Loss: 1.8434e-04\n",
      "Epoch [30/100], Loss: 2.0299e-04\n",
      "Epoch [40/100], Loss: 2.3612e-04\n",
      "Epoch [50/100], Loss: 3.0272e-04\n",
      "Epoch [60/100], Loss: 5.1690e-04\n",
      "Epoch [70/100], Loss: 7.0300e-04\n",
      "Epoch [80/100], Loss: 7.3275e-04\n",
      "Epoch [90/100], Loss: 7.4742e-04\n",
      "Epoch [100/100], Loss: 7.5922e-04\n",
      "#####--training model 193--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.2202e-02\n",
      "Epoch [20/100], Loss: 6.2774e-02\n",
      "Epoch [30/100], Loss: 6.2899e-02\n",
      "Epoch [40/100], Loss: 6.2948e-02\n",
      "Epoch [50/100], Loss: 6.2589e-02\n",
      "Epoch [60/100], Loss: 5.4510e-02\n",
      "Epoch [70/100], Loss: 2.7003e-02\n",
      "Epoch [80/100], Loss: 2.4752e-02\n",
      "Epoch [90/100], Loss: 2.4567e-02\n",
      "Epoch [100/100], Loss: 2.8260e-02\n",
      "#####--training model 194--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8878e-03\n",
      "Epoch [20/100], Loss: 3.5843e-03\n",
      "Epoch [30/100], Loss: 2.9225e-03\n",
      "Epoch [40/100], Loss: 1.9058e-03\n",
      "Epoch [50/100], Loss: 1.4544e-03\n",
      "Epoch [60/100], Loss: 1.2087e-03\n",
      "Epoch [70/100], Loss: 1.0352e-03\n",
      "Epoch [80/100], Loss: 9.0529e-04\n",
      "Epoch [90/100], Loss: 8.0575e-04\n",
      "Epoch [100/100], Loss: 7.2251e-04\n",
      "#####--training model 195--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.2753e-07\n",
      "Epoch [20/100], Loss: 6.8545e-06\n",
      "Epoch [30/100], Loss: 1.1650e-05\n",
      "Epoch [40/100], Loss: 6.9623e-06\n",
      "Epoch [50/100], Loss: 1.3973e-05\n",
      "Epoch [60/100], Loss: 3.0161e-05\n",
      "Epoch [70/100], Loss: 4.4742e-05\n",
      "Epoch [80/100], Loss: 5.0673e-05\n",
      "Epoch [90/100], Loss: 5.2797e-05\n",
      "Epoch [100/100], Loss: 5.3611e-05\n",
      "#####--training model 196--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.1301e-03\n",
      "Epoch [20/100], Loss: 1.3797e-03\n",
      "Epoch [30/100], Loss: 7.8812e-04\n",
      "Epoch [40/100], Loss: 5.2237e-04\n",
      "Epoch [50/100], Loss: 4.1492e-04\n",
      "Epoch [60/100], Loss: 4.4810e-04\n",
      "Epoch [70/100], Loss: 4.1771e-04\n",
      "Epoch [80/100], Loss: 3.7632e-04\n",
      "Epoch [90/100], Loss: 3.3295e-04\n",
      "Epoch [100/100], Loss: 2.8900e-04\n",
      "#####--training model 197--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5805e-04\n",
      "Epoch [20/100], Loss: 2.0242e-04\n",
      "Epoch [30/100], Loss: 1.9878e-04\n",
      "Epoch [40/100], Loss: 2.0108e-04\n",
      "Epoch [50/100], Loss: 2.0450e-04\n",
      "Epoch [60/100], Loss: 2.1008e-04\n",
      "Epoch [70/100], Loss: 2.3218e-04\n",
      "Epoch [80/100], Loss: 2.3883e-04\n",
      "Epoch [90/100], Loss: 2.2270e-04\n",
      "Epoch [100/100], Loss: 2.1010e-04\n",
      "#####--training model 198--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.5495e-03\n",
      "Epoch [20/100], Loss: 4.8038e-03\n",
      "Epoch [30/100], Loss: 1.5734e-03\n",
      "Epoch [40/100], Loss: 1.0328e-03\n",
      "Epoch [50/100], Loss: 8.9399e-04\n",
      "Epoch [60/100], Loss: 7.9762e-04\n",
      "Epoch [70/100], Loss: 7.0850e-04\n",
      "Epoch [80/100], Loss: 6.2698e-04\n",
      "Epoch [90/100], Loss: 5.6756e-04\n",
      "Epoch [100/100], Loss: 5.3647e-04\n",
      "#####--training model 199--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.8921e-03\n",
      "Epoch [20/100], Loss: 7.5668e-03\n",
      "Epoch [30/100], Loss: 6.9439e-03\n",
      "Epoch [40/100], Loss: 2.5423e-03\n",
      "Epoch [50/100], Loss: 2.5919e-03\n",
      "Epoch [60/100], Loss: 1.6470e-03\n",
      "Epoch [70/100], Loss: 1.0035e-03\n",
      "Epoch [80/100], Loss: 8.9691e-04\n",
      "Epoch [90/100], Loss: 8.7578e-04\n",
      "Epoch [100/100], Loss: 8.6830e-04\n",
      "#####--training model 200--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5397e-03\n",
      "Epoch [20/100], Loss: 5.5708e-04\n",
      "Epoch [30/100], Loss: 5.2576e-04\n",
      "Epoch [40/100], Loss: 4.5435e-04\n",
      "Epoch [50/100], Loss: 3.5184e-04\n",
      "Epoch [60/100], Loss: 2.3313e-04\n",
      "Epoch [70/100], Loss: 1.2065e-04\n",
      "Epoch [80/100], Loss: 3.8115e-05\n",
      "Epoch [90/100], Loss: 1.4222e-06\n",
      "Epoch [100/100], Loss: 1.2792e-05\n",
      "#####--training model 201--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1479e-03\n",
      "Epoch [20/100], Loss: 7.6712e-04\n",
      "Epoch [30/100], Loss: 5.5321e-04\n",
      "Epoch [40/100], Loss: 3.6916e-04\n",
      "Epoch [50/100], Loss: 2.7193e-04\n",
      "Epoch [60/100], Loss: 2.1781e-04\n",
      "Epoch [70/100], Loss: 1.6653e-04\n",
      "Epoch [80/100], Loss: 1.3856e-04\n",
      "Epoch [90/100], Loss: 1.2254e-04\n",
      "Epoch [100/100], Loss: 1.1350e-04\n",
      "#####--training model 202--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.9451e-04\n",
      "Epoch [20/100], Loss: 7.6114e-04\n",
      "Epoch [30/100], Loss: 9.1320e-04\n",
      "Epoch [40/100], Loss: 1.2815e-03\n",
      "Epoch [50/100], Loss: 1.1741e-03\n",
      "Epoch [60/100], Loss: 9.9694e-04\n",
      "Epoch [70/100], Loss: 9.2303e-04\n",
      "Epoch [80/100], Loss: 9.0203e-04\n",
      "Epoch [90/100], Loss: 8.8403e-04\n",
      "Epoch [100/100], Loss: 8.5943e-04\n",
      "#####--training model 203--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0745e-02\n",
      "Epoch [20/100], Loss: 2.0732e-02\n",
      "Epoch [30/100], Loss: 1.9880e-02\n",
      "Epoch [40/100], Loss: 1.9287e-02\n",
      "Epoch [50/100], Loss: 1.8423e-02\n",
      "Epoch [60/100], Loss: 1.6959e-02\n",
      "Epoch [70/100], Loss: 1.5280e-02\n",
      "Epoch [80/100], Loss: 1.3803e-02\n",
      "Epoch [90/100], Loss: 1.2963e-02\n",
      "Epoch [100/100], Loss: 1.2597e-02\n",
      "#####--training model 204--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3916e-04\n",
      "Epoch [20/100], Loss: 3.0554e-04\n",
      "Epoch [30/100], Loss: 3.0283e-04\n",
      "Epoch [40/100], Loss: 3.0092e-04\n",
      "Epoch [50/100], Loss: 2.9857e-04\n",
      "Epoch [60/100], Loss: 2.9547e-04\n",
      "Epoch [70/100], Loss: 2.9102e-04\n",
      "Epoch [80/100], Loss: 2.8412e-04\n",
      "Epoch [90/100], Loss: 2.7008e-04\n",
      "Epoch [100/100], Loss: 2.3964e-04\n",
      "#####--training model 205--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.7669e-03\n",
      "Epoch [20/100], Loss: 5.9946e-03\n",
      "Epoch [30/100], Loss: 4.2662e-03\n",
      "Epoch [40/100], Loss: 3.6268e-03\n",
      "Epoch [50/100], Loss: 3.3916e-03\n",
      "Epoch [60/100], Loss: 3.2695e-03\n",
      "Epoch [70/100], Loss: 3.2045e-03\n",
      "Epoch [80/100], Loss: 3.1564e-03\n",
      "Epoch [90/100], Loss: 3.1088e-03\n",
      "Epoch [100/100], Loss: 3.0628e-03\n",
      "#####--training model 206--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9011e-04\n",
      "Epoch [20/100], Loss: 1.6250e-04\n",
      "Epoch [30/100], Loss: 1.3187e-04\n",
      "Epoch [40/100], Loss: 1.2346e-04\n",
      "Epoch [50/100], Loss: 1.2159e-04\n",
      "Epoch [60/100], Loss: 1.2120e-04\n",
      "Epoch [70/100], Loss: 1.2103e-04\n",
      "Epoch [80/100], Loss: 1.2097e-04\n",
      "Epoch [90/100], Loss: 1.2136e-04\n",
      "Epoch [100/100], Loss: 1.2396e-04\n",
      "#####--training model 207--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7979e-03\n",
      "Epoch [20/100], Loss: 2.9527e-03\n",
      "Epoch [30/100], Loss: 3.3643e-03\n",
      "Epoch [40/100], Loss: 3.1716e-03\n",
      "Epoch [50/100], Loss: 2.9730e-03\n",
      "Epoch [60/100], Loss: 2.8676e-03\n",
      "Epoch [70/100], Loss: 2.8056e-03\n",
      "Epoch [80/100], Loss: 2.7536e-03\n",
      "Epoch [90/100], Loss: 2.7108e-03\n",
      "Epoch [100/100], Loss: 2.6690e-03\n",
      "#####--training model 208--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3472e-02\n",
      "Epoch [20/100], Loss: 1.2826e-02\n",
      "Epoch [30/100], Loss: 9.6810e-03\n",
      "Epoch [40/100], Loss: 7.7773e-03\n",
      "Epoch [50/100], Loss: 7.0328e-03\n",
      "Epoch [60/100], Loss: 6.6725e-03\n",
      "Epoch [70/100], Loss: 6.3857e-03\n",
      "Epoch [80/100], Loss: 6.1113e-03\n",
      "Epoch [90/100], Loss: 5.8372e-03\n",
      "Epoch [100/100], Loss: 5.5640e-03\n",
      "#####--training model 209--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7735e-02\n",
      "Epoch [20/100], Loss: 1.3457e-02\n",
      "Epoch [30/100], Loss: 9.9652e-03\n",
      "Epoch [40/100], Loss: 7.9056e-03\n",
      "Epoch [50/100], Loss: 6.9696e-03\n",
      "Epoch [60/100], Loss: 6.4887e-03\n",
      "Epoch [70/100], Loss: 6.1904e-03\n",
      "Epoch [80/100], Loss: 6.0265e-03\n",
      "Epoch [90/100], Loss: 5.9733e-03\n",
      "Epoch [100/100], Loss: 5.9910e-03\n",
      "#####--training model 210--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.8557e-05\n",
      "Epoch [20/100], Loss: 3.8708e-05\n",
      "Epoch [30/100], Loss: 2.2769e-05\n",
      "Epoch [40/100], Loss: 1.5385e-05\n",
      "Epoch [50/100], Loss: 1.1294e-05\n",
      "Epoch [60/100], Loss: 8.7635e-06\n",
      "Epoch [70/100], Loss: 7.0895e-06\n",
      "Epoch [80/100], Loss: 5.9362e-06\n",
      "Epoch [90/100], Loss: 5.1247e-06\n",
      "Epoch [100/100], Loss: 4.5513e-06\n",
      "#####--training model 211--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.5859e-02\n",
      "Epoch [20/100], Loss: 2.1018e-03\n",
      "Epoch [30/100], Loss: 1.9718e-03\n",
      "Epoch [40/100], Loss: 1.8337e-03\n",
      "Epoch [50/100], Loss: 1.5982e-03\n",
      "Epoch [60/100], Loss: 6.3099e-04\n",
      "Epoch [70/100], Loss: 1.9806e-03\n",
      "Epoch [80/100], Loss: 1.7063e-03\n",
      "Epoch [90/100], Loss: 2.3336e-03\n",
      "Epoch [100/100], Loss: 2.0312e-03\n",
      "#####--training model 212--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1027e-03\n",
      "Epoch [20/100], Loss: 1.0841e-03\n",
      "Epoch [30/100], Loss: 6.9008e-04\n",
      "Epoch [40/100], Loss: 3.8826e-04\n",
      "Epoch [50/100], Loss: 2.6800e-04\n",
      "Epoch [60/100], Loss: 1.9704e-04\n",
      "Epoch [70/100], Loss: 1.3833e-04\n",
      "Epoch [80/100], Loss: 9.7552e-05\n",
      "Epoch [90/100], Loss: 8.1088e-05\n",
      "Epoch [100/100], Loss: 7.2013e-05\n",
      "#####--training model 213--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.1731e-03\n",
      "Epoch [20/100], Loss: 1.0686e-03\n",
      "Epoch [30/100], Loss: 5.4003e-04\n",
      "Epoch [40/100], Loss: 4.4881e-04\n",
      "Epoch [50/100], Loss: 3.7297e-04\n",
      "Epoch [60/100], Loss: 3.1223e-04\n",
      "Epoch [70/100], Loss: 2.7801e-04\n",
      "Epoch [80/100], Loss: 2.8002e-04\n",
      "Epoch [90/100], Loss: 2.6210e-04\n",
      "Epoch [100/100], Loss: 2.2410e-04\n",
      "#####--training model 214--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.2129e-02\n",
      "Epoch [20/100], Loss: 5.0441e-03\n",
      "Epoch [30/100], Loss: 3.5877e-03\n",
      "Epoch [40/100], Loss: 2.7272e-03\n",
      "Epoch [50/100], Loss: 1.6930e-03\n",
      "Epoch [60/100], Loss: 4.8217e-04\n",
      "Epoch [70/100], Loss: 1.7852e-04\n",
      "Epoch [80/100], Loss: 4.0717e-04\n",
      "Epoch [90/100], Loss: 4.7557e-04\n",
      "Epoch [100/100], Loss: 4.9675e-04\n",
      "#####--training model 215--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.6116e-02\n",
      "Epoch [20/100], Loss: 1.3570e-03\n",
      "Epoch [30/100], Loss: 6.8730e-04\n",
      "Epoch [40/100], Loss: 2.9712e-04\n",
      "Epoch [50/100], Loss: 2.6829e-04\n",
      "Epoch [60/100], Loss: 5.5563e-04\n",
      "Epoch [70/100], Loss: 4.0443e-04\n",
      "Epoch [80/100], Loss: 2.0446e-04\n",
      "Epoch [90/100], Loss: 1.2474e-04\n",
      "Epoch [100/100], Loss: 1.1773e-04\n",
      "#####--training model 216--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2829e-04\n",
      "Epoch [20/100], Loss: 4.4256e-05\n",
      "Epoch [30/100], Loss: 2.1191e-05\n",
      "Epoch [40/100], Loss: 1.2152e-05\n",
      "Epoch [50/100], Loss: 7.6852e-06\n",
      "Epoch [60/100], Loss: 5.1562e-06\n",
      "Epoch [70/100], Loss: 3.5971e-06\n",
      "Epoch [80/100], Loss: 2.5781e-06\n",
      "Epoch [90/100], Loss: 1.8836e-06\n",
      "Epoch [100/100], Loss: 1.3954e-06\n",
      "#####--training model 217--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.1767e-02\n",
      "Epoch [20/100], Loss: 3.0775e-03\n",
      "Epoch [30/100], Loss: 2.1699e-03\n",
      "Epoch [40/100], Loss: 1.7577e-03\n",
      "Epoch [50/100], Loss: 1.3719e-03\n",
      "Epoch [60/100], Loss: 9.9374e-04\n",
      "Epoch [70/100], Loss: 6.6926e-04\n",
      "Epoch [80/100], Loss: 4.2637e-04\n",
      "Epoch [90/100], Loss: 2.6996e-04\n",
      "Epoch [100/100], Loss: 2.0391e-04\n",
      "#####--training model 218--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7220e-04\n",
      "Epoch [20/100], Loss: 3.3870e-04\n",
      "Epoch [30/100], Loss: 5.1768e-04\n",
      "Epoch [40/100], Loss: 5.9279e-04\n",
      "Epoch [50/100], Loss: 5.9004e-04\n",
      "Epoch [60/100], Loss: 5.6093e-04\n",
      "Epoch [70/100], Loss: 5.3953e-04\n",
      "Epoch [80/100], Loss: 5.3757e-04\n",
      "Epoch [90/100], Loss: 5.5374e-04\n",
      "Epoch [100/100], Loss: 5.8353e-04\n",
      "#####--training model 219--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5118e-04\n",
      "Epoch [20/100], Loss: 5.6303e-05\n",
      "Epoch [30/100], Loss: 2.9967e-05\n",
      "Epoch [40/100], Loss: 1.8577e-05\n",
      "Epoch [50/100], Loss: 1.2531e-05\n",
      "Epoch [60/100], Loss: 8.9170e-06\n",
      "Epoch [70/100], Loss: 6.5840e-06\n",
      "Epoch [80/100], Loss: 4.9963e-06\n",
      "Epoch [90/100], Loss: 3.8738e-06\n",
      "Epoch [100/100], Loss: 3.0577e-06\n",
      "#####--training model 220--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8102e-03\n",
      "Epoch [20/100], Loss: 1.3718e-03\n",
      "Epoch [30/100], Loss: 1.3221e-03\n",
      "Epoch [40/100], Loss: 1.4440e-03\n",
      "Epoch [50/100], Loss: 1.7910e-03\n",
      "Epoch [60/100], Loss: 2.4189e-03\n",
      "Epoch [70/100], Loss: 3.0738e-03\n",
      "Epoch [80/100], Loss: 3.4582e-03\n",
      "Epoch [90/100], Loss: 3.5486e-03\n",
      "Epoch [100/100], Loss: 3.4417e-03\n",
      "#####--training model 221--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2353e-03\n",
      "Epoch [20/100], Loss: 2.8120e-03\n",
      "Epoch [30/100], Loss: 3.7537e-03\n",
      "Epoch [40/100], Loss: 3.2318e-03\n",
      "Epoch [50/100], Loss: 2.8349e-03\n",
      "Epoch [60/100], Loss: 2.5011e-03\n",
      "Epoch [70/100], Loss: 2.2504e-03\n",
      "Epoch [80/100], Loss: 2.1160e-03\n",
      "Epoch [90/100], Loss: 2.0316e-03\n",
      "Epoch [100/100], Loss: 1.9600e-03\n",
      "#####--training model 222--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8855e-03\n",
      "Epoch [20/100], Loss: 1.9231e-03\n",
      "Epoch [30/100], Loss: 1.8091e-03\n",
      "Epoch [40/100], Loss: 1.3132e-03\n",
      "Epoch [50/100], Loss: 9.1475e-04\n",
      "Epoch [60/100], Loss: 7.1238e-04\n",
      "Epoch [70/100], Loss: 5.6695e-04\n",
      "Epoch [80/100], Loss: 4.6127e-04\n",
      "Epoch [90/100], Loss: 3.9947e-04\n",
      "Epoch [100/100], Loss: 3.6293e-04\n",
      "#####--training model 223--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.8380e-02\n",
      "Epoch [20/100], Loss: 8.9744e-03\n",
      "Epoch [30/100], Loss: 5.1335e-03\n",
      "Epoch [40/100], Loss: 5.1843e-03\n",
      "Epoch [50/100], Loss: 5.4421e-03\n",
      "Epoch [60/100], Loss: 5.6518e-03\n",
      "Epoch [70/100], Loss: 5.7901e-03\n",
      "Epoch [80/100], Loss: 5.6834e-03\n",
      "Epoch [90/100], Loss: 5.5127e-03\n",
      "Epoch [100/100], Loss: 5.3682e-03\n",
      "#####--training model 224--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.0285e-02\n",
      "Epoch [20/100], Loss: 6.5986e-02\n",
      "Epoch [30/100], Loss: 7.7969e-02\n",
      "Epoch [40/100], Loss: 8.1268e-02\n",
      "Epoch [50/100], Loss: 8.3595e-02\n",
      "Epoch [60/100], Loss: 8.6519e-02\n",
      "Epoch [70/100], Loss: 8.4876e-02\n",
      "Epoch [80/100], Loss: 8.0266e-02\n",
      "Epoch [90/100], Loss: 7.2708e-02\n",
      "Epoch [100/100], Loss: 6.3237e-02\n",
      "#####--training model 225--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0309e-02\n",
      "Epoch [20/100], Loss: 6.0427e-03\n",
      "Epoch [30/100], Loss: 5.6164e-03\n",
      "Epoch [40/100], Loss: 4.8540e-03\n",
      "Epoch [50/100], Loss: 4.2386e-03\n",
      "Epoch [60/100], Loss: 3.7414e-03\n",
      "Epoch [70/100], Loss: 3.3663e-03\n",
      "Epoch [80/100], Loss: 3.0691e-03\n",
      "Epoch [90/100], Loss: 2.8260e-03\n",
      "Epoch [100/100], Loss: 2.6497e-03\n",
      "#####--training model 226--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4139e-04\n",
      "Epoch [20/100], Loss: 4.3118e-04\n",
      "Epoch [30/100], Loss: 1.8529e-03\n",
      "Epoch [40/100], Loss: 1.8500e-03\n",
      "Epoch [50/100], Loss: 1.2371e-03\n",
      "Epoch [60/100], Loss: 8.7240e-04\n",
      "Epoch [70/100], Loss: 7.2067e-04\n",
      "Epoch [80/100], Loss: 6.8197e-04\n",
      "Epoch [90/100], Loss: 6.9670e-04\n",
      "Epoch [100/100], Loss: 7.4269e-04\n",
      "#####--training model 227--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.5199e-03\n",
      "Epoch [20/100], Loss: 3.5838e-03\n",
      "Epoch [30/100], Loss: 4.7256e-03\n",
      "Epoch [40/100], Loss: 6.4294e-03\n",
      "Epoch [50/100], Loss: 6.5936e-03\n",
      "Epoch [60/100], Loss: 6.1519e-03\n",
      "Epoch [70/100], Loss: 5.7994e-03\n",
      "Epoch [80/100], Loss: 5.5633e-03\n",
      "Epoch [90/100], Loss: 5.4149e-03\n",
      "Epoch [100/100], Loss: 5.3306e-03\n",
      "#####--training model 228--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.8430e-03\n",
      "Epoch [20/100], Loss: 2.1987e-03\n",
      "Epoch [30/100], Loss: 1.3869e-03\n",
      "Epoch [40/100], Loss: 8.6871e-04\n",
      "Epoch [50/100], Loss: 7.2015e-04\n",
      "Epoch [60/100], Loss: 6.2575e-04\n",
      "Epoch [70/100], Loss: 5.2671e-04\n",
      "Epoch [80/100], Loss: 4.6761e-04\n",
      "Epoch [90/100], Loss: 4.2703e-04\n",
      "Epoch [100/100], Loss: 3.9283e-04\n",
      "#####--training model 229--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.7514e-05\n",
      "Epoch [20/100], Loss: 3.7962e-05\n",
      "Epoch [30/100], Loss: 2.1265e-05\n",
      "Epoch [40/100], Loss: 1.3954e-05\n",
      "Epoch [50/100], Loss: 1.0029e-05\n",
      "Epoch [60/100], Loss: 7.6612e-06\n",
      "Epoch [70/100], Loss: 6.1259e-06\n",
      "Epoch [80/100], Loss: 5.0848e-06\n",
      "Epoch [90/100], Loss: 4.3610e-06\n",
      "Epoch [100/100], Loss: 3.8539e-06\n",
      "#####--training model 230--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2507e-03\n",
      "Epoch [20/100], Loss: 1.2404e-03\n",
      "Epoch [30/100], Loss: 1.2873e-03\n",
      "Epoch [40/100], Loss: 1.8886e-03\n",
      "Epoch [50/100], Loss: 2.5109e-03\n",
      "Epoch [60/100], Loss: 3.0445e-03\n",
      "Epoch [70/100], Loss: 3.3293e-03\n",
      "Epoch [80/100], Loss: 3.4437e-03\n",
      "Epoch [90/100], Loss: 3.4749e-03\n",
      "Epoch [100/100], Loss: 3.5102e-03\n",
      "#####--training model 231--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6915e-04\n",
      "Epoch [20/100], Loss: 2.3244e-04\n",
      "Epoch [30/100], Loss: 1.8161e-04\n",
      "Epoch [40/100], Loss: 8.9596e-05\n",
      "Epoch [50/100], Loss: 5.6907e-05\n",
      "Epoch [60/100], Loss: 5.5670e-05\n",
      "Epoch [70/100], Loss: 6.0030e-05\n",
      "Epoch [80/100], Loss: 6.1495e-05\n",
      "Epoch [90/100], Loss: 5.9357e-05\n",
      "Epoch [100/100], Loss: 5.4854e-05\n",
      "#####--training model 232--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.1571e-03\n",
      "Epoch [20/100], Loss: 1.8520e-03\n",
      "Epoch [30/100], Loss: 1.3643e-03\n",
      "Epoch [40/100], Loss: 1.0799e-03\n",
      "Epoch [50/100], Loss: 8.9332e-04\n",
      "Epoch [60/100], Loss: 8.0171e-04\n",
      "Epoch [70/100], Loss: 7.6063e-04\n",
      "Epoch [80/100], Loss: 7.3736e-04\n",
      "Epoch [90/100], Loss: 7.2006e-04\n",
      "Epoch [100/100], Loss: 7.0435e-04\n",
      "#####--training model 233--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8661e-02\n",
      "Epoch [20/100], Loss: 2.3404e-02\n",
      "Epoch [30/100], Loss: 1.9426e-02\n",
      "Epoch [40/100], Loss: 1.6271e-02\n",
      "Epoch [50/100], Loss: 1.3835e-02\n",
      "Epoch [60/100], Loss: 1.2827e-02\n",
      "Epoch [70/100], Loss: 1.2375e-02\n",
      "Epoch [80/100], Loss: 1.2031e-02\n",
      "Epoch [90/100], Loss: 1.1663e-02\n",
      "Epoch [100/100], Loss: 1.1240e-02\n",
      "#####--training model 234--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2881e-02\n",
      "Epoch [20/100], Loss: 6.4703e-03\n",
      "Epoch [30/100], Loss: 5.4106e-03\n",
      "Epoch [40/100], Loss: 5.4412e-03\n",
      "Epoch [50/100], Loss: 5.6763e-03\n",
      "Epoch [60/100], Loss: 5.9915e-03\n",
      "Epoch [70/100], Loss: 6.2167e-03\n",
      "Epoch [80/100], Loss: 6.3090e-03\n",
      "Epoch [90/100], Loss: 6.3017e-03\n",
      "Epoch [100/100], Loss: 6.2384e-03\n",
      "#####--training model 235--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.0797e-04\n",
      "Epoch [20/100], Loss: 2.8851e-04\n",
      "Epoch [30/100], Loss: 1.6498e-04\n",
      "Epoch [40/100], Loss: 9.2821e-05\n",
      "Epoch [50/100], Loss: 5.2054e-05\n",
      "Epoch [60/100], Loss: 3.0693e-05\n",
      "Epoch [70/100], Loss: 2.0632e-05\n",
      "Epoch [80/100], Loss: 1.5723e-05\n",
      "Epoch [90/100], Loss: 1.3547e-05\n",
      "Epoch [100/100], Loss: 1.3013e-05\n",
      "#####--training model 236--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9650e-03\n",
      "Epoch [20/100], Loss: 2.9968e-03\n",
      "Epoch [30/100], Loss: 2.8104e-03\n",
      "Epoch [40/100], Loss: 2.9406e-03\n",
      "Epoch [50/100], Loss: 3.0462e-03\n",
      "Epoch [60/100], Loss: 3.1139e-03\n",
      "Epoch [70/100], Loss: 3.1499e-03\n",
      "Epoch [80/100], Loss: 3.1516e-03\n",
      "Epoch [90/100], Loss: 3.1428e-03\n",
      "Epoch [100/100], Loss: 3.1410e-03\n",
      "#####--training model 237--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6552e-03\n",
      "Epoch [20/100], Loss: 1.7342e-03\n",
      "Epoch [30/100], Loss: 1.8964e-03\n",
      "Epoch [40/100], Loss: 7.9761e-04\n",
      "Epoch [50/100], Loss: 6.0385e-04\n",
      "Epoch [60/100], Loss: 6.4167e-04\n",
      "Epoch [70/100], Loss: 6.3352e-04\n",
      "Epoch [80/100], Loss: 6.0191e-04\n",
      "Epoch [90/100], Loss: 5.8063e-04\n",
      "Epoch [100/100], Loss: 5.6258e-04\n",
      "#####--training model 238--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7043e-02\n",
      "Epoch [20/100], Loss: 1.6331e-02\n",
      "Epoch [30/100], Loss: 1.6784e-02\n",
      "Epoch [40/100], Loss: 1.9101e-02\n",
      "Epoch [50/100], Loss: 1.9553e-02\n",
      "Epoch [60/100], Loss: 2.0287e-02\n",
      "Epoch [70/100], Loss: 2.0944e-02\n",
      "Epoch [80/100], Loss: 2.1192e-02\n",
      "Epoch [90/100], Loss: 2.1406e-02\n",
      "Epoch [100/100], Loss: 2.1568e-02\n",
      "#####--training model 239--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.5511e-02\n",
      "Epoch [20/100], Loss: 3.9409e-02\n",
      "Epoch [30/100], Loss: 1.9431e-04\n",
      "Epoch [40/100], Loss: 8.1924e-04\n",
      "Epoch [50/100], Loss: 1.3503e-03\n",
      "Epoch [60/100], Loss: 1.4660e-03\n",
      "Epoch [70/100], Loss: 1.3545e-03\n",
      "Epoch [80/100], Loss: 1.1243e-03\n",
      "Epoch [90/100], Loss: 8.6935e-04\n",
      "Epoch [100/100], Loss: 6.7761e-04\n",
      "#####--training model 240--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3749e-03\n",
      "Epoch [20/100], Loss: 9.3770e-03\n",
      "Epoch [30/100], Loss: 6.0230e-03\n",
      "Epoch [40/100], Loss: 3.5931e-03\n",
      "Epoch [50/100], Loss: 2.2025e-03\n",
      "Epoch [60/100], Loss: 1.7324e-03\n",
      "Epoch [70/100], Loss: 1.6394e-03\n",
      "Epoch [80/100], Loss: 1.6592e-03\n",
      "Epoch [90/100], Loss: 1.6889e-03\n",
      "Epoch [100/100], Loss: 1.7035e-03\n",
      "#####--training model 241--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.3399e-05\n",
      "Epoch [20/100], Loss: 1.9095e-04\n",
      "Epoch [30/100], Loss: 1.4806e-04\n",
      "Epoch [40/100], Loss: 1.0001e-04\n",
      "Epoch [50/100], Loss: 9.1378e-05\n",
      "Epoch [60/100], Loss: 9.0255e-05\n",
      "Epoch [70/100], Loss: 9.2453e-05\n",
      "Epoch [80/100], Loss: 9.0910e-05\n",
      "Epoch [90/100], Loss: 8.3000e-05\n",
      "Epoch [100/100], Loss: 7.1859e-05\n",
      "#####--training model 242--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4617e-03\n",
      "Epoch [20/100], Loss: 2.3322e-03\n",
      "Epoch [30/100], Loss: 1.4727e-03\n",
      "Epoch [40/100], Loss: 1.3506e-03\n",
      "Epoch [50/100], Loss: 1.4514e-03\n",
      "Epoch [60/100], Loss: 1.8235e-03\n",
      "Epoch [70/100], Loss: 1.7796e-03\n",
      "Epoch [80/100], Loss: 1.7103e-03\n",
      "Epoch [90/100], Loss: 1.6515e-03\n",
      "Epoch [100/100], Loss: 1.5994e-03\n",
      "#####--training model 243--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.7752e-04\n",
      "Epoch [20/100], Loss: 2.8926e-04\n",
      "Epoch [30/100], Loss: 3.2080e-04\n",
      "Epoch [40/100], Loss: 4.9724e-04\n",
      "Epoch [50/100], Loss: 2.5612e-04\n",
      "Epoch [60/100], Loss: 1.9208e-04\n",
      "Epoch [70/100], Loss: 1.3618e-04\n",
      "Epoch [80/100], Loss: 9.0061e-05\n",
      "Epoch [90/100], Loss: 6.9101e-05\n",
      "Epoch [100/100], Loss: 8.8244e-05\n",
      "#####--training model 244--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.4589e-04\n",
      "Epoch [20/100], Loss: 9.6683e-04\n",
      "Epoch [30/100], Loss: 9.8871e-04\n",
      "Epoch [40/100], Loss: 1.0174e-03\n",
      "Epoch [50/100], Loss: 1.0050e-03\n",
      "Epoch [60/100], Loss: 9.5898e-04\n",
      "Epoch [70/100], Loss: 9.0014e-04\n",
      "Epoch [80/100], Loss: 8.5088e-04\n",
      "Epoch [90/100], Loss: 8.1421e-04\n",
      "Epoch [100/100], Loss: 7.8462e-04\n",
      "#####--training model 245--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.2662e-04\n",
      "Epoch [20/100], Loss: 4.0965e-04\n",
      "Epoch [30/100], Loss: 1.4654e-04\n",
      "Epoch [40/100], Loss: 1.0026e-04\n",
      "Epoch [50/100], Loss: 9.6755e-05\n",
      "Epoch [60/100], Loss: 1.2225e-04\n",
      "Epoch [70/100], Loss: 1.4105e-04\n",
      "Epoch [80/100], Loss: 1.5069e-04\n",
      "Epoch [90/100], Loss: 1.5458e-04\n",
      "Epoch [100/100], Loss: 1.5552e-04\n",
      "#####--training model 246--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0418e-04\n",
      "Epoch [20/100], Loss: 1.8706e-05\n",
      "Epoch [30/100], Loss: 2.6371e-05\n",
      "Epoch [40/100], Loss: 3.0913e-05\n",
      "Epoch [50/100], Loss: 2.1354e-05\n",
      "Epoch [60/100], Loss: 1.0150e-05\n",
      "Epoch [70/100], Loss: 7.7483e-06\n",
      "Epoch [80/100], Loss: 1.7853e-05\n",
      "Epoch [90/100], Loss: 4.6012e-05\n",
      "Epoch [100/100], Loss: 1.3539e-04\n",
      "#####--training model 247--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5596e-02\n",
      "Epoch [20/100], Loss: 8.2592e-04\n",
      "Epoch [30/100], Loss: 9.7086e-04\n",
      "Epoch [40/100], Loss: 8.4281e-04\n",
      "Epoch [50/100], Loss: 9.5212e-04\n",
      "Epoch [60/100], Loss: 1.1090e-03\n",
      "Epoch [70/100], Loss: 1.2356e-03\n",
      "Epoch [80/100], Loss: 1.3147e-03\n",
      "Epoch [90/100], Loss: 1.3563e-03\n",
      "Epoch [100/100], Loss: 1.3676e-03\n",
      "#####--training model 248--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.3886e-02\n",
      "Epoch [20/100], Loss: 4.1575e-02\n",
      "Epoch [30/100], Loss: 3.8816e-04\n",
      "Epoch [40/100], Loss: 1.6833e-04\n",
      "Epoch [50/100], Loss: 2.2960e-04\n",
      "Epoch [60/100], Loss: 2.8816e-04\n",
      "Epoch [70/100], Loss: 2.5113e-04\n",
      "Epoch [80/100], Loss: 1.6970e-04\n",
      "Epoch [90/100], Loss: 2.8620e-04\n",
      "Epoch [100/100], Loss: 4.3562e-04\n",
      "#####--training model 249--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.1648e-03\n",
      "Epoch [20/100], Loss: 5.1122e-03\n",
      "Epoch [30/100], Loss: 4.9629e-03\n",
      "Epoch [40/100], Loss: 5.4643e-03\n",
      "Epoch [50/100], Loss: 5.6874e-03\n",
      "Epoch [60/100], Loss: 5.8868e-03\n",
      "Epoch [70/100], Loss: 5.9938e-03\n",
      "Epoch [80/100], Loss: 6.0782e-03\n",
      "Epoch [90/100], Loss: 6.1568e-03\n",
      "Epoch [100/100], Loss: 6.2104e-03\n",
      "#####--training model 250--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8733e-03\n",
      "Epoch [20/100], Loss: 3.9885e-03\n",
      "Epoch [30/100], Loss: 1.4210e-03\n",
      "Epoch [40/100], Loss: 1.4135e-03\n",
      "Epoch [50/100], Loss: 1.4918e-03\n",
      "Epoch [60/100], Loss: 1.5569e-03\n",
      "Epoch [70/100], Loss: 1.6117e-03\n",
      "Epoch [80/100], Loss: 1.6239e-03\n",
      "Epoch [90/100], Loss: 1.6360e-03\n",
      "Epoch [100/100], Loss: 1.6610e-03\n",
      "#####--training model 251--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.8186e-04\n",
      "Epoch [20/100], Loss: 5.7119e-04\n",
      "Epoch [30/100], Loss: 5.8122e-04\n",
      "Epoch [40/100], Loss: 6.2363e-04\n",
      "Epoch [50/100], Loss: 6.3154e-04\n",
      "Epoch [60/100], Loss: 6.5328e-04\n",
      "Epoch [70/100], Loss: 6.8169e-04\n",
      "Epoch [80/100], Loss: 7.0865e-04\n",
      "Epoch [90/100], Loss: 7.3424e-04\n",
      "Epoch [100/100], Loss: 7.5696e-04\n",
      "#####--training model 252--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2167e-04\n",
      "Epoch [20/100], Loss: 1.2329e-04\n",
      "Epoch [30/100], Loss: 9.8445e-05\n",
      "Epoch [40/100], Loss: 9.1213e-05\n",
      "Epoch [50/100], Loss: 9.2026e-05\n",
      "Epoch [60/100], Loss: 9.6167e-05\n",
      "Epoch [70/100], Loss: 1.0225e-04\n",
      "Epoch [80/100], Loss: 1.0391e-04\n",
      "Epoch [90/100], Loss: 9.1638e-05\n",
      "Epoch [100/100], Loss: 4.7329e-05\n",
      "#####--training model 253--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8923e-03\n",
      "Epoch [20/100], Loss: 3.0743e-03\n",
      "Epoch [30/100], Loss: 2.7387e-03\n",
      "Epoch [40/100], Loss: 2.1778e-03\n",
      "Epoch [50/100], Loss: 1.7157e-03\n",
      "Epoch [60/100], Loss: 1.3794e-03\n",
      "Epoch [70/100], Loss: 1.1747e-03\n",
      "Epoch [80/100], Loss: 1.0748e-03\n",
      "Epoch [90/100], Loss: 1.0233e-03\n",
      "Epoch [100/100], Loss: 9.9247e-04\n",
      "#####--training model 254--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9112e-03\n",
      "Epoch [20/100], Loss: 2.2006e-03\n",
      "Epoch [30/100], Loss: 2.2271e-03\n",
      "Epoch [40/100], Loss: 2.2319e-03\n",
      "Epoch [50/100], Loss: 2.1143e-03\n",
      "Epoch [60/100], Loss: 1.9802e-03\n",
      "Epoch [70/100], Loss: 1.8757e-03\n",
      "Epoch [80/100], Loss: 1.8171e-03\n",
      "Epoch [90/100], Loss: 1.8061e-03\n",
      "Epoch [100/100], Loss: 1.8377e-03\n",
      "#####--training model 255--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.9559e-03\n",
      "Epoch [20/100], Loss: 3.7033e-03\n",
      "Epoch [30/100], Loss: 2.9042e-03\n",
      "Epoch [40/100], Loss: 2.3554e-03\n",
      "Epoch [50/100], Loss: 2.0246e-03\n",
      "Epoch [60/100], Loss: 1.6680e-03\n",
      "Epoch [70/100], Loss: 1.1201e-03\n",
      "Epoch [80/100], Loss: 7.9602e-04\n",
      "Epoch [90/100], Loss: 6.7045e-04\n",
      "Epoch [100/100], Loss: 5.7520e-04\n",
      "#####--training model 256--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.7224e-04\n",
      "Epoch [20/100], Loss: 5.6636e-04\n",
      "Epoch [30/100], Loss: 1.0875e-03\n",
      "Epoch [40/100], Loss: 1.1010e-03\n",
      "Epoch [50/100], Loss: 1.0372e-03\n",
      "Epoch [60/100], Loss: 1.0305e-03\n",
      "Epoch [70/100], Loss: 1.0450e-03\n",
      "Epoch [80/100], Loss: 1.0597e-03\n",
      "Epoch [90/100], Loss: 1.0678e-03\n",
      "Epoch [100/100], Loss: 1.0712e-03\n",
      "#####--training model 257--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.3190e-03\n",
      "Epoch [20/100], Loss: 5.0324e-03\n",
      "Epoch [30/100], Loss: 3.3590e-03\n",
      "Epoch [40/100], Loss: 2.5687e-03\n",
      "Epoch [50/100], Loss: 2.1658e-03\n",
      "Epoch [60/100], Loss: 1.5933e-03\n",
      "Epoch [70/100], Loss: 9.1785e-04\n",
      "Epoch [80/100], Loss: 5.3493e-04\n",
      "Epoch [90/100], Loss: 3.9296e-04\n",
      "Epoch [100/100], Loss: 3.2711e-04\n",
      "#####--training model 258--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.8484e-04\n",
      "Epoch [20/100], Loss: 6.7517e-04\n",
      "Epoch [30/100], Loss: 7.0556e-04\n",
      "Epoch [40/100], Loss: 4.7151e-04\n",
      "Epoch [50/100], Loss: 3.3405e-04\n",
      "Epoch [60/100], Loss: 2.4464e-04\n",
      "Epoch [70/100], Loss: 1.1147e-04\n",
      "Epoch [80/100], Loss: 7.4638e-05\n",
      "Epoch [90/100], Loss: 9.4180e-05\n",
      "Epoch [100/100], Loss: 1.1414e-04\n",
      "#####--training model 259--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4326e-02\n",
      "Epoch [20/100], Loss: 3.7540e-03\n",
      "Epoch [30/100], Loss: 3.3056e-03\n",
      "Epoch [40/100], Loss: 2.8612e-03\n",
      "Epoch [50/100], Loss: 2.7222e-03\n",
      "Epoch [60/100], Loss: 2.6619e-03\n",
      "Epoch [70/100], Loss: 2.6162e-03\n",
      "Epoch [80/100], Loss: 2.5873e-03\n",
      "Epoch [90/100], Loss: 2.5706e-03\n",
      "Epoch [100/100], Loss: 2.5607e-03\n",
      "#####--training model 260--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.2752e-03\n",
      "Epoch [20/100], Loss: 3.2213e-03\n",
      "Epoch [30/100], Loss: 1.6356e-03\n",
      "Epoch [40/100], Loss: 1.3550e-03\n",
      "Epoch [50/100], Loss: 1.3474e-03\n",
      "Epoch [60/100], Loss: 1.1985e-03\n",
      "Epoch [70/100], Loss: 1.0489e-03\n",
      "Epoch [80/100], Loss: 9.1837e-04\n",
      "Epoch [90/100], Loss: 8.0244e-04\n",
      "Epoch [100/100], Loss: 6.9268e-04\n",
      "#####--training model 261--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1623e-03\n",
      "Epoch [20/100], Loss: 8.9491e-05\n",
      "Epoch [30/100], Loss: 1.5374e-04\n",
      "Epoch [40/100], Loss: 2.8144e-04\n",
      "Epoch [50/100], Loss: 4.0974e-04\n",
      "Epoch [60/100], Loss: 4.6208e-04\n",
      "Epoch [70/100], Loss: 4.8042e-04\n",
      "Epoch [80/100], Loss: 4.8821e-04\n",
      "Epoch [90/100], Loss: 4.8752e-04\n",
      "Epoch [100/100], Loss: 4.8270e-04\n",
      "#####--training model 262--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.3771e-03\n",
      "Epoch [20/100], Loss: 7.9666e-03\n",
      "Epoch [30/100], Loss: 1.0935e-02\n",
      "Epoch [40/100], Loss: 9.3583e-03\n",
      "Epoch [50/100], Loss: 7.2417e-03\n",
      "Epoch [60/100], Loss: 4.9621e-03\n",
      "Epoch [70/100], Loss: 2.8892e-03\n",
      "Epoch [80/100], Loss: 1.4802e-03\n",
      "Epoch [90/100], Loss: 8.0057e-04\n",
      "Epoch [100/100], Loss: 5.3859e-04\n",
      "#####--training model 263--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.6632e-03\n",
      "Epoch [20/100], Loss: 7.0665e-03\n",
      "Epoch [30/100], Loss: 6.3885e-03\n",
      "Epoch [40/100], Loss: 5.0517e-03\n",
      "Epoch [50/100], Loss: 4.2896e-03\n",
      "Epoch [60/100], Loss: 3.8075e-03\n",
      "Epoch [70/100], Loss: 3.5122e-03\n",
      "Epoch [80/100], Loss: 3.3205e-03\n",
      "Epoch [90/100], Loss: 3.1751e-03\n",
      "Epoch [100/100], Loss: 3.0519e-03\n",
      "#####--training model 264--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6922e-04\n",
      "Epoch [20/100], Loss: 1.1089e-04\n",
      "Epoch [30/100], Loss: 3.3361e-05\n",
      "Epoch [40/100], Loss: 6.3465e-06\n",
      "Epoch [50/100], Loss: 3.1878e-06\n",
      "Epoch [60/100], Loss: 1.0793e-05\n",
      "Epoch [70/100], Loss: 1.7212e-05\n",
      "Epoch [80/100], Loss: 2.1343e-05\n",
      "Epoch [90/100], Loss: 2.3388e-05\n",
      "Epoch [100/100], Loss: 2.4262e-05\n",
      "#####--training model 265--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4383e-02\n",
      "Epoch [20/100], Loss: 1.8358e-02\n",
      "Epoch [30/100], Loss: 1.2378e-02\n",
      "Epoch [40/100], Loss: 8.5502e-03\n",
      "Epoch [50/100], Loss: 6.9490e-03\n",
      "Epoch [60/100], Loss: 6.6095e-03\n",
      "Epoch [70/100], Loss: 6.5602e-03\n",
      "Epoch [80/100], Loss: 6.5013e-03\n",
      "Epoch [90/100], Loss: 6.4455e-03\n",
      "Epoch [100/100], Loss: 6.3784e-03\n",
      "#####--training model 266--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6199e-06\n",
      "Epoch [20/100], Loss: 2.2011e-04\n",
      "Epoch [30/100], Loss: 7.4819e-04\n",
      "Epoch [40/100], Loss: 3.4905e-04\n",
      "Epoch [50/100], Loss: 2.6228e-04\n",
      "Epoch [60/100], Loss: 3.3997e-04\n",
      "Epoch [70/100], Loss: 5.3721e-04\n",
      "Epoch [80/100], Loss: 7.4960e-04\n",
      "Epoch [90/100], Loss: 7.8224e-04\n",
      "Epoch [100/100], Loss: 7.4401e-04\n",
      "#####--training model 267--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5187e-02\n",
      "Epoch [20/100], Loss: 2.6297e-02\n",
      "Epoch [30/100], Loss: 2.7965e-02\n",
      "Epoch [40/100], Loss: 2.8279e-02\n",
      "Epoch [50/100], Loss: 2.8049e-02\n",
      "Epoch [60/100], Loss: 2.8005e-02\n",
      "Epoch [70/100], Loss: 2.7988e-02\n",
      "Epoch [80/100], Loss: 2.7969e-02\n",
      "Epoch [90/100], Loss: 2.7940e-02\n",
      "Epoch [100/100], Loss: 2.7930e-02\n",
      "#####--training model 268--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5420e-03\n",
      "Epoch [20/100], Loss: 7.9633e-03\n",
      "Epoch [30/100], Loss: 6.4667e-03\n",
      "Epoch [40/100], Loss: 4.8047e-03\n",
      "Epoch [50/100], Loss: 4.1105e-03\n",
      "Epoch [60/100], Loss: 4.0320e-03\n",
      "Epoch [70/100], Loss: 4.0780e-03\n",
      "Epoch [80/100], Loss: 4.1130e-03\n",
      "Epoch [90/100], Loss: 4.1235e-03\n",
      "Epoch [100/100], Loss: 4.1227e-03\n",
      "#####--training model 269--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6103e-03\n",
      "Epoch [20/100], Loss: 1.3019e-03\n",
      "Epoch [30/100], Loss: 8.3907e-04\n",
      "Epoch [40/100], Loss: 5.1183e-04\n",
      "Epoch [50/100], Loss: 3.0744e-04\n",
      "Epoch [60/100], Loss: 1.7547e-04\n",
      "Epoch [70/100], Loss: 9.4892e-05\n",
      "Epoch [80/100], Loss: 5.7327e-05\n",
      "Epoch [90/100], Loss: 4.2848e-05\n",
      "Epoch [100/100], Loss: 3.6359e-05\n",
      "#####--training model 270--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0655e-02\n",
      "Epoch [20/100], Loss: 2.4146e-05\n",
      "Epoch [30/100], Loss: 1.4270e-04\n",
      "Epoch [40/100], Loss: 1.8284e-04\n",
      "Epoch [50/100], Loss: 2.0017e-04\n",
      "Epoch [60/100], Loss: 1.8743e-04\n",
      "Epoch [70/100], Loss: 1.5011e-04\n",
      "Epoch [80/100], Loss: 1.2718e-04\n",
      "Epoch [90/100], Loss: 1.1627e-04\n",
      "Epoch [100/100], Loss: 1.0896e-04\n",
      "#####--training model 271--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.2979e-03\n",
      "Epoch [20/100], Loss: 1.6299e-03\n",
      "Epoch [30/100], Loss: 1.3538e-03\n",
      "Epoch [40/100], Loss: 1.1038e-03\n",
      "Epoch [50/100], Loss: 8.7822e-04\n",
      "Epoch [60/100], Loss: 7.4910e-04\n",
      "Epoch [70/100], Loss: 6.9534e-04\n",
      "Epoch [80/100], Loss: 6.7252e-04\n",
      "Epoch [90/100], Loss: 6.5719e-04\n",
      "Epoch [100/100], Loss: 6.4003e-04\n",
      "#####--training model 272--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2797e-02\n",
      "Epoch [20/100], Loss: 1.3482e-02\n",
      "Epoch [30/100], Loss: 1.2738e-02\n",
      "Epoch [40/100], Loss: 1.2891e-02\n",
      "Epoch [50/100], Loss: 1.3416e-02\n",
      "Epoch [60/100], Loss: 1.3721e-02\n",
      "Epoch [70/100], Loss: 1.3654e-02\n",
      "Epoch [80/100], Loss: 1.3615e-02\n",
      "Epoch [90/100], Loss: 1.3623e-02\n",
      "Epoch [100/100], Loss: 1.3625e-02\n",
      "#####--training model 273--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2979e-03\n",
      "Epoch [20/100], Loss: 1.4900e-03\n",
      "Epoch [30/100], Loss: 1.7505e-03\n",
      "Epoch [40/100], Loss: 1.9279e-03\n",
      "Epoch [50/100], Loss: 2.0251e-03\n",
      "Epoch [60/100], Loss: 2.0872e-03\n",
      "Epoch [70/100], Loss: 2.1371e-03\n",
      "Epoch [80/100], Loss: 2.1831e-03\n",
      "Epoch [90/100], Loss: 2.2252e-03\n",
      "Epoch [100/100], Loss: 2.2615e-03\n",
      "#####--training model 274--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.4514e-04\n",
      "Epoch [20/100], Loss: 3.2465e-03\n",
      "Epoch [30/100], Loss: 2.3984e-03\n",
      "Epoch [40/100], Loss: 9.9703e-04\n",
      "Epoch [50/100], Loss: 6.6798e-04\n",
      "Epoch [60/100], Loss: 6.5005e-04\n",
      "Epoch [70/100], Loss: 6.7957e-04\n",
      "Epoch [80/100], Loss: 7.1206e-04\n",
      "Epoch [90/100], Loss: 7.2389e-04\n",
      "Epoch [100/100], Loss: 7.2249e-04\n",
      "#####--training model 275--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.0414e-02\n",
      "Epoch [20/100], Loss: 3.0170e-02\n",
      "Epoch [30/100], Loss: 1.9350e-02\n",
      "Epoch [40/100], Loss: 9.9766e-03\n",
      "Epoch [50/100], Loss: 2.0257e-03\n",
      "Epoch [60/100], Loss: 1.3569e-04\n",
      "Epoch [70/100], Loss: 5.6482e-05\n",
      "Epoch [80/100], Loss: 1.8305e-04\n",
      "Epoch [90/100], Loss: 2.7459e-04\n",
      "Epoch [100/100], Loss: 2.1740e-04\n",
      "#####--training model 276--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0774e-02\n",
      "Epoch [20/100], Loss: 2.3883e-03\n",
      "Epoch [30/100], Loss: 2.3670e-03\n",
      "Epoch [40/100], Loss: 2.5268e-03\n",
      "Epoch [50/100], Loss: 2.4287e-03\n",
      "Epoch [60/100], Loss: 2.1246e-03\n",
      "Epoch [70/100], Loss: 1.9939e-03\n",
      "Epoch [80/100], Loss: 1.9631e-03\n",
      "Epoch [90/100], Loss: 1.9941e-03\n",
      "Epoch [100/100], Loss: 2.0566e-03\n",
      "#####--training model 277--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3406e-03\n",
      "Epoch [20/100], Loss: 2.6754e-04\n",
      "Epoch [30/100], Loss: 2.8308e-04\n",
      "Epoch [40/100], Loss: 2.6493e-04\n",
      "Epoch [50/100], Loss: 2.6698e-04\n",
      "Epoch [60/100], Loss: 2.8388e-04\n",
      "Epoch [70/100], Loss: 3.0368e-04\n",
      "Epoch [80/100], Loss: 3.1318e-04\n",
      "Epoch [90/100], Loss: 3.1566e-04\n",
      "Epoch [100/100], Loss: 3.2548e-04\n",
      "#####--training model 278--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.7165e-02\n",
      "Epoch [20/100], Loss: 4.3543e-02\n",
      "Epoch [30/100], Loss: 1.2531e-02\n",
      "Epoch [40/100], Loss: 1.6393e-03\n",
      "Epoch [50/100], Loss: 6.2941e-04\n",
      "Epoch [60/100], Loss: 6.0477e-04\n",
      "Epoch [70/100], Loss: 6.5692e-04\n",
      "Epoch [80/100], Loss: 6.2529e-04\n",
      "Epoch [90/100], Loss: 5.0538e-04\n",
      "Epoch [100/100], Loss: 3.6308e-04\n",
      "#####--training model 279--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2595e-04\n",
      "Epoch [20/100], Loss: 4.9802e-05\n",
      "Epoch [30/100], Loss: 2.7560e-05\n",
      "Epoch [40/100], Loss: 1.7663e-05\n",
      "Epoch [50/100], Loss: 1.2310e-05\n",
      "Epoch [60/100], Loss: 9.0640e-06\n",
      "Epoch [70/100], Loss: 6.9457e-06\n",
      "Epoch [80/100], Loss: 5.4923e-06\n",
      "Epoch [90/100], Loss: 4.4599e-06\n",
      "Epoch [100/100], Loss: 3.7092e-06\n",
      "#####--training model 280--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0817e-04\n",
      "Epoch [20/100], Loss: 8.5088e-05\n",
      "Epoch [30/100], Loss: 1.1903e-04\n",
      "Epoch [40/100], Loss: 2.0240e-04\n",
      "Epoch [50/100], Loss: 2.6966e-04\n",
      "Epoch [60/100], Loss: 2.9912e-04\n",
      "Epoch [70/100], Loss: 3.1810e-04\n",
      "Epoch [80/100], Loss: 3.3965e-04\n",
      "Epoch [90/100], Loss: 3.6112e-04\n",
      "Epoch [100/100], Loss: 3.7883e-04\n",
      "#####--training model 281--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.5008e-04\n",
      "Epoch [20/100], Loss: 5.1162e-04\n",
      "Epoch [30/100], Loss: 5.0175e-04\n",
      "Epoch [40/100], Loss: 4.9335e-04\n",
      "Epoch [50/100], Loss: 4.8591e-04\n",
      "Epoch [60/100], Loss: 4.7994e-04\n",
      "Epoch [70/100], Loss: 4.7586e-04\n",
      "Epoch [80/100], Loss: 4.7186e-04\n",
      "Epoch [90/100], Loss: 4.6934e-04\n",
      "Epoch [100/100], Loss: 4.5739e-04\n",
      "#####--training model 282--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5043e-02\n",
      "Epoch [20/100], Loss: 2.0139e-02\n",
      "Epoch [30/100], Loss: 2.0646e-02\n",
      "Epoch [40/100], Loss: 1.8070e-02\n",
      "Epoch [50/100], Loss: 1.5279e-02\n",
      "Epoch [60/100], Loss: 1.2969e-02\n",
      "Epoch [70/100], Loss: 1.1319e-02\n",
      "Epoch [80/100], Loss: 1.0267e-02\n",
      "Epoch [90/100], Loss: 9.6300e-03\n",
      "Epoch [100/100], Loss: 9.2227e-03\n",
      "#####--training model 283--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7571e-03\n",
      "Epoch [20/100], Loss: 1.7898e-03\n",
      "Epoch [30/100], Loss: 1.2299e-03\n",
      "Epoch [40/100], Loss: 1.0939e-03\n",
      "Epoch [50/100], Loss: 1.0607e-03\n",
      "Epoch [60/100], Loss: 1.0191e-03\n",
      "Epoch [70/100], Loss: 1.0019e-03\n",
      "Epoch [80/100], Loss: 9.8937e-04\n",
      "Epoch [90/100], Loss: 9.6453e-04\n",
      "Epoch [100/100], Loss: 9.2452e-04\n",
      "#####--training model 284--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3367e-03\n",
      "Epoch [20/100], Loss: 7.4878e-04\n",
      "Epoch [30/100], Loss: 2.7778e-04\n",
      "Epoch [40/100], Loss: 2.2565e-04\n",
      "Epoch [50/100], Loss: 2.0038e-04\n",
      "Epoch [60/100], Loss: 1.9063e-04\n",
      "Epoch [70/100], Loss: 2.3198e-04\n",
      "Epoch [80/100], Loss: 2.9140e-04\n",
      "Epoch [90/100], Loss: 3.0285e-04\n",
      "Epoch [100/100], Loss: 2.7453e-04\n",
      "#####--training model 285--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7837e-04\n",
      "Epoch [20/100], Loss: 6.5475e-05\n",
      "Epoch [30/100], Loss: 3.3922e-05\n",
      "Epoch [40/100], Loss: 2.0717e-05\n",
      "Epoch [50/100], Loss: 1.3942e-05\n",
      "Epoch [60/100], Loss: 9.9459e-06\n",
      "Epoch [70/100], Loss: 7.3741e-06\n",
      "Epoch [80/100], Loss: 5.6231e-06\n",
      "Epoch [90/100], Loss: 4.3881e-06\n",
      "Epoch [100/100], Loss: 3.4974e-06\n",
      "#####--training model 286--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.3233e-04\n",
      "Epoch [20/100], Loss: 2.3861e-04\n",
      "Epoch [30/100], Loss: 2.3004e-04\n",
      "Epoch [40/100], Loss: 2.3304e-04\n",
      "Epoch [50/100], Loss: 2.1241e-04\n",
      "Epoch [60/100], Loss: 1.8994e-04\n",
      "Epoch [70/100], Loss: 1.8121e-04\n",
      "Epoch [80/100], Loss: 1.8313e-04\n",
      "Epoch [90/100], Loss: 1.9113e-04\n",
      "Epoch [100/100], Loss: 2.0311e-04\n",
      "#####--training model 287--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.8304e-03\n",
      "Epoch [20/100], Loss: 1.7903e-03\n",
      "Epoch [30/100], Loss: 1.2797e-03\n",
      "Epoch [40/100], Loss: 1.0750e-03\n",
      "Epoch [50/100], Loss: 8.8476e-04\n",
      "Epoch [60/100], Loss: 7.2676e-04\n",
      "Epoch [70/100], Loss: 6.1800e-04\n",
      "Epoch [80/100], Loss: 5.5961e-04\n",
      "Epoch [90/100], Loss: 5.4278e-04\n",
      "Epoch [100/100], Loss: 5.5889e-04\n",
      "#####--training model 288--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4459e-04\n",
      "Epoch [20/100], Loss: 5.3616e-05\n",
      "Epoch [30/100], Loss: 2.8765e-05\n",
      "Epoch [40/100], Loss: 1.7946e-05\n",
      "Epoch [50/100], Loss: 1.2177e-05\n",
      "Epoch [60/100], Loss: 8.7174e-06\n",
      "Epoch [70/100], Loss: 6.4802e-06\n",
      "Epoch [80/100], Loss: 4.9555e-06\n",
      "Epoch [90/100], Loss: 3.8769e-06\n",
      "Epoch [100/100], Loss: 3.0927e-06\n",
      "#####--training model 289--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2383e-03\n",
      "Epoch [20/100], Loss: 9.1067e-04\n",
      "Epoch [30/100], Loss: 9.0535e-04\n",
      "Epoch [40/100], Loss: 9.3790e-04\n",
      "Epoch [50/100], Loss: 9.4644e-04\n",
      "Epoch [60/100], Loss: 9.5251e-04\n",
      "Epoch [70/100], Loss: 9.5918e-04\n",
      "Epoch [80/100], Loss: 9.6510e-04\n",
      "Epoch [90/100], Loss: 9.6930e-04\n",
      "Epoch [100/100], Loss: 9.7301e-04\n",
      "#####--training model 290--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.4422e-03\n",
      "Epoch [20/100], Loss: 1.5919e-03\n",
      "Epoch [30/100], Loss: 1.1647e-03\n",
      "Epoch [40/100], Loss: 7.4962e-04\n",
      "Epoch [50/100], Loss: 5.2794e-04\n",
      "Epoch [60/100], Loss: 4.6092e-04\n",
      "Epoch [70/100], Loss: 4.5632e-04\n",
      "Epoch [80/100], Loss: 4.6693e-04\n",
      "Epoch [90/100], Loss: 4.6989e-04\n",
      "Epoch [100/100], Loss: 4.6086e-04\n",
      "#####--training model 291--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.1178e-02\n",
      "Epoch [20/100], Loss: 1.3889e-02\n",
      "Epoch [30/100], Loss: 1.0772e-02\n",
      "Epoch [40/100], Loss: 8.7652e-03\n",
      "Epoch [50/100], Loss: 7.2189e-03\n",
      "Epoch [60/100], Loss: 6.2652e-03\n",
      "Epoch [70/100], Loss: 5.6392e-03\n",
      "Epoch [80/100], Loss: 5.0735e-03\n",
      "Epoch [90/100], Loss: 4.5266e-03\n",
      "Epoch [100/100], Loss: 4.0031e-03\n",
      "#####--training model 292--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.3892e-04\n",
      "Epoch [20/100], Loss: 3.3248e-04\n",
      "Epoch [30/100], Loss: 2.2054e-04\n",
      "Epoch [40/100], Loss: 1.9269e-04\n",
      "Epoch [50/100], Loss: 1.7728e-04\n",
      "Epoch [60/100], Loss: 1.9363e-04\n",
      "Epoch [70/100], Loss: 2.1651e-04\n",
      "Epoch [80/100], Loss: 2.2965e-04\n",
      "Epoch [90/100], Loss: 2.3787e-04\n",
      "Epoch [100/100], Loss: 2.3843e-04\n",
      "#####--training model 293--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9000e-03\n",
      "Epoch [20/100], Loss: 2.9598e-03\n",
      "Epoch [30/100], Loss: 3.2759e-03\n",
      "Epoch [40/100], Loss: 3.4519e-03\n",
      "Epoch [50/100], Loss: 3.5829e-03\n",
      "Epoch [60/100], Loss: 3.7360e-03\n",
      "Epoch [70/100], Loss: 3.8858e-03\n",
      "Epoch [80/100], Loss: 3.9798e-03\n",
      "Epoch [90/100], Loss: 4.0318e-03\n",
      "Epoch [100/100], Loss: 4.0692e-03\n",
      "#####--training model 294--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.4918e-03\n",
      "Epoch [20/100], Loss: 7.4586e-03\n",
      "Epoch [30/100], Loss: 9.6541e-03\n",
      "Epoch [40/100], Loss: 9.1474e-03\n",
      "Epoch [50/100], Loss: 6.3668e-03\n",
      "Epoch [60/100], Loss: 3.8275e-03\n",
      "Epoch [70/100], Loss: 3.1339e-03\n",
      "Epoch [80/100], Loss: 2.9787e-03\n",
      "Epoch [90/100], Loss: 2.7370e-03\n",
      "Epoch [100/100], Loss: 2.1729e-03\n",
      "#####--training model 295--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.0115e-03\n",
      "Epoch [20/100], Loss: 5.7188e-03\n",
      "Epoch [30/100], Loss: 5.4108e-03\n",
      "Epoch [40/100], Loss: 4.4076e-03\n",
      "Epoch [50/100], Loss: 3.5787e-03\n",
      "Epoch [60/100], Loss: 3.1139e-03\n",
      "Epoch [70/100], Loss: 2.9421e-03\n",
      "Epoch [80/100], Loss: 2.8651e-03\n",
      "Epoch [90/100], Loss: 2.7929e-03\n",
      "Epoch [100/100], Loss: 2.7172e-03\n",
      "#####--training model 296--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.0694e-03\n",
      "Epoch [20/100], Loss: 4.7511e-03\n",
      "Epoch [30/100], Loss: 2.6929e-03\n",
      "Epoch [40/100], Loss: 1.7352e-03\n",
      "Epoch [50/100], Loss: 1.3014e-03\n",
      "Epoch [60/100], Loss: 1.1817e-03\n",
      "Epoch [70/100], Loss: 1.2383e-03\n",
      "Epoch [80/100], Loss: 1.3472e-03\n",
      "Epoch [90/100], Loss: 1.4425e-03\n",
      "Epoch [100/100], Loss: 1.4972e-03\n",
      "#####--training model 297--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.5083e-04\n",
      "Epoch [20/100], Loss: 5.1614e-04\n",
      "Epoch [30/100], Loss: 4.7640e-04\n",
      "Epoch [40/100], Loss: 4.2520e-04\n",
      "Epoch [50/100], Loss: 4.5233e-04\n",
      "Epoch [60/100], Loss: 5.0477e-04\n",
      "Epoch [70/100], Loss: 5.4789e-04\n",
      "Epoch [80/100], Loss: 5.8590e-04\n",
      "Epoch [90/100], Loss: 6.2930e-04\n",
      "Epoch [100/100], Loss: 6.8445e-04\n",
      "#####--training model 298--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.8698e-04\n",
      "Epoch [20/100], Loss: 8.7604e-04\n",
      "Epoch [30/100], Loss: 9.1499e-04\n",
      "Epoch [40/100], Loss: 3.0025e-04\n",
      "Epoch [50/100], Loss: 1.8641e-04\n",
      "Epoch [60/100], Loss: 2.0930e-04\n",
      "Epoch [70/100], Loss: 2.2123e-04\n",
      "Epoch [80/100], Loss: 2.3022e-04\n",
      "Epoch [90/100], Loss: 2.3657e-04\n",
      "Epoch [100/100], Loss: 2.2494e-04\n",
      "#####--training model 299--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.5255e-04\n",
      "Epoch [20/100], Loss: 1.2271e-04\n",
      "Epoch [30/100], Loss: 1.5865e-04\n",
      "Epoch [40/100], Loss: 1.3819e-04\n",
      "Epoch [50/100], Loss: 7.9849e-05\n",
      "Epoch [60/100], Loss: 5.4226e-05\n",
      "Epoch [70/100], Loss: 4.2610e-05\n",
      "Epoch [80/100], Loss: 4.0579e-05\n",
      "Epoch [90/100], Loss: 4.4543e-05\n",
      "Epoch [100/100], Loss: 5.1011e-05\n",
      "#####--training model 300--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4965e-03\n",
      "Epoch [20/100], Loss: 1.6296e-03\n",
      "Epoch [30/100], Loss: 1.7552e-03\n",
      "Epoch [40/100], Loss: 1.8689e-03\n",
      "Epoch [50/100], Loss: 1.9869e-03\n",
      "Epoch [60/100], Loss: 2.1056e-03\n",
      "Epoch [70/100], Loss: 2.2190e-03\n",
      "Epoch [80/100], Loss: 2.3186e-03\n",
      "Epoch [90/100], Loss: 2.3940e-03\n",
      "Epoch [100/100], Loss: 2.4417e-03\n",
      "#####--training model 301--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.6155e-05\n",
      "Epoch [20/100], Loss: 7.0064e-05\n",
      "Epoch [30/100], Loss: 7.5436e-05\n",
      "Epoch [40/100], Loss: 5.6294e-05\n",
      "Epoch [50/100], Loss: 2.0701e-05\n",
      "Epoch [60/100], Loss: 3.6234e-05\n",
      "Epoch [70/100], Loss: 5.1797e-05\n",
      "Epoch [80/100], Loss: 4.2188e-05\n",
      "Epoch [90/100], Loss: 3.4248e-05\n",
      "Epoch [100/100], Loss: 2.8181e-05\n",
      "#####--training model 302--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.1477e-03\n",
      "Epoch [20/100], Loss: 2.0682e-03\n",
      "Epoch [30/100], Loss: 1.9911e-03\n",
      "Epoch [40/100], Loss: 1.8802e-03\n",
      "Epoch [50/100], Loss: 1.6839e-03\n",
      "Epoch [60/100], Loss: 1.4591e-03\n",
      "Epoch [70/100], Loss: 7.8581e-04\n",
      "Epoch [80/100], Loss: 4.6012e-04\n",
      "Epoch [90/100], Loss: 3.2966e-04\n",
      "Epoch [100/100], Loss: 2.2110e-04\n",
      "#####--training model 303--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9105e-04\n",
      "Epoch [20/100], Loss: 2.3614e-04\n",
      "Epoch [30/100], Loss: 2.3132e-04\n",
      "Epoch [40/100], Loss: 2.3003e-04\n",
      "Epoch [50/100], Loss: 2.2872e-04\n",
      "Epoch [60/100], Loss: 2.2729e-04\n",
      "Epoch [70/100], Loss: 2.2571e-04\n",
      "Epoch [80/100], Loss: 2.2391e-04\n",
      "Epoch [90/100], Loss: 2.2158e-04\n",
      "Epoch [100/100], Loss: 2.1648e-04\n",
      "#####--training model 304--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9482e-04\n",
      "Epoch [20/100], Loss: 7.3722e-05\n",
      "Epoch [30/100], Loss: 4.0593e-05\n",
      "Epoch [40/100], Loss: 2.6315e-05\n",
      "Epoch [50/100], Loss: 1.8726e-05\n",
      "Epoch [60/100], Loss: 1.4178e-05\n",
      "Epoch [70/100], Loss: 1.1241e-05\n",
      "Epoch [80/100], Loss: 9.2526e-06\n",
      "Epoch [90/100], Loss: 7.8685e-06\n",
      "Epoch [100/100], Loss: 6.8944e-06\n",
      "#####--training model 305--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1783e-03\n",
      "Epoch [20/100], Loss: 1.2063e-03\n",
      "Epoch [30/100], Loss: 1.2343e-03\n",
      "Epoch [40/100], Loss: 1.2630e-03\n",
      "Epoch [50/100], Loss: 1.2940e-03\n",
      "Epoch [60/100], Loss: 1.3293e-03\n",
      "Epoch [70/100], Loss: 1.3671e-03\n",
      "Epoch [80/100], Loss: 1.4301e-03\n",
      "Epoch [90/100], Loss: 1.5912e-03\n",
      "Epoch [100/100], Loss: 9.7560e-04\n",
      "#####--training model 306--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9046e-04\n",
      "Epoch [20/100], Loss: 1.7331e-04\n",
      "Epoch [30/100], Loss: 1.4571e-04\n",
      "Epoch [40/100], Loss: 1.3967e-04\n",
      "Epoch [50/100], Loss: 1.4013e-04\n",
      "Epoch [60/100], Loss: 1.4397e-04\n",
      "Epoch [70/100], Loss: 1.5940e-04\n",
      "Epoch [80/100], Loss: 1.8103e-04\n",
      "Epoch [90/100], Loss: 1.9706e-04\n",
      "Epoch [100/100], Loss: 2.0654e-04\n",
      "#####--training model 307--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9667e-03\n",
      "Epoch [20/100], Loss: 2.0802e-03\n",
      "Epoch [30/100], Loss: 2.2362e-03\n",
      "Epoch [40/100], Loss: 2.6255e-03\n",
      "Epoch [50/100], Loss: 1.7555e-03\n",
      "Epoch [60/100], Loss: 1.0402e-03\n",
      "Epoch [70/100], Loss: 6.9557e-04\n",
      "Epoch [80/100], Loss: 5.1982e-04\n",
      "Epoch [90/100], Loss: 4.2784e-04\n",
      "Epoch [100/100], Loss: 3.9890e-04\n",
      "#####--training model 308--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.1515e-02\n",
      "Epoch [20/100], Loss: 7.2423e-02\n",
      "Epoch [30/100], Loss: 7.2123e-02\n",
      "Epoch [40/100], Loss: 1.7215e-02\n",
      "Epoch [50/100], Loss: 7.5775e-03\n",
      "Epoch [60/100], Loss: 8.3842e-03\n",
      "Epoch [70/100], Loss: 8.4742e-03\n",
      "Epoch [80/100], Loss: 7.9045e-03\n",
      "Epoch [90/100], Loss: 6.8795e-03\n",
      "Epoch [100/100], Loss: 5.4776e-03\n",
      "#####--training model 309--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0906e-04\n",
      "Epoch [20/100], Loss: 8.7044e-05\n",
      "Epoch [30/100], Loss: 8.5523e-05\n",
      "Epoch [40/100], Loss: 8.5045e-05\n",
      "Epoch [50/100], Loss: 8.4540e-05\n",
      "Epoch [60/100], Loss: 8.3968e-05\n",
      "Epoch [70/100], Loss: 8.3300e-05\n",
      "Epoch [80/100], Loss: 8.2499e-05\n",
      "Epoch [90/100], Loss: 8.1424e-05\n",
      "Epoch [100/100], Loss: 7.9378e-05\n",
      "#####--training model 310--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.1024e-04\n",
      "Epoch [20/100], Loss: 4.0313e-05\n",
      "Epoch [30/100], Loss: 2.3884e-04\n",
      "Epoch [40/100], Loss: 4.5618e-04\n",
      "Epoch [50/100], Loss: 4.8150e-04\n",
      "Epoch [60/100], Loss: 3.9866e-04\n",
      "Epoch [70/100], Loss: 3.4878e-04\n",
      "Epoch [80/100], Loss: 3.1592e-04\n",
      "Epoch [90/100], Loss: 2.9078e-04\n",
      "Epoch [100/100], Loss: 2.7321e-04\n",
      "#####--training model 311--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3358e-03\n",
      "Epoch [20/100], Loss: 1.3600e-03\n",
      "Epoch [30/100], Loss: 1.3811e-03\n",
      "Epoch [40/100], Loss: 1.3893e-03\n",
      "Epoch [50/100], Loss: 6.4981e-04\n",
      "Epoch [60/100], Loss: 5.4475e-04\n",
      "Epoch [70/100], Loss: 4.5907e-04\n",
      "Epoch [80/100], Loss: 3.9991e-04\n",
      "Epoch [90/100], Loss: 3.4979e-04\n",
      "Epoch [100/100], Loss: 3.0586e-04\n",
      "#####--training model 312--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.8048e-04\n",
      "Epoch [20/100], Loss: 7.2708e-05\n",
      "Epoch [30/100], Loss: 4.2202e-05\n",
      "Epoch [40/100], Loss: 2.8884e-05\n",
      "Epoch [50/100], Loss: 2.1792e-05\n",
      "Epoch [60/100], Loss: 1.7583e-05\n",
      "Epoch [70/100], Loss: 1.4935e-05\n",
      "Epoch [80/100], Loss: 1.3232e-05\n",
      "Epoch [90/100], Loss: 1.2148e-05\n",
      "Epoch [100/100], Loss: 1.1485e-05\n",
      "#####--training model 313--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5424e-04\n",
      "Epoch [20/100], Loss: 6.6086e-05\n",
      "Epoch [30/100], Loss: 4.0631e-05\n",
      "Epoch [40/100], Loss: 2.9475e-05\n",
      "Epoch [50/100], Loss: 2.3658e-05\n",
      "Epoch [60/100], Loss: 2.0401e-05\n",
      "Epoch [70/100], Loss: 1.8571e-05\n",
      "Epoch [80/100], Loss: 1.7612e-05\n",
      "Epoch [90/100], Loss: 1.7190e-05\n",
      "Epoch [100/100], Loss: 1.7101e-05\n",
      "#####--training model 314--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0867e-04\n",
      "Epoch [20/100], Loss: 1.1682e-04\n",
      "Epoch [30/100], Loss: 9.8051e-05\n",
      "Epoch [40/100], Loss: 9.4439e-05\n",
      "Epoch [50/100], Loss: 9.4835e-05\n",
      "Epoch [60/100], Loss: 9.9230e-05\n",
      "Epoch [70/100], Loss: 1.2323e-04\n",
      "Epoch [80/100], Loss: 1.3391e-04\n",
      "Epoch [90/100], Loss: 1.0616e-04\n",
      "Epoch [100/100], Loss: 8.5086e-05\n",
      "#####--training model 315--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.1212e-03\n",
      "Epoch [20/100], Loss: 2.4903e-03\n",
      "Epoch [30/100], Loss: 2.3978e-03\n",
      "Epoch [40/100], Loss: 2.3567e-03\n",
      "Epoch [50/100], Loss: 2.3147e-03\n",
      "Epoch [60/100], Loss: 2.2696e-03\n",
      "Epoch [70/100], Loss: 2.2290e-03\n",
      "Epoch [80/100], Loss: 2.1779e-03\n",
      "Epoch [90/100], Loss: 2.1019e-03\n",
      "Epoch [100/100], Loss: 2.0061e-03\n",
      "#####--training model 316--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.4478e-05\n",
      "Epoch [20/100], Loss: 2.5907e-05\n",
      "Epoch [30/100], Loss: 1.7567e-05\n",
      "Epoch [40/100], Loss: 1.6359e-05\n",
      "Epoch [50/100], Loss: 1.6345e-05\n",
      "Epoch [60/100], Loss: 1.6410e-05\n",
      "Epoch [70/100], Loss: 1.6905e-05\n",
      "Epoch [80/100], Loss: 1.8054e-05\n",
      "Epoch [90/100], Loss: 2.3462e-05\n",
      "Epoch [100/100], Loss: 1.2199e-05\n",
      "#####--training model 317--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5415e-02\n",
      "Epoch [20/100], Loss: 1.5416e-02\n",
      "Epoch [30/100], Loss: 1.5405e-02\n",
      "Epoch [40/100], Loss: 1.5385e-02\n",
      "Epoch [50/100], Loss: 1.5346e-02\n",
      "Epoch [60/100], Loss: 1.5242e-02\n",
      "Epoch [70/100], Loss: 1.4803e-02\n",
      "Epoch [80/100], Loss: 1.3565e-02\n",
      "Epoch [90/100], Loss: 1.3878e-02\n",
      "Epoch [100/100], Loss: 1.3868e-02\n",
      "#####--training model 318--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1222e-03\n",
      "Epoch [20/100], Loss: 1.3160e-03\n",
      "Epoch [30/100], Loss: 1.3797e-03\n",
      "Epoch [40/100], Loss: 1.3988e-03\n",
      "Epoch [50/100], Loss: 1.4004e-03\n",
      "Epoch [60/100], Loss: 1.3902e-03\n",
      "Epoch [70/100], Loss: 1.3664e-03\n",
      "Epoch [80/100], Loss: 1.3102e-03\n",
      "Epoch [90/100], Loss: 1.1992e-03\n",
      "Epoch [100/100], Loss: 1.2373e-03\n",
      "#####--training model 319--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8165e-04\n",
      "Epoch [20/100], Loss: 3.3234e-04\n",
      "Epoch [30/100], Loss: 3.3317e-04\n",
      "Epoch [40/100], Loss: 3.3550e-04\n",
      "Epoch [50/100], Loss: 3.3826e-04\n",
      "Epoch [60/100], Loss: 3.4144e-04\n",
      "Epoch [70/100], Loss: 3.4509e-04\n",
      "Epoch [80/100], Loss: 3.4935e-04\n",
      "Epoch [90/100], Loss: 3.5485e-04\n",
      "Epoch [100/100], Loss: 3.6304e-04\n",
      "#####--training model 320--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0323e-04\n",
      "Epoch [20/100], Loss: 2.3120e-04\n",
      "Epoch [30/100], Loss: 2.2429e-04\n",
      "Epoch [40/100], Loss: 2.2373e-04\n",
      "Epoch [50/100], Loss: 2.2370e-04\n",
      "Epoch [60/100], Loss: 2.2338e-04\n",
      "Epoch [70/100], Loss: 2.2396e-04\n",
      "Epoch [80/100], Loss: 2.2008e-04\n",
      "Epoch [90/100], Loss: 1.5842e-04\n",
      "Epoch [100/100], Loss: 1.2794e-04\n",
      "#####--training model 321--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.8683e-04\n",
      "Epoch [20/100], Loss: 9.8455e-05\n",
      "Epoch [30/100], Loss: 7.4938e-05\n",
      "Epoch [40/100], Loss: 6.6449e-05\n",
      "Epoch [50/100], Loss: 6.3495e-05\n",
      "Epoch [60/100], Loss: 6.2653e-05\n",
      "Epoch [70/100], Loss: 6.2447e-05\n",
      "Epoch [80/100], Loss: 6.2364e-05\n",
      "Epoch [90/100], Loss: 6.2293e-05\n",
      "Epoch [100/100], Loss: 6.2232e-05\n",
      "#####--training model 322--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4726e-03\n",
      "Epoch [20/100], Loss: 1.4667e-03\n",
      "Epoch [30/100], Loss: 1.4663e-03\n",
      "Epoch [40/100], Loss: 1.4631e-03\n",
      "Epoch [50/100], Loss: 1.0409e-03\n",
      "Epoch [60/100], Loss: 6.2621e-04\n",
      "Epoch [70/100], Loss: 1.3186e-04\n",
      "Epoch [80/100], Loss: 5.6597e-05\n",
      "Epoch [90/100], Loss: 8.5662e-05\n",
      "Epoch [100/100], Loss: 1.0717e-04\n",
      "#####--training model 323--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1772e-04\n",
      "Epoch [20/100], Loss: 1.2526e-04\n",
      "Epoch [30/100], Loss: 1.4562e-04\n",
      "Epoch [40/100], Loss: 6.1302e-05\n",
      "Epoch [50/100], Loss: 4.4815e-05\n",
      "Epoch [60/100], Loss: 6.3608e-05\n",
      "Epoch [70/100], Loss: 7.0823e-05\n",
      "Epoch [80/100], Loss: 7.3839e-05\n",
      "Epoch [90/100], Loss: 7.5099e-05\n",
      "Epoch [100/100], Loss: 7.4923e-05\n",
      "#####--training model 324--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.4205e-04\n",
      "Epoch [20/100], Loss: 3.6392e-04\n",
      "Epoch [30/100], Loss: 3.6858e-04\n",
      "Epoch [40/100], Loss: 4.3355e-04\n",
      "Epoch [50/100], Loss: 4.6553e-04\n",
      "Epoch [60/100], Loss: 3.0507e-04\n",
      "Epoch [70/100], Loss: 2.6255e-04\n",
      "Epoch [80/100], Loss: 2.0332e-04\n",
      "Epoch [90/100], Loss: 1.8400e-04\n",
      "Epoch [100/100], Loss: 1.1396e-04\n",
      "#####--training model 325--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.3343e-03\n",
      "Epoch [20/100], Loss: 4.2796e-03\n",
      "Epoch [30/100], Loss: 3.8871e-03\n",
      "Epoch [40/100], Loss: 2.6283e-03\n",
      "Epoch [50/100], Loss: 1.9528e-03\n",
      "Epoch [60/100], Loss: 1.6433e-03\n",
      "Epoch [70/100], Loss: 1.4849e-03\n",
      "Epoch [80/100], Loss: 1.3926e-03\n",
      "Epoch [90/100], Loss: 1.3210e-03\n",
      "Epoch [100/100], Loss: 1.2481e-03\n",
      "#####--training model 326--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.7691e-04\n",
      "Epoch [20/100], Loss: 2.6238e-04\n",
      "Epoch [30/100], Loss: 2.6649e-04\n",
      "Epoch [40/100], Loss: 2.7378e-04\n",
      "Epoch [50/100], Loss: 2.9066e-04\n",
      "Epoch [60/100], Loss: 1.3629e-04\n",
      "Epoch [70/100], Loss: 7.3944e-05\n",
      "Epoch [80/100], Loss: 4.2492e-05\n",
      "Epoch [90/100], Loss: 2.0990e-05\n",
      "Epoch [100/100], Loss: 1.2650e-05\n",
      "#####--training model 327--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4528e-04\n",
      "Epoch [20/100], Loss: 6.5192e-05\n",
      "Epoch [30/100], Loss: 4.2428e-05\n",
      "Epoch [40/100], Loss: 3.2444e-05\n",
      "Epoch [50/100], Loss: 2.7310e-05\n",
      "Epoch [60/100], Loss: 2.4540e-05\n",
      "Epoch [70/100], Loss: 2.3084e-05\n",
      "Epoch [80/100], Loss: 2.2373e-05\n",
      "Epoch [90/100], Loss: 2.2041e-05\n",
      "Epoch [100/100], Loss: 2.1855e-05\n",
      "#####--training model 328--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.9720e-03\n",
      "Epoch [20/100], Loss: 5.0699e-03\n",
      "Epoch [30/100], Loss: 5.0786e-03\n",
      "Epoch [40/100], Loss: 5.0802e-03\n",
      "Epoch [50/100], Loss: 5.0672e-03\n",
      "Epoch [60/100], Loss: 4.9964e-03\n",
      "Epoch [70/100], Loss: 4.4425e-03\n",
      "Epoch [80/100], Loss: 3.2221e-03\n",
      "Epoch [90/100], Loss: 3.5068e-03\n",
      "Epoch [100/100], Loss: 3.5887e-03\n",
      "#####--training model 329--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.3972e-04\n",
      "Epoch [20/100], Loss: 4.1600e-04\n",
      "Epoch [30/100], Loss: 4.4347e-04\n",
      "Epoch [40/100], Loss: 5.0511e-04\n",
      "Epoch [50/100], Loss: 6.7517e-04\n",
      "Epoch [60/100], Loss: 6.2043e-04\n",
      "Epoch [70/100], Loss: 4.6020e-04\n",
      "Epoch [80/100], Loss: 3.3848e-04\n",
      "Epoch [90/100], Loss: 3.3185e-04\n",
      "Epoch [100/100], Loss: 3.6059e-04\n",
      "#####--training model 330--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5641e-03\n",
      "Epoch [20/100], Loss: 2.2812e-03\n",
      "Epoch [30/100], Loss: 1.8196e-03\n",
      "Epoch [40/100], Loss: 1.4291e-03\n",
      "Epoch [50/100], Loss: 1.1418e-03\n",
      "Epoch [60/100], Loss: 9.3044e-04\n",
      "Epoch [70/100], Loss: 7.4894e-04\n",
      "Epoch [80/100], Loss: 5.3532e-04\n",
      "Epoch [90/100], Loss: 3.1571e-04\n",
      "Epoch [100/100], Loss: 2.1858e-04\n",
      "#####--training model 331--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6001e-01\n",
      "Epoch [20/100], Loss: 1.3279e-02\n",
      "Epoch [30/100], Loss: 1.0768e-02\n",
      "Epoch [40/100], Loss: 1.0671e-02\n",
      "Epoch [50/100], Loss: 1.0874e-02\n",
      "Epoch [60/100], Loss: 1.1552e-02\n",
      "Epoch [70/100], Loss: 1.2264e-02\n",
      "Epoch [80/100], Loss: 1.6232e-02\n",
      "Epoch [90/100], Loss: 1.3347e-02\n",
      "Epoch [100/100], Loss: 1.3832e-02\n",
      "#####--training model 332--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.5829e-04\n",
      "Epoch [20/100], Loss: 9.1639e-04\n",
      "Epoch [30/100], Loss: 1.3770e-03\n",
      "Epoch [40/100], Loss: 1.0906e-03\n",
      "Epoch [50/100], Loss: 7.7934e-04\n",
      "Epoch [60/100], Loss: 5.9408e-04\n",
      "Epoch [70/100], Loss: 4.4844e-04\n",
      "Epoch [80/100], Loss: 3.3594e-04\n",
      "Epoch [90/100], Loss: 2.5862e-04\n",
      "Epoch [100/100], Loss: 2.0307e-04\n",
      "#####--training model 333--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4664e-03\n",
      "Epoch [20/100], Loss: 1.4269e-03\n",
      "Epoch [30/100], Loss: 1.1054e-03\n",
      "Epoch [40/100], Loss: 6.0965e-04\n",
      "Epoch [50/100], Loss: 5.1486e-04\n",
      "Epoch [60/100], Loss: 4.5387e-04\n",
      "Epoch [70/100], Loss: 4.4668e-04\n",
      "Epoch [80/100], Loss: 4.6137e-04\n",
      "Epoch [90/100], Loss: 4.7530e-04\n",
      "Epoch [100/100], Loss: 4.8636e-04\n",
      "#####--training model 334--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0177e-03\n",
      "Epoch [20/100], Loss: 2.1657e-03\n",
      "Epoch [30/100], Loss: 3.2457e-03\n",
      "Epoch [40/100], Loss: 1.8125e-03\n",
      "Epoch [50/100], Loss: 1.3214e-03\n",
      "Epoch [60/100], Loss: 1.1376e-03\n",
      "Epoch [70/100], Loss: 1.0470e-03\n",
      "Epoch [80/100], Loss: 9.8833e-04\n",
      "Epoch [90/100], Loss: 9.4396e-04\n",
      "Epoch [100/100], Loss: 9.0778e-04\n",
      "#####--training model 335--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7568e-04\n",
      "Epoch [20/100], Loss: 7.7247e-05\n",
      "Epoch [30/100], Loss: 5.1390e-05\n",
      "Epoch [40/100], Loss: 4.1104e-05\n",
      "Epoch [50/100], Loss: 3.6577e-05\n",
      "Epoch [60/100], Loss: 3.4722e-05\n",
      "Epoch [70/100], Loss: 3.4150e-05\n",
      "Epoch [80/100], Loss: 3.4120e-05\n",
      "Epoch [90/100], Loss: 3.4291e-05\n",
      "Epoch [100/100], Loss: 3.4582e-05\n",
      "#####--training model 336--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7551e-04\n",
      "Epoch [20/100], Loss: 6.1185e-05\n",
      "Epoch [30/100], Loss: 3.1115e-05\n",
      "Epoch [40/100], Loss: 1.8522e-05\n",
      "Epoch [50/100], Loss: 1.2006e-05\n",
      "Epoch [60/100], Loss: 8.1998e-06\n",
      "Epoch [70/100], Loss: 5.7964e-06\n",
      "Epoch [80/100], Loss: 4.1960e-06\n",
      "Epoch [90/100], Loss: 3.0894e-06\n",
      "Epoch [100/100], Loss: 2.3030e-06\n",
      "#####--training model 337--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0784e-04\n",
      "Epoch [20/100], Loss: 4.9637e-05\n",
      "Epoch [30/100], Loss: 3.5104e-05\n",
      "Epoch [40/100], Loss: 2.9944e-05\n",
      "Epoch [50/100], Loss: 2.7977e-05\n",
      "Epoch [60/100], Loss: 2.7320e-05\n",
      "Epoch [70/100], Loss: 2.7186e-05\n",
      "Epoch [80/100], Loss: 2.7223e-05\n",
      "Epoch [90/100], Loss: 2.7305e-05\n",
      "Epoch [100/100], Loss: 2.7404e-05\n",
      "#####--training model 338--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9282e-03\n",
      "Epoch [20/100], Loss: 1.8441e-03\n",
      "Epoch [30/100], Loss: 3.2721e-03\n",
      "Epoch [40/100], Loss: 3.9421e-03\n",
      "Epoch [50/100], Loss: 3.9312e-03\n",
      "Epoch [60/100], Loss: 3.7520e-03\n",
      "Epoch [70/100], Loss: 3.4552e-03\n",
      "Epoch [80/100], Loss: 3.2296e-03\n",
      "Epoch [90/100], Loss: 3.2061e-03\n",
      "Epoch [100/100], Loss: 3.2575e-03\n",
      "#####--training model 339--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9930e-04\n",
      "Epoch [20/100], Loss: 2.5176e-04\n",
      "Epoch [30/100], Loss: 2.5177e-04\n",
      "Epoch [40/100], Loss: 2.5554e-04\n",
      "Epoch [50/100], Loss: 2.6188e-04\n",
      "Epoch [60/100], Loss: 2.7150e-04\n",
      "Epoch [70/100], Loss: 2.8295e-04\n",
      "Epoch [80/100], Loss: 3.0153e-04\n",
      "Epoch [90/100], Loss: 3.3715e-04\n",
      "Epoch [100/100], Loss: 4.1616e-04\n",
      "#####--training model 340--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.3713e-03\n",
      "Epoch [20/100], Loss: 2.0691e-03\n",
      "Epoch [30/100], Loss: 2.0881e-03\n",
      "Epoch [40/100], Loss: 1.6616e-03\n",
      "Epoch [50/100], Loss: 1.2826e-03\n",
      "Epoch [60/100], Loss: 1.0221e-03\n",
      "Epoch [70/100], Loss: 8.5254e-04\n",
      "Epoch [80/100], Loss: 7.0387e-04\n",
      "Epoch [90/100], Loss: 5.9352e-04\n",
      "Epoch [100/100], Loss: 5.1828e-04\n",
      "#####--training model 341--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2848e-04\n",
      "Epoch [20/100], Loss: 4.3636e-05\n",
      "Epoch [30/100], Loss: 2.1937e-05\n",
      "Epoch [40/100], Loss: 1.3016e-05\n",
      "Epoch [50/100], Loss: 8.4348e-06\n",
      "Epoch [60/100], Loss: 5.7663e-06\n",
      "Epoch [70/100], Loss: 4.0821e-06\n",
      "Epoch [80/100], Loss: 2.9599e-06\n",
      "Epoch [90/100], Loss: 2.1830e-06\n",
      "Epoch [100/100], Loss: 1.6299e-06\n",
      "#####--training model 342--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.8670e-04\n",
      "Epoch [20/100], Loss: 4.7454e-04\n",
      "Epoch [30/100], Loss: 4.1579e-04\n",
      "Epoch [40/100], Loss: 5.0907e-04\n",
      "Epoch [50/100], Loss: 5.9234e-04\n",
      "Epoch [60/100], Loss: 6.5791e-04\n",
      "Epoch [70/100], Loss: 7.2089e-04\n",
      "Epoch [80/100], Loss: 7.7957e-04\n",
      "Epoch [90/100], Loss: 8.2515e-04\n",
      "Epoch [100/100], Loss: 8.6044e-04\n",
      "#####--training model 343--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4869e-04\n",
      "Epoch [20/100], Loss: 5.4316e-05\n",
      "Epoch [30/100], Loss: 2.8542e-05\n",
      "Epoch [40/100], Loss: 1.7496e-05\n",
      "Epoch [50/100], Loss: 1.1676e-05\n",
      "Epoch [60/100], Loss: 8.2197e-06\n",
      "Epoch [70/100], Loss: 6.0026e-06\n",
      "Epoch [80/100], Loss: 4.5024e-06\n",
      "Epoch [90/100], Loss: 3.4476e-06\n",
      "Epoch [100/100], Loss: 2.6848e-06\n",
      "#####--training model 344--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.4230e-03\n",
      "Epoch [20/100], Loss: 7.0398e-03\n",
      "Epoch [30/100], Loss: 7.2009e-03\n",
      "Epoch [40/100], Loss: 7.2392e-03\n",
      "Epoch [50/100], Loss: 7.2450e-03\n",
      "Epoch [60/100], Loss: 7.2410e-03\n",
      "Epoch [70/100], Loss: 7.2279e-03\n",
      "Epoch [80/100], Loss: 7.1697e-03\n",
      "Epoch [90/100], Loss: 7.0211e-03\n",
      "Epoch [100/100], Loss: 6.6380e-03\n",
      "#####--training model 345--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.4433e-03\n",
      "Epoch [20/100], Loss: 1.5913e-03\n",
      "Epoch [30/100], Loss: 1.6261e-03\n",
      "Epoch [40/100], Loss: 1.6510e-03\n",
      "Epoch [50/100], Loss: 1.6739e-03\n",
      "Epoch [60/100], Loss: 1.4718e-03\n",
      "Epoch [70/100], Loss: 5.6506e-04\n",
      "Epoch [80/100], Loss: 5.5316e-04\n",
      "Epoch [90/100], Loss: 2.9334e-04\n",
      "Epoch [100/100], Loss: 3.1240e-04\n",
      "#####--training model 346--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.2804e-03\n",
      "Epoch [20/100], Loss: 7.9314e-04\n",
      "Epoch [30/100], Loss: 5.8839e-04\n",
      "Epoch [40/100], Loss: 4.5208e-04\n",
      "Epoch [50/100], Loss: 3.7437e-04\n",
      "Epoch [60/100], Loss: 3.3879e-04\n",
      "Epoch [70/100], Loss: 3.1439e-04\n",
      "Epoch [80/100], Loss: 2.9655e-04\n",
      "Epoch [90/100], Loss: 2.8212e-04\n",
      "Epoch [100/100], Loss: 2.6914e-04\n",
      "#####--training model 347--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3898e-04\n",
      "Epoch [20/100], Loss: 3.2050e-04\n",
      "Epoch [30/100], Loss: 3.1415e-04\n",
      "Epoch [40/100], Loss: 8.5108e-05\n",
      "Epoch [50/100], Loss: 4.6837e-05\n",
      "Epoch [60/100], Loss: 1.8120e-05\n",
      "Epoch [70/100], Loss: 1.3901e-05\n",
      "Epoch [80/100], Loss: 1.4201e-05\n",
      "Epoch [90/100], Loss: 1.3405e-05\n",
      "Epoch [100/100], Loss: 1.7760e-05\n",
      "#####--training model 348--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5882e-02\n",
      "Epoch [20/100], Loss: 1.0612e-02\n",
      "Epoch [30/100], Loss: 8.6830e-03\n",
      "Epoch [40/100], Loss: 6.7968e-03\n",
      "Epoch [50/100], Loss: 5.2089e-03\n",
      "Epoch [60/100], Loss: 4.3793e-03\n",
      "Epoch [70/100], Loss: 4.0171e-03\n",
      "Epoch [80/100], Loss: 3.7972e-03\n",
      "Epoch [90/100], Loss: 3.6420e-03\n",
      "Epoch [100/100], Loss: 3.5270e-03\n",
      "#####--training model 349--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.1092e-04\n",
      "Epoch [20/100], Loss: 3.1346e-04\n",
      "Epoch [30/100], Loss: 2.4454e-04\n",
      "Epoch [40/100], Loss: 2.8086e-04\n",
      "Epoch [50/100], Loss: 2.5737e-04\n",
      "Epoch [60/100], Loss: 1.6958e-04\n",
      "Epoch [70/100], Loss: 7.7132e-05\n",
      "Epoch [80/100], Loss: 3.2310e-05\n",
      "Epoch [90/100], Loss: 2.0538e-05\n",
      "Epoch [100/100], Loss: 1.7756e-05\n",
      "#####--training model 350--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.9900e-03\n",
      "Epoch [20/100], Loss: 1.2980e-03\n",
      "Epoch [30/100], Loss: 5.7926e-04\n",
      "Epoch [40/100], Loss: 3.7636e-04\n",
      "Epoch [50/100], Loss: 2.6298e-04\n",
      "Epoch [60/100], Loss: 1.7962e-04\n",
      "Epoch [70/100], Loss: 1.4142e-04\n",
      "Epoch [80/100], Loss: 1.3598e-04\n",
      "Epoch [90/100], Loss: 1.3237e-04\n",
      "Epoch [100/100], Loss: 1.2700e-04\n",
      "#####--training model 351--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7951e-04\n",
      "Epoch [20/100], Loss: 1.7751e-04\n",
      "Epoch [30/100], Loss: 1.7671e-04\n",
      "Epoch [40/100], Loss: 2.0940e-04\n",
      "Epoch [50/100], Loss: 2.3610e-04\n",
      "Epoch [60/100], Loss: 2.5017e-04\n",
      "Epoch [70/100], Loss: 2.3645e-04\n",
      "Epoch [80/100], Loss: 2.2359e-04\n",
      "Epoch [90/100], Loss: 2.1625e-04\n",
      "Epoch [100/100], Loss: 2.1012e-04\n",
      "#####--training model 352--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.6897e-06\n",
      "Epoch [20/100], Loss: 3.4390e-04\n",
      "Epoch [30/100], Loss: 3.6217e-04\n",
      "Epoch [40/100], Loss: 3.7095e-04\n",
      "Epoch [50/100], Loss: 3.6875e-04\n",
      "Epoch [60/100], Loss: 3.7103e-04\n",
      "Epoch [70/100], Loss: 3.8026e-04\n",
      "Epoch [80/100], Loss: 3.8917e-04\n",
      "Epoch [90/100], Loss: 3.9472e-04\n",
      "Epoch [100/100], Loss: 3.9967e-04\n",
      "#####--training model 353--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.6962e-04\n",
      "Epoch [20/100], Loss: 2.8986e-04\n",
      "Epoch [30/100], Loss: 1.6522e-04\n",
      "Epoch [40/100], Loss: 2.1411e-04\n",
      "Epoch [50/100], Loss: 3.1648e-04\n",
      "Epoch [60/100], Loss: 3.1682e-04\n",
      "Epoch [70/100], Loss: 3.1599e-04\n",
      "Epoch [80/100], Loss: 3.4728e-04\n",
      "Epoch [90/100], Loss: 3.9160e-04\n",
      "Epoch [100/100], Loss: 4.3701e-04\n",
      "#####--training model 354--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3586e-02\n",
      "Epoch [20/100], Loss: 1.4299e-02\n",
      "Epoch [30/100], Loss: 1.4458e-02\n",
      "Epoch [40/100], Loss: 1.4514e-02\n",
      "Epoch [50/100], Loss: 1.4548e-02\n",
      "Epoch [60/100], Loss: 1.4564e-02\n",
      "Epoch [70/100], Loss: 1.4566e-02\n",
      "Epoch [80/100], Loss: 1.4502e-02\n",
      "Epoch [90/100], Loss: 1.3677e-02\n",
      "Epoch [100/100], Loss: 1.1228e-02\n",
      "#####--training model 355--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3669e-03\n",
      "Epoch [20/100], Loss: 1.6698e-03\n",
      "Epoch [30/100], Loss: 1.4452e-03\n",
      "Epoch [40/100], Loss: 1.0176e-03\n",
      "Epoch [50/100], Loss: 6.4180e-04\n",
      "Epoch [60/100], Loss: 4.8302e-04\n",
      "Epoch [70/100], Loss: 4.3503e-04\n",
      "Epoch [80/100], Loss: 4.1670e-04\n",
      "Epoch [90/100], Loss: 4.0411e-04\n",
      "Epoch [100/100], Loss: 3.9039e-04\n",
      "#####--training model 356--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.2205e-04\n",
      "Epoch [20/100], Loss: 8.3480e-04\n",
      "Epoch [30/100], Loss: 8.9511e-04\n",
      "Epoch [40/100], Loss: 9.2804e-04\n",
      "Epoch [50/100], Loss: 1.0461e-03\n",
      "Epoch [60/100], Loss: 1.2482e-03\n",
      "Epoch [70/100], Loss: 1.4307e-03\n",
      "Epoch [80/100], Loss: 1.5396e-03\n",
      "Epoch [90/100], Loss: 1.5936e-03\n",
      "Epoch [100/100], Loss: 1.6218e-03\n",
      "#####--training model 357--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.1327e-04\n",
      "Epoch [20/100], Loss: 4.7967e-04\n",
      "Epoch [30/100], Loss: 1.8812e-04\n",
      "Epoch [40/100], Loss: 1.6098e-04\n",
      "Epoch [50/100], Loss: 3.2962e-04\n",
      "Epoch [60/100], Loss: 3.9699e-04\n",
      "Epoch [70/100], Loss: 4.4628e-04\n",
      "Epoch [80/100], Loss: 1.8657e-03\n",
      "Epoch [90/100], Loss: 1.2465e-03\n",
      "Epoch [100/100], Loss: 3.8199e-04\n",
      "#####--training model 358--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.8971e-05\n",
      "Epoch [20/100], Loss: 3.5514e-05\n",
      "Epoch [30/100], Loss: 5.9020e-05\n",
      "Epoch [40/100], Loss: 7.6771e-05\n",
      "Epoch [50/100], Loss: 8.7147e-05\n",
      "Epoch [60/100], Loss: 1.0477e-04\n",
      "Epoch [70/100], Loss: 1.2003e-04\n",
      "Epoch [80/100], Loss: 1.3008e-04\n",
      "Epoch [90/100], Loss: 1.3755e-04\n",
      "Epoch [100/100], Loss: 1.4470e-04\n",
      "#####--training model 359--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2527e-04\n",
      "Epoch [20/100], Loss: 4.5343e-05\n",
      "Epoch [30/100], Loss: 2.3339e-05\n",
      "Epoch [40/100], Loss: 1.3977e-05\n",
      "Epoch [50/100], Loss: 9.0938e-06\n",
      "Epoch [60/100], Loss: 6.2273e-06\n",
      "Epoch [70/100], Loss: 4.4110e-06\n",
      "Epoch [80/100], Loss: 3.1985e-06\n",
      "Epoch [90/100], Loss: 2.3584e-06\n",
      "Epoch [100/100], Loss: 1.7602e-06\n",
      "#####--training model 360--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4089e-05\n",
      "Epoch [20/100], Loss: 1.3990e-05\n",
      "Epoch [30/100], Loss: 1.4126e-05\n",
      "Epoch [40/100], Loss: 1.4262e-05\n",
      "Epoch [50/100], Loss: 1.4392e-05\n",
      "Epoch [60/100], Loss: 1.4507e-05\n",
      "Epoch [70/100], Loss: 1.4602e-05\n",
      "Epoch [80/100], Loss: 1.4672e-05\n",
      "Epoch [90/100], Loss: 1.4716e-05\n",
      "Epoch [100/100], Loss: 1.4734e-05\n",
      "#####--training model 361--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2353e-03\n",
      "Epoch [20/100], Loss: 2.2853e-03\n",
      "Epoch [30/100], Loss: 2.2957e-03\n",
      "Epoch [40/100], Loss: 2.3309e-03\n",
      "Epoch [50/100], Loss: 2.3681e-03\n",
      "Epoch [60/100], Loss: 2.3923e-03\n",
      "Epoch [70/100], Loss: 2.4143e-03\n",
      "Epoch [80/100], Loss: 2.4363e-03\n",
      "Epoch [90/100], Loss: 2.4594e-03\n",
      "Epoch [100/100], Loss: 2.4840e-03\n",
      "#####--training model 362--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.6310e-04\n",
      "Epoch [20/100], Loss: 2.4963e-04\n",
      "Epoch [30/100], Loss: 4.5859e-05\n",
      "Epoch [40/100], Loss: 1.4763e-05\n",
      "Epoch [50/100], Loss: 2.1627e-05\n",
      "Epoch [60/100], Loss: 3.5574e-05\n",
      "Epoch [70/100], Loss: 5.2808e-05\n",
      "Epoch [80/100], Loss: 7.7178e-05\n",
      "Epoch [90/100], Loss: 1.0670e-04\n",
      "Epoch [100/100], Loss: 1.3768e-04\n",
      "#####--training model 363--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3985e-04\n",
      "Epoch [20/100], Loss: 9.6472e-04\n",
      "Epoch [30/100], Loss: 3.0608e-03\n",
      "Epoch [40/100], Loss: 3.5468e-03\n",
      "Epoch [50/100], Loss: 3.8045e-03\n",
      "Epoch [60/100], Loss: 4.3069e-03\n",
      "Epoch [70/100], Loss: 7.6313e-03\n",
      "Epoch [80/100], Loss: 6.7727e-03\n",
      "Epoch [90/100], Loss: 5.6927e-03\n",
      "Epoch [100/100], Loss: 4.8676e-03\n",
      "#####--training model 364--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4346e-04\n",
      "Epoch [20/100], Loss: 5.2143e-05\n",
      "Epoch [30/100], Loss: 2.6851e-05\n",
      "Epoch [40/100], Loss: 1.6057e-05\n",
      "Epoch [50/100], Loss: 1.0415e-05\n",
      "Epoch [60/100], Loss: 7.1013e-06\n",
      "Epoch [70/100], Loss: 5.0047e-06\n",
      "Epoch [80/100], Loss: 3.6100e-06\n",
      "Epoch [90/100], Loss: 2.6482e-06\n",
      "Epoch [100/100], Loss: 1.9674e-06\n",
      "#####--training model 365--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.0996e-02\n",
      "Epoch [20/100], Loss: 6.1476e-02\n",
      "Epoch [30/100], Loss: 6.0269e-02\n",
      "Epoch [40/100], Loss: 6.0084e-02\n",
      "Epoch [50/100], Loss: 6.1389e-02\n",
      "Epoch [60/100], Loss: 6.3459e-02\n",
      "Epoch [70/100], Loss: 6.4885e-02\n",
      "Epoch [80/100], Loss: 6.5376e-02\n",
      "Epoch [90/100], Loss: 6.4945e-02\n",
      "Epoch [100/100], Loss: 6.3328e-02\n",
      "#####--training model 366--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.7799e-04\n",
      "Epoch [20/100], Loss: 1.1246e-04\n",
      "Epoch [30/100], Loss: 6.8029e-05\n",
      "Epoch [40/100], Loss: 5.0028e-05\n",
      "Epoch [50/100], Loss: 4.1098e-05\n",
      "Epoch [60/100], Loss: 3.6347e-05\n",
      "Epoch [70/100], Loss: 3.3877e-05\n",
      "Epoch [80/100], Loss: 3.2741e-05\n",
      "Epoch [90/100], Loss: 3.2357e-05\n",
      "Epoch [100/100], Loss: 3.2338e-05\n",
      "#####--training model 367--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.5743e-04\n",
      "Epoch [20/100], Loss: 4.4007e-04\n",
      "Epoch [30/100], Loss: 4.5360e-04\n",
      "Epoch [40/100], Loss: 4.9493e-04\n",
      "Epoch [50/100], Loss: 2.6553e-04\n",
      "Epoch [60/100], Loss: 1.8093e-04\n",
      "Epoch [70/100], Loss: 1.7064e-04\n",
      "Epoch [80/100], Loss: 1.6316e-04\n",
      "Epoch [90/100], Loss: 1.5163e-04\n",
      "Epoch [100/100], Loss: 1.2870e-04\n",
      "#####--training model 368--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.5005e-04\n",
      "Epoch [20/100], Loss: 1.1057e-03\n",
      "Epoch [30/100], Loss: 1.0453e-03\n",
      "Epoch [40/100], Loss: 1.0340e-03\n",
      "Epoch [50/100], Loss: 9.6026e-04\n",
      "Epoch [60/100], Loss: 9.0840e-04\n",
      "Epoch [70/100], Loss: 8.9032e-04\n",
      "Epoch [80/100], Loss: 8.9242e-04\n",
      "Epoch [90/100], Loss: 8.9910e-04\n",
      "Epoch [100/100], Loss: 8.9187e-04\n",
      "#####--training model 369--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3090e-03\n",
      "Epoch [20/100], Loss: 1.4402e-04\n",
      "Epoch [30/100], Loss: 2.6701e-04\n",
      "Epoch [40/100], Loss: 4.2441e-04\n",
      "Epoch [50/100], Loss: 5.6304e-04\n",
      "Epoch [60/100], Loss: 6.0156e-04\n",
      "Epoch [70/100], Loss: 6.0777e-04\n",
      "Epoch [80/100], Loss: 6.0390e-04\n",
      "Epoch [90/100], Loss: 5.9937e-04\n",
      "Epoch [100/100], Loss: 5.9812e-04\n",
      "#####--training model 370--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3134e-03\n",
      "Epoch [20/100], Loss: 1.3795e-03\n",
      "Epoch [30/100], Loss: 1.1031e-03\n",
      "Epoch [40/100], Loss: 7.8729e-04\n",
      "Epoch [50/100], Loss: 5.8704e-04\n",
      "Epoch [60/100], Loss: 4.4787e-04\n",
      "Epoch [70/100], Loss: 3.5294e-04\n",
      "Epoch [80/100], Loss: 2.8756e-04\n",
      "Epoch [90/100], Loss: 2.3936e-04\n",
      "Epoch [100/100], Loss: 1.9913e-04\n",
      "#####--training model 371--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.7816e-03\n",
      "Epoch [20/100], Loss: 3.8784e-03\n",
      "Epoch [30/100], Loss: 2.1554e-03\n",
      "Epoch [40/100], Loss: 1.4031e-03\n",
      "Epoch [50/100], Loss: 1.0355e-03\n",
      "Epoch [60/100], Loss: 7.6723e-04\n",
      "Epoch [70/100], Loss: 6.0658e-04\n",
      "Epoch [80/100], Loss: 5.1804e-04\n",
      "Epoch [90/100], Loss: 4.6028e-04\n",
      "Epoch [100/100], Loss: 4.1806e-04\n",
      "#####--training model 372--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.0927e-04\n",
      "Epoch [20/100], Loss: 1.2316e-03\n",
      "Epoch [30/100], Loss: 1.8860e-03\n",
      "Epoch [40/100], Loss: 1.9485e-03\n",
      "Epoch [50/100], Loss: 1.8102e-03\n",
      "Epoch [60/100], Loss: 1.7100e-03\n",
      "Epoch [70/100], Loss: 1.6565e-03\n",
      "Epoch [80/100], Loss: 1.6292e-03\n",
      "Epoch [90/100], Loss: 1.6145e-03\n",
      "Epoch [100/100], Loss: 1.6047e-03\n",
      "#####--training model 373--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8925e-04\n",
      "Epoch [20/100], Loss: 2.3943e-04\n",
      "Epoch [30/100], Loss: 2.3531e-04\n",
      "Epoch [40/100], Loss: 2.3721e-04\n",
      "Epoch [50/100], Loss: 2.4604e-04\n",
      "Epoch [60/100], Loss: 2.7462e-04\n",
      "Epoch [70/100], Loss: 2.9515e-04\n",
      "Epoch [80/100], Loss: 2.0647e-04\n",
      "Epoch [90/100], Loss: 1.8198e-04\n",
      "Epoch [100/100], Loss: 1.7573e-04\n",
      "#####--training model 374--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.7571e-03\n",
      "Epoch [20/100], Loss: 2.9639e-03\n",
      "Epoch [30/100], Loss: 1.2116e-03\n",
      "Epoch [40/100], Loss: 8.6419e-04\n",
      "Epoch [50/100], Loss: 7.8095e-04\n",
      "Epoch [60/100], Loss: 7.1947e-04\n",
      "Epoch [70/100], Loss: 6.2328e-04\n",
      "Epoch [80/100], Loss: 5.0906e-04\n",
      "Epoch [90/100], Loss: 4.1813e-04\n",
      "Epoch [100/100], Loss: 3.7026e-04\n",
      "#####--training model 375--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.0222e-04\n",
      "Epoch [20/100], Loss: 1.8745e-04\n",
      "Epoch [30/100], Loss: 4.9703e-05\n",
      "Epoch [40/100], Loss: 1.4161e-05\n",
      "Epoch [50/100], Loss: 8.4483e-06\n",
      "Epoch [60/100], Loss: 8.3284e-06\n",
      "Epoch [70/100], Loss: 8.8653e-06\n",
      "Epoch [80/100], Loss: 1.0307e-05\n",
      "Epoch [90/100], Loss: 1.3087e-05\n",
      "Epoch [100/100], Loss: 1.7004e-05\n",
      "#####--training model 376--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.7666e-04\n",
      "Epoch [20/100], Loss: 3.7220e-04\n",
      "Epoch [30/100], Loss: 1.8929e-04\n",
      "Epoch [40/100], Loss: 8.8980e-05\n",
      "Epoch [50/100], Loss: 6.3195e-05\n",
      "Epoch [60/100], Loss: 5.2823e-05\n",
      "Epoch [70/100], Loss: 5.1295e-05\n",
      "Epoch [80/100], Loss: 6.0890e-05\n",
      "Epoch [90/100], Loss: 7.6818e-05\n",
      "Epoch [100/100], Loss: 9.1033e-05\n",
      "#####--training model 377--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.7679e-02\n",
      "Epoch [20/100], Loss: 9.5357e-03\n",
      "Epoch [30/100], Loss: 1.0556e-02\n",
      "Epoch [40/100], Loss: 9.9087e-03\n",
      "Epoch [50/100], Loss: 8.2238e-03\n",
      "Epoch [60/100], Loss: 6.1645e-03\n",
      "Epoch [70/100], Loss: 4.1417e-03\n",
      "Epoch [80/100], Loss: 2.8410e-03\n",
      "Epoch [90/100], Loss: 2.0228e-03\n",
      "Epoch [100/100], Loss: 1.4583e-03\n",
      "#####--training model 378--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0778e-04\n",
      "Epoch [20/100], Loss: 7.0500e-04\n",
      "Epoch [30/100], Loss: 1.9364e-04\n",
      "Epoch [40/100], Loss: 3.0090e-04\n",
      "Epoch [50/100], Loss: 3.6363e-04\n",
      "Epoch [60/100], Loss: 3.0070e-04\n",
      "Epoch [70/100], Loss: 2.1344e-04\n",
      "Epoch [80/100], Loss: 1.3461e-04\n",
      "Epoch [90/100], Loss: 8.0278e-05\n",
      "Epoch [100/100], Loss: 5.1405e-05\n",
      "#####--training model 379--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.9771e-03\n",
      "Epoch [20/100], Loss: 3.4151e-03\n",
      "Epoch [30/100], Loss: 2.7289e-03\n",
      "Epoch [40/100], Loss: 2.1978e-03\n",
      "Epoch [50/100], Loss: 1.8976e-03\n",
      "Epoch [60/100], Loss: 1.8296e-03\n",
      "Epoch [70/100], Loss: 1.8227e-03\n",
      "Epoch [80/100], Loss: 1.8021e-03\n",
      "Epoch [90/100], Loss: 1.7850e-03\n",
      "Epoch [100/100], Loss: 1.7855e-03\n",
      "#####--training model 380--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4697e-03\n",
      "Epoch [20/100], Loss: 1.9956e-03\n",
      "Epoch [30/100], Loss: 2.0274e-03\n",
      "Epoch [40/100], Loss: 1.6531e-03\n",
      "Epoch [50/100], Loss: 1.0474e-03\n",
      "Epoch [60/100], Loss: 8.3812e-04\n",
      "Epoch [70/100], Loss: 7.2116e-04\n",
      "Epoch [80/100], Loss: 6.7028e-04\n",
      "Epoch [90/100], Loss: 6.8306e-04\n",
      "Epoch [100/100], Loss: 7.3247e-04\n",
      "#####--training model 381--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.7744e-03\n",
      "Epoch [20/100], Loss: 2.9071e-03\n",
      "Epoch [30/100], Loss: 3.1088e-03\n",
      "Epoch [40/100], Loss: 2.6035e-03\n",
      "Epoch [50/100], Loss: 2.1936e-03\n",
      "Epoch [60/100], Loss: 1.8903e-03\n",
      "Epoch [70/100], Loss: 1.6458e-03\n",
      "Epoch [80/100], Loss: 1.4414e-03\n",
      "Epoch [90/100], Loss: 1.2739e-03\n",
      "Epoch [100/100], Loss: 1.1432e-03\n",
      "#####--training model 382--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2389e-03\n",
      "Epoch [20/100], Loss: 1.2450e-03\n",
      "Epoch [30/100], Loss: 1.2635e-03\n",
      "Epoch [40/100], Loss: 1.2825e-03\n",
      "Epoch [50/100], Loss: 1.3774e-03\n",
      "Epoch [60/100], Loss: 1.5582e-03\n",
      "Epoch [70/100], Loss: 1.0937e-03\n",
      "Epoch [80/100], Loss: 8.8180e-04\n",
      "Epoch [90/100], Loss: 6.7587e-04\n",
      "Epoch [100/100], Loss: 5.4087e-04\n",
      "#####--training model 383--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3768e-02\n",
      "Epoch [20/100], Loss: 9.0547e-03\n",
      "Epoch [30/100], Loss: 4.8289e-03\n",
      "Epoch [40/100], Loss: 3.0101e-03\n",
      "Epoch [50/100], Loss: 2.5043e-03\n",
      "Epoch [60/100], Loss: 2.3602e-03\n",
      "Epoch [70/100], Loss: 2.3099e-03\n",
      "Epoch [80/100], Loss: 2.2706e-03\n",
      "Epoch [90/100], Loss: 2.2218e-03\n",
      "Epoch [100/100], Loss: 2.1677e-03\n",
      "#####--training model 384--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3662e-03\n",
      "Epoch [20/100], Loss: 1.4923e-03\n",
      "Epoch [30/100], Loss: 5.0116e-04\n",
      "Epoch [40/100], Loss: 2.8052e-04\n",
      "Epoch [50/100], Loss: 3.3572e-04\n",
      "Epoch [60/100], Loss: 5.0820e-04\n",
      "Epoch [70/100], Loss: 6.0776e-04\n",
      "Epoch [80/100], Loss: 6.0674e-04\n",
      "Epoch [90/100], Loss: 6.1663e-04\n",
      "Epoch [100/100], Loss: 6.2766e-04\n",
      "#####--training model 385--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.5824e-05\n",
      "Epoch [20/100], Loss: 2.1858e-03\n",
      "Epoch [30/100], Loss: 3.2918e-03\n",
      "Epoch [40/100], Loss: 3.1069e-03\n",
      "Epoch [50/100], Loss: 1.7384e-03\n",
      "Epoch [60/100], Loss: 6.4267e-04\n",
      "Epoch [70/100], Loss: 2.9573e-04\n",
      "Epoch [80/100], Loss: 2.0422e-04\n",
      "Epoch [90/100], Loss: 1.3837e-04\n",
      "Epoch [100/100], Loss: 8.1609e-05\n",
      "#####--training model 386--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.5384e-03\n",
      "Epoch [20/100], Loss: 2.9011e-03\n",
      "Epoch [30/100], Loss: 1.7739e-03\n",
      "Epoch [40/100], Loss: 1.1414e-03\n",
      "Epoch [50/100], Loss: 8.3801e-04\n",
      "Epoch [60/100], Loss: 6.6337e-04\n",
      "Epoch [70/100], Loss: 5.4877e-04\n",
      "Epoch [80/100], Loss: 4.6822e-04\n",
      "Epoch [90/100], Loss: 4.0793e-04\n",
      "Epoch [100/100], Loss: 3.6107e-04\n",
      "#####--training model 387--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.1834e-03\n",
      "Epoch [20/100], Loss: 3.8138e-03\n",
      "Epoch [30/100], Loss: 3.5435e-03\n",
      "Epoch [40/100], Loss: 2.8439e-03\n",
      "Epoch [50/100], Loss: 2.3396e-03\n",
      "Epoch [60/100], Loss: 1.9732e-03\n",
      "Epoch [70/100], Loss: 1.7351e-03\n",
      "Epoch [80/100], Loss: 1.6153e-03\n",
      "Epoch [90/100], Loss: 1.5660e-03\n",
      "Epoch [100/100], Loss: 1.5951e-03\n",
      "#####--training model 388--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1945e-03\n",
      "Epoch [20/100], Loss: 1.2749e-03\n",
      "Epoch [30/100], Loss: 1.4291e-03\n",
      "Epoch [40/100], Loss: 1.5213e-03\n",
      "Epoch [50/100], Loss: 1.6306e-03\n",
      "Epoch [60/100], Loss: 1.7231e-03\n",
      "Epoch [70/100], Loss: 1.7866e-03\n",
      "Epoch [80/100], Loss: 1.8299e-03\n",
      "Epoch [90/100], Loss: 1.8558e-03\n",
      "Epoch [100/100], Loss: 1.8660e-03\n",
      "#####--training model 389--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0953e-02\n",
      "Epoch [20/100], Loss: 6.5844e-03\n",
      "Epoch [30/100], Loss: 4.0868e-03\n",
      "Epoch [40/100], Loss: 2.7288e-03\n",
      "Epoch [50/100], Loss: 2.1504e-03\n",
      "Epoch [60/100], Loss: 2.0213e-03\n",
      "Epoch [70/100], Loss: 1.9289e-03\n",
      "Epoch [80/100], Loss: 1.8408e-03\n",
      "Epoch [90/100], Loss: 1.7722e-03\n",
      "Epoch [100/100], Loss: 1.7192e-03\n",
      "#####--training model 390--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5384e-03\n",
      "Epoch [20/100], Loss: 1.5312e-03\n",
      "Epoch [30/100], Loss: 1.5150e-03\n",
      "Epoch [40/100], Loss: 1.8414e-03\n",
      "Epoch [50/100], Loss: 1.7020e-03\n",
      "Epoch [60/100], Loss: 1.5952e-03\n",
      "Epoch [70/100], Loss: 1.7191e-03\n",
      "Epoch [80/100], Loss: 2.5304e-03\n",
      "Epoch [90/100], Loss: 2.2562e-03\n",
      "Epoch [100/100], Loss: 2.3908e-03\n",
      "#####--training model 391--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.3824e-04\n",
      "Epoch [20/100], Loss: 8.5511e-04\n",
      "Epoch [30/100], Loss: 7.7919e-04\n",
      "Epoch [40/100], Loss: 6.5933e-04\n",
      "Epoch [50/100], Loss: 6.6828e-04\n",
      "Epoch [60/100], Loss: 6.2478e-04\n",
      "Epoch [70/100], Loss: 5.7398e-04\n",
      "Epoch [80/100], Loss: 5.5077e-04\n",
      "Epoch [90/100], Loss: 5.4345e-04\n",
      "Epoch [100/100], Loss: 5.4386e-04\n",
      "#####--training model 392--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6185e-04\n",
      "Epoch [20/100], Loss: 8.2913e-04\n",
      "Epoch [30/100], Loss: 1.9341e-04\n",
      "Epoch [40/100], Loss: 3.3048e-05\n",
      "Epoch [50/100], Loss: 8.7552e-05\n",
      "Epoch [60/100], Loss: 1.8039e-04\n",
      "Epoch [70/100], Loss: 2.1546e-04\n",
      "Epoch [80/100], Loss: 2.0791e-04\n",
      "Epoch [90/100], Loss: 1.8537e-04\n",
      "Epoch [100/100], Loss: 1.6058e-04\n",
      "#####--training model 393--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.7939e-04\n",
      "Epoch [20/100], Loss: 2.9473e-04\n",
      "Epoch [30/100], Loss: 3.2471e-04\n",
      "Epoch [40/100], Loss: 5.9099e-04\n",
      "Epoch [50/100], Loss: 1.2501e-03\n",
      "Epoch [60/100], Loss: 7.0316e-04\n",
      "Epoch [70/100], Loss: 4.3021e-04\n",
      "Epoch [80/100], Loss: 3.7641e-04\n",
      "Epoch [90/100], Loss: 3.3725e-04\n",
      "Epoch [100/100], Loss: 3.1179e-04\n",
      "#####--training model 394--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.8656e-03\n",
      "Epoch [20/100], Loss: 6.2509e-03\n",
      "Epoch [30/100], Loss: 5.4578e-03\n",
      "Epoch [40/100], Loss: 5.0118e-03\n",
      "Epoch [50/100], Loss: 4.9861e-03\n",
      "Epoch [60/100], Loss: 5.2882e-03\n",
      "Epoch [70/100], Loss: 5.5048e-03\n",
      "Epoch [80/100], Loss: 5.5183e-03\n",
      "Epoch [90/100], Loss: 5.4950e-03\n",
      "Epoch [100/100], Loss: 5.4741e-03\n",
      "#####--training model 395--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8303e-03\n",
      "Epoch [20/100], Loss: 3.0301e-03\n",
      "Epoch [30/100], Loss: 3.7917e-03\n",
      "Epoch [40/100], Loss: 2.5330e-03\n",
      "Epoch [50/100], Loss: 2.6603e-03\n",
      "Epoch [60/100], Loss: 2.1864e-03\n",
      "Epoch [70/100], Loss: 1.7525e-03\n",
      "Epoch [80/100], Loss: 1.5081e-03\n",
      "Epoch [90/100], Loss: 1.3641e-03\n",
      "Epoch [100/100], Loss: 1.2740e-03\n",
      "#####--training model 396--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6397e-04\n",
      "Epoch [20/100], Loss: 5.9576e-05\n",
      "Epoch [30/100], Loss: 3.0641e-05\n",
      "Epoch [40/100], Loss: 1.8326e-05\n",
      "Epoch [50/100], Loss: 1.1910e-05\n",
      "Epoch [60/100], Loss: 8.1477e-06\n",
      "Epoch [70/100], Loss: 5.7668e-06\n",
      "Epoch [80/100], Loss: 4.1788e-06\n",
      "Epoch [90/100], Loss: 3.0795e-06\n",
      "Epoch [100/100], Loss: 2.2973e-06\n",
      "#####--training model 397--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.7599e-04\n",
      "Epoch [20/100], Loss: 6.9774e-04\n",
      "Epoch [30/100], Loss: 7.2067e-04\n",
      "Epoch [40/100], Loss: 7.4778e-04\n",
      "Epoch [50/100], Loss: 7.8803e-04\n",
      "Epoch [60/100], Loss: 8.8129e-04\n",
      "Epoch [70/100], Loss: 1.1217e-03\n",
      "Epoch [80/100], Loss: 1.0664e-03\n",
      "Epoch [90/100], Loss: 9.0288e-04\n",
      "Epoch [100/100], Loss: 7.9948e-04\n",
      "#####--training model 398--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0408e-03\n",
      "Epoch [20/100], Loss: 4.1297e-04\n",
      "Epoch [30/100], Loss: 4.1336e-04\n",
      "Epoch [40/100], Loss: 2.8741e-04\n",
      "Epoch [50/100], Loss: 2.7726e-04\n",
      "Epoch [60/100], Loss: 3.3224e-04\n",
      "Epoch [70/100], Loss: 3.7721e-04\n",
      "Epoch [80/100], Loss: 3.7014e-04\n",
      "Epoch [90/100], Loss: 3.2645e-04\n",
      "Epoch [100/100], Loss: 3.0574e-04\n",
      "#####--training model 399--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7243e-02\n",
      "Epoch [20/100], Loss: 1.6427e-02\n",
      "Epoch [30/100], Loss: 1.3082e-02\n",
      "Epoch [40/100], Loss: 1.1193e-02\n",
      "Epoch [50/100], Loss: 8.6751e-03\n",
      "Epoch [60/100], Loss: 7.2292e-03\n",
      "Epoch [70/100], Loss: 6.5021e-03\n",
      "Epoch [80/100], Loss: 5.8424e-03\n",
      "Epoch [90/100], Loss: 5.1241e-03\n",
      "Epoch [100/100], Loss: 4.4058e-03\n",
      "#####--training model 400--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7688e-02\n",
      "Epoch [20/100], Loss: 1.8474e-02\n",
      "Epoch [30/100], Loss: 1.8627e-02\n",
      "Epoch [40/100], Loss: 1.8653e-02\n",
      "Epoch [50/100], Loss: 1.8563e-02\n",
      "Epoch [60/100], Loss: 1.8910e-03\n",
      "Epoch [70/100], Loss: 2.5289e-03\n",
      "Epoch [80/100], Loss: 1.9761e-03\n",
      "Epoch [90/100], Loss: 1.8057e-03\n",
      "Epoch [100/100], Loss: 1.8254e-03\n",
      "#####--training model 401--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.6855e-04\n",
      "Epoch [20/100], Loss: 4.6065e-04\n",
      "Epoch [30/100], Loss: 4.5997e-04\n",
      "Epoch [40/100], Loss: 5.2292e-04\n",
      "Epoch [50/100], Loss: 5.7769e-04\n",
      "Epoch [60/100], Loss: 5.6155e-04\n",
      "Epoch [70/100], Loss: 5.5380e-04\n",
      "Epoch [80/100], Loss: 5.5593e-04\n",
      "Epoch [90/100], Loss: 5.6226e-04\n",
      "Epoch [100/100], Loss: 5.6563e-04\n",
      "#####--training model 402--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0451e-02\n",
      "Epoch [20/100], Loss: 2.0286e-04\n",
      "Epoch [30/100], Loss: 6.1933e-05\n",
      "Epoch [40/100], Loss: 1.2025e-04\n",
      "Epoch [50/100], Loss: 1.4856e-04\n",
      "Epoch [60/100], Loss: 1.7143e-04\n",
      "Epoch [70/100], Loss: 1.8630e-04\n",
      "Epoch [80/100], Loss: 1.9214e-04\n",
      "Epoch [90/100], Loss: 1.9127e-04\n",
      "Epoch [100/100], Loss: 1.8662e-04\n",
      "#####--training model 403--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8157e-02\n",
      "Epoch [20/100], Loss: 2.4510e-02\n",
      "Epoch [30/100], Loss: 1.5168e-03\n",
      "Epoch [40/100], Loss: 1.3567e-03\n",
      "Epoch [50/100], Loss: 1.6979e-03\n",
      "Epoch [60/100], Loss: 1.8987e-03\n",
      "Epoch [70/100], Loss: 1.8479e-03\n",
      "Epoch [80/100], Loss: 1.7391e-03\n",
      "Epoch [90/100], Loss: 1.6543e-03\n",
      "Epoch [100/100], Loss: 1.5952e-03\n",
      "#####--training model 404--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4613e-04\n",
      "Epoch [20/100], Loss: 6.9882e-05\n",
      "Epoch [30/100], Loss: 5.3194e-05\n",
      "Epoch [40/100], Loss: 4.8283e-05\n",
      "Epoch [50/100], Loss: 4.6948e-05\n",
      "Epoch [60/100], Loss: 4.6638e-05\n",
      "Epoch [70/100], Loss: 4.6518e-05\n",
      "Epoch [80/100], Loss: 4.6397e-05\n",
      "Epoch [90/100], Loss: 4.6251e-05\n",
      "Epoch [100/100], Loss: 4.6078e-05\n",
      "#####--training model 405--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.5472e-04\n",
      "Epoch [20/100], Loss: 5.1850e-04\n",
      "Epoch [30/100], Loss: 5.3422e-04\n",
      "Epoch [40/100], Loss: 5.7681e-04\n",
      "Epoch [50/100], Loss: 6.2559e-04\n",
      "Epoch [60/100], Loss: 5.4084e-04\n",
      "Epoch [70/100], Loss: 4.7417e-04\n",
      "Epoch [80/100], Loss: 3.8377e-04\n",
      "Epoch [90/100], Loss: 3.2730e-04\n",
      "Epoch [100/100], Loss: 2.8970e-04\n",
      "#####--training model 406--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3176e-04\n",
      "Epoch [20/100], Loss: 2.8373e-04\n",
      "Epoch [30/100], Loss: 2.9399e-04\n",
      "Epoch [40/100], Loss: 3.1315e-04\n",
      "Epoch [50/100], Loss: 3.4288e-04\n",
      "Epoch [60/100], Loss: 3.7427e-04\n",
      "Epoch [70/100], Loss: 4.0012e-04\n",
      "Epoch [80/100], Loss: 4.2239e-04\n",
      "Epoch [90/100], Loss: 4.3911e-04\n",
      "Epoch [100/100], Loss: 4.5109e-04\n",
      "#####--training model 407--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.1956e-05\n",
      "Epoch [20/100], Loss: 1.9612e-04\n",
      "Epoch [30/100], Loss: 4.0136e-04\n",
      "Epoch [40/100], Loss: 4.4149e-04\n",
      "Epoch [50/100], Loss: 4.3921e-04\n",
      "Epoch [60/100], Loss: 4.6590e-04\n",
      "Epoch [70/100], Loss: 5.2504e-04\n",
      "Epoch [80/100], Loss: 6.3495e-04\n",
      "Epoch [90/100], Loss: 8.1997e-04\n",
      "Epoch [100/100], Loss: 9.8844e-04\n",
      "#####--training model 408--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0248e-04\n",
      "Epoch [20/100], Loss: 3.7498e-05\n",
      "Epoch [30/100], Loss: 2.0513e-05\n",
      "Epoch [40/100], Loss: 1.2793e-05\n",
      "Epoch [50/100], Loss: 8.5521e-06\n",
      "Epoch [60/100], Loss: 5.9683e-06\n",
      "Epoch [70/100], Loss: 4.2863e-06\n",
      "Epoch [80/100], Loss: 3.1405e-06\n",
      "Epoch [90/100], Loss: 2.3342e-06\n",
      "Epoch [100/100], Loss: 1.7531e-06\n",
      "#####--training model 409--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2652e-03\n",
      "Epoch [20/100], Loss: 1.0690e-03\n",
      "Epoch [30/100], Loss: 8.6669e-04\n",
      "Epoch [40/100], Loss: 7.7193e-04\n",
      "Epoch [50/100], Loss: 6.9370e-04\n",
      "Epoch [60/100], Loss: 6.4202e-04\n",
      "Epoch [70/100], Loss: 6.1516e-04\n",
      "Epoch [80/100], Loss: 6.0169e-04\n",
      "Epoch [90/100], Loss: 5.9474e-04\n",
      "Epoch [100/100], Loss: 5.9004e-04\n",
      "#####--training model 410--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.5865e-04\n",
      "Epoch [20/100], Loss: 4.4269e-04\n",
      "Epoch [30/100], Loss: 4.5183e-04\n",
      "Epoch [40/100], Loss: 4.6446e-04\n",
      "Epoch [50/100], Loss: 4.8266e-04\n",
      "Epoch [60/100], Loss: 5.1270e-04\n",
      "Epoch [70/100], Loss: 6.1128e-04\n",
      "Epoch [80/100], Loss: 9.0718e-04\n",
      "Epoch [90/100], Loss: 8.6715e-04\n",
      "Epoch [100/100], Loss: 6.3736e-04\n",
      "#####--training model 411--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.2600e-04\n",
      "Epoch [20/100], Loss: 9.4786e-04\n",
      "Epoch [30/100], Loss: 9.9833e-04\n",
      "Epoch [40/100], Loss: 1.5421e-03\n",
      "Epoch [50/100], Loss: 1.6960e-03\n",
      "Epoch [60/100], Loss: 1.7097e-03\n",
      "Epoch [70/100], Loss: 1.7233e-03\n",
      "Epoch [80/100], Loss: 1.5589e-03\n",
      "Epoch [90/100], Loss: 1.4509e-03\n",
      "Epoch [100/100], Loss: 1.3870e-03\n",
      "#####--training model 412--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.2006e-03\n",
      "Epoch [20/100], Loss: 7.4724e-03\n",
      "Epoch [30/100], Loss: 6.6580e-03\n",
      "Epoch [40/100], Loss: 3.2512e-03\n",
      "Epoch [50/100], Loss: 2.3265e-03\n",
      "Epoch [60/100], Loss: 1.5084e-03\n",
      "Epoch [70/100], Loss: 9.5576e-04\n",
      "Epoch [80/100], Loss: 7.9350e-04\n",
      "Epoch [90/100], Loss: 7.5832e-04\n",
      "Epoch [100/100], Loss: 7.5247e-04\n",
      "#####--training model 413--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5209e-04\n",
      "Epoch [20/100], Loss: 1.2086e-04\n",
      "Epoch [30/100], Loss: 8.8519e-05\n",
      "Epoch [40/100], Loss: 7.6767e-05\n",
      "Epoch [50/100], Loss: 7.2794e-05\n",
      "Epoch [60/100], Loss: 7.2422e-05\n",
      "Epoch [70/100], Loss: 7.5002e-05\n",
      "Epoch [80/100], Loss: 8.7612e-05\n",
      "Epoch [90/100], Loss: 7.7734e-05\n",
      "Epoch [100/100], Loss: 9.5754e-05\n",
      "#####--training model 414--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.8474e-03\n",
      "Epoch [20/100], Loss: 4.2254e-03\n",
      "Epoch [30/100], Loss: 4.9256e-03\n",
      "Epoch [40/100], Loss: 5.1145e-03\n",
      "Epoch [50/100], Loss: 5.0524e-03\n",
      "Epoch [60/100], Loss: 5.1084e-03\n",
      "Epoch [70/100], Loss: 5.2876e-03\n",
      "Epoch [80/100], Loss: 5.2762e-03\n",
      "Epoch [90/100], Loss: 5.0880e-03\n",
      "Epoch [100/100], Loss: 4.7452e-03\n",
      "#####--training model 415--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3633e-03\n",
      "Epoch [20/100], Loss: 3.6680e-03\n",
      "Epoch [30/100], Loss: 3.6344e-03\n",
      "Epoch [40/100], Loss: 3.4911e-03\n",
      "Epoch [50/100], Loss: 3.4155e-03\n",
      "Epoch [60/100], Loss: 3.3901e-03\n",
      "Epoch [70/100], Loss: 3.3843e-03\n",
      "Epoch [80/100], Loss: 3.3585e-03\n",
      "Epoch [90/100], Loss: 3.2103e-03\n",
      "Epoch [100/100], Loss: 2.9160e-03\n",
      "#####--training model 416--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8720e-04\n",
      "Epoch [20/100], Loss: 3.1760e-04\n",
      "Epoch [30/100], Loss: 3.2374e-04\n",
      "Epoch [40/100], Loss: 3.5969e-04\n",
      "Epoch [50/100], Loss: 2.7289e-04\n",
      "Epoch [60/100], Loss: 3.0688e-04\n",
      "Epoch [70/100], Loss: 1.8735e-04\n",
      "Epoch [80/100], Loss: 1.3872e-04\n",
      "Epoch [90/100], Loss: 1.1213e-04\n",
      "Epoch [100/100], Loss: 1.0676e-04\n",
      "#####--training model 417--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.4845e-04\n",
      "Epoch [20/100], Loss: 8.3959e-04\n",
      "Epoch [30/100], Loss: 7.0369e-04\n",
      "Epoch [40/100], Loss: 4.7228e-04\n",
      "Epoch [50/100], Loss: 2.6253e-04\n",
      "Epoch [60/100], Loss: 1.4868e-04\n",
      "Epoch [70/100], Loss: 1.0670e-04\n",
      "Epoch [80/100], Loss: 9.0137e-05\n",
      "Epoch [90/100], Loss: 7.9584e-05\n",
      "Epoch [100/100], Loss: 7.0091e-05\n",
      "#####--training model 418--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6830e-04\n",
      "Epoch [20/100], Loss: 1.9150e-04\n",
      "Epoch [30/100], Loss: 1.8067e-04\n",
      "Epoch [40/100], Loss: 1.8088e-04\n",
      "Epoch [50/100], Loss: 1.8486e-04\n",
      "Epoch [60/100], Loss: 1.9291e-04\n",
      "Epoch [70/100], Loss: 2.0846e-04\n",
      "Epoch [80/100], Loss: 2.6379e-04\n",
      "Epoch [90/100], Loss: 2.2767e-04\n",
      "Epoch [100/100], Loss: 2.0334e-04\n",
      "#####--training model 419--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9782e-04\n",
      "Epoch [20/100], Loss: 1.1703e-04\n",
      "Epoch [30/100], Loss: 9.7618e-05\n",
      "Epoch [40/100], Loss: 9.2094e-05\n",
      "Epoch [50/100], Loss: 9.0458e-05\n",
      "Epoch [60/100], Loss: 8.9574e-05\n",
      "Epoch [70/100], Loss: 8.8673e-05\n",
      "Epoch [80/100], Loss: 8.7644e-05\n",
      "Epoch [90/100], Loss: 8.6489e-05\n",
      "Epoch [100/100], Loss: 8.5231e-05\n",
      "#####--training model 420--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4053e-03\n",
      "Epoch [20/100], Loss: 2.7301e-04\n",
      "Epoch [30/100], Loss: 2.7669e-04\n",
      "Epoch [40/100], Loss: 2.6485e-04\n",
      "Epoch [50/100], Loss: 2.2489e-04\n",
      "Epoch [60/100], Loss: 1.6793e-04\n",
      "Epoch [70/100], Loss: 1.1458e-04\n",
      "Epoch [80/100], Loss: 7.8866e-05\n",
      "Epoch [90/100], Loss: 5.6280e-05\n",
      "Epoch [100/100], Loss: 4.0572e-05\n",
      "#####--training model 421--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.8439e-04\n",
      "Epoch [20/100], Loss: 4.4286e-04\n",
      "Epoch [30/100], Loss: 5.1421e-04\n",
      "Epoch [40/100], Loss: 6.8151e-04\n",
      "Epoch [50/100], Loss: 4.8081e-04\n",
      "Epoch [60/100], Loss: 4.1615e-04\n",
      "Epoch [70/100], Loss: 3.8277e-04\n",
      "Epoch [80/100], Loss: 3.5895e-04\n",
      "Epoch [90/100], Loss: 3.3717e-04\n",
      "Epoch [100/100], Loss: 3.1582e-04\n",
      "#####--training model 422--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.1918e-03\n",
      "Epoch [20/100], Loss: 3.0248e-03\n",
      "Epoch [30/100], Loss: 2.8596e-03\n",
      "Epoch [40/100], Loss: 1.2385e-03\n",
      "Epoch [50/100], Loss: 1.0300e-03\n",
      "Epoch [60/100], Loss: 1.3672e-03\n",
      "Epoch [70/100], Loss: 8.8931e-04\n",
      "Epoch [80/100], Loss: 7.3015e-04\n",
      "Epoch [90/100], Loss: 6.7856e-04\n",
      "Epoch [100/100], Loss: 6.5322e-04\n",
      "#####--training model 423--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.6988e-04\n",
      "Epoch [20/100], Loss: 8.4291e-04\n",
      "Epoch [30/100], Loss: 9.1029e-04\n",
      "Epoch [40/100], Loss: 9.3657e-04\n",
      "Epoch [50/100], Loss: 9.3705e-04\n",
      "Epoch [60/100], Loss: 8.0083e-04\n",
      "Epoch [70/100], Loss: 9.3789e-04\n",
      "Epoch [80/100], Loss: 1.0273e-03\n",
      "Epoch [90/100], Loss: 1.0865e-03\n",
      "Epoch [100/100], Loss: 1.0336e-03\n",
      "#####--training model 424--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2038e-04\n",
      "Epoch [20/100], Loss: 1.7857e-04\n",
      "Epoch [30/100], Loss: 1.7540e-04\n",
      "Epoch [40/100], Loss: 1.7443e-04\n",
      "Epoch [50/100], Loss: 1.7557e-04\n",
      "Epoch [60/100], Loss: 1.6218e-04\n",
      "Epoch [70/100], Loss: 9.7008e-05\n",
      "Epoch [80/100], Loss: 7.9665e-05\n",
      "Epoch [90/100], Loss: 6.3686e-05\n",
      "Epoch [100/100], Loss: 5.7133e-05\n",
      "#####--training model 425--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.7200e-03\n",
      "Epoch [20/100], Loss: 2.2832e-03\n",
      "Epoch [30/100], Loss: 2.1815e-03\n",
      "Epoch [40/100], Loss: 2.1951e-03\n",
      "Epoch [50/100], Loss: 2.2037e-03\n",
      "Epoch [60/100], Loss: 2.0859e-03\n",
      "Epoch [70/100], Loss: 1.6366e-03\n",
      "Epoch [80/100], Loss: 1.4574e-03\n",
      "Epoch [90/100], Loss: 1.4354e-03\n",
      "Epoch [100/100], Loss: 1.4415e-03\n",
      "#####--training model 426--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4998e-03\n",
      "Epoch [20/100], Loss: 1.5365e-03\n",
      "Epoch [30/100], Loss: 1.6480e-03\n",
      "Epoch [40/100], Loss: 2.5302e-03\n",
      "Epoch [50/100], Loss: 2.1904e-03\n",
      "Epoch [60/100], Loss: 1.8727e-03\n",
      "Epoch [70/100], Loss: 1.9087e-03\n",
      "Epoch [80/100], Loss: 1.9633e-03\n",
      "Epoch [90/100], Loss: 2.0165e-03\n",
      "Epoch [100/100], Loss: 2.0628e-03\n",
      "#####--training model 427--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7851e-04\n",
      "Epoch [20/100], Loss: 7.7588e-05\n",
      "Epoch [30/100], Loss: 4.8666e-05\n",
      "Epoch [40/100], Loss: 3.6977e-05\n",
      "Epoch [50/100], Loss: 3.1848e-05\n",
      "Epoch [60/100], Loss: 2.9945e-05\n",
      "Epoch [70/100], Loss: 2.9731e-05\n",
      "Epoch [80/100], Loss: 3.2856e-05\n",
      "Epoch [90/100], Loss: 3.4119e-05\n",
      "Epoch [100/100], Loss: 4.6836e-05\n",
      "#####--training model 428--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8017e-04\n",
      "Epoch [20/100], Loss: 2.4154e-04\n",
      "Epoch [30/100], Loss: 2.4251e-04\n",
      "Epoch [40/100], Loss: 2.4768e-04\n",
      "Epoch [50/100], Loss: 2.6182e-04\n",
      "Epoch [60/100], Loss: 2.9109e-04\n",
      "Epoch [70/100], Loss: 3.3754e-04\n",
      "Epoch [80/100], Loss: 3.2445e-04\n",
      "Epoch [90/100], Loss: 2.6027e-04\n",
      "Epoch [100/100], Loss: 1.8529e-04\n",
      "#####--training model 429--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0906e-02\n",
      "Epoch [20/100], Loss: 1.1822e-02\n",
      "Epoch [30/100], Loss: 1.2789e-02\n",
      "Epoch [40/100], Loss: 1.3445e-02\n",
      "Epoch [50/100], Loss: 1.4186e-02\n",
      "Epoch [60/100], Loss: 1.5017e-02\n",
      "Epoch [70/100], Loss: 1.5787e-02\n",
      "Epoch [80/100], Loss: 1.6370e-02\n",
      "Epoch [90/100], Loss: 1.6590e-02\n",
      "Epoch [100/100], Loss: 1.6268e-02\n",
      "#####--training model 430--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.7792e-03\n",
      "Epoch [20/100], Loss: 5.0551e-03\n",
      "Epoch [30/100], Loss: 5.4957e-03\n",
      "Epoch [40/100], Loss: 6.3456e-03\n",
      "Epoch [50/100], Loss: 7.0208e-03\n",
      "Epoch [60/100], Loss: 7.2654e-03\n",
      "Epoch [70/100], Loss: 7.3724e-03\n",
      "Epoch [80/100], Loss: 7.4205e-03\n",
      "Epoch [90/100], Loss: 7.4414e-03\n",
      "Epoch [100/100], Loss: 7.4597e-03\n",
      "#####--training model 431--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.3988e-03\n",
      "Epoch [20/100], Loss: 1.4508e-03\n",
      "Epoch [30/100], Loss: 1.0345e-03\n",
      "Epoch [40/100], Loss: 9.0041e-04\n",
      "Epoch [50/100], Loss: 9.4936e-04\n",
      "Epoch [60/100], Loss: 9.0414e-04\n",
      "Epoch [70/100], Loss: 7.0558e-04\n",
      "Epoch [80/100], Loss: 5.3520e-04\n",
      "Epoch [90/100], Loss: 4.4999e-04\n",
      "Epoch [100/100], Loss: 3.4514e-04\n",
      "#####--training model 432--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3987e-04\n",
      "Epoch [20/100], Loss: 5.1876e-05\n",
      "Epoch [30/100], Loss: 2.6885e-05\n",
      "Epoch [40/100], Loss: 1.6142e-05\n",
      "Epoch [50/100], Loss: 1.0514e-05\n",
      "Epoch [60/100], Loss: 7.2032e-06\n",
      "Epoch [70/100], Loss: 5.1035e-06\n",
      "Epoch [80/100], Loss: 3.7010e-06\n",
      "Epoch [90/100], Loss: 2.7289e-06\n",
      "Epoch [100/100], Loss: 2.0368e-06\n",
      "#####--training model 433--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4965e-04\n",
      "Epoch [20/100], Loss: 1.3344e-04\n",
      "Epoch [30/100], Loss: 1.0235e-04\n",
      "Epoch [40/100], Loss: 9.1958e-05\n",
      "Epoch [50/100], Loss: 8.8897e-05\n",
      "Epoch [60/100], Loss: 8.8359e-05\n",
      "Epoch [70/100], Loss: 8.8509e-05\n",
      "Epoch [80/100], Loss: 8.8915e-05\n",
      "Epoch [90/100], Loss: 8.9805e-05\n",
      "Epoch [100/100], Loss: 9.2943e-05\n",
      "#####--training model 434--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.1528e-04\n",
      "Epoch [20/100], Loss: 5.3630e-04\n",
      "Epoch [30/100], Loss: 4.0737e-04\n",
      "Epoch [40/100], Loss: 1.6863e-04\n",
      "Epoch [50/100], Loss: 6.2141e-05\n",
      "Epoch [60/100], Loss: 4.9742e-05\n",
      "Epoch [70/100], Loss: 4.5882e-05\n",
      "Epoch [80/100], Loss: 4.3378e-05\n",
      "Epoch [90/100], Loss: 4.1408e-05\n",
      "Epoch [100/100], Loss: 3.9704e-05\n",
      "#####--training model 435--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6490e-01\n",
      "Epoch [20/100], Loss: 1.5458e-01\n",
      "Epoch [30/100], Loss: 1.4402e-01\n",
      "Epoch [40/100], Loss: 1.2574e-01\n",
      "Epoch [50/100], Loss: 1.0822e-01\n",
      "Epoch [60/100], Loss: 9.5160e-02\n",
      "Epoch [70/100], Loss: 8.4679e-02\n",
      "Epoch [80/100], Loss: 7.4526e-02\n",
      "Epoch [90/100], Loss: 6.8855e-02\n",
      "Epoch [100/100], Loss: 6.5728e-02\n",
      "#####--training model 436--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8128e-03\n",
      "Epoch [20/100], Loss: 4.1740e-03\n",
      "Epoch [30/100], Loss: 4.2469e-03\n",
      "Epoch [40/100], Loss: 4.2590e-03\n",
      "Epoch [50/100], Loss: 4.2608e-03\n",
      "Epoch [60/100], Loss: 4.2615e-03\n",
      "Epoch [70/100], Loss: 4.2619e-03\n",
      "Epoch [80/100], Loss: 4.2617e-03\n",
      "Epoch [90/100], Loss: 4.2585e-03\n",
      "Epoch [100/100], Loss: 4.2389e-03\n",
      "#####--training model 437--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0347e-03\n",
      "Epoch [20/100], Loss: 1.7219e-03\n",
      "Epoch [30/100], Loss: 1.0026e-03\n",
      "Epoch [40/100], Loss: 1.0749e-03\n",
      "Epoch [50/100], Loss: 1.1869e-03\n",
      "Epoch [60/100], Loss: 1.2674e-03\n",
      "Epoch [70/100], Loss: 1.3145e-03\n",
      "Epoch [80/100], Loss: 1.3477e-03\n",
      "Epoch [90/100], Loss: 1.3692e-03\n",
      "Epoch [100/100], Loss: 1.3830e-03\n",
      "#####--training model 438--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4581e-02\n",
      "Epoch [20/100], Loss: 2.7408e-02\n",
      "Epoch [30/100], Loss: 3.0521e-02\n",
      "Epoch [40/100], Loss: 3.3981e-02\n",
      "Epoch [50/100], Loss: 3.6108e-02\n",
      "Epoch [60/100], Loss: 3.7269e-02\n",
      "Epoch [70/100], Loss: 3.7806e-02\n",
      "Epoch [80/100], Loss: 3.7992e-02\n",
      "Epoch [90/100], Loss: 3.8026e-02\n",
      "Epoch [100/100], Loss: 3.7992e-02\n",
      "#####--training model 439--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.0593e-03\n",
      "Epoch [20/100], Loss: 4.3117e-03\n",
      "Epoch [30/100], Loss: 1.7749e-03\n",
      "Epoch [40/100], Loss: 1.3210e-03\n",
      "Epoch [50/100], Loss: 1.0631e-03\n",
      "Epoch [60/100], Loss: 9.0560e-04\n",
      "Epoch [70/100], Loss: 8.4468e-04\n",
      "Epoch [80/100], Loss: 8.2127e-04\n",
      "Epoch [90/100], Loss: 8.1362e-04\n",
      "Epoch [100/100], Loss: 8.0892e-04\n",
      "#####--training model 440--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.6700e-03\n",
      "Epoch [20/100], Loss: 5.7544e-03\n",
      "Epoch [30/100], Loss: 3.8677e-03\n",
      "Epoch [40/100], Loss: 2.8566e-03\n",
      "Epoch [50/100], Loss: 2.4736e-03\n",
      "Epoch [60/100], Loss: 2.3402e-03\n",
      "Epoch [70/100], Loss: 2.2596e-03\n",
      "Epoch [80/100], Loss: 2.1144e-03\n",
      "Epoch [90/100], Loss: 1.8874e-03\n",
      "Epoch [100/100], Loss: 1.6394e-03\n",
      "#####--training model 441--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9996e-03\n",
      "Epoch [20/100], Loss: 2.6738e-03\n",
      "Epoch [30/100], Loss: 2.6642e-03\n",
      "Epoch [40/100], Loss: 2.8306e-03\n",
      "Epoch [50/100], Loss: 2.9450e-03\n",
      "Epoch [60/100], Loss: 2.9782e-03\n",
      "Epoch [70/100], Loss: 2.9653e-03\n",
      "Epoch [80/100], Loss: 2.9160e-03\n",
      "Epoch [90/100], Loss: 2.8356e-03\n",
      "Epoch [100/100], Loss: 2.7219e-03\n",
      "#####--training model 442--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8815e-04\n",
      "Epoch [20/100], Loss: 1.5461e-04\n",
      "Epoch [30/100], Loss: 1.2380e-04\n",
      "Epoch [40/100], Loss: 1.1968e-04\n",
      "Epoch [50/100], Loss: 1.5381e-04\n",
      "Epoch [60/100], Loss: 2.4356e-04\n",
      "Epoch [70/100], Loss: 1.9988e-04\n",
      "Epoch [80/100], Loss: 1.2881e-04\n",
      "Epoch [90/100], Loss: 9.4097e-05\n",
      "Epoch [100/100], Loss: 7.8898e-05\n",
      "#####--training model 443--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1515e-03\n",
      "Epoch [20/100], Loss: 1.1178e-03\n",
      "Epoch [30/100], Loss: 1.1606e-03\n",
      "Epoch [40/100], Loss: 1.2260e-03\n",
      "Epoch [50/100], Loss: 1.2566e-03\n",
      "Epoch [60/100], Loss: 1.2661e-03\n",
      "Epoch [70/100], Loss: 1.2688e-03\n",
      "Epoch [80/100], Loss: 1.2729e-03\n",
      "Epoch [90/100], Loss: 1.2787e-03\n",
      "Epoch [100/100], Loss: 1.2839e-03\n",
      "#####--training model 444--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.2051e-02\n",
      "Epoch [20/100], Loss: 1.7599e-02\n",
      "Epoch [30/100], Loss: 1.2272e-02\n",
      "Epoch [40/100], Loss: 7.8224e-03\n",
      "Epoch [50/100], Loss: 5.9161e-03\n",
      "Epoch [60/100], Loss: 5.1749e-03\n",
      "Epoch [70/100], Loss: 4.5701e-03\n",
      "Epoch [80/100], Loss: 3.8417e-03\n",
      "Epoch [90/100], Loss: 3.1360e-03\n",
      "Epoch [100/100], Loss: 2.5665e-03\n",
      "#####--training model 445--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0145e-03\n",
      "Epoch [20/100], Loss: 9.5661e-04\n",
      "Epoch [30/100], Loss: 4.2494e-03\n",
      "Epoch [40/100], Loss: 3.1346e-03\n",
      "Epoch [50/100], Loss: 1.9919e-03\n",
      "Epoch [60/100], Loss: 1.8939e-03\n",
      "Epoch [70/100], Loss: 2.1552e-03\n",
      "Epoch [80/100], Loss: 2.3860e-03\n",
      "Epoch [90/100], Loss: 2.4401e-03\n",
      "Epoch [100/100], Loss: 2.4016e-03\n",
      "#####--training model 446--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8874e-05\n",
      "Epoch [20/100], Loss: 4.4728e-05\n",
      "Epoch [30/100], Loss: 3.4451e-05\n",
      "Epoch [40/100], Loss: 7.1707e-05\n",
      "Epoch [50/100], Loss: 1.0365e-03\n",
      "Epoch [60/100], Loss: 3.0579e-04\n",
      "Epoch [70/100], Loss: 1.4533e-04\n",
      "Epoch [80/100], Loss: 7.1943e-05\n",
      "Epoch [90/100], Loss: 5.0777e-05\n",
      "Epoch [100/100], Loss: 3.9651e-05\n",
      "#####--training model 447--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6507e-04\n",
      "Epoch [20/100], Loss: 2.7045e-04\n",
      "Epoch [30/100], Loss: 2.7010e-04\n",
      "Epoch [40/100], Loss: 1.9428e-03\n",
      "Epoch [50/100], Loss: 2.2061e-03\n",
      "Epoch [60/100], Loss: 2.0770e-03\n",
      "Epoch [70/100], Loss: 1.9414e-03\n",
      "Epoch [80/100], Loss: 1.8456e-03\n",
      "Epoch [90/100], Loss: 1.7862e-03\n",
      "Epoch [100/100], Loss: 1.7544e-03\n",
      "#####--training model 448--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1401e-04\n",
      "Epoch [20/100], Loss: 1.4968e-03\n",
      "Epoch [30/100], Loss: 3.0480e-03\n",
      "Epoch [40/100], Loss: 4.1277e-03\n",
      "Epoch [50/100], Loss: 4.9433e-03\n",
      "Epoch [60/100], Loss: 5.1142e-03\n",
      "Epoch [70/100], Loss: 5.4305e-03\n",
      "Epoch [80/100], Loss: 5.8370e-03\n",
      "Epoch [90/100], Loss: 6.2769e-03\n",
      "Epoch [100/100], Loss: 6.6703e-03\n",
      "#####--training model 449--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.6741e-03\n",
      "Epoch [20/100], Loss: 3.0406e-03\n",
      "Epoch [30/100], Loss: 2.4932e-03\n",
      "Epoch [40/100], Loss: 1.9559e-03\n",
      "Epoch [50/100], Loss: 1.3674e-03\n",
      "Epoch [60/100], Loss: 8.0912e-04\n",
      "Epoch [70/100], Loss: 5.6093e-04\n",
      "Epoch [80/100], Loss: 4.6166e-04\n",
      "Epoch [90/100], Loss: 4.0806e-04\n",
      "Epoch [100/100], Loss: 3.7961e-04\n",
      "#####--training model 450--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.7911e-02\n",
      "Epoch [20/100], Loss: 9.4477e-02\n",
      "Epoch [30/100], Loss: 1.1780e-02\n",
      "Epoch [40/100], Loss: 6.2014e-03\n",
      "Epoch [50/100], Loss: 2.9942e-03\n",
      "Epoch [60/100], Loss: 1.1711e-03\n",
      "Epoch [70/100], Loss: 8.6267e-04\n",
      "Epoch [80/100], Loss: 9.4067e-04\n",
      "Epoch [90/100], Loss: 1.0983e-03\n",
      "Epoch [100/100], Loss: 1.2028e-03\n",
      "#####--training model 451--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2623e-04\n",
      "Epoch [20/100], Loss: 4.6705e-05\n",
      "Epoch [30/100], Loss: 2.4172e-05\n",
      "Epoch [40/100], Loss: 1.4502e-05\n",
      "Epoch [50/100], Loss: 9.4418e-06\n",
      "Epoch [60/100], Loss: 6.4669e-06\n",
      "Epoch [70/100], Loss: 4.5809e-06\n",
      "Epoch [80/100], Loss: 3.3215e-06\n",
      "Epoch [90/100], Loss: 2.4489e-06\n",
      "Epoch [100/100], Loss: 1.8275e-06\n",
      "#####--training model 452--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3090e-04\n",
      "Epoch [20/100], Loss: 5.9386e-05\n",
      "Epoch [30/100], Loss: 3.6034e-05\n",
      "Epoch [40/100], Loss: 2.5298e-05\n",
      "Epoch [50/100], Loss: 1.9503e-05\n",
      "Epoch [60/100], Loss: 1.6084e-05\n",
      "Epoch [70/100], Loss: 1.3983e-05\n",
      "Epoch [80/100], Loss: 1.2692e-05\n",
      "Epoch [90/100], Loss: 1.1935e-05\n",
      "Epoch [100/100], Loss: 1.1533e-05\n",
      "#####--training model 453--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6829e-03\n",
      "Epoch [20/100], Loss: 2.0562e-03\n",
      "Epoch [30/100], Loss: 3.0160e-03\n",
      "Epoch [40/100], Loss: 2.5745e-03\n",
      "Epoch [50/100], Loss: 2.2210e-03\n",
      "Epoch [60/100], Loss: 2.1084e-03\n",
      "Epoch [70/100], Loss: 2.0928e-03\n",
      "Epoch [80/100], Loss: 2.0985e-03\n",
      "Epoch [90/100], Loss: 2.0484e-03\n",
      "Epoch [100/100], Loss: 1.9461e-03\n",
      "#####--training model 454--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4953e-03\n",
      "Epoch [20/100], Loss: 1.6027e-03\n",
      "Epoch [30/100], Loss: 2.0528e-03\n",
      "Epoch [40/100], Loss: 1.8749e-03\n",
      "Epoch [50/100], Loss: 1.1912e-03\n",
      "Epoch [60/100], Loss: 9.1574e-04\n",
      "Epoch [70/100], Loss: 7.0299e-04\n",
      "Epoch [80/100], Loss: 4.1354e-04\n",
      "Epoch [90/100], Loss: 2.4633e-04\n",
      "Epoch [100/100], Loss: 1.9324e-04\n",
      "#####--training model 455--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4240e-03\n",
      "Epoch [20/100], Loss: 1.2684e-02\n",
      "Epoch [30/100], Loss: 2.4259e-02\n",
      "Epoch [40/100], Loss: 3.0948e-02\n",
      "Epoch [50/100], Loss: 3.4643e-02\n",
      "Epoch [60/100], Loss: 3.4684e-02\n",
      "Epoch [70/100], Loss: 3.1163e-02\n",
      "Epoch [80/100], Loss: 2.1705e-02\n",
      "Epoch [90/100], Loss: 1.2490e-02\n",
      "Epoch [100/100], Loss: 8.9092e-03\n",
      "#####--training model 456--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4739e-04\n",
      "Epoch [20/100], Loss: 5.1828e-05\n",
      "Epoch [30/100], Loss: 2.6285e-05\n",
      "Epoch [40/100], Loss: 1.5608e-05\n",
      "Epoch [50/100], Loss: 1.0100e-05\n",
      "Epoch [60/100], Loss: 6.8904e-06\n",
      "Epoch [70/100], Loss: 4.8673e-06\n",
      "Epoch [80/100], Loss: 3.5218e-06\n",
      "Epoch [90/100], Loss: 2.5923e-06\n",
      "Epoch [100/100], Loss: 1.9320e-06\n",
      "#####--training model 457--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9988e-03\n",
      "Epoch [20/100], Loss: 2.4726e-03\n",
      "Epoch [30/100], Loss: 1.8014e-03\n",
      "Epoch [40/100], Loss: 1.9123e-03\n",
      "Epoch [50/100], Loss: 2.0262e-03\n",
      "Epoch [60/100], Loss: 2.1263e-03\n",
      "Epoch [70/100], Loss: 2.2184e-03\n",
      "Epoch [80/100], Loss: 2.3164e-03\n",
      "Epoch [90/100], Loss: 2.4145e-03\n",
      "Epoch [100/100], Loss: 2.5062e-03\n",
      "#####--training model 458--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5462e-04\n",
      "Epoch [20/100], Loss: 9.7534e-05\n",
      "Epoch [30/100], Loss: 5.5494e-05\n",
      "Epoch [40/100], Loss: 3.7376e-05\n",
      "Epoch [50/100], Loss: 2.7742e-05\n",
      "Epoch [60/100], Loss: 2.2001e-05\n",
      "Epoch [70/100], Loss: 1.8352e-05\n",
      "Epoch [80/100], Loss: 1.5959e-05\n",
      "Epoch [90/100], Loss: 1.4385e-05\n",
      "Epoch [100/100], Loss: 1.3372e-05\n",
      "#####--training model 459--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3679e-04\n",
      "Epoch [20/100], Loss: 2.7999e-04\n",
      "Epoch [30/100], Loss: 2.8960e-04\n",
      "Epoch [40/100], Loss: 2.8700e-04\n",
      "Epoch [50/100], Loss: 2.7868e-04\n",
      "Epoch [60/100], Loss: 2.4869e-04\n",
      "Epoch [70/100], Loss: 2.0603e-04\n",
      "Epoch [80/100], Loss: 2.9063e-04\n",
      "Epoch [90/100], Loss: 3.5539e-04\n",
      "Epoch [100/100], Loss: 3.7410e-04\n",
      "#####--training model 460--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.4371e-04\n",
      "Epoch [20/100], Loss: 4.7272e-04\n",
      "Epoch [30/100], Loss: 4.6818e-04\n",
      "Epoch [40/100], Loss: 4.6236e-04\n",
      "Epoch [50/100], Loss: 4.5468e-04\n",
      "Epoch [60/100], Loss: 4.4305e-04\n",
      "Epoch [70/100], Loss: 4.2476e-04\n",
      "Epoch [80/100], Loss: 4.0172e-04\n",
      "Epoch [90/100], Loss: 5.6956e-04\n",
      "Epoch [100/100], Loss: 4.8694e-04\n",
      "#####--training model 461--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.3408e-03\n",
      "Epoch [20/100], Loss: 7.3680e-03\n",
      "Epoch [30/100], Loss: 1.6623e-03\n",
      "Epoch [40/100], Loss: 6.9198e-04\n",
      "Epoch [50/100], Loss: 2.6838e-04\n",
      "Epoch [60/100], Loss: 2.1268e-04\n",
      "Epoch [70/100], Loss: 1.9488e-04\n",
      "Epoch [80/100], Loss: 1.8419e-04\n",
      "Epoch [90/100], Loss: 1.7727e-04\n",
      "Epoch [100/100], Loss: 1.7245e-04\n",
      "#####--training model 462--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6405e-02\n",
      "Epoch [20/100], Loss: 1.6671e-02\n",
      "Epoch [30/100], Loss: 1.3772e-02\n",
      "Epoch [40/100], Loss: 1.5101e-02\n",
      "Epoch [50/100], Loss: 1.6712e-02\n",
      "Epoch [60/100], Loss: 1.7950e-02\n",
      "Epoch [70/100], Loss: 1.8668e-02\n",
      "Epoch [80/100], Loss: 1.9117e-02\n",
      "Epoch [90/100], Loss: 1.9410e-02\n",
      "Epoch [100/100], Loss: 1.9602e-02\n",
      "#####--training model 463--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.8919e-02\n",
      "Epoch [20/100], Loss: 9.4734e-02\n",
      "Epoch [30/100], Loss: 8.7337e-02\n",
      "Epoch [40/100], Loss: 7.7767e-02\n",
      "Epoch [50/100], Loss: 6.7189e-02\n",
      "Epoch [60/100], Loss: 5.7106e-02\n",
      "Epoch [70/100], Loss: 4.8441e-02\n",
      "Epoch [80/100], Loss: 4.1587e-02\n",
      "Epoch [90/100], Loss: 3.6330e-02\n",
      "Epoch [100/100], Loss: 3.2060e-02\n",
      "#####--training model 464--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5264e-04\n",
      "Epoch [20/100], Loss: 1.5460e-04\n",
      "Epoch [30/100], Loss: 1.6319e-04\n",
      "Epoch [40/100], Loss: 1.6028e-04\n",
      "Epoch [50/100], Loss: 1.8874e-04\n",
      "Epoch [60/100], Loss: 1.8007e-04\n",
      "Epoch [70/100], Loss: 1.7227e-04\n",
      "Epoch [80/100], Loss: 1.6731e-04\n",
      "Epoch [90/100], Loss: 1.6298e-04\n",
      "Epoch [100/100], Loss: 1.5995e-04\n",
      "#####--training model 465--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.8647e-03\n",
      "Epoch [20/100], Loss: 1.8187e-03\n",
      "Epoch [30/100], Loss: 1.7904e-03\n",
      "Epoch [40/100], Loss: 1.7766e-03\n",
      "Epoch [50/100], Loss: 1.7860e-03\n",
      "Epoch [60/100], Loss: 1.7171e-03\n",
      "Epoch [70/100], Loss: 5.5158e-04\n",
      "Epoch [80/100], Loss: 1.8652e-04\n",
      "Epoch [90/100], Loss: 1.0429e-04\n",
      "Epoch [100/100], Loss: 7.6685e-05\n",
      "#####--training model 466--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.1162e-03\n",
      "Epoch [20/100], Loss: 9.0231e-03\n",
      "Epoch [30/100], Loss: 8.9318e-03\n",
      "Epoch [40/100], Loss: 8.7904e-03\n",
      "Epoch [50/100], Loss: 8.4620e-03\n",
      "Epoch [60/100], Loss: 7.2078e-03\n",
      "Epoch [70/100], Loss: 4.5594e-03\n",
      "Epoch [80/100], Loss: 3.4250e-03\n",
      "Epoch [90/100], Loss: 3.3050e-03\n",
      "Epoch [100/100], Loss: 3.3380e-03\n",
      "#####--training model 467--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6193e-04\n",
      "Epoch [20/100], Loss: 1.1182e-04\n",
      "Epoch [30/100], Loss: 1.0920e-04\n",
      "Epoch [40/100], Loss: 1.0907e-04\n",
      "Epoch [50/100], Loss: 1.0895e-04\n",
      "Epoch [60/100], Loss: 1.0881e-04\n",
      "Epoch [70/100], Loss: 1.0866e-04\n",
      "Epoch [80/100], Loss: 1.0854e-04\n",
      "Epoch [90/100], Loss: 1.0850e-04\n",
      "Epoch [100/100], Loss: 1.0875e-04\n",
      "#####--training model 468--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.0495e-03\n",
      "Epoch [20/100], Loss: 1.3128e-03\n",
      "Epoch [30/100], Loss: 7.3092e-04\n",
      "Epoch [40/100], Loss: 5.7936e-04\n",
      "Epoch [50/100], Loss: 5.3853e-04\n",
      "Epoch [60/100], Loss: 4.8141e-04\n",
      "Epoch [70/100], Loss: 3.9719e-04\n",
      "Epoch [80/100], Loss: 3.3396e-04\n",
      "Epoch [90/100], Loss: 2.9821e-04\n",
      "Epoch [100/100], Loss: 2.8191e-04\n",
      "#####--training model 469--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.8912e-03\n",
      "Epoch [20/100], Loss: 9.4426e-03\n",
      "Epoch [30/100], Loss: 9.5678e-03\n",
      "Epoch [40/100], Loss: 9.6126e-03\n",
      "Epoch [50/100], Loss: 9.6345e-03\n",
      "Epoch [60/100], Loss: 9.6095e-03\n",
      "Epoch [70/100], Loss: 1.0379e-02\n",
      "Epoch [80/100], Loss: 1.5959e-03\n",
      "Epoch [90/100], Loss: 1.7003e-03\n",
      "Epoch [100/100], Loss: 1.6182e-03\n",
      "#####--training model 470--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1835e-03\n",
      "Epoch [20/100], Loss: 1.1804e-03\n",
      "Epoch [30/100], Loss: 1.1591e-03\n",
      "Epoch [40/100], Loss: 8.1753e-04\n",
      "Epoch [50/100], Loss: 8.4072e-04\n",
      "Epoch [60/100], Loss: 8.7270e-04\n",
      "Epoch [70/100], Loss: 9.0668e-04\n",
      "Epoch [80/100], Loss: 9.2455e-04\n",
      "Epoch [90/100], Loss: 9.3314e-04\n",
      "Epoch [100/100], Loss: 9.4165e-04\n",
      "#####--training model 471--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.9576e-04\n",
      "Epoch [20/100], Loss: 4.8816e-04\n",
      "Epoch [30/100], Loss: 5.0086e-04\n",
      "Epoch [40/100], Loss: 5.2915e-04\n",
      "Epoch [50/100], Loss: 5.7620e-04\n",
      "Epoch [60/100], Loss: 6.3796e-04\n",
      "Epoch [70/100], Loss: 7.0749e-04\n",
      "Epoch [80/100], Loss: 7.6485e-04\n",
      "Epoch [90/100], Loss: 7.9464e-04\n",
      "Epoch [100/100], Loss: 7.9559e-04\n",
      "#####--training model 472--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.0748e-03\n",
      "Epoch [20/100], Loss: 5.7589e-03\n",
      "Epoch [30/100], Loss: 4.0977e-03\n",
      "Epoch [40/100], Loss: 2.7190e-03\n",
      "Epoch [50/100], Loss: 2.5317e-03\n",
      "Epoch [60/100], Loss: 2.6304e-03\n",
      "Epoch [70/100], Loss: 2.6958e-03\n",
      "Epoch [80/100], Loss: 2.7366e-03\n",
      "Epoch [90/100], Loss: 2.7608e-03\n",
      "Epoch [100/100], Loss: 2.7742e-03\n",
      "#####--training model 473--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2106e-03\n",
      "Epoch [20/100], Loss: 1.2048e-03\n",
      "Epoch [30/100], Loss: 1.1962e-03\n",
      "Epoch [40/100], Loss: 1.1504e-03\n",
      "Epoch [50/100], Loss: 7.8705e-04\n",
      "Epoch [60/100], Loss: 7.6849e-04\n",
      "Epoch [70/100], Loss: 7.4050e-04\n",
      "Epoch [80/100], Loss: 6.6581e-04\n",
      "Epoch [90/100], Loss: 6.7713e-04\n",
      "Epoch [100/100], Loss: 6.8656e-04\n",
      "#####--training model 474--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.4039e-02\n",
      "Epoch [20/100], Loss: 5.1437e-02\n",
      "Epoch [30/100], Loss: 4.6681e-02\n",
      "Epoch [40/100], Loss: 4.6901e-02\n",
      "Epoch [50/100], Loss: 4.8338e-02\n",
      "Epoch [60/100], Loss: 4.9391e-02\n",
      "Epoch [70/100], Loss: 4.9841e-02\n",
      "Epoch [80/100], Loss: 4.9921e-02\n",
      "Epoch [90/100], Loss: 4.9816e-02\n",
      "Epoch [100/100], Loss: 4.9611e-02\n",
      "#####--training model 475--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3310e-02\n",
      "Epoch [20/100], Loss: 2.1875e-02\n",
      "Epoch [30/100], Loss: 2.2601e-02\n",
      "Epoch [40/100], Loss: 2.3540e-02\n",
      "Epoch [50/100], Loss: 2.3985e-02\n",
      "Epoch [60/100], Loss: 2.3969e-02\n",
      "Epoch [70/100], Loss: 2.3678e-02\n",
      "Epoch [80/100], Loss: 2.3346e-02\n",
      "Epoch [90/100], Loss: 2.3091e-02\n",
      "Epoch [100/100], Loss: 2.2871e-02\n",
      "#####--training model 476--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.0832e-04\n",
      "Epoch [20/100], Loss: 6.8649e-04\n",
      "Epoch [30/100], Loss: 3.8582e-04\n",
      "Epoch [40/100], Loss: 2.4962e-04\n",
      "Epoch [50/100], Loss: 2.0543e-04\n",
      "Epoch [60/100], Loss: 1.8195e-04\n",
      "Epoch [70/100], Loss: 1.6815e-04\n",
      "Epoch [80/100], Loss: 1.6095e-04\n",
      "Epoch [90/100], Loss: 1.5725e-04\n",
      "Epoch [100/100], Loss: 1.5328e-04\n",
      "#####--training model 477--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4206e-03\n",
      "Epoch [20/100], Loss: 4.2943e-03\n",
      "Epoch [30/100], Loss: 4.5353e-03\n",
      "Epoch [40/100], Loss: 4.8920e-03\n",
      "Epoch [50/100], Loss: 5.0539e-03\n",
      "Epoch [60/100], Loss: 5.0423e-03\n",
      "Epoch [70/100], Loss: 4.9710e-03\n",
      "Epoch [80/100], Loss: 4.8948e-03\n",
      "Epoch [90/100], Loss: 4.8210e-03\n",
      "Epoch [100/100], Loss: 4.7399e-03\n",
      "#####--training model 478--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3259e-04\n",
      "Epoch [20/100], Loss: 1.0535e-03\n",
      "Epoch [30/100], Loss: 6.4864e-05\n",
      "Epoch [40/100], Loss: 5.5664e-05\n",
      "Epoch [50/100], Loss: 5.6842e-05\n",
      "Epoch [60/100], Loss: 6.0867e-05\n",
      "Epoch [70/100], Loss: 5.9233e-05\n",
      "Epoch [80/100], Loss: 5.8844e-05\n",
      "Epoch [90/100], Loss: 6.0867e-05\n",
      "Epoch [100/100], Loss: 6.4482e-05\n",
      "#####--training model 479--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.9386e-04\n",
      "Epoch [20/100], Loss: 1.0378e-03\n",
      "Epoch [30/100], Loss: 1.1214e-03\n",
      "Epoch [40/100], Loss: 1.1699e-03\n",
      "Epoch [50/100], Loss: 5.4719e-04\n",
      "Epoch [60/100], Loss: 3.0284e-04\n",
      "Epoch [70/100], Loss: 1.1536e-04\n",
      "Epoch [80/100], Loss: 7.7419e-05\n",
      "Epoch [90/100], Loss: 6.3288e-05\n",
      "Epoch [100/100], Loss: 5.5767e-05\n",
      "#####--training model 480--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.2473e-03\n",
      "Epoch [20/100], Loss: 3.9351e-03\n",
      "Epoch [30/100], Loss: 3.4318e-03\n",
      "Epoch [40/100], Loss: 3.0825e-03\n",
      "Epoch [50/100], Loss: 2.8963e-03\n",
      "Epoch [60/100], Loss: 2.7702e-03\n",
      "Epoch [70/100], Loss: 2.6794e-03\n",
      "Epoch [80/100], Loss: 2.5823e-03\n",
      "Epoch [90/100], Loss: 2.4582e-03\n",
      "Epoch [100/100], Loss: 2.3090e-03\n",
      "#####--training model 481--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.3572e-02\n",
      "Epoch [20/100], Loss: 3.9383e-03\n",
      "Epoch [30/100], Loss: 4.0080e-03\n",
      "Epoch [40/100], Loss: 4.1844e-03\n",
      "Epoch [50/100], Loss: 4.4234e-03\n",
      "Epoch [60/100], Loss: 4.6573e-03\n",
      "Epoch [70/100], Loss: 4.9661e-03\n",
      "Epoch [80/100], Loss: 5.6400e-03\n",
      "Epoch [90/100], Loss: 6.2397e-03\n",
      "Epoch [100/100], Loss: 6.2780e-03\n",
      "#####--training model 482--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.6712e-04\n",
      "Epoch [20/100], Loss: 3.2609e-04\n",
      "Epoch [30/100], Loss: 3.2266e-04\n",
      "Epoch [40/100], Loss: 3.2105e-04\n",
      "Epoch [50/100], Loss: 3.1813e-04\n",
      "Epoch [60/100], Loss: 2.7876e-04\n",
      "Epoch [70/100], Loss: 2.3742e-04\n",
      "Epoch [80/100], Loss: 2.4939e-04\n",
      "Epoch [90/100], Loss: 2.2803e-04\n",
      "Epoch [100/100], Loss: 1.9803e-04\n",
      "#####--training model 483--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8819e-03\n",
      "Epoch [20/100], Loss: 2.5897e-03\n",
      "Epoch [30/100], Loss: 3.7203e-03\n",
      "Epoch [40/100], Loss: 4.4323e-03\n",
      "Epoch [50/100], Loss: 4.2256e-03\n",
      "Epoch [60/100], Loss: 3.1872e-03\n",
      "Epoch [70/100], Loss: 2.5680e-03\n",
      "Epoch [80/100], Loss: 2.4695e-03\n",
      "Epoch [90/100], Loss: 2.4007e-03\n",
      "Epoch [100/100], Loss: 2.3329e-03\n",
      "#####--training model 484--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.8648e-04\n",
      "Epoch [20/100], Loss: 9.2792e-04\n",
      "Epoch [30/100], Loss: 8.7447e-04\n",
      "Epoch [40/100], Loss: 8.0096e-04\n",
      "Epoch [50/100], Loss: 6.2403e-04\n",
      "Epoch [60/100], Loss: 1.8822e-04\n",
      "Epoch [70/100], Loss: 1.7591e-04\n",
      "Epoch [80/100], Loss: 1.6102e-04\n",
      "Epoch [90/100], Loss: 1.4882e-04\n",
      "Epoch [100/100], Loss: 1.3330e-04\n",
      "#####--training model 485--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4332e-03\n",
      "Epoch [20/100], Loss: 3.6308e-03\n",
      "Epoch [30/100], Loss: 1.5977e-03\n",
      "Epoch [40/100], Loss: 1.2465e-03\n",
      "Epoch [50/100], Loss: 9.7721e-04\n",
      "Epoch [60/100], Loss: 7.8580e-04\n",
      "Epoch [70/100], Loss: 6.8573e-04\n",
      "Epoch [80/100], Loss: 6.2982e-04\n",
      "Epoch [90/100], Loss: 6.0770e-04\n",
      "Epoch [100/100], Loss: 5.6133e-04\n",
      "#####--training model 486--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.7804e-03\n",
      "Epoch [20/100], Loss: 3.7014e-03\n",
      "Epoch [30/100], Loss: 3.5420e-03\n",
      "Epoch [40/100], Loss: 2.8502e-03\n",
      "Epoch [50/100], Loss: 1.8573e-03\n",
      "Epoch [60/100], Loss: 1.0828e-03\n",
      "Epoch [70/100], Loss: 8.7531e-04\n",
      "Epoch [80/100], Loss: 8.0824e-04\n",
      "Epoch [90/100], Loss: 7.6376e-04\n",
      "Epoch [100/100], Loss: 7.1403e-04\n",
      "#####--training model 487--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4068e-03\n",
      "Epoch [20/100], Loss: 5.2139e-03\n",
      "Epoch [30/100], Loss: 2.6706e-03\n",
      "Epoch [40/100], Loss: 5.2824e-04\n",
      "Epoch [50/100], Loss: 1.4809e-04\n",
      "Epoch [60/100], Loss: 1.4948e-04\n",
      "Epoch [70/100], Loss: 1.4636e-04\n",
      "Epoch [80/100], Loss: 1.2142e-04\n",
      "Epoch [90/100], Loss: 8.6307e-05\n",
      "Epoch [100/100], Loss: 5.7274e-05\n",
      "#####--training model 488--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.9994e-04\n",
      "Epoch [20/100], Loss: 4.0638e-04\n",
      "Epoch [30/100], Loss: 3.9175e-04\n",
      "Epoch [40/100], Loss: 3.8322e-04\n",
      "Epoch [50/100], Loss: 3.7404e-04\n",
      "Epoch [60/100], Loss: 3.6352e-04\n",
      "Epoch [70/100], Loss: 3.5118e-04\n",
      "Epoch [80/100], Loss: 3.3570e-04\n",
      "Epoch [90/100], Loss: 3.1424e-04\n",
      "Epoch [100/100], Loss: 2.7504e-04\n",
      "#####--training model 489--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4169e-03\n",
      "Epoch [20/100], Loss: 8.8992e-03\n",
      "Epoch [30/100], Loss: 5.7150e-03\n",
      "Epoch [40/100], Loss: 3.3847e-03\n",
      "Epoch [50/100], Loss: 2.3851e-03\n",
      "Epoch [60/100], Loss: 2.1977e-03\n",
      "Epoch [70/100], Loss: 2.3350e-03\n",
      "Epoch [80/100], Loss: 2.6100e-03\n",
      "Epoch [90/100], Loss: 2.8594e-03\n",
      "Epoch [100/100], Loss: 3.0204e-03\n",
      "#####--training model 490--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.7364e-03\n",
      "Epoch [20/100], Loss: 4.8820e-03\n",
      "Epoch [30/100], Loss: 3.3957e-03\n",
      "Epoch [40/100], Loss: 2.4664e-03\n",
      "Epoch [50/100], Loss: 2.0284e-03\n",
      "Epoch [60/100], Loss: 1.8068e-03\n",
      "Epoch [70/100], Loss: 1.6626e-03\n",
      "Epoch [80/100], Loss: 1.5421e-03\n",
      "Epoch [90/100], Loss: 1.4376e-03\n",
      "Epoch [100/100], Loss: 1.3470e-03\n",
      "#####--training model 491--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.6636e-03\n",
      "Epoch [20/100], Loss: 4.3746e-03\n",
      "Epoch [30/100], Loss: 3.6500e-03\n",
      "Epoch [40/100], Loss: 3.4867e-03\n",
      "Epoch [50/100], Loss: 3.4662e-03\n",
      "Epoch [60/100], Loss: 3.4672e-03\n",
      "Epoch [70/100], Loss: 3.4666e-03\n",
      "Epoch [80/100], Loss: 3.4615e-03\n",
      "Epoch [90/100], Loss: 3.4562e-03\n",
      "Epoch [100/100], Loss: 3.4559e-03\n",
      "#####--training model 492--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1849e-02\n",
      "Epoch [20/100], Loss: 1.2009e-02\n",
      "Epoch [30/100], Loss: 1.1920e-02\n",
      "Epoch [40/100], Loss: 6.8736e-03\n",
      "Epoch [50/100], Loss: 4.9812e-03\n",
      "Epoch [60/100], Loss: 3.6723e-03\n",
      "Epoch [70/100], Loss: 3.5246e-03\n",
      "Epoch [80/100], Loss: 3.4881e-03\n",
      "Epoch [90/100], Loss: 3.4908e-03\n",
      "Epoch [100/100], Loss: 3.5061e-03\n",
      "#####--training model 493--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9161e-03\n",
      "Epoch [20/100], Loss: 2.8333e-03\n",
      "Epoch [30/100], Loss: 2.6641e-03\n",
      "Epoch [40/100], Loss: 6.8026e-04\n",
      "Epoch [50/100], Loss: 4.8317e-04\n",
      "Epoch [60/100], Loss: 5.8535e-04\n",
      "Epoch [70/100], Loss: 7.0446e-04\n",
      "Epoch [80/100], Loss: 6.5973e-04\n",
      "Epoch [90/100], Loss: 6.2781e-04\n",
      "Epoch [100/100], Loss: 6.1414e-04\n",
      "#####--training model 494--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.4504e-03\n",
      "Epoch [20/100], Loss: 5.2584e-03\n",
      "Epoch [30/100], Loss: 3.4013e-03\n",
      "Epoch [40/100], Loss: 2.9129e-03\n",
      "Epoch [50/100], Loss: 2.7465e-03\n",
      "Epoch [60/100], Loss: 2.6265e-03\n",
      "Epoch [70/100], Loss: 2.4568e-03\n",
      "Epoch [80/100], Loss: 2.0912e-03\n",
      "Epoch [90/100], Loss: 1.2017e-03\n",
      "Epoch [100/100], Loss: 4.7436e-04\n",
      "#####--training model 495--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0321e-03\n",
      "Epoch [20/100], Loss: 9.0896e-04\n",
      "Epoch [30/100], Loss: 1.9693e-03\n",
      "Epoch [40/100], Loss: 3.1992e-03\n",
      "Epoch [50/100], Loss: 4.3679e-03\n",
      "Epoch [60/100], Loss: 5.3246e-03\n",
      "Epoch [70/100], Loss: 5.8635e-03\n",
      "Epoch [80/100], Loss: 6.0952e-03\n",
      "Epoch [90/100], Loss: 6.2613e-03\n",
      "Epoch [100/100], Loss: 6.4616e-03\n",
      "#####--training model 496--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.7320e-03\n",
      "Epoch [20/100], Loss: 8.5784e-03\n",
      "Epoch [30/100], Loss: 8.7510e-03\n",
      "Epoch [40/100], Loss: 7.3821e-03\n",
      "Epoch [50/100], Loss: 5.9624e-03\n",
      "Epoch [60/100], Loss: 5.0862e-03\n",
      "Epoch [70/100], Loss: 4.5940e-03\n",
      "Epoch [80/100], Loss: 4.3328e-03\n",
      "Epoch [90/100], Loss: 4.1967e-03\n",
      "Epoch [100/100], Loss: 4.1275e-03\n",
      "#####--training model 497--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4603e-04\n",
      "Epoch [20/100], Loss: 5.6743e-05\n",
      "Epoch [30/100], Loss: 3.0268e-05\n",
      "Epoch [40/100], Loss: 1.8602e-05\n",
      "Epoch [50/100], Loss: 1.2409e-05\n",
      "Epoch [60/100], Loss: 8.7289e-06\n",
      "Epoch [70/100], Loss: 6.3702e-06\n",
      "Epoch [80/100], Loss: 4.7756e-06\n",
      "Epoch [90/100], Loss: 3.6550e-06\n",
      "Epoch [100/100], Loss: 2.8447e-06\n",
      "#####--training model 498--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1296e-03\n",
      "Epoch [20/100], Loss: 1.1154e-03\n",
      "Epoch [30/100], Loss: 1.1089e-03\n",
      "Epoch [40/100], Loss: 1.0742e-03\n",
      "Epoch [50/100], Loss: 7.7313e-04\n",
      "Epoch [60/100], Loss: 6.7054e-04\n",
      "Epoch [70/100], Loss: 5.8193e-04\n",
      "Epoch [80/100], Loss: 4.0170e-04\n",
      "Epoch [90/100], Loss: 1.8548e-04\n",
      "Epoch [100/100], Loss: 7.1926e-05\n",
      "#####--training model 499--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0552e-04\n",
      "Epoch [20/100], Loss: 4.6383e-05\n",
      "Epoch [30/100], Loss: 9.9039e-05\n",
      "Epoch [40/100], Loss: 2.0779e-04\n",
      "Epoch [50/100], Loss: 3.0851e-04\n",
      "Epoch [60/100], Loss: 4.4705e-04\n",
      "Epoch [70/100], Loss: 5.6152e-04\n",
      "Epoch [80/100], Loss: 4.6886e-04\n",
      "Epoch [90/100], Loss: 4.0430e-04\n",
      "Epoch [100/100], Loss: 3.7411e-04\n",
      "#####--training model 500--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1382e-02\n",
      "Epoch [20/100], Loss: 7.8817e-03\n",
      "Epoch [30/100], Loss: 5.5337e-03\n",
      "Epoch [40/100], Loss: 3.7988e-03\n",
      "Epoch [50/100], Loss: 2.9904e-03\n",
      "Epoch [60/100], Loss: 2.4346e-03\n",
      "Epoch [70/100], Loss: 2.0851e-03\n",
      "Epoch [80/100], Loss: 1.8750e-03\n",
      "Epoch [90/100], Loss: 1.7374e-03\n",
      "Epoch [100/100], Loss: 1.6344e-03\n",
      "#####--training model 501--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.3453e-04\n",
      "Epoch [20/100], Loss: 4.7314e-04\n",
      "Epoch [30/100], Loss: 5.2264e-04\n",
      "Epoch [40/100], Loss: 7.9143e-04\n",
      "Epoch [50/100], Loss: 3.1618e-04\n",
      "Epoch [60/100], Loss: 1.5547e-04\n",
      "Epoch [70/100], Loss: 7.7991e-05\n",
      "Epoch [80/100], Loss: 5.4046e-05\n",
      "Epoch [90/100], Loss: 4.9014e-05\n",
      "Epoch [100/100], Loss: 4.7874e-05\n",
      "#####--training model 502--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3468e-04\n",
      "Epoch [20/100], Loss: 5.0821e-05\n",
      "Epoch [30/100], Loss: 2.7233e-05\n",
      "Epoch [40/100], Loss: 1.6923e-05\n",
      "Epoch [50/100], Loss: 1.1410e-05\n",
      "Epoch [60/100], Loss: 8.0979e-06\n",
      "Epoch [70/100], Loss: 5.9526e-06\n",
      "Epoch [80/100], Loss: 4.4893e-06\n",
      "Epoch [90/100], Loss: 3.4536e-06\n",
      "Epoch [100/100], Loss: 2.7003e-06\n",
      "#####--training model 503--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.0003e-02\n",
      "Epoch [20/100], Loss: 3.9817e-02\n",
      "Epoch [30/100], Loss: 3.9631e-02\n",
      "Epoch [40/100], Loss: 3.9366e-02\n",
      "Epoch [50/100], Loss: 3.8865e-02\n",
      "Epoch [60/100], Loss: 3.7636e-02\n",
      "Epoch [70/100], Loss: 2.8330e-02\n",
      "Epoch [80/100], Loss: 1.6516e-02\n",
      "Epoch [90/100], Loss: 1.2852e-02\n",
      "Epoch [100/100], Loss: 1.1733e-02\n",
      "#####--training model 504--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6357e-04\n",
      "Epoch [20/100], Loss: 5.7135e-05\n",
      "Epoch [30/100], Loss: 2.9155e-05\n",
      "Epoch [40/100], Loss: 1.7413e-05\n",
      "Epoch [50/100], Loss: 1.1315e-05\n",
      "Epoch [60/100], Loss: 7.7403e-06\n",
      "Epoch [70/100], Loss: 5.4773e-06\n",
      "Epoch [80/100], Loss: 3.9675e-06\n",
      "Epoch [90/100], Loss: 2.9222e-06\n",
      "Epoch [100/100], Loss: 2.1785e-06\n",
      "#####--training model 505--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1431e-03\n",
      "Epoch [20/100], Loss: 1.1438e-03\n",
      "Epoch [30/100], Loss: 1.1292e-03\n",
      "Epoch [40/100], Loss: 1.0896e-03\n",
      "Epoch [50/100], Loss: 9.8288e-04\n",
      "Epoch [60/100], Loss: 6.1908e-04\n",
      "Epoch [70/100], Loss: 6.1885e-04\n",
      "Epoch [80/100], Loss: 7.6347e-04\n",
      "Epoch [90/100], Loss: 7.6144e-04\n",
      "Epoch [100/100], Loss: 6.6162e-04\n",
      "#####--training model 506--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.1385e-02\n",
      "Epoch [20/100], Loss: 5.1858e-02\n",
      "Epoch [30/100], Loss: 5.1899e-02\n",
      "Epoch [40/100], Loss: 5.1883e-02\n",
      "Epoch [50/100], Loss: 5.1852e-02\n",
      "Epoch [60/100], Loss: 5.1802e-02\n",
      "Epoch [70/100], Loss: 5.1707e-02\n",
      "Epoch [80/100], Loss: 5.1508e-02\n",
      "Epoch [90/100], Loss: 5.1102e-02\n",
      "Epoch [100/100], Loss: 5.0325e-02\n",
      "#####--training model 507--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3993e-03\n",
      "Epoch [20/100], Loss: 1.4314e-03\n",
      "Epoch [30/100], Loss: 1.5274e-03\n",
      "Epoch [40/100], Loss: 1.4390e-03\n",
      "Epoch [50/100], Loss: 1.0736e-03\n",
      "Epoch [60/100], Loss: 9.2383e-04\n",
      "Epoch [70/100], Loss: 8.7016e-04\n",
      "Epoch [80/100], Loss: 8.5737e-04\n",
      "Epoch [90/100], Loss: 8.6330e-04\n",
      "Epoch [100/100], Loss: 8.6077e-04\n",
      "#####--training model 508--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.5298e-04\n",
      "Epoch [20/100], Loss: 5.8738e-04\n",
      "Epoch [30/100], Loss: 7.8425e-04\n",
      "Epoch [40/100], Loss: 1.0652e-03\n",
      "Epoch [50/100], Loss: 9.0835e-04\n",
      "Epoch [60/100], Loss: 7.8522e-04\n",
      "Epoch [70/100], Loss: 8.5815e-04\n",
      "Epoch [80/100], Loss: 9.8252e-04\n",
      "Epoch [90/100], Loss: 9.8757e-04\n",
      "Epoch [100/100], Loss: 9.9721e-04\n",
      "#####--training model 509--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2626e-04\n",
      "Epoch [20/100], Loss: 4.8435e-05\n",
      "Epoch [30/100], Loss: 2.9922e-05\n",
      "Epoch [40/100], Loss: 2.3534e-05\n",
      "Epoch [50/100], Loss: 2.1228e-05\n",
      "Epoch [60/100], Loss: 2.0466e-05\n",
      "Epoch [70/100], Loss: 2.0188e-05\n",
      "Epoch [80/100], Loss: 1.9989e-05\n",
      "Epoch [90/100], Loss: 1.9764e-05\n",
      "Epoch [100/100], Loss: 1.9496e-05\n",
      "#####--training model 510--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5187e-04\n",
      "Epoch [20/100], Loss: 1.8155e-04\n",
      "Epoch [30/100], Loss: 1.7949e-04\n",
      "Epoch [40/100], Loss: 1.9672e-04\n",
      "Epoch [50/100], Loss: 3.4694e-04\n",
      "Epoch [60/100], Loss: 5.9476e-04\n",
      "Epoch [70/100], Loss: 4.9245e-04\n",
      "Epoch [80/100], Loss: 3.9062e-04\n",
      "Epoch [90/100], Loss: 2.2433e-04\n",
      "Epoch [100/100], Loss: 1.0977e-04\n",
      "#####--training model 511--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8276e-04\n",
      "Epoch [20/100], Loss: 2.7530e-04\n",
      "Epoch [30/100], Loss: 2.5873e-04\n",
      "Epoch [40/100], Loss: 2.5371e-04\n",
      "Epoch [50/100], Loss: 2.5305e-04\n",
      "Epoch [60/100], Loss: 1.2534e-04\n",
      "Epoch [70/100], Loss: 6.5923e-05\n",
      "Epoch [80/100], Loss: 5.2271e-05\n",
      "Epoch [90/100], Loss: 4.1926e-05\n",
      "Epoch [100/100], Loss: 3.6752e-05\n",
      "#####--training model 512--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.0964e-03\n",
      "Epoch [20/100], Loss: 3.8001e-03\n",
      "Epoch [30/100], Loss: 2.0558e-03\n",
      "Epoch [40/100], Loss: 1.2182e-03\n",
      "Epoch [50/100], Loss: 1.0379e-03\n",
      "Epoch [60/100], Loss: 9.6432e-04\n",
      "Epoch [70/100], Loss: 9.2527e-04\n",
      "Epoch [80/100], Loss: 9.0376e-04\n",
      "Epoch [90/100], Loss: 8.6836e-04\n",
      "Epoch [100/100], Loss: 8.8489e-04\n",
      "#####--training model 513--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1482e-03\n",
      "Epoch [20/100], Loss: 1.2817e-03\n",
      "Epoch [30/100], Loss: 1.3280e-03\n",
      "Epoch [40/100], Loss: 1.3433e-03\n",
      "Epoch [50/100], Loss: 1.3471e-03\n",
      "Epoch [60/100], Loss: 1.3474e-03\n",
      "Epoch [70/100], Loss: 1.3471e-03\n",
      "Epoch [80/100], Loss: 1.3466e-03\n",
      "Epoch [90/100], Loss: 1.3458e-03\n",
      "Epoch [100/100], Loss: 1.3444e-03\n",
      "#####--training model 514--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.6941e-03\n",
      "Epoch [20/100], Loss: 7.3848e-03\n",
      "Epoch [30/100], Loss: 3.7024e-03\n",
      "Epoch [40/100], Loss: 2.3661e-03\n",
      "Epoch [50/100], Loss: 1.4497e-03\n",
      "Epoch [60/100], Loss: 1.1930e-03\n",
      "Epoch [70/100], Loss: 1.0838e-03\n",
      "Epoch [80/100], Loss: 1.0059e-03\n",
      "Epoch [90/100], Loss: 9.3890e-04\n",
      "Epoch [100/100], Loss: 8.8089e-04\n",
      "#####--training model 515--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2977e-04\n",
      "Epoch [20/100], Loss: 4.8188e-05\n",
      "Epoch [30/100], Loss: 2.5374e-05\n",
      "Epoch [40/100], Loss: 1.5567e-05\n",
      "Epoch [50/100], Loss: 1.0397e-05\n",
      "Epoch [60/100], Loss: 7.3268e-06\n",
      "Epoch [70/100], Loss: 5.3571e-06\n",
      "Epoch [80/100], Loss: 4.0242e-06\n",
      "Epoch [90/100], Loss: 3.0868e-06\n",
      "Epoch [100/100], Loss: 2.4088e-06\n",
      "#####--training model 516--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.5796e-04\n",
      "Epoch [20/100], Loss: 6.4867e-04\n",
      "Epoch [30/100], Loss: 6.2466e-04\n",
      "Epoch [40/100], Loss: 4.3650e-04\n",
      "Epoch [50/100], Loss: 4.5658e-04\n",
      "Epoch [60/100], Loss: 4.3228e-04\n",
      "Epoch [70/100], Loss: 4.1833e-04\n",
      "Epoch [80/100], Loss: 4.0690e-04\n",
      "Epoch [90/100], Loss: 3.9829e-04\n",
      "Epoch [100/100], Loss: 3.9295e-04\n",
      "#####--training model 517--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2474e-03\n",
      "Epoch [20/100], Loss: 2.2918e-03\n",
      "Epoch [30/100], Loss: 8.2570e-04\n",
      "Epoch [40/100], Loss: 6.1470e-04\n",
      "Epoch [50/100], Loss: 4.5640e-04\n",
      "Epoch [60/100], Loss: 3.7773e-04\n",
      "Epoch [70/100], Loss: 3.5129e-04\n",
      "Epoch [80/100], Loss: 3.4401e-04\n",
      "Epoch [90/100], Loss: 3.5677e-04\n",
      "Epoch [100/100], Loss: 3.9688e-04\n",
      "#####--training model 518--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5713e-03\n",
      "Epoch [20/100], Loss: 1.6790e-03\n",
      "Epoch [30/100], Loss: 2.3775e-03\n",
      "Epoch [40/100], Loss: 1.2502e-03\n",
      "Epoch [50/100], Loss: 1.1631e-03\n",
      "Epoch [60/100], Loss: 1.0899e-03\n",
      "Epoch [70/100], Loss: 9.9896e-04\n",
      "Epoch [80/100], Loss: 9.0289e-04\n",
      "Epoch [90/100], Loss: 8.1586e-04\n",
      "Epoch [100/100], Loss: 7.3102e-04\n",
      "#####--training model 519--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.3169e-04\n",
      "Epoch [20/100], Loss: 5.9011e-04\n",
      "Epoch [30/100], Loss: 6.4073e-04\n",
      "Epoch [40/100], Loss: 7.2957e-04\n",
      "Epoch [50/100], Loss: 6.1647e-04\n",
      "Epoch [60/100], Loss: 4.8161e-04\n",
      "Epoch [70/100], Loss: 3.7931e-04\n",
      "Epoch [80/100], Loss: 3.0113e-04\n",
      "Epoch [90/100], Loss: 2.3955e-04\n",
      "Epoch [100/100], Loss: 1.8581e-04\n",
      "#####--training model 520--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7709e-04\n",
      "Epoch [20/100], Loss: 7.2909e-05\n",
      "Epoch [30/100], Loss: 4.3690e-05\n",
      "Epoch [40/100], Loss: 3.1230e-05\n",
      "Epoch [50/100], Loss: 2.4911e-05\n",
      "Epoch [60/100], Loss: 2.1498e-05\n",
      "Epoch [70/100], Loss: 1.9686e-05\n",
      "Epoch [80/100], Loss: 1.8814e-05\n",
      "Epoch [90/100], Loss: 1.8472e-05\n",
      "Epoch [100/100], Loss: 1.8387e-05\n",
      "#####--training model 521--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.6092e-04\n",
      "Epoch [20/100], Loss: 4.3355e-04\n",
      "Epoch [30/100], Loss: 4.4064e-04\n",
      "Epoch [40/100], Loss: 4.4921e-04\n",
      "Epoch [50/100], Loss: 4.5861e-04\n",
      "Epoch [60/100], Loss: 4.6922e-04\n",
      "Epoch [70/100], Loss: 4.8255e-04\n",
      "Epoch [80/100], Loss: 5.0448e-04\n",
      "Epoch [90/100], Loss: 5.5096e-04\n",
      "Epoch [100/100], Loss: 6.1659e-04\n",
      "#####--training model 522--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.4743e-04\n",
      "Epoch [20/100], Loss: 6.7508e-04\n",
      "Epoch [30/100], Loss: 6.9873e-04\n",
      "Epoch [40/100], Loss: 7.2779e-04\n",
      "Epoch [50/100], Loss: 7.8732e-04\n",
      "Epoch [60/100], Loss: 1.0543e-03\n",
      "Epoch [70/100], Loss: 3.8550e-04\n",
      "Epoch [80/100], Loss: 1.3347e-04\n",
      "Epoch [90/100], Loss: 9.8562e-05\n",
      "Epoch [100/100], Loss: 8.8670e-05\n",
      "#####--training model 523--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.6832e-04\n",
      "Epoch [20/100], Loss: 1.0576e-03\n",
      "Epoch [30/100], Loss: 1.3221e-03\n",
      "Epoch [40/100], Loss: 9.8798e-04\n",
      "Epoch [50/100], Loss: 8.1047e-04\n",
      "Epoch [60/100], Loss: 7.3041e-04\n",
      "Epoch [70/100], Loss: 6.8668e-04\n",
      "Epoch [80/100], Loss: 6.4792e-04\n",
      "Epoch [90/100], Loss: 6.1806e-04\n",
      "Epoch [100/100], Loss: 5.9798e-04\n",
      "#####--training model 524--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4383e-04\n",
      "Epoch [20/100], Loss: 2.8499e-04\n",
      "Epoch [30/100], Loss: 2.8543e-04\n",
      "Epoch [40/100], Loss: 2.9181e-04\n",
      "Epoch [50/100], Loss: 3.0089e-04\n",
      "Epoch [60/100], Loss: 3.1110e-04\n",
      "Epoch [70/100], Loss: 3.3932e-04\n",
      "Epoch [80/100], Loss: 4.8713e-04\n",
      "Epoch [90/100], Loss: 5.1985e-04\n",
      "Epoch [100/100], Loss: 2.8915e-04\n",
      "#####--training model 525--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0903e-04\n",
      "Epoch [20/100], Loss: 2.1307e-04\n",
      "Epoch [30/100], Loss: 1.9714e-04\n",
      "Epoch [40/100], Loss: 1.9596e-04\n",
      "Epoch [50/100], Loss: 1.9707e-04\n",
      "Epoch [60/100], Loss: 1.9865e-04\n",
      "Epoch [70/100], Loss: 2.0075e-04\n",
      "Epoch [80/100], Loss: 2.0405e-04\n",
      "Epoch [90/100], Loss: 2.1096e-04\n",
      "Epoch [100/100], Loss: 2.1794e-04\n",
      "#####--training model 526--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6054e-03\n",
      "Epoch [20/100], Loss: 1.3980e-03\n",
      "Epoch [30/100], Loss: 8.9701e-04\n",
      "Epoch [40/100], Loss: 6.4186e-04\n",
      "Epoch [50/100], Loss: 2.9385e-04\n",
      "Epoch [60/100], Loss: 1.1854e-04\n",
      "Epoch [70/100], Loss: 8.1244e-05\n",
      "Epoch [80/100], Loss: 6.8712e-05\n",
      "Epoch [90/100], Loss: 6.2265e-05\n",
      "Epoch [100/100], Loss: 5.8767e-05\n",
      "#####--training model 527--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6676e-03\n",
      "Epoch [20/100], Loss: 1.7268e-03\n",
      "Epoch [30/100], Loss: 1.9164e-03\n",
      "Epoch [40/100], Loss: 2.4846e-03\n",
      "Epoch [50/100], Loss: 2.1275e-03\n",
      "Epoch [60/100], Loss: 1.8113e-03\n",
      "Epoch [70/100], Loss: 1.7335e-03\n",
      "Epoch [80/100], Loss: 1.7574e-03\n",
      "Epoch [90/100], Loss: 1.6565e-03\n",
      "Epoch [100/100], Loss: 1.5316e-03\n",
      "#####--training model 528--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1767e-04\n",
      "Epoch [20/100], Loss: 4.2808e-05\n",
      "Epoch [30/100], Loss: 2.1974e-05\n",
      "Epoch [40/100], Loss: 1.3129e-05\n",
      "Epoch [50/100], Loss: 8.5282e-06\n",
      "Epoch [60/100], Loss: 5.8326e-06\n",
      "Epoch [70/100], Loss: 4.1274e-06\n",
      "Epoch [80/100], Loss: 2.9905e-06\n",
      "Epoch [90/100], Loss: 2.2035e-06\n",
      "Epoch [100/100], Loss: 1.6437e-06\n"
     ]
    }
   ],
   "source": [
    "folder_name  = 'models_od\\\\'\n",
    "\n",
    "for feature in range(num_features): \n",
    "\n",
    "    print('#####--training model %d--#####\\n' % feature)\n",
    "    \n",
    "    # Get model and optimizer\n",
    "    model = models[feature]\n",
    "    optimizer = optimizers[feature]\n",
    "\n",
    "    # Create training dataset and dataloader for current feature\n",
    "    train_loader = get_dataloader(np.expand_dims(trainX[:, :, feature], axis = 2), np.expand_dims(trainY[:, feature], axis = 1),\n",
    "                                   batch_size, num_workers, shuffle)\n",
    "    \n",
    "    # Train the model\n",
    "    loss = train(model, train_loader, epochs, criterion, optimizer)\n",
    "\n",
    "    # Save the model, we will get model outputs in a later loop\n",
    "    model_name = 'model_%d.pth' % feature\n",
    "    model_path = folder_name+model_name\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros((test_data.shape[0]-10, test_data.shape[1]))\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for i in range(529):\n",
    "    path = 'models_od\\\\model_%d.pth' % i\n",
    "    model = RNN(input_size, hidden_size, num_layers)\n",
    "    model.load_state_dict(torch.load(path, weights_only=True))\n",
    "    model.eval()\n",
    "\n",
    "    testX_i = np.expand_dims(testX[:, :, i], axis = 2)\n",
    "    testY_i = np.expand_dims(testY[:, i], axis = 1)\n",
    "\n",
    "    # Create test_loader\n",
    "    test_loader = get_dataloader(testX_i, testY_i,\n",
    "                                batch_size, num_workers, shuffle)\n",
    "\n",
    "    total_loss = 0.0 \n",
    "\n",
    "    model_outputs = [] # account for window size\n",
    "    test_loss = np.zeros((testY_i.shape[0], 1))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, targets) in enumerate(test_loader): \n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            model_outputs.append(outputs.flatten())\n",
    "\n",
    "\n",
    "    # Concatenate all outputs into a single tensor\n",
    "    model_outputs =  torch.cat(model_outputs, dim=0).numpy()\n",
    "\n",
    "    # Save the model_outputs\n",
    "    np.save('model_outputs_od\\\\geant_local_mse_od_%i.npy' % i, \n",
    "        model_outputs)\n",
    "\n",
    "    # Inverse normalize the prediction\n",
    "    inverse_preds = model_outputs * (max_vals_test[i] - min_vals_test[i]) + min_vals_test[i]\n",
    "\n",
    "    # Add inverse normalized predictions to largers matrix\n",
    "    predictions[:, i] = inverse_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_save_heatmap(test_data/1e5, predictions/1e5, num_nodes=23, save_path = 'Figs\\\\heat_maps',\n",
    "                          fig_name= 'inverse_normalized_model_predictions_local.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-10\n"
     ]
    }
   ],
   "source": [
    "# Compute MCF on inverse normalized predictions\n",
    "mlu_preds, Nans = mlu_on_preds(predictions, num_nodes=23, capacity = 1e7, topo='fc')\n",
    "\n",
    "if Nans: \n",
    "    print('NaN values in mlu_preds, ending program')\n",
    "\n",
    "# Save MLUs\n",
    "np.save('mlu_baseline\\\\mlu_preds_geant_local_mse.npy', mlu_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MCF baseline on original dataset\n",
    "mlu_gt = np.load('mlu_baseline\\\\mlu_baseline_geant_fc.npy')\n",
    "mlu_gt = mlu_gt[len(train_data):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mlu cdf and mlu comparison\n",
    "plot_and_save_ecdf(mlu_gt, mlu_preds, save_path = 'Figs\\\\ecdfs', fig_name='CDF_mlu_geant_local_mse.png')\n",
    "plot_and_save_mlu_compare(mlu_gt, mlu_preds, save_path='Figs\\\\mlu_compare', fig_name='mlu_compare_geant_local_mse.png')\n",
    "plot_and_save_pdf(mlu_gt, mlu_preds, save_path = 'Figs\\\\pdfs', fig_name='PDF_mlu_geant_local_mse.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all predictions\n",
    "for i in range(144):\n",
    "    plt.plot(test_data[10:, i], label = 'Original')\n",
    "    plt.plot(predictions[:, i], label = 'Prediction')\n",
    "    plt.xlabel('Time Index')\n",
    "    plt.ylabel('Traffic Demand (bps)')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.savefig('Figs\\\\od_pairs\\\\prediction_local_%d.png' % i, dpi = 300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
