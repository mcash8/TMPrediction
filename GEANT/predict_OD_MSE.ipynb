{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "from torch.autograd import *\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from utils import * \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Geant Dataset\n",
    "data = read_geant_data()\n",
    "start_idx = 0 \n",
    "end_idx = int((60/15)*24*21) # three weeks of data (same number of samples as abilene for 1 week)\n",
    "data = data[start_idx:end_idx]\n",
    "\n",
    "# Train Test Split \n",
    "train_data, test_data = train_test_split(data, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-wise min-max normalization (normalize each element over time)\n",
    "min_vals_train = train_data.min(axis=0)  # Shape (144,)\n",
    "max_vals_train = train_data.max(axis=0)  # Shape (144,)\n",
    "train_data_norm = (train_data - min_vals_train) / (max_vals_train - min_vals_train + 1e-8)  # Avoid division by zero\n",
    "\n",
    "# Feature-wise min-max normalization (normalize each element over time)\n",
    "min_vals_test = test_data.min(axis=0)  # Shape (144,)\n",
    "max_vals_test = test_data.max(axis=0)  # Shape (144,)\n",
    "test_data_norm = (test_data - min_vals_test) / (max_vals_test - min_vals_test + 1e-8)  # Avoid division by zero\n",
    "\n",
    "# Window the dataset\n",
    "trainX, trainY= create_dataset(train_data_norm, 10) \n",
    "testX, testY = create_dataset(test_data_norm, 10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyper parameters \n",
    "input_size = 1  # Each feature is treated as an individual time series\n",
    "hidden_size = 30\n",
    "num_layers = 1\n",
    "learn_rate = 0.001 \n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "num_features = 23 * 23  # Total number of features in the flattened traffic matrix\n",
    "shuffle = False #don't want to lose the time dependency\n",
    "num_workers = 0  # Number of subprocesses to use for data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a separate model for each feature in the traffic matrix\n",
    "models = [RNN(input_size, hidden_size, num_layers) for _ in range(num_features)]\n",
    "optimizers = [optim.Adam(model.parameters(), lr=learn_rate) for model in models]\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####--training model 0--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2278e-04\n",
      "Epoch [20/100], Loss: 1.4211e-03\n",
      "Epoch [30/100], Loss: 1.9306e-03\n",
      "Epoch [40/100], Loss: 2.7916e-03\n",
      "Epoch [50/100], Loss: 3.6398e-03\n",
      "Epoch [60/100], Loss: 4.0653e-03\n",
      "Epoch [70/100], Loss: 3.6213e-03\n",
      "Epoch [80/100], Loss: 3.1896e-03\n",
      "Epoch [90/100], Loss: 3.0066e-03\n",
      "Epoch [100/100], Loss: 2.9712e-03\n",
      "#####--training model 1--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3607e-02\n",
      "Epoch [20/100], Loss: 1.7870e-02\n",
      "Epoch [30/100], Loss: 1.1440e-02\n",
      "Epoch [40/100], Loss: 6.9626e-03\n",
      "Epoch [50/100], Loss: 5.3262e-03\n",
      "Epoch [60/100], Loss: 4.7486e-03\n",
      "Epoch [70/100], Loss: 4.4519e-03\n",
      "Epoch [80/100], Loss: 4.2378e-03\n",
      "Epoch [90/100], Loss: 4.0588e-03\n",
      "Epoch [100/100], Loss: 3.8988e-03\n",
      "#####--training model 2--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0468e-03\n",
      "Epoch [20/100], Loss: 1.0840e-03\n",
      "Epoch [30/100], Loss: 1.0944e-03\n",
      "Epoch [40/100], Loss: 1.0948e-03\n",
      "Epoch [50/100], Loss: 1.7449e-03\n",
      "Epoch [60/100], Loss: 1.5267e-03\n",
      "Epoch [70/100], Loss: 1.2161e-03\n",
      "Epoch [80/100], Loss: 1.8150e-03\n",
      "Epoch [90/100], Loss: 2.1555e-03\n",
      "Epoch [100/100], Loss: 2.1387e-03\n",
      "#####--training model 3--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.5954e-03\n",
      "Epoch [20/100], Loss: 1.0643e-02\n",
      "Epoch [30/100], Loss: 1.8442e-02\n",
      "Epoch [40/100], Loss: 2.5388e-02\n",
      "Epoch [50/100], Loss: 2.8953e-02\n",
      "Epoch [60/100], Loss: 3.0627e-02\n",
      "Epoch [70/100], Loss: 3.1279e-02\n",
      "Epoch [80/100], Loss: 3.0953e-02\n",
      "Epoch [90/100], Loss: 2.9507e-02\n",
      "Epoch [100/100], Loss: 2.7613e-02\n",
      "#####--training model 4--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3026e-03\n",
      "Epoch [20/100], Loss: 4.0047e-04\n",
      "Epoch [30/100], Loss: 2.6752e-04\n",
      "Epoch [40/100], Loss: 2.0802e-04\n",
      "Epoch [50/100], Loss: 1.6362e-04\n",
      "Epoch [60/100], Loss: 1.2172e-04\n",
      "Epoch [70/100], Loss: 7.9438e-05\n",
      "Epoch [80/100], Loss: 4.7655e-05\n",
      "Epoch [90/100], Loss: 2.9931e-05\n",
      "Epoch [100/100], Loss: 2.2775e-05\n",
      "#####--training model 5--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4886e-03\n",
      "Epoch [20/100], Loss: 7.0949e-04\n",
      "Epoch [30/100], Loss: 2.1309e-04\n",
      "Epoch [40/100], Loss: 7.4687e-05\n",
      "Epoch [50/100], Loss: 4.0092e-05\n",
      "Epoch [60/100], Loss: 2.6039e-05\n",
      "Epoch [70/100], Loss: 1.8922e-05\n",
      "Epoch [80/100], Loss: 1.4454e-05\n",
      "Epoch [90/100], Loss: 1.1001e-05\n",
      "Epoch [100/100], Loss: 8.2648e-06\n",
      "#####--training model 6--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2902e-03\n",
      "Epoch [20/100], Loss: 1.5101e-03\n",
      "Epoch [30/100], Loss: 2.2317e-03\n",
      "Epoch [40/100], Loss: 3.0599e-03\n",
      "Epoch [50/100], Loss: 3.6754e-03\n",
      "Epoch [60/100], Loss: 4.0792e-03\n",
      "Epoch [70/100], Loss: 4.3629e-03\n",
      "Epoch [80/100], Loss: 4.5696e-03\n",
      "Epoch [90/100], Loss: 4.7094e-03\n",
      "Epoch [100/100], Loss: 4.8011e-03\n",
      "#####--training model 7--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3058e-03\n",
      "Epoch [20/100], Loss: 1.3747e-03\n",
      "Epoch [30/100], Loss: 2.8348e-04\n",
      "Epoch [40/100], Loss: 1.1807e-04\n",
      "Epoch [50/100], Loss: 7.3242e-05\n",
      "Epoch [60/100], Loss: 5.0132e-05\n",
      "Epoch [70/100], Loss: 3.5393e-05\n",
      "Epoch [80/100], Loss: 2.2299e-05\n",
      "Epoch [90/100], Loss: 1.2432e-05\n",
      "Epoch [100/100], Loss: 7.4553e-06\n",
      "#####--training model 8--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.8673e-03\n",
      "Epoch [20/100], Loss: 4.5963e-04\n",
      "Epoch [30/100], Loss: 1.9496e-04\n",
      "Epoch [40/100], Loss: 1.3502e-04\n",
      "Epoch [50/100], Loss: 9.2059e-05\n",
      "Epoch [60/100], Loss: 6.5756e-05\n",
      "Epoch [70/100], Loss: 4.5960e-05\n",
      "Epoch [80/100], Loss: 3.1127e-05\n",
      "Epoch [90/100], Loss: 2.1200e-05\n",
      "Epoch [100/100], Loss: 1.5080e-05\n",
      "#####--training model 9--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3760e-02\n",
      "Epoch [20/100], Loss: 3.4408e-02\n",
      "Epoch [30/100], Loss: 3.3966e-02\n",
      "Epoch [40/100], Loss: 9.8968e-03\n",
      "Epoch [50/100], Loss: 1.7386e-02\n",
      "Epoch [60/100], Loss: 1.7168e-02\n",
      "Epoch [70/100], Loss: 2.0334e-02\n",
      "Epoch [80/100], Loss: 1.8967e-02\n",
      "Epoch [90/100], Loss: 1.5279e-02\n",
      "Epoch [100/100], Loss: 1.4948e-02\n",
      "#####--training model 10--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6708e-04\n",
      "Epoch [20/100], Loss: 1.9468e-04\n",
      "Epoch [30/100], Loss: 1.8939e-04\n",
      "Epoch [40/100], Loss: 1.9119e-04\n",
      "Epoch [50/100], Loss: 1.9372e-04\n",
      "Epoch [60/100], Loss: 1.9666e-04\n",
      "Epoch [70/100], Loss: 1.9995e-04\n",
      "Epoch [80/100], Loss: 2.0347e-04\n",
      "Epoch [90/100], Loss: 2.0704e-04\n",
      "Epoch [100/100], Loss: 2.1045e-04\n",
      "#####--training model 11--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.0212e-03\n",
      "Epoch [20/100], Loss: 1.2733e-03\n",
      "Epoch [30/100], Loss: 1.0176e-03\n",
      "Epoch [40/100], Loss: 6.6122e-04\n",
      "Epoch [50/100], Loss: 5.2207e-04\n",
      "Epoch [60/100], Loss: 5.4650e-04\n",
      "Epoch [70/100], Loss: 5.7407e-04\n",
      "Epoch [80/100], Loss: 5.8057e-04\n",
      "Epoch [90/100], Loss: 5.7521e-04\n",
      "Epoch [100/100], Loss: 5.7681e-04\n",
      "#####--training model 12--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1909e-03\n",
      "Epoch [20/100], Loss: 3.6783e-04\n",
      "Epoch [30/100], Loss: 1.2190e-03\n",
      "Epoch [40/100], Loss: 1.0781e-03\n",
      "Epoch [50/100], Loss: 9.4851e-04\n",
      "Epoch [60/100], Loss: 8.3569e-04\n",
      "Epoch [70/100], Loss: 7.4226e-04\n",
      "Epoch [80/100], Loss: 6.8118e-04\n",
      "Epoch [90/100], Loss: 6.4466e-04\n",
      "Epoch [100/100], Loss: 6.0292e-04\n",
      "#####--training model 13--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7024e-04\n",
      "Epoch [20/100], Loss: 7.2905e-05\n",
      "Epoch [30/100], Loss: 4.7832e-05\n",
      "Epoch [40/100], Loss: 3.8495e-05\n",
      "Epoch [50/100], Loss: 3.4810e-05\n",
      "Epoch [60/100], Loss: 3.3523e-05\n",
      "Epoch [70/100], Loss: 3.3179e-05\n",
      "Epoch [80/100], Loss: 3.3113e-05\n",
      "Epoch [90/100], Loss: 3.3097e-05\n",
      "Epoch [100/100], Loss: 3.3085e-05\n",
      "#####--training model 14--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.2280e-03\n",
      "Epoch [20/100], Loss: 4.1722e-03\n",
      "Epoch [30/100], Loss: 4.2174e-03\n",
      "Epoch [40/100], Loss: 4.2764e-03\n",
      "Epoch [50/100], Loss: 4.6004e-03\n",
      "Epoch [60/100], Loss: 4.7679e-03\n",
      "Epoch [70/100], Loss: 4.8049e-03\n",
      "Epoch [80/100], Loss: 4.8178e-03\n",
      "Epoch [90/100], Loss: 4.8153e-03\n",
      "Epoch [100/100], Loss: 4.8193e-03\n",
      "#####--training model 15--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7537e-01\n",
      "Epoch [20/100], Loss: 2.2536e-02\n",
      "Epoch [30/100], Loss: 2.3221e-02\n",
      "Epoch [40/100], Loss: 2.4015e-02\n",
      "Epoch [50/100], Loss: 2.4679e-02\n",
      "Epoch [60/100], Loss: 2.5126e-02\n",
      "Epoch [70/100], Loss: 2.5267e-02\n",
      "Epoch [80/100], Loss: 2.5111e-02\n",
      "Epoch [90/100], Loss: 2.4809e-02\n",
      "Epoch [100/100], Loss: 2.4502e-02\n",
      "#####--training model 16--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.5100e-03\n",
      "Epoch [20/100], Loss: 3.9318e-03\n",
      "Epoch [30/100], Loss: 3.6421e-03\n",
      "Epoch [40/100], Loss: 3.0338e-03\n",
      "Epoch [50/100], Loss: 2.5578e-03\n",
      "Epoch [60/100], Loss: 2.2273e-03\n",
      "Epoch [70/100], Loss: 2.0045e-03\n",
      "Epoch [80/100], Loss: 1.8605e-03\n",
      "Epoch [90/100], Loss: 1.7565e-03\n",
      "Epoch [100/100], Loss: 1.6695e-03\n",
      "#####--training model 17--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6472e-03\n",
      "Epoch [20/100], Loss: 1.1001e-03\n",
      "Epoch [30/100], Loss: 7.5551e-04\n",
      "Epoch [40/100], Loss: 4.9987e-04\n",
      "Epoch [50/100], Loss: 4.1468e-04\n",
      "Epoch [60/100], Loss: 4.6037e-04\n",
      "Epoch [70/100], Loss: 5.3589e-04\n",
      "Epoch [80/100], Loss: 5.8444e-04\n",
      "Epoch [90/100], Loss: 6.1276e-04\n",
      "Epoch [100/100], Loss: 6.3303e-04\n",
      "#####--training model 18--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.0356e-04\n",
      "Epoch [20/100], Loss: 1.0113e-03\n",
      "Epoch [30/100], Loss: 1.1126e-03\n",
      "Epoch [40/100], Loss: 2.2086e-03\n",
      "Epoch [50/100], Loss: 2.9084e-03\n",
      "Epoch [60/100], Loss: 2.8086e-03\n",
      "Epoch [70/100], Loss: 2.3687e-03\n",
      "Epoch [80/100], Loss: 2.0138e-03\n",
      "Epoch [90/100], Loss: 1.7931e-03\n",
      "Epoch [100/100], Loss: 1.6449e-03\n",
      "#####--training model 19--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0323e-03\n",
      "Epoch [20/100], Loss: 1.9973e-03\n",
      "Epoch [30/100], Loss: 1.9508e-03\n",
      "Epoch [40/100], Loss: 1.8870e-03\n",
      "Epoch [50/100], Loss: 1.7557e-03\n",
      "Epoch [60/100], Loss: 1.4735e-03\n",
      "Epoch [70/100], Loss: 1.5497e-03\n",
      "Epoch [80/100], Loss: 2.7472e-03\n",
      "Epoch [90/100], Loss: 3.6050e-03\n",
      "Epoch [100/100], Loss: 4.1101e-03\n",
      "#####--training model 20--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0966e-01\n",
      "Epoch [20/100], Loss: 8.8058e-02\n",
      "Epoch [30/100], Loss: 5.3443e-02\n",
      "Epoch [40/100], Loss: 2.5083e-02\n",
      "Epoch [50/100], Loss: 1.0565e-02\n",
      "Epoch [60/100], Loss: 6.4646e-03\n",
      "Epoch [70/100], Loss: 5.7342e-03\n",
      "Epoch [80/100], Loss: 5.1329e-03\n",
      "Epoch [90/100], Loss: 4.3899e-03\n",
      "Epoch [100/100], Loss: 3.7271e-03\n",
      "#####--training model 21--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1314e-02\n",
      "Epoch [20/100], Loss: 1.0599e-02\n",
      "Epoch [30/100], Loss: 1.0967e-02\n",
      "Epoch [40/100], Loss: 1.1991e-02\n",
      "Epoch [50/100], Loss: 1.2827e-02\n",
      "Epoch [60/100], Loss: 1.3287e-02\n",
      "Epoch [70/100], Loss: 1.3434e-02\n",
      "Epoch [80/100], Loss: 1.3375e-02\n",
      "Epoch [90/100], Loss: 1.3198e-02\n",
      "Epoch [100/100], Loss: 1.2960e-02\n",
      "#####--training model 22--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2982e-04\n",
      "Epoch [20/100], Loss: 1.7427e-04\n",
      "Epoch [30/100], Loss: 1.7518e-04\n",
      "Epoch [40/100], Loss: 1.8270e-04\n",
      "Epoch [50/100], Loss: 1.9852e-04\n",
      "Epoch [60/100], Loss: 2.5727e-04\n",
      "Epoch [70/100], Loss: 4.1781e-04\n",
      "Epoch [80/100], Loss: 3.5726e-04\n",
      "Epoch [90/100], Loss: 3.2080e-04\n",
      "Epoch [100/100], Loss: 2.2631e-04\n",
      "#####--training model 23--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.0857e-02\n",
      "Epoch [20/100], Loss: 1.5306e-02\n",
      "Epoch [30/100], Loss: 7.8942e-03\n",
      "Epoch [40/100], Loss: 3.9692e-03\n",
      "Epoch [50/100], Loss: 3.1343e-03\n",
      "Epoch [60/100], Loss: 2.7541e-03\n",
      "Epoch [70/100], Loss: 2.5154e-03\n",
      "Epoch [80/100], Loss: 2.3998e-03\n",
      "Epoch [90/100], Loss: 2.3438e-03\n",
      "Epoch [100/100], Loss: 2.3135e-03\n",
      "#####--training model 24--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.6651e-03\n",
      "Epoch [20/100], Loss: 5.4766e-03\n",
      "Epoch [30/100], Loss: 5.1761e-03\n",
      "Epoch [40/100], Loss: 3.9664e-03\n",
      "Epoch [50/100], Loss: 2.4442e-03\n",
      "Epoch [60/100], Loss: 1.8627e-03\n",
      "Epoch [70/100], Loss: 1.3534e-03\n",
      "Epoch [80/100], Loss: 9.8974e-04\n",
      "Epoch [90/100], Loss: 1.0162e-03\n",
      "Epoch [100/100], Loss: 1.0543e-03\n",
      "#####--training model 25--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.4077e-04\n",
      "Epoch [20/100], Loss: 6.8315e-04\n",
      "Epoch [30/100], Loss: 1.6635e-04\n",
      "Epoch [40/100], Loss: 1.3088e-04\n",
      "Epoch [50/100], Loss: 1.1227e-04\n",
      "Epoch [60/100], Loss: 1.0190e-04\n",
      "Epoch [70/100], Loss: 9.5667e-05\n",
      "Epoch [80/100], Loss: 8.4606e-05\n",
      "Epoch [90/100], Loss: 7.2035e-05\n",
      "Epoch [100/100], Loss: 6.1173e-05\n",
      "#####--training model 26--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.8294e-04\n",
      "Epoch [20/100], Loss: 3.8911e-04\n",
      "Epoch [30/100], Loss: 5.3260e-04\n",
      "Epoch [40/100], Loss: 3.0387e-04\n",
      "Epoch [50/100], Loss: 8.0735e-05\n",
      "Epoch [60/100], Loss: 9.8910e-06\n",
      "Epoch [70/100], Loss: 2.6215e-05\n",
      "Epoch [80/100], Loss: 6.6331e-05\n",
      "Epoch [90/100], Loss: 9.3177e-05\n",
      "Epoch [100/100], Loss: 1.0497e-04\n",
      "#####--training model 27--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.4336e-03\n",
      "Epoch [20/100], Loss: 4.4749e-03\n",
      "Epoch [30/100], Loss: 4.5172e-03\n",
      "Epoch [40/100], Loss: 4.6256e-03\n",
      "Epoch [50/100], Loss: 5.3244e-03\n",
      "Epoch [60/100], Loss: 5.6757e-03\n",
      "Epoch [70/100], Loss: 5.8743e-03\n",
      "Epoch [80/100], Loss: 6.0200e-03\n",
      "Epoch [90/100], Loss: 6.0663e-03\n",
      "Epoch [100/100], Loss: 6.0585e-03\n",
      "#####--training model 28--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.9768e-04\n",
      "Epoch [20/100], Loss: 2.2899e-04\n",
      "Epoch [30/100], Loss: 1.1134e-04\n",
      "Epoch [40/100], Loss: 5.5307e-05\n",
      "Epoch [50/100], Loss: 1.6357e-05\n",
      "Epoch [60/100], Loss: 8.8829e-06\n",
      "Epoch [70/100], Loss: 6.3659e-06\n",
      "Epoch [80/100], Loss: 5.0488e-06\n",
      "Epoch [90/100], Loss: 4.1680e-06\n",
      "Epoch [100/100], Loss: 3.4701e-06\n",
      "#####--training model 29--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.2827e-03\n",
      "Epoch [20/100], Loss: 4.8028e-03\n",
      "Epoch [30/100], Loss: 3.3674e-03\n",
      "Epoch [40/100], Loss: 2.2398e-03\n",
      "Epoch [50/100], Loss: 1.9212e-03\n",
      "Epoch [60/100], Loss: 1.8253e-03\n",
      "Epoch [70/100], Loss: 1.7781e-03\n",
      "Epoch [80/100], Loss: 1.7436e-03\n",
      "Epoch [90/100], Loss: 1.7119e-03\n",
      "Epoch [100/100], Loss: 1.6804e-03\n",
      "#####--training model 30--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.2681e-03\n",
      "Epoch [20/100], Loss: 1.8060e-02\n",
      "Epoch [30/100], Loss: 1.0343e-02\n",
      "Epoch [40/100], Loss: 5.2168e-03\n",
      "Epoch [50/100], Loss: 3.5622e-03\n",
      "Epoch [60/100], Loss: 2.8639e-03\n",
      "Epoch [70/100], Loss: 2.4740e-03\n",
      "Epoch [80/100], Loss: 2.3888e-03\n",
      "Epoch [90/100], Loss: 2.4288e-03\n",
      "Epoch [100/100], Loss: 2.5041e-03\n",
      "#####--training model 31--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5267e-03\n",
      "Epoch [20/100], Loss: 1.0561e-03\n",
      "Epoch [30/100], Loss: 8.3487e-04\n",
      "Epoch [40/100], Loss: 8.8052e-04\n",
      "Epoch [50/100], Loss: 8.7496e-04\n",
      "Epoch [60/100], Loss: 8.8423e-04\n",
      "Epoch [70/100], Loss: 8.7712e-04\n",
      "Epoch [80/100], Loss: 8.6746e-04\n",
      "Epoch [90/100], Loss: 8.4907e-04\n",
      "Epoch [100/100], Loss: 8.1490e-04\n",
      "#####--training model 32--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0035e-04\n",
      "Epoch [20/100], Loss: 3.2077e-02\n",
      "Epoch [30/100], Loss: 2.3143e-02\n",
      "Epoch [40/100], Loss: 1.8264e-02\n",
      "Epoch [50/100], Loss: 1.4805e-02\n",
      "Epoch [60/100], Loss: 1.2343e-02\n",
      "Epoch [70/100], Loss: 1.0054e-02\n",
      "Epoch [80/100], Loss: 8.5669e-03\n",
      "Epoch [90/100], Loss: 7.6943e-03\n",
      "Epoch [100/100], Loss: 7.1034e-03\n",
      "#####--training model 33--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.3384e-03\n",
      "Epoch [20/100], Loss: 3.3979e-03\n",
      "Epoch [30/100], Loss: 1.8023e-03\n",
      "Epoch [40/100], Loss: 1.1719e-03\n",
      "Epoch [50/100], Loss: 8.9112e-04\n",
      "Epoch [60/100], Loss: 7.5160e-04\n",
      "Epoch [70/100], Loss: 6.6094e-04\n",
      "Epoch [80/100], Loss: 5.8756e-04\n",
      "Epoch [90/100], Loss: 5.2140e-04\n",
      "Epoch [100/100], Loss: 4.6542e-04\n",
      "#####--training model 34--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.6988e-04\n",
      "Epoch [20/100], Loss: 1.5467e-03\n",
      "Epoch [30/100], Loss: 1.5026e-03\n",
      "Epoch [40/100], Loss: 1.3477e-03\n",
      "Epoch [50/100], Loss: 1.2623e-03\n",
      "Epoch [60/100], Loss: 1.2450e-03\n",
      "Epoch [70/100], Loss: 1.2587e-03\n",
      "Epoch [80/100], Loss: 1.2820e-03\n",
      "Epoch [90/100], Loss: 1.3051e-03\n",
      "Epoch [100/100], Loss: 1.3223e-03\n",
      "#####--training model 35--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.2777e-04\n",
      "Epoch [20/100], Loss: 4.1809e-04\n",
      "Epoch [30/100], Loss: 2.0806e-04\n",
      "Epoch [40/100], Loss: 1.2999e-04\n",
      "Epoch [50/100], Loss: 1.0492e-04\n",
      "Epoch [60/100], Loss: 9.1371e-05\n",
      "Epoch [70/100], Loss: 8.3216e-05\n",
      "Epoch [80/100], Loss: 8.1707e-05\n",
      "Epoch [90/100], Loss: 7.8396e-05\n",
      "Epoch [100/100], Loss: 7.7153e-05\n",
      "#####--training model 36--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3216e-03\n",
      "Epoch [20/100], Loss: 2.7069e-03\n",
      "Epoch [30/100], Loss: 1.8792e-03\n",
      "Epoch [40/100], Loss: 1.2250e-03\n",
      "Epoch [50/100], Loss: 8.9519e-04\n",
      "Epoch [60/100], Loss: 7.3307e-04\n",
      "Epoch [70/100], Loss: 6.4204e-04\n",
      "Epoch [80/100], Loss: 5.6983e-04\n",
      "Epoch [90/100], Loss: 5.0705e-04\n",
      "Epoch [100/100], Loss: 4.5549e-04\n",
      "#####--training model 37--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.0390e-03\n",
      "Epoch [20/100], Loss: 1.0935e-03\n",
      "Epoch [30/100], Loss: 6.3996e-04\n",
      "Epoch [40/100], Loss: 5.9427e-04\n",
      "Epoch [50/100], Loss: 4.9766e-04\n",
      "Epoch [60/100], Loss: 4.4046e-04\n",
      "Epoch [70/100], Loss: 4.6191e-04\n",
      "Epoch [80/100], Loss: 5.0410e-04\n",
      "Epoch [90/100], Loss: 4.7316e-04\n",
      "Epoch [100/100], Loss: 4.1336e-04\n",
      "#####--training model 38--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.5323e-03\n",
      "Epoch [20/100], Loss: 3.2572e-03\n",
      "Epoch [30/100], Loss: 1.1839e-03\n",
      "Epoch [40/100], Loss: 8.8516e-04\n",
      "Epoch [50/100], Loss: 9.8157e-04\n",
      "Epoch [60/100], Loss: 1.1092e-03\n",
      "Epoch [70/100], Loss: 1.2123e-03\n",
      "Epoch [80/100], Loss: 1.2750e-03\n",
      "Epoch [90/100], Loss: 1.2931e-03\n",
      "Epoch [100/100], Loss: 1.2755e-03\n",
      "#####--training model 39--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.5504e-03\n",
      "Epoch [20/100], Loss: 1.0490e-02\n",
      "Epoch [30/100], Loss: 9.4731e-03\n",
      "Epoch [40/100], Loss: 9.0588e-03\n",
      "Epoch [50/100], Loss: 8.8480e-03\n",
      "Epoch [60/100], Loss: 8.7106e-03\n",
      "Epoch [70/100], Loss: 8.6165e-03\n",
      "Epoch [80/100], Loss: 8.5650e-03\n",
      "Epoch [90/100], Loss: 8.5675e-03\n",
      "Epoch [100/100], Loss: 8.5535e-03\n",
      "#####--training model 40--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3710e-04\n",
      "Epoch [20/100], Loss: 8.5743e-04\n",
      "Epoch [30/100], Loss: 8.6100e-04\n",
      "Epoch [40/100], Loss: 7.1475e-04\n",
      "Epoch [50/100], Loss: 6.5509e-04\n",
      "Epoch [60/100], Loss: 6.3164e-04\n",
      "Epoch [70/100], Loss: 6.1695e-04\n",
      "Epoch [80/100], Loss: 6.0360e-04\n",
      "Epoch [90/100], Loss: 5.9197e-04\n",
      "Epoch [100/100], Loss: 5.8183e-04\n",
      "#####--training model 41--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2653e-03\n",
      "Epoch [20/100], Loss: 6.5700e-04\n",
      "Epoch [30/100], Loss: 3.9610e-04\n",
      "Epoch [40/100], Loss: 2.7541e-04\n",
      "Epoch [50/100], Loss: 2.0848e-04\n",
      "Epoch [60/100], Loss: 1.4822e-04\n",
      "Epoch [70/100], Loss: 1.1251e-04\n",
      "Epoch [80/100], Loss: 9.5346e-05\n",
      "Epoch [90/100], Loss: 8.3124e-05\n",
      "Epoch [100/100], Loss: 7.3599e-05\n",
      "#####--training model 42--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4477e-03\n",
      "Epoch [20/100], Loss: 1.6271e-03\n",
      "Epoch [30/100], Loss: 6.1254e-04\n",
      "Epoch [40/100], Loss: 6.4639e-04\n",
      "Epoch [50/100], Loss: 7.5076e-04\n",
      "Epoch [60/100], Loss: 8.4681e-04\n",
      "Epoch [70/100], Loss: 9.0200e-04\n",
      "Epoch [80/100], Loss: 9.2394e-04\n",
      "Epoch [90/100], Loss: 9.2622e-04\n",
      "Epoch [100/100], Loss: 9.0872e-04\n",
      "#####--training model 43--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.1455e-02\n",
      "Epoch [20/100], Loss: 4.5498e-03\n",
      "Epoch [30/100], Loss: 3.2899e-03\n",
      "Epoch [40/100], Loss: 2.6471e-03\n",
      "Epoch [50/100], Loss: 2.2169e-03\n",
      "Epoch [60/100], Loss: 1.9400e-03\n",
      "Epoch [70/100], Loss: 1.7686e-03\n",
      "Epoch [80/100], Loss: 1.6814e-03\n",
      "Epoch [90/100], Loss: 1.6476e-03\n",
      "Epoch [100/100], Loss: 1.6335e-03\n",
      "#####--training model 44--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.3258e-03\n",
      "Epoch [20/100], Loss: 2.6306e-02\n",
      "Epoch [30/100], Loss: 2.6002e-02\n",
      "Epoch [40/100], Loss: 2.0767e-02\n",
      "Epoch [50/100], Loss: 1.3627e-02\n",
      "Epoch [60/100], Loss: 8.2050e-03\n",
      "Epoch [70/100], Loss: 5.2948e-03\n",
      "Epoch [80/100], Loss: 4.0490e-03\n",
      "Epoch [90/100], Loss: 3.4376e-03\n",
      "Epoch [100/100], Loss: 3.0609e-03\n",
      "#####--training model 45--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9261e-04\n",
      "Epoch [20/100], Loss: 1.7196e-04\n",
      "Epoch [30/100], Loss: 1.7095e-04\n",
      "Epoch [40/100], Loss: 1.7106e-04\n",
      "Epoch [50/100], Loss: 1.7122e-04\n",
      "Epoch [60/100], Loss: 1.7143e-04\n",
      "Epoch [70/100], Loss: 1.7171e-04\n",
      "Epoch [80/100], Loss: 1.7217e-04\n",
      "Epoch [90/100], Loss: 1.7300e-04\n",
      "Epoch [100/100], Loss: 1.7487e-04\n",
      "#####--training model 46--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6396e-03\n",
      "Epoch [20/100], Loss: 2.5561e-03\n",
      "Epoch [30/100], Loss: 3.2319e-03\n",
      "Epoch [40/100], Loss: 3.5278e-03\n",
      "Epoch [50/100], Loss: 3.6623e-03\n",
      "Epoch [60/100], Loss: 3.6538e-03\n",
      "Epoch [70/100], Loss: 3.5068e-03\n",
      "Epoch [80/100], Loss: 3.3263e-03\n",
      "Epoch [90/100], Loss: 3.1677e-03\n",
      "Epoch [100/100], Loss: 3.0443e-03\n",
      "#####--training model 47--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8758e-03\n",
      "Epoch [20/100], Loss: 2.4800e-03\n",
      "Epoch [30/100], Loss: 2.1221e-03\n",
      "Epoch [40/100], Loss: 1.6882e-03\n",
      "Epoch [50/100], Loss: 1.3464e-03\n",
      "Epoch [60/100], Loss: 1.1896e-03\n",
      "Epoch [70/100], Loss: 1.0939e-03\n",
      "Epoch [80/100], Loss: 1.0235e-03\n",
      "Epoch [90/100], Loss: 9.7052e-04\n",
      "Epoch [100/100], Loss: 9.2419e-04\n",
      "#####--training model 48--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4993e-03\n",
      "Epoch [20/100], Loss: 3.8290e-04\n",
      "Epoch [30/100], Loss: 2.0820e-04\n",
      "Epoch [40/100], Loss: 1.2801e-04\n",
      "Epoch [50/100], Loss: 8.0997e-05\n",
      "Epoch [60/100], Loss: 4.8782e-05\n",
      "Epoch [70/100], Loss: 2.9525e-05\n",
      "Epoch [80/100], Loss: 1.8199e-05\n",
      "Epoch [90/100], Loss: 1.1802e-05\n",
      "Epoch [100/100], Loss: 8.3700e-06\n",
      "#####--training model 49--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9659e-04\n",
      "Epoch [20/100], Loss: 1.3852e-04\n",
      "Epoch [30/100], Loss: 1.3722e-04\n",
      "Epoch [40/100], Loss: 1.4958e-04\n",
      "Epoch [50/100], Loss: 1.6252e-04\n",
      "Epoch [60/100], Loss: 1.7242e-04\n",
      "Epoch [70/100], Loss: 1.8107e-04\n",
      "Epoch [80/100], Loss: 5.4763e-05\n",
      "Epoch [90/100], Loss: 1.9443e-05\n",
      "Epoch [100/100], Loss: 9.7783e-06\n",
      "#####--training model 50--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.1813e-03\n",
      "Epoch [20/100], Loss: 2.3124e-03\n",
      "Epoch [30/100], Loss: 2.4266e-03\n",
      "Epoch [40/100], Loss: 1.0137e-03\n",
      "Epoch [50/100], Loss: 9.1146e-04\n",
      "Epoch [60/100], Loss: 7.6724e-04\n",
      "Epoch [70/100], Loss: 5.4658e-04\n",
      "Epoch [80/100], Loss: 3.7456e-04\n",
      "Epoch [90/100], Loss: 3.0626e-04\n",
      "Epoch [100/100], Loss: 2.7493e-04\n",
      "#####--training model 51--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6936e-04\n",
      "Epoch [20/100], Loss: 2.1585e-04\n",
      "Epoch [30/100], Loss: 2.0840e-04\n",
      "Epoch [40/100], Loss: 2.0611e-04\n",
      "Epoch [50/100], Loss: 2.0396e-04\n",
      "Epoch [60/100], Loss: 2.0156e-04\n",
      "Epoch [70/100], Loss: 1.9900e-04\n",
      "Epoch [80/100], Loss: 1.9677e-04\n",
      "Epoch [90/100], Loss: 1.7286e-04\n",
      "Epoch [100/100], Loss: 1.6506e-04\n",
      "#####--training model 52--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3927e-01\n",
      "Epoch [20/100], Loss: 1.7914e-01\n",
      "Epoch [30/100], Loss: 1.0090e-01\n",
      "Epoch [40/100], Loss: 4.9178e-02\n",
      "Epoch [50/100], Loss: 2.1137e-02\n",
      "Epoch [60/100], Loss: 1.3504e-02\n",
      "Epoch [70/100], Loss: 1.0669e-02\n",
      "Epoch [80/100], Loss: 8.5668e-03\n",
      "Epoch [90/100], Loss: 6.9608e-03\n",
      "Epoch [100/100], Loss: 5.8378e-03\n",
      "#####--training model 53--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4657e-03\n",
      "Epoch [20/100], Loss: 1.5777e-03\n",
      "Epoch [30/100], Loss: 2.7491e-03\n",
      "Epoch [40/100], Loss: 1.9682e-03\n",
      "Epoch [50/100], Loss: 1.3962e-03\n",
      "Epoch [60/100], Loss: 1.2373e-03\n",
      "Epoch [70/100], Loss: 1.1258e-03\n",
      "Epoch [80/100], Loss: 1.0188e-03\n",
      "Epoch [90/100], Loss: 9.0946e-04\n",
      "Epoch [100/100], Loss: 8.1392e-04\n",
      "#####--training model 54--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.5235e-04\n",
      "Epoch [20/100], Loss: 7.0736e-04\n",
      "Epoch [30/100], Loss: 8.3161e-04\n",
      "Epoch [40/100], Loss: 1.8957e-03\n",
      "Epoch [50/100], Loss: 1.3278e-03\n",
      "Epoch [60/100], Loss: 9.0627e-04\n",
      "Epoch [70/100], Loss: 6.6568e-04\n",
      "Epoch [80/100], Loss: 5.3712e-04\n",
      "Epoch [90/100], Loss: 4.4758e-04\n",
      "Epoch [100/100], Loss: 3.7175e-04\n",
      "#####--training model 55--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.0992e-02\n",
      "Epoch [20/100], Loss: 7.6806e-02\n",
      "Epoch [30/100], Loss: 5.7960e-02\n",
      "Epoch [40/100], Loss: 2.4715e-02\n",
      "Epoch [50/100], Loss: 1.4521e-02\n",
      "Epoch [60/100], Loss: 1.0824e-02\n",
      "Epoch [70/100], Loss: 8.5444e-03\n",
      "Epoch [80/100], Loss: 7.0501e-03\n",
      "Epoch [90/100], Loss: 6.1532e-03\n",
      "Epoch [100/100], Loss: 5.4723e-03\n",
      "#####--training model 56--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4238e-03\n",
      "Epoch [20/100], Loss: 6.4149e-04\n",
      "Epoch [30/100], Loss: 2.8076e-04\n",
      "Epoch [40/100], Loss: 1.7983e-04\n",
      "Epoch [50/100], Loss: 1.2150e-04\n",
      "Epoch [60/100], Loss: 8.7664e-05\n",
      "Epoch [70/100], Loss: 6.3388e-05\n",
      "Epoch [80/100], Loss: 4.3022e-05\n",
      "Epoch [90/100], Loss: 2.6102e-05\n",
      "Epoch [100/100], Loss: 1.6644e-05\n",
      "#####--training model 57--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1077e-02\n",
      "Epoch [20/100], Loss: 1.3663e-03\n",
      "Epoch [30/100], Loss: 1.0039e-03\n",
      "Epoch [40/100], Loss: 1.0902e-03\n",
      "Epoch [50/100], Loss: 1.2675e-03\n",
      "Epoch [60/100], Loss: 1.3271e-03\n",
      "Epoch [70/100], Loss: 1.3507e-03\n",
      "Epoch [80/100], Loss: 1.3358e-03\n",
      "Epoch [90/100], Loss: 1.2815e-03\n",
      "Epoch [100/100], Loss: 1.1834e-03\n",
      "#####--training model 58--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.9698e-03\n",
      "Epoch [20/100], Loss: 7.3585e-03\n",
      "Epoch [30/100], Loss: 5.8092e-03\n",
      "Epoch [40/100], Loss: 5.8166e-03\n",
      "Epoch [50/100], Loss: 6.1583e-03\n",
      "Epoch [60/100], Loss: 6.5272e-03\n",
      "Epoch [70/100], Loss: 6.8987e-03\n",
      "Epoch [80/100], Loss: 7.3086e-03\n",
      "Epoch [90/100], Loss: 7.6821e-03\n",
      "Epoch [100/100], Loss: 7.9660e-03\n",
      "#####--training model 59--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.7711e-03\n",
      "Epoch [20/100], Loss: 1.6629e-03\n",
      "Epoch [30/100], Loss: 5.3724e-04\n",
      "Epoch [40/100], Loss: 2.1040e-04\n",
      "Epoch [50/100], Loss: 1.0257e-04\n",
      "Epoch [60/100], Loss: 6.3541e-05\n",
      "Epoch [70/100], Loss: 4.6806e-05\n",
      "Epoch [80/100], Loss: 3.1618e-05\n",
      "Epoch [90/100], Loss: 1.8741e-05\n",
      "Epoch [100/100], Loss: 1.2515e-05\n",
      "#####--training model 60--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.3793e-03\n",
      "Epoch [20/100], Loss: 4.9639e-03\n",
      "Epoch [30/100], Loss: 5.1390e-03\n",
      "Epoch [40/100], Loss: 5.3216e-03\n",
      "Epoch [50/100], Loss: 5.4632e-03\n",
      "Epoch [60/100], Loss: 5.6049e-03\n",
      "Epoch [70/100], Loss: 5.7083e-03\n",
      "Epoch [80/100], Loss: 5.7488e-03\n",
      "Epoch [90/100], Loss: 5.7498e-03\n",
      "Epoch [100/100], Loss: 5.7161e-03\n",
      "#####--training model 61--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.7496e-04\n",
      "Epoch [20/100], Loss: 1.8794e-03\n",
      "Epoch [30/100], Loss: 2.2516e-03\n",
      "Epoch [40/100], Loss: 2.4913e-03\n",
      "Epoch [50/100], Loss: 2.7366e-03\n",
      "Epoch [60/100], Loss: 2.9211e-03\n",
      "Epoch [70/100], Loss: 3.0186e-03\n",
      "Epoch [80/100], Loss: 3.0791e-03\n",
      "Epoch [90/100], Loss: 3.1277e-03\n",
      "Epoch [100/100], Loss: 3.1821e-03\n",
      "#####--training model 62--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3190e-03\n",
      "Epoch [20/100], Loss: 3.1935e-03\n",
      "Epoch [30/100], Loss: 3.4838e-03\n",
      "Epoch [40/100], Loss: 3.4850e-03\n",
      "Epoch [50/100], Loss: 3.4234e-03\n",
      "Epoch [60/100], Loss: 3.3566e-03\n",
      "Epoch [70/100], Loss: 3.2832e-03\n",
      "Epoch [80/100], Loss: 3.2008e-03\n",
      "Epoch [90/100], Loss: 3.1121e-03\n",
      "Epoch [100/100], Loss: 3.0220e-03\n",
      "#####--training model 63--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0030e-03\n",
      "Epoch [20/100], Loss: 4.5840e-04\n",
      "Epoch [30/100], Loss: 1.4501e-04\n",
      "Epoch [40/100], Loss: 4.7039e-05\n",
      "Epoch [50/100], Loss: 1.5585e-05\n",
      "Epoch [60/100], Loss: 1.7903e-05\n",
      "Epoch [70/100], Loss: 2.6604e-05\n",
      "Epoch [80/100], Loss: 3.1784e-05\n",
      "Epoch [90/100], Loss: 3.4040e-05\n",
      "Epoch [100/100], Loss: 4.0262e-05\n",
      "#####--training model 64--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4765e-03\n",
      "Epoch [20/100], Loss: 4.5490e-03\n",
      "Epoch [30/100], Loss: 5.9340e-03\n",
      "Epoch [40/100], Loss: 6.6304e-03\n",
      "Epoch [50/100], Loss: 6.9688e-03\n",
      "Epoch [60/100], Loss: 7.1005e-03\n",
      "Epoch [70/100], Loss: 7.1098e-03\n",
      "Epoch [80/100], Loss: 7.1025e-03\n",
      "Epoch [90/100], Loss: 7.1152e-03\n",
      "Epoch [100/100], Loss: 7.1397e-03\n",
      "#####--training model 65--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.8580e-02\n",
      "Epoch [20/100], Loss: 8.2012e-02\n",
      "Epoch [30/100], Loss: 7.9561e-02\n",
      "Epoch [40/100], Loss: 7.5597e-02\n",
      "Epoch [50/100], Loss: 7.1903e-02\n",
      "Epoch [60/100], Loss: 6.9518e-02\n",
      "Epoch [70/100], Loss: 6.8567e-02\n",
      "Epoch [80/100], Loss: 6.8237e-02\n",
      "Epoch [90/100], Loss: 6.7885e-02\n",
      "Epoch [100/100], Loss: 6.7238e-02\n",
      "#####--training model 66--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.2891e-03\n",
      "Epoch [20/100], Loss: 4.5106e-03\n",
      "Epoch [30/100], Loss: 4.2416e-03\n",
      "Epoch [40/100], Loss: 4.4918e-03\n",
      "Epoch [50/100], Loss: 5.1982e-03\n",
      "Epoch [60/100], Loss: 5.9348e-03\n",
      "Epoch [70/100], Loss: 6.4824e-03\n",
      "Epoch [80/100], Loss: 6.7924e-03\n",
      "Epoch [90/100], Loss: 6.8925e-03\n",
      "Epoch [100/100], Loss: 6.8399e-03\n",
      "#####--training model 67--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.5376e-02\n",
      "Epoch [20/100], Loss: 5.4182e-03\n",
      "Epoch [30/100], Loss: 5.6987e-03\n",
      "Epoch [40/100], Loss: 5.7395e-03\n",
      "Epoch [50/100], Loss: 5.8421e-03\n",
      "Epoch [60/100], Loss: 6.5567e-03\n",
      "Epoch [70/100], Loss: 6.9538e-03\n",
      "Epoch [80/100], Loss: 6.8902e-03\n",
      "Epoch [90/100], Loss: 6.6956e-03\n",
      "Epoch [100/100], Loss: 6.4439e-03\n",
      "#####--training model 68--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.7291e-02\n",
      "Epoch [20/100], Loss: 2.6447e-02\n",
      "Epoch [30/100], Loss: 1.3981e-02\n",
      "Epoch [40/100], Loss: 1.0970e-02\n",
      "Epoch [50/100], Loss: 1.0624e-02\n",
      "Epoch [60/100], Loss: 1.1322e-02\n",
      "Epoch [70/100], Loss: 1.2440e-02\n",
      "Epoch [80/100], Loss: 1.3868e-02\n",
      "Epoch [90/100], Loss: 1.4114e-02\n",
      "Epoch [100/100], Loss: 1.3461e-02\n",
      "#####--training model 69--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0427e-02\n",
      "Epoch [20/100], Loss: 2.5838e-03\n",
      "Epoch [30/100], Loss: 1.4314e-03\n",
      "Epoch [40/100], Loss: 1.1234e-03\n",
      "Epoch [50/100], Loss: 7.3037e-04\n",
      "Epoch [60/100], Loss: 3.8049e-04\n",
      "Epoch [70/100], Loss: 2.1661e-04\n",
      "Epoch [80/100], Loss: 1.5031e-04\n",
      "Epoch [90/100], Loss: 1.9668e-04\n",
      "Epoch [100/100], Loss: 2.0368e-04\n",
      "#####--training model 70--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5606e-03\n",
      "Epoch [20/100], Loss: 6.6952e-04\n",
      "Epoch [30/100], Loss: 4.8883e-04\n",
      "Epoch [40/100], Loss: 3.7863e-04\n",
      "Epoch [50/100], Loss: 2.9950e-04\n",
      "Epoch [60/100], Loss: 2.3917e-04\n",
      "Epoch [70/100], Loss: 1.9553e-04\n",
      "Epoch [80/100], Loss: 1.6665e-04\n",
      "Epoch [90/100], Loss: 1.4790e-04\n",
      "Epoch [100/100], Loss: 1.3590e-04\n",
      "#####--training model 71--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8129e-04\n",
      "Epoch [20/100], Loss: 2.8648e-04\n",
      "Epoch [30/100], Loss: 2.8447e-04\n",
      "Epoch [40/100], Loss: 1.0780e-04\n",
      "Epoch [50/100], Loss: 5.0767e-05\n",
      "Epoch [60/100], Loss: 2.6149e-05\n",
      "Epoch [70/100], Loss: 1.3980e-05\n",
      "Epoch [80/100], Loss: 9.7596e-06\n",
      "Epoch [90/100], Loss: 4.7384e-06\n",
      "Epoch [100/100], Loss: 1.6429e-05\n",
      "#####--training model 72--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.9742e-03\n",
      "Epoch [20/100], Loss: 9.7537e-03\n",
      "Epoch [30/100], Loss: 1.0033e-02\n",
      "Epoch [40/100], Loss: 1.0150e-02\n",
      "Epoch [50/100], Loss: 1.0197e-02\n",
      "Epoch [60/100], Loss: 1.0216e-02\n",
      "Epoch [70/100], Loss: 1.0226e-02\n",
      "Epoch [80/100], Loss: 1.0236e-02\n",
      "Epoch [90/100], Loss: 1.0247e-02\n",
      "Epoch [100/100], Loss: 1.0258e-02\n",
      "#####--training model 73--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0549e-02\n",
      "Epoch [20/100], Loss: 6.3070e-03\n",
      "Epoch [30/100], Loss: 4.8194e-03\n",
      "Epoch [40/100], Loss: 3.2955e-03\n",
      "Epoch [50/100], Loss: 2.3255e-03\n",
      "Epoch [60/100], Loss: 1.8162e-03\n",
      "Epoch [70/100], Loss: 1.5226e-03\n",
      "Epoch [80/100], Loss: 1.3447e-03\n",
      "Epoch [90/100], Loss: 1.2403e-03\n",
      "Epoch [100/100], Loss: 1.1775e-03\n",
      "#####--training model 74--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.3827e-04\n",
      "Epoch [20/100], Loss: 7.4176e-04\n",
      "Epoch [30/100], Loss: 7.4644e-04\n",
      "Epoch [40/100], Loss: 6.3771e-04\n",
      "Epoch [50/100], Loss: 5.5403e-04\n",
      "Epoch [60/100], Loss: 4.5646e-04\n",
      "Epoch [70/100], Loss: 2.9060e-04\n",
      "Epoch [80/100], Loss: 1.6260e-04\n",
      "Epoch [90/100], Loss: 1.2293e-04\n",
      "Epoch [100/100], Loss: 9.3638e-05\n",
      "#####--training model 75--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.5036e-05\n",
      "Epoch [20/100], Loss: 9.1780e-05\n",
      "Epoch [30/100], Loss: 1.4608e-04\n",
      "Epoch [40/100], Loss: 2.1739e-04\n",
      "Epoch [50/100], Loss: 2.7870e-04\n",
      "Epoch [60/100], Loss: 3.5127e-04\n",
      "Epoch [70/100], Loss: 4.5646e-04\n",
      "Epoch [80/100], Loss: 6.4770e-04\n",
      "Epoch [90/100], Loss: 9.4998e-04\n",
      "Epoch [100/100], Loss: 1.2879e-03\n",
      "#####--training model 76--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0417e-03\n",
      "Epoch [20/100], Loss: 2.2470e-03\n",
      "Epoch [30/100], Loss: 1.5451e-03\n",
      "Epoch [40/100], Loss: 1.1450e-03\n",
      "Epoch [50/100], Loss: 9.2712e-04\n",
      "Epoch [60/100], Loss: 7.8520e-04\n",
      "Epoch [70/100], Loss: 6.9816e-04\n",
      "Epoch [80/100], Loss: 6.4579e-04\n",
      "Epoch [90/100], Loss: 6.1077e-04\n",
      "Epoch [100/100], Loss: 5.8494e-04\n",
      "#####--training model 77--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6589e-03\n",
      "Epoch [20/100], Loss: 9.0264e-04\n",
      "Epoch [30/100], Loss: 5.2091e-04\n",
      "Epoch [40/100], Loss: 3.1298e-04\n",
      "Epoch [50/100], Loss: 2.3368e-04\n",
      "Epoch [60/100], Loss: 2.0357e-04\n",
      "Epoch [70/100], Loss: 1.8265e-04\n",
      "Epoch [80/100], Loss: 1.5377e-04\n",
      "Epoch [90/100], Loss: 1.3955e-04\n",
      "Epoch [100/100], Loss: 1.2999e-04\n",
      "#####--training model 78--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2644e-04\n",
      "Epoch [20/100], Loss: 4.6649e-05\n",
      "Epoch [30/100], Loss: 2.4444e-05\n",
      "Epoch [40/100], Loss: 1.4809e-05\n",
      "Epoch [50/100], Loss: 9.7096e-06\n",
      "Epoch [60/100], Loss: 6.6852e-06\n",
      "Epoch [70/100], Loss: 4.7544e-06\n",
      "Epoch [80/100], Loss: 3.4581e-06\n",
      "Epoch [90/100], Loss: 2.5558e-06\n",
      "Epoch [100/100], Loss: 1.9112e-06\n",
      "#####--training model 79--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.9519e-03\n",
      "Epoch [20/100], Loss: 1.7074e-03\n",
      "Epoch [30/100], Loss: 1.2338e-03\n",
      "Epoch [40/100], Loss: 8.0118e-04\n",
      "Epoch [50/100], Loss: 5.5301e-04\n",
      "Epoch [60/100], Loss: 4.0075e-04\n",
      "Epoch [70/100], Loss: 3.1700e-04\n",
      "Epoch [80/100], Loss: 2.7341e-04\n",
      "Epoch [90/100], Loss: 2.5109e-04\n",
      "Epoch [100/100], Loss: 2.3764e-04\n",
      "#####--training model 80--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3733e-04\n",
      "Epoch [20/100], Loss: 1.2925e-04\n",
      "Epoch [30/100], Loss: 4.4718e-05\n",
      "Epoch [40/100], Loss: 5.4124e-05\n",
      "Epoch [50/100], Loss: 4.0937e-05\n",
      "Epoch [60/100], Loss: 2.6838e-05\n",
      "Epoch [70/100], Loss: 2.2902e-05\n",
      "Epoch [80/100], Loss: 2.1957e-05\n",
      "Epoch [90/100], Loss: 2.0923e-05\n",
      "Epoch [100/100], Loss: 2.0421e-05\n",
      "#####--training model 81--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4382e-04\n",
      "Epoch [20/100], Loss: 1.3642e-04\n",
      "Epoch [30/100], Loss: 1.0778e-04\n",
      "Epoch [40/100], Loss: 9.7898e-05\n",
      "Epoch [50/100], Loss: 9.5178e-05\n",
      "Epoch [60/100], Loss: 1.0031e-04\n",
      "Epoch [70/100], Loss: 1.0327e-04\n",
      "Epoch [80/100], Loss: 3.2084e-05\n",
      "Epoch [90/100], Loss: 2.0833e-05\n",
      "Epoch [100/100], Loss: 1.6272e-05\n",
      "#####--training model 82--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3590e-03\n",
      "Epoch [20/100], Loss: 1.7250e-03\n",
      "Epoch [30/100], Loss: 1.2583e-03\n",
      "Epoch [40/100], Loss: 8.1033e-04\n",
      "Epoch [50/100], Loss: 5.9746e-04\n",
      "Epoch [60/100], Loss: 5.0521e-04\n",
      "Epoch [70/100], Loss: 4.2376e-04\n",
      "Epoch [80/100], Loss: 3.6073e-04\n",
      "Epoch [90/100], Loss: 3.2177e-04\n",
      "Epoch [100/100], Loss: 3.0046e-04\n",
      "#####--training model 83--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.8041e-03\n",
      "Epoch [20/100], Loss: 5.8931e-03\n",
      "Epoch [30/100], Loss: 4.8094e-03\n",
      "Epoch [40/100], Loss: 4.0083e-03\n",
      "Epoch [50/100], Loss: 3.2447e-03\n",
      "Epoch [60/100], Loss: 2.7012e-03\n",
      "Epoch [70/100], Loss: 2.4850e-03\n",
      "Epoch [80/100], Loss: 2.4363e-03\n",
      "Epoch [90/100], Loss: 2.4503e-03\n",
      "Epoch [100/100], Loss: 2.4754e-03\n",
      "#####--training model 84--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.3104e-03\n",
      "Epoch [20/100], Loss: 2.7733e-03\n",
      "Epoch [30/100], Loss: 2.5742e-03\n",
      "Epoch [40/100], Loss: 2.0772e-03\n",
      "Epoch [50/100], Loss: 1.5531e-03\n",
      "Epoch [60/100], Loss: 1.2356e-03\n",
      "Epoch [70/100], Loss: 1.0598e-03\n",
      "Epoch [80/100], Loss: 9.3303e-04\n",
      "Epoch [90/100], Loss: 8.3789e-04\n",
      "Epoch [100/100], Loss: 7.8096e-04\n",
      "#####--training model 85--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.4459e-03\n",
      "Epoch [20/100], Loss: 2.6735e-03\n",
      "Epoch [30/100], Loss: 1.9791e-03\n",
      "Epoch [40/100], Loss: 1.7689e-03\n",
      "Epoch [50/100], Loss: 1.6864e-03\n",
      "Epoch [60/100], Loss: 1.6434e-03\n",
      "Epoch [70/100], Loss: 1.3714e-03\n",
      "Epoch [80/100], Loss: 1.2039e-03\n",
      "Epoch [90/100], Loss: 1.2893e-03\n",
      "Epoch [100/100], Loss: 1.3971e-03\n",
      "#####--training model 86--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.6009e-03\n",
      "Epoch [20/100], Loss: 9.4430e-04\n",
      "Epoch [30/100], Loss: 3.7380e-04\n",
      "Epoch [40/100], Loss: 3.0614e-04\n",
      "Epoch [50/100], Loss: 4.0494e-04\n",
      "Epoch [60/100], Loss: 4.8366e-04\n",
      "Epoch [70/100], Loss: 5.4873e-04\n",
      "Epoch [80/100], Loss: 6.2158e-04\n",
      "Epoch [90/100], Loss: 7.1276e-04\n",
      "Epoch [100/100], Loss: 8.0709e-04\n",
      "#####--training model 87--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.8962e-03\n",
      "Epoch [20/100], Loss: 3.6678e-03\n",
      "Epoch [30/100], Loss: 2.1419e-03\n",
      "Epoch [40/100], Loss: 1.2193e-03\n",
      "Epoch [50/100], Loss: 8.2724e-04\n",
      "Epoch [60/100], Loss: 6.8212e-04\n",
      "Epoch [70/100], Loss: 6.0718e-04\n",
      "Epoch [80/100], Loss: 5.6445e-04\n",
      "Epoch [90/100], Loss: 5.4053e-04\n",
      "Epoch [100/100], Loss: 5.3295e-04\n",
      "#####--training model 88--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.6583e-04\n",
      "Epoch [20/100], Loss: 6.8572e-04\n",
      "Epoch [30/100], Loss: 8.6742e-04\n",
      "Epoch [40/100], Loss: 7.3268e-04\n",
      "Epoch [50/100], Loss: 6.5262e-04\n",
      "Epoch [60/100], Loss: 6.5772e-04\n",
      "Epoch [70/100], Loss: 6.6131e-04\n",
      "Epoch [80/100], Loss: 6.5326e-04\n",
      "Epoch [90/100], Loss: 6.2623e-04\n",
      "Epoch [100/100], Loss: 5.7012e-04\n",
      "#####--training model 89--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0752e-03\n",
      "Epoch [20/100], Loss: 5.4201e-03\n",
      "Epoch [30/100], Loss: 8.0559e-03\n",
      "Epoch [40/100], Loss: 9.9597e-03\n",
      "Epoch [50/100], Loss: 1.1601e-02\n",
      "Epoch [60/100], Loss: 1.2794e-02\n",
      "Epoch [70/100], Loss: 1.3352e-02\n",
      "Epoch [80/100], Loss: 1.3415e-02\n",
      "Epoch [90/100], Loss: 1.3184e-02\n",
      "Epoch [100/100], Loss: 1.2793e-02\n",
      "#####--training model 90--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.9895e-04\n",
      "Epoch [20/100], Loss: 8.7863e-04\n",
      "Epoch [30/100], Loss: 6.4455e-04\n",
      "Epoch [40/100], Loss: 2.8454e-04\n",
      "Epoch [50/100], Loss: 1.0001e-04\n",
      "Epoch [60/100], Loss: 6.4577e-05\n",
      "Epoch [70/100], Loss: 4.9475e-05\n",
      "Epoch [80/100], Loss: 4.2631e-05\n",
      "Epoch [90/100], Loss: 3.9699e-05\n",
      "Epoch [100/100], Loss: 3.9730e-05\n",
      "#####--training model 91--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.2971e-05\n",
      "Epoch [20/100], Loss: 2.1287e-05\n",
      "Epoch [30/100], Loss: 1.4544e-05\n",
      "Epoch [40/100], Loss: 1.3498e-05\n",
      "Epoch [50/100], Loss: 1.3667e-05\n",
      "Epoch [60/100], Loss: 1.3978e-05\n",
      "Epoch [70/100], Loss: 1.4188e-05\n",
      "Epoch [80/100], Loss: 1.4288e-05\n",
      "Epoch [90/100], Loss: 1.4326e-05\n",
      "Epoch [100/100], Loss: 1.4342e-05\n",
      "#####--training model 92--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.4410e-03\n",
      "Epoch [20/100], Loss: 1.2985e-03\n",
      "Epoch [30/100], Loss: 7.3853e-04\n",
      "Epoch [40/100], Loss: 5.1102e-04\n",
      "Epoch [50/100], Loss: 4.0117e-04\n",
      "Epoch [60/100], Loss: 3.4491e-04\n",
      "Epoch [70/100], Loss: 3.2022e-04\n",
      "Epoch [80/100], Loss: 3.1041e-04\n",
      "Epoch [90/100], Loss: 2.8901e-04\n",
      "Epoch [100/100], Loss: 2.6492e-04\n",
      "#####--training model 93--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3002e-04\n",
      "Epoch [20/100], Loss: 2.2175e-04\n",
      "Epoch [30/100], Loss: 1.5017e-04\n",
      "Epoch [40/100], Loss: 1.0236e-04\n",
      "Epoch [50/100], Loss: 9.2457e-05\n",
      "Epoch [60/100], Loss: 9.1052e-05\n",
      "Epoch [70/100], Loss: 8.9215e-05\n",
      "Epoch [80/100], Loss: 8.6803e-05\n",
      "Epoch [90/100], Loss: 8.4229e-05\n",
      "Epoch [100/100], Loss: 8.1737e-05\n",
      "#####--training model 94--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9637e-04\n",
      "Epoch [20/100], Loss: 1.2054e-04\n",
      "Epoch [30/100], Loss: 1.0405e-04\n",
      "Epoch [40/100], Loss: 9.9663e-05\n",
      "Epoch [50/100], Loss: 9.7582e-05\n",
      "Epoch [60/100], Loss: 9.5687e-05\n",
      "Epoch [70/100], Loss: 9.3755e-05\n",
      "Epoch [80/100], Loss: 9.1864e-05\n",
      "Epoch [90/100], Loss: 8.9894e-05\n",
      "Epoch [100/100], Loss: 8.2337e-05\n",
      "#####--training model 95--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1331e-05\n",
      "Epoch [20/100], Loss: 1.1041e-04\n",
      "Epoch [30/100], Loss: 6.2250e-05\n",
      "Epoch [40/100], Loss: 1.5697e-05\n",
      "Epoch [50/100], Loss: 2.2740e-05\n",
      "Epoch [60/100], Loss: 2.1969e-05\n",
      "Epoch [70/100], Loss: 2.2352e-05\n",
      "Epoch [80/100], Loss: 2.5556e-05\n",
      "Epoch [90/100], Loss: 3.1211e-05\n",
      "Epoch [100/100], Loss: 3.8829e-05\n",
      "#####--training model 96--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1423e-04\n",
      "Epoch [20/100], Loss: 4.2960e-05\n",
      "Epoch [30/100], Loss: 2.2446e-05\n",
      "Epoch [40/100], Loss: 1.3548e-05\n",
      "Epoch [50/100], Loss: 8.8573e-06\n",
      "Epoch [60/100], Loss: 6.0842e-06\n",
      "Epoch [70/100], Loss: 4.3189e-06\n",
      "Epoch [80/100], Loss: 3.1365e-06\n",
      "Epoch [90/100], Loss: 2.3153e-06\n",
      "Epoch [100/100], Loss: 1.7295e-06\n",
      "#####--training model 97--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9730e-03\n",
      "Epoch [20/100], Loss: 3.0630e-03\n",
      "Epoch [30/100], Loss: 2.8333e-03\n",
      "Epoch [40/100], Loss: 1.5830e-03\n",
      "Epoch [50/100], Loss: 1.3110e-03\n",
      "Epoch [60/100], Loss: 1.1371e-03\n",
      "Epoch [70/100], Loss: 9.1083e-04\n",
      "Epoch [80/100], Loss: 4.7638e-04\n",
      "Epoch [90/100], Loss: 2.3298e-04\n",
      "Epoch [100/100], Loss: 1.6696e-04\n",
      "#####--training model 98--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6961e-03\n",
      "Epoch [20/100], Loss: 1.8018e-03\n",
      "Epoch [30/100], Loss: 2.0958e-03\n",
      "Epoch [40/100], Loss: 2.4085e-03\n",
      "Epoch [50/100], Loss: 2.6258e-03\n",
      "Epoch [60/100], Loss: 2.7373e-03\n",
      "Epoch [70/100], Loss: 2.7199e-03\n",
      "Epoch [80/100], Loss: 2.6602e-03\n",
      "Epoch [90/100], Loss: 2.6455e-03\n",
      "Epoch [100/100], Loss: 2.6706e-03\n",
      "#####--training model 99--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4638e-03\n",
      "Epoch [20/100], Loss: 7.2214e-04\n",
      "Epoch [30/100], Loss: 6.9775e-04\n",
      "Epoch [40/100], Loss: 7.5277e-04\n",
      "Epoch [50/100], Loss: 7.6638e-04\n",
      "Epoch [60/100], Loss: 7.2182e-04\n",
      "Epoch [70/100], Loss: 6.6576e-04\n",
      "Epoch [80/100], Loss: 6.2016e-04\n",
      "Epoch [90/100], Loss: 5.7667e-04\n",
      "Epoch [100/100], Loss: 5.3430e-04\n",
      "#####--training model 100--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3222e-04\n",
      "Epoch [20/100], Loss: 2.6127e-04\n",
      "Epoch [30/100], Loss: 2.8611e-04\n",
      "Epoch [40/100], Loss: 3.0872e-04\n",
      "Epoch [50/100], Loss: 3.2413e-04\n",
      "Epoch [60/100], Loss: 3.2914e-04\n",
      "Epoch [70/100], Loss: 3.3239e-04\n",
      "Epoch [80/100], Loss: 3.3637e-04\n",
      "Epoch [90/100], Loss: 3.4143e-04\n",
      "Epoch [100/100], Loss: 3.4730e-04\n",
      "#####--training model 101--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.7521e-03\n",
      "Epoch [20/100], Loss: 4.9562e-03\n",
      "Epoch [30/100], Loss: 3.9020e-03\n",
      "Epoch [40/100], Loss: 3.7763e-03\n",
      "Epoch [50/100], Loss: 2.9747e-03\n",
      "Epoch [60/100], Loss: 1.6841e-03\n",
      "Epoch [70/100], Loss: 7.5622e-04\n",
      "Epoch [80/100], Loss: 1.1192e-03\n",
      "Epoch [90/100], Loss: 1.2416e-03\n",
      "Epoch [100/100], Loss: 1.3096e-03\n",
      "#####--training model 102--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2390e-03\n",
      "Epoch [20/100], Loss: 9.7513e-04\n",
      "Epoch [30/100], Loss: 1.1528e-03\n",
      "Epoch [40/100], Loss: 1.4098e-03\n",
      "Epoch [50/100], Loss: 1.5398e-03\n",
      "Epoch [60/100], Loss: 1.6670e-03\n",
      "Epoch [70/100], Loss: 1.5992e-03\n",
      "Epoch [80/100], Loss: 1.5120e-03\n",
      "Epoch [90/100], Loss: 1.4538e-03\n",
      "Epoch [100/100], Loss: 1.4151e-03\n",
      "#####--training model 103--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9825e-04\n",
      "Epoch [20/100], Loss: 4.3263e-05\n",
      "Epoch [30/100], Loss: 2.5593e-05\n",
      "Epoch [40/100], Loss: 2.7428e-05\n",
      "Epoch [50/100], Loss: 2.8727e-05\n",
      "Epoch [60/100], Loss: 2.9834e-05\n",
      "Epoch [70/100], Loss: 3.0578e-05\n",
      "Epoch [80/100], Loss: 3.0536e-05\n",
      "Epoch [90/100], Loss: 2.9588e-05\n",
      "Epoch [100/100], Loss: 2.8404e-05\n",
      "#####--training model 104--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.6947e-03\n",
      "Epoch [20/100], Loss: 2.4758e-03\n",
      "Epoch [30/100], Loss: 2.1022e-03\n",
      "Epoch [40/100], Loss: 1.7629e-03\n",
      "Epoch [50/100], Loss: 1.5894e-03\n",
      "Epoch [60/100], Loss: 1.6176e-03\n",
      "Epoch [70/100], Loss: 1.7648e-03\n",
      "Epoch [80/100], Loss: 1.9145e-03\n",
      "Epoch [90/100], Loss: 2.0201e-03\n",
      "Epoch [100/100], Loss: 2.1033e-03\n",
      "#####--training model 105--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5556e-03\n",
      "Epoch [20/100], Loss: 1.5550e-03\n",
      "Epoch [30/100], Loss: 1.5529e-03\n",
      "Epoch [40/100], Loss: 1.5487e-03\n",
      "Epoch [50/100], Loss: 1.5635e-03\n",
      "Epoch [60/100], Loss: 1.5883e-03\n",
      "Epoch [70/100], Loss: 1.6149e-03\n",
      "Epoch [80/100], Loss: 1.6276e-03\n",
      "Epoch [90/100], Loss: 1.6454e-03\n",
      "Epoch [100/100], Loss: 1.6883e-03\n",
      "#####--training model 106--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8515e-03\n",
      "Epoch [20/100], Loss: 3.0025e-03\n",
      "Epoch [30/100], Loss: 1.5369e-03\n",
      "Epoch [40/100], Loss: 1.2733e-03\n",
      "Epoch [50/100], Loss: 1.1497e-03\n",
      "Epoch [60/100], Loss: 9.1845e-04\n",
      "Epoch [70/100], Loss: 7.6165e-04\n",
      "Epoch [80/100], Loss: 6.7160e-04\n",
      "Epoch [90/100], Loss: 6.1438e-04\n",
      "Epoch [100/100], Loss: 5.7035e-04\n",
      "#####--training model 107--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5859e-03\n",
      "Epoch [20/100], Loss: 2.9053e-03\n",
      "Epoch [30/100], Loss: 6.7129e-04\n",
      "Epoch [40/100], Loss: 2.9844e-04\n",
      "Epoch [50/100], Loss: 8.4969e-05\n",
      "Epoch [60/100], Loss: 2.4681e-05\n",
      "Epoch [70/100], Loss: 1.1208e-05\n",
      "Epoch [80/100], Loss: 9.0307e-06\n",
      "Epoch [90/100], Loss: 1.0150e-05\n",
      "Epoch [100/100], Loss: 1.1733e-05\n",
      "#####--training model 108--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2782e-05\n",
      "Epoch [20/100], Loss: 1.3266e-04\n",
      "Epoch [30/100], Loss: 1.3872e-04\n",
      "Epoch [40/100], Loss: 1.2135e-04\n",
      "Epoch [50/100], Loss: 1.0750e-04\n",
      "Epoch [60/100], Loss: 9.7174e-05\n",
      "Epoch [70/100], Loss: 8.5737e-05\n",
      "Epoch [80/100], Loss: 7.1081e-05\n",
      "Epoch [90/100], Loss: 5.6854e-05\n",
      "Epoch [100/100], Loss: 4.2850e-05\n",
      "#####--training model 109--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3066e-03\n",
      "Epoch [20/100], Loss: 3.0029e-03\n",
      "Epoch [30/100], Loss: 1.0861e-03\n",
      "Epoch [40/100], Loss: 7.8082e-04\n",
      "Epoch [50/100], Loss: 6.1181e-04\n",
      "Epoch [60/100], Loss: 4.8778e-04\n",
      "Epoch [70/100], Loss: 3.5491e-04\n",
      "Epoch [80/100], Loss: 3.0506e-04\n",
      "Epoch [90/100], Loss: 3.0174e-04\n",
      "Epoch [100/100], Loss: 3.1838e-04\n",
      "#####--training model 110--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2467e-03\n",
      "Epoch [20/100], Loss: 3.3953e-03\n",
      "Epoch [30/100], Loss: 2.2139e-03\n",
      "Epoch [40/100], Loss: 1.8239e-03\n",
      "Epoch [50/100], Loss: 1.3768e-03\n",
      "Epoch [60/100], Loss: 1.1190e-03\n",
      "Epoch [70/100], Loss: 9.6531e-04\n",
      "Epoch [80/100], Loss: 8.5814e-04\n",
      "Epoch [90/100], Loss: 7.7771e-04\n",
      "Epoch [100/100], Loss: 7.2110e-04\n",
      "#####--training model 111--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.8386e-03\n",
      "Epoch [20/100], Loss: 8.0110e-04\n",
      "Epoch [30/100], Loss: 1.1519e-03\n",
      "Epoch [40/100], Loss: 1.0142e-03\n",
      "Epoch [50/100], Loss: 8.2317e-04\n",
      "Epoch [60/100], Loss: 7.6827e-04\n",
      "Epoch [70/100], Loss: 8.4619e-04\n",
      "Epoch [80/100], Loss: 8.6021e-04\n",
      "Epoch [90/100], Loss: 8.2625e-04\n",
      "Epoch [100/100], Loss: 7.6377e-04\n",
      "#####--training model 112--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8912e-03\n",
      "Epoch [20/100], Loss: 4.2496e-03\n",
      "Epoch [30/100], Loss: 2.1810e-03\n",
      "Epoch [40/100], Loss: 1.4736e-03\n",
      "Epoch [50/100], Loss: 1.0156e-03\n",
      "Epoch [60/100], Loss: 8.1812e-04\n",
      "Epoch [70/100], Loss: 6.4159e-04\n",
      "Epoch [80/100], Loss: 4.5781e-04\n",
      "Epoch [90/100], Loss: 3.4343e-04\n",
      "Epoch [100/100], Loss: 2.9428e-04\n",
      "#####--training model 113--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.3184e-03\n",
      "Epoch [20/100], Loss: 2.8728e-03\n",
      "Epoch [30/100], Loss: 1.9148e-03\n",
      "Epoch [40/100], Loss: 1.4593e-03\n",
      "Epoch [50/100], Loss: 1.2117e-03\n",
      "Epoch [60/100], Loss: 1.1665e-03\n",
      "Epoch [70/100], Loss: 1.0899e-03\n",
      "Epoch [80/100], Loss: 1.0028e-03\n",
      "Epoch [90/100], Loss: 9.2372e-04\n",
      "Epoch [100/100], Loss: 8.6171e-04\n",
      "#####--training model 114--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4929e-04\n",
      "Epoch [20/100], Loss: 2.1353e-04\n",
      "Epoch [30/100], Loss: 1.8453e-04\n",
      "Epoch [40/100], Loss: 1.7877e-04\n",
      "Epoch [50/100], Loss: 1.7899e-04\n",
      "Epoch [60/100], Loss: 1.8190e-04\n",
      "Epoch [70/100], Loss: 1.9292e-04\n",
      "Epoch [80/100], Loss: 2.4404e-04\n",
      "Epoch [90/100], Loss: 1.8935e-04\n",
      "Epoch [100/100], Loss: 2.1487e-04\n",
      "#####--training model 115--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4310e-03\n",
      "Epoch [20/100], Loss: 6.9667e-04\n",
      "Epoch [30/100], Loss: 1.6422e-03\n",
      "Epoch [40/100], Loss: 1.0072e-03\n",
      "Epoch [50/100], Loss: 6.7516e-04\n",
      "Epoch [60/100], Loss: 7.0702e-04\n",
      "Epoch [70/100], Loss: 7.1202e-04\n",
      "Epoch [80/100], Loss: 7.1343e-04\n",
      "Epoch [90/100], Loss: 7.1785e-04\n",
      "Epoch [100/100], Loss: 7.2575e-04\n",
      "#####--training model 116--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2366e-04\n",
      "Epoch [20/100], Loss: 6.8132e-04\n",
      "Epoch [30/100], Loss: 1.1273e-03\n",
      "Epoch [40/100], Loss: 1.2961e-03\n",
      "Epoch [50/100], Loss: 1.3896e-03\n",
      "Epoch [60/100], Loss: 1.4413e-03\n",
      "Epoch [70/100], Loss: 1.4790e-03\n",
      "Epoch [80/100], Loss: 1.5132e-03\n",
      "Epoch [90/100], Loss: 1.5398e-03\n",
      "Epoch [100/100], Loss: 1.5558e-03\n",
      "#####--training model 117--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.8731e-04\n",
      "Epoch [20/100], Loss: 7.8712e-04\n",
      "Epoch [30/100], Loss: 4.1262e-04\n",
      "Epoch [40/100], Loss: 3.8863e-04\n",
      "Epoch [50/100], Loss: 3.5701e-04\n",
      "Epoch [60/100], Loss: 3.2427e-04\n",
      "Epoch [70/100], Loss: 2.8892e-04\n",
      "Epoch [80/100], Loss: 2.5189e-04\n",
      "Epoch [90/100], Loss: 2.1847e-04\n",
      "Epoch [100/100], Loss: 1.9589e-04\n",
      "#####--training model 118--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3068e-03\n",
      "Epoch [20/100], Loss: 2.5439e-03\n",
      "Epoch [30/100], Loss: 1.6977e-03\n",
      "Epoch [40/100], Loss: 1.0669e-03\n",
      "Epoch [50/100], Loss: 6.8155e-04\n",
      "Epoch [60/100], Loss: 4.5054e-04\n",
      "Epoch [70/100], Loss: 2.9912e-04\n",
      "Epoch [80/100], Loss: 2.1835e-04\n",
      "Epoch [90/100], Loss: 1.8518e-04\n",
      "Epoch [100/100], Loss: 1.6790e-04\n",
      "#####--training model 119--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.2427e-03\n",
      "Epoch [20/100], Loss: 6.5551e-03\n",
      "Epoch [30/100], Loss: 4.5681e-03\n",
      "Epoch [40/100], Loss: 3.6617e-03\n",
      "Epoch [50/100], Loss: 3.3937e-03\n",
      "Epoch [60/100], Loss: 3.3235e-03\n",
      "Epoch [70/100], Loss: 3.2667e-03\n",
      "Epoch [80/100], Loss: 3.1903e-03\n",
      "Epoch [90/100], Loss: 3.1023e-03\n",
      "Epoch [100/100], Loss: 3.0124e-03\n",
      "#####--training model 120--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1909e-04\n",
      "Epoch [20/100], Loss: 4.5975e-05\n",
      "Epoch [30/100], Loss: 2.4379e-05\n",
      "Epoch [40/100], Loss: 1.4850e-05\n",
      "Epoch [50/100], Loss: 9.7685e-06\n",
      "Epoch [60/100], Loss: 6.7408e-06\n",
      "Epoch [70/100], Loss: 4.8019e-06\n",
      "Epoch [80/100], Loss: 3.4970e-06\n",
      "Epoch [90/100], Loss: 2.5871e-06\n",
      "Epoch [100/100], Loss: 1.9360e-06\n",
      "#####--training model 121--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4215e-04\n",
      "Epoch [20/100], Loss: 3.4199e-04\n",
      "Epoch [30/100], Loss: 3.5399e-04\n",
      "Epoch [40/100], Loss: 3.7468e-04\n",
      "Epoch [50/100], Loss: 4.5188e-04\n",
      "Epoch [60/100], Loss: 2.2034e-04\n",
      "Epoch [70/100], Loss: 1.5232e-04\n",
      "Epoch [80/100], Loss: 7.7812e-05\n",
      "Epoch [90/100], Loss: 3.3187e-05\n",
      "Epoch [100/100], Loss: 1.2778e-05\n",
      "#####--training model 122--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0661e-03\n",
      "Epoch [20/100], Loss: 1.0589e-03\n",
      "Epoch [30/100], Loss: 1.0645e-03\n",
      "Epoch [40/100], Loss: 1.0748e-03\n",
      "Epoch [50/100], Loss: 1.0997e-03\n",
      "Epoch [60/100], Loss: 1.1335e-03\n",
      "Epoch [70/100], Loss: 8.4803e-04\n",
      "Epoch [80/100], Loss: 6.6147e-04\n",
      "Epoch [90/100], Loss: 5.2277e-04\n",
      "Epoch [100/100], Loss: 4.1855e-04\n",
      "#####--training model 123--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6216e-04\n",
      "Epoch [20/100], Loss: 1.0381e-04\n",
      "Epoch [30/100], Loss: 9.4645e-05\n",
      "Epoch [40/100], Loss: 9.4076e-05\n",
      "Epoch [50/100], Loss: 9.4786e-05\n",
      "Epoch [60/100], Loss: 9.5718e-05\n",
      "Epoch [70/100], Loss: 9.6820e-05\n",
      "Epoch [80/100], Loss: 9.8106e-05\n",
      "Epoch [90/100], Loss: 9.9599e-05\n",
      "Epoch [100/100], Loss: 1.0136e-04\n",
      "#####--training model 124--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.9989e-04\n",
      "Epoch [20/100], Loss: 9.7108e-04\n",
      "Epoch [30/100], Loss: 1.0432e-03\n",
      "Epoch [40/100], Loss: 1.0780e-03\n",
      "Epoch [50/100], Loss: 1.0951e-03\n",
      "Epoch [60/100], Loss: 1.1034e-03\n",
      "Epoch [70/100], Loss: 1.1080e-03\n",
      "Epoch [80/100], Loss: 1.1105e-03\n",
      "Epoch [90/100], Loss: 1.1104e-03\n",
      "Epoch [100/100], Loss: 1.1052e-03\n",
      "#####--training model 125--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5775e-04\n",
      "Epoch [20/100], Loss: 1.7704e-04\n",
      "Epoch [30/100], Loss: 1.6586e-04\n",
      "Epoch [40/100], Loss: 1.6410e-04\n",
      "Epoch [50/100], Loss: 1.6317e-04\n",
      "Epoch [60/100], Loss: 1.6216e-04\n",
      "Epoch [70/100], Loss: 1.6107e-04\n",
      "Epoch [80/100], Loss: 1.5983e-04\n",
      "Epoch [90/100], Loss: 1.5748e-04\n",
      "Epoch [100/100], Loss: 1.5218e-04\n",
      "#####--training model 126--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3358e-03\n",
      "Epoch [20/100], Loss: 1.2072e-03\n",
      "Epoch [30/100], Loss: 1.1259e-04\n",
      "Epoch [40/100], Loss: 3.4789e-05\n",
      "Epoch [50/100], Loss: 1.5673e-05\n",
      "Epoch [60/100], Loss: 1.3711e-05\n",
      "Epoch [70/100], Loss: 2.2079e-05\n",
      "Epoch [80/100], Loss: 3.4567e-05\n",
      "Epoch [90/100], Loss: 5.7440e-05\n",
      "Epoch [100/100], Loss: 8.6609e-05\n",
      "#####--training model 127--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4721e-04\n",
      "Epoch [20/100], Loss: 8.0882e-05\n",
      "Epoch [30/100], Loss: 3.6806e-05\n",
      "Epoch [40/100], Loss: 2.7116e-05\n",
      "Epoch [50/100], Loss: 2.4067e-05\n",
      "Epoch [60/100], Loss: 2.2025e-05\n",
      "Epoch [70/100], Loss: 2.7304e-05\n",
      "Epoch [80/100], Loss: 4.4139e-05\n",
      "Epoch [90/100], Loss: 7.3585e-05\n",
      "Epoch [100/100], Loss: 1.0940e-04\n",
      "#####--training model 128--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.1703e-03\n",
      "Epoch [20/100], Loss: 5.5834e-03\n",
      "Epoch [30/100], Loss: 5.7361e-03\n",
      "Epoch [40/100], Loss: 5.8002e-03\n",
      "Epoch [50/100], Loss: 5.8254e-03\n",
      "Epoch [60/100], Loss: 5.8340e-03\n",
      "Epoch [70/100], Loss: 5.8372e-03\n",
      "Epoch [80/100], Loss: 5.8396e-03\n",
      "Epoch [90/100], Loss: 5.8422e-03\n",
      "Epoch [100/100], Loss: 5.8453e-03\n",
      "#####--training model 129--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5992e-04\n",
      "Epoch [20/100], Loss: 2.2282e-04\n",
      "Epoch [30/100], Loss: 2.2258e-04\n",
      "Epoch [40/100], Loss: 2.2444e-04\n",
      "Epoch [50/100], Loss: 2.2693e-04\n",
      "Epoch [60/100], Loss: 2.3067e-04\n",
      "Epoch [70/100], Loss: 2.3798e-04\n",
      "Epoch [80/100], Loss: 2.5889e-04\n",
      "Epoch [90/100], Loss: 3.5524e-04\n",
      "Epoch [100/100], Loss: 4.4512e-04\n",
      "#####--training model 130--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3502e-02\n",
      "Epoch [20/100], Loss: 1.3732e-02\n",
      "Epoch [30/100], Loss: 1.3732e-02\n",
      "Epoch [40/100], Loss: 1.3719e-02\n",
      "Epoch [50/100], Loss: 1.3690e-02\n",
      "Epoch [60/100], Loss: 1.3596e-02\n",
      "Epoch [70/100], Loss: 1.3338e-02\n",
      "Epoch [80/100], Loss: 1.2697e-02\n",
      "Epoch [90/100], Loss: 1.1694e-02\n",
      "Epoch [100/100], Loss: 1.1601e-02\n",
      "#####--training model 131--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.5904e-03\n",
      "Epoch [20/100], Loss: 4.4892e-03\n",
      "Epoch [30/100], Loss: 3.5628e-03\n",
      "Epoch [40/100], Loss: 2.8654e-03\n",
      "Epoch [50/100], Loss: 2.2448e-03\n",
      "Epoch [60/100], Loss: 1.7586e-03\n",
      "Epoch [70/100], Loss: 1.4671e-03\n",
      "Epoch [80/100], Loss: 1.3906e-03\n",
      "Epoch [90/100], Loss: 1.4616e-03\n",
      "Epoch [100/100], Loss: 1.5745e-03\n",
      "#####--training model 132--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.8760e-04\n",
      "Epoch [20/100], Loss: 4.9353e-04\n",
      "Epoch [30/100], Loss: 5.0297e-04\n",
      "Epoch [40/100], Loss: 5.3004e-04\n",
      "Epoch [50/100], Loss: 4.5277e-04\n",
      "Epoch [60/100], Loss: 4.4546e-04\n",
      "Epoch [70/100], Loss: 4.4825e-04\n",
      "Epoch [80/100], Loss: 4.5603e-04\n",
      "Epoch [90/100], Loss: 4.7201e-04\n",
      "Epoch [100/100], Loss: 4.9050e-04\n",
      "#####--training model 133--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.0963e-04\n",
      "Epoch [20/100], Loss: 5.9081e-04\n",
      "Epoch [30/100], Loss: 5.9849e-04\n",
      "Epoch [40/100], Loss: 6.0600e-04\n",
      "Epoch [50/100], Loss: 6.1334e-04\n",
      "Epoch [60/100], Loss: 6.2061e-04\n",
      "Epoch [70/100], Loss: 6.2851e-04\n",
      "Epoch [80/100], Loss: 6.3878e-04\n",
      "Epoch [90/100], Loss: 6.5576e-04\n",
      "Epoch [100/100], Loss: 6.9853e-04\n",
      "#####--training model 134--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5946e-04\n",
      "Epoch [20/100], Loss: 1.3269e-04\n",
      "Epoch [30/100], Loss: 9.8703e-05\n",
      "Epoch [40/100], Loss: 8.6965e-05\n",
      "Epoch [50/100], Loss: 8.3307e-05\n",
      "Epoch [60/100], Loss: 8.2622e-05\n",
      "Epoch [70/100], Loss: 8.2808e-05\n",
      "Epoch [80/100], Loss: 8.3207e-05\n",
      "Epoch [90/100], Loss: 8.3696e-05\n",
      "Epoch [100/100], Loss: 8.4268e-05\n",
      "#####--training model 135--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.7539e-04\n",
      "Epoch [20/100], Loss: 4.7199e-04\n",
      "Epoch [30/100], Loss: 4.7558e-04\n",
      "Epoch [40/100], Loss: 4.8030e-04\n",
      "Epoch [50/100], Loss: 4.8803e-04\n",
      "Epoch [60/100], Loss: 5.0346e-04\n",
      "Epoch [70/100], Loss: 5.5127e-04\n",
      "Epoch [80/100], Loss: 4.1123e-04\n",
      "Epoch [90/100], Loss: 2.7719e-04\n",
      "Epoch [100/100], Loss: 2.3419e-04\n",
      "#####--training model 136--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.3839e-04\n",
      "Epoch [20/100], Loss: 9.9462e-04\n",
      "Epoch [30/100], Loss: 1.2880e-03\n",
      "Epoch [40/100], Loss: 9.6724e-04\n",
      "Epoch [50/100], Loss: 8.9737e-04\n",
      "Epoch [60/100], Loss: 8.8478e-04\n",
      "Epoch [70/100], Loss: 9.1509e-04\n",
      "Epoch [80/100], Loss: 9.4042e-04\n",
      "Epoch [90/100], Loss: 9.1852e-04\n",
      "Epoch [100/100], Loss: 8.5673e-04\n",
      "#####--training model 137--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5858e-02\n",
      "Epoch [20/100], Loss: 1.5871e-02\n",
      "Epoch [30/100], Loss: 1.5862e-02\n",
      "Epoch [40/100], Loss: 1.5824e-02\n",
      "Epoch [50/100], Loss: 1.5737e-02\n",
      "Epoch [60/100], Loss: 1.6881e-02\n",
      "Epoch [70/100], Loss: 1.7080e-02\n",
      "Epoch [80/100], Loss: 1.7251e-02\n",
      "Epoch [90/100], Loss: 1.7450e-02\n",
      "Epoch [100/100], Loss: 1.7613e-02\n",
      "#####--training model 138--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.5678e-04\n",
      "Epoch [20/100], Loss: 6.3803e-04\n",
      "Epoch [30/100], Loss: 6.0932e-04\n",
      "Epoch [40/100], Loss: 6.5257e-04\n",
      "Epoch [50/100], Loss: 8.0501e-04\n",
      "Epoch [60/100], Loss: 7.6224e-04\n",
      "Epoch [70/100], Loss: 7.4211e-04\n",
      "Epoch [80/100], Loss: 7.3419e-04\n",
      "Epoch [90/100], Loss: 7.3051e-04\n",
      "Epoch [100/100], Loss: 7.2796e-04\n",
      "#####--training model 139--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1129e-03\n",
      "Epoch [20/100], Loss: 1.1614e-03\n",
      "Epoch [30/100], Loss: 1.1955e-03\n",
      "Epoch [40/100], Loss: 1.2433e-03\n",
      "Epoch [50/100], Loss: 1.3856e-03\n",
      "Epoch [60/100], Loss: 6.9012e-04\n",
      "Epoch [70/100], Loss: 3.4713e-04\n",
      "Epoch [80/100], Loss: 1.8471e-04\n",
      "Epoch [90/100], Loss: 1.5531e-04\n",
      "Epoch [100/100], Loss: 1.5446e-04\n",
      "#####--training model 140--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3158e-03\n",
      "Epoch [20/100], Loss: 8.1738e-04\n",
      "Epoch [30/100], Loss: 8.1908e-04\n",
      "Epoch [40/100], Loss: 5.3678e-04\n",
      "Epoch [50/100], Loss: 3.4574e-04\n",
      "Epoch [60/100], Loss: 2.5816e-04\n",
      "Epoch [70/100], Loss: 2.1002e-04\n",
      "Epoch [80/100], Loss: 1.7596e-04\n",
      "Epoch [90/100], Loss: 1.5040e-04\n",
      "Epoch [100/100], Loss: 1.3115e-04\n",
      "#####--training model 141--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.4577e-03\n",
      "Epoch [20/100], Loss: 5.1937e-03\n",
      "Epoch [30/100], Loss: 5.6381e-03\n",
      "Epoch [40/100], Loss: 5.9121e-03\n",
      "Epoch [50/100], Loss: 5.9896e-03\n",
      "Epoch [60/100], Loss: 6.0337e-03\n",
      "Epoch [70/100], Loss: 6.0577e-03\n",
      "Epoch [80/100], Loss: 6.0330e-03\n",
      "Epoch [90/100], Loss: 5.8787e-03\n",
      "Epoch [100/100], Loss: 5.4892e-03\n",
      "#####--training model 142--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8246e-04\n",
      "Epoch [20/100], Loss: 3.0263e-04\n",
      "Epoch [30/100], Loss: 2.0601e-04\n",
      "Epoch [40/100], Loss: 1.9466e-04\n",
      "Epoch [50/100], Loss: 1.8307e-04\n",
      "Epoch [60/100], Loss: 1.5616e-04\n",
      "Epoch [70/100], Loss: 1.2865e-04\n",
      "Epoch [80/100], Loss: 1.1962e-04\n",
      "Epoch [90/100], Loss: 1.2060e-04\n",
      "Epoch [100/100], Loss: 1.2830e-04\n",
      "#####--training model 143--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.6748e-04\n",
      "Epoch [20/100], Loss: 8.8611e-04\n",
      "Epoch [30/100], Loss: 3.2237e-04\n",
      "Epoch [40/100], Loss: 1.5890e-04\n",
      "Epoch [50/100], Loss: 7.5844e-05\n",
      "Epoch [60/100], Loss: 3.5709e-05\n",
      "Epoch [70/100], Loss: 2.2077e-05\n",
      "Epoch [80/100], Loss: 1.5122e-05\n",
      "Epoch [90/100], Loss: 1.0570e-05\n",
      "Epoch [100/100], Loss: 7.5424e-06\n",
      "#####--training model 144--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7123e-03\n",
      "Epoch [20/100], Loss: 1.7199e-03\n",
      "Epoch [30/100], Loss: 1.7518e-03\n",
      "Epoch [40/100], Loss: 1.8010e-03\n",
      "Epoch [50/100], Loss: 1.8552e-03\n",
      "Epoch [60/100], Loss: 1.9020e-03\n",
      "Epoch [70/100], Loss: 1.9329e-03\n",
      "Epoch [80/100], Loss: 1.9483e-03\n",
      "Epoch [90/100], Loss: 1.9612e-03\n",
      "Epoch [100/100], Loss: 1.9774e-03\n",
      "#####--training model 145--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4964e-03\n",
      "Epoch [20/100], Loss: 1.4428e-03\n",
      "Epoch [30/100], Loss: 1.3129e-03\n",
      "Epoch [40/100], Loss: 1.0919e-03\n",
      "Epoch [50/100], Loss: 8.6560e-04\n",
      "Epoch [60/100], Loss: 7.2812e-04\n",
      "Epoch [70/100], Loss: 5.3618e-04\n",
      "Epoch [80/100], Loss: 3.5560e-04\n",
      "Epoch [90/100], Loss: 2.4080e-04\n",
      "Epoch [100/100], Loss: 1.8125e-04\n",
      "#####--training model 146--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4997e-02\n",
      "Epoch [20/100], Loss: 1.2429e-02\n",
      "Epoch [30/100], Loss: 9.9000e-03\n",
      "Epoch [40/100], Loss: 5.8493e-03\n",
      "Epoch [50/100], Loss: 2.9178e-03\n",
      "Epoch [60/100], Loss: 1.9187e-03\n",
      "Epoch [70/100], Loss: 1.5840e-03\n",
      "Epoch [80/100], Loss: 1.4131e-03\n",
      "Epoch [90/100], Loss: 1.2810e-03\n",
      "Epoch [100/100], Loss: 1.1416e-03\n",
      "#####--training model 147--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0750e-01\n",
      "Epoch [20/100], Loss: 1.0675e-01\n",
      "Epoch [30/100], Loss: 1.3513e-02\n",
      "Epoch [40/100], Loss: 1.0174e-02\n",
      "Epoch [50/100], Loss: 1.0491e-02\n",
      "Epoch [60/100], Loss: 1.1191e-02\n",
      "Epoch [70/100], Loss: 1.1558e-02\n",
      "Epoch [80/100], Loss: 1.1530e-02\n",
      "Epoch [90/100], Loss: 1.1355e-02\n",
      "Epoch [100/100], Loss: 1.1103e-02\n",
      "#####--training model 148--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4800e-04\n",
      "Epoch [20/100], Loss: 1.2853e-04\n",
      "Epoch [30/100], Loss: 1.0499e-04\n",
      "Epoch [40/100], Loss: 9.9465e-05\n",
      "Epoch [50/100], Loss: 9.8342e-05\n",
      "Epoch [60/100], Loss: 9.7947e-05\n",
      "Epoch [70/100], Loss: 9.7548e-05\n",
      "Epoch [80/100], Loss: 9.7049e-05\n",
      "Epoch [90/100], Loss: 9.6431e-05\n",
      "Epoch [100/100], Loss: 9.5689e-05\n",
      "#####--training model 149--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.1719e-03\n",
      "Epoch [20/100], Loss: 3.3863e-03\n",
      "Epoch [30/100], Loss: 3.6470e-03\n",
      "Epoch [40/100], Loss: 4.1367e-03\n",
      "Epoch [50/100], Loss: 4.4017e-03\n",
      "Epoch [60/100], Loss: 4.5013e-03\n",
      "Epoch [70/100], Loss: 4.5156e-03\n",
      "Epoch [80/100], Loss: 4.4793e-03\n",
      "Epoch [90/100], Loss: 4.4255e-03\n",
      "Epoch [100/100], Loss: 4.4179e-03\n",
      "#####--training model 150--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.0937e-03\n",
      "Epoch [20/100], Loss: 7.5687e-03\n",
      "Epoch [30/100], Loss: 9.4908e-03\n",
      "Epoch [40/100], Loss: 9.2631e-03\n",
      "Epoch [50/100], Loss: 8.4220e-03\n",
      "Epoch [60/100], Loss: 7.8845e-03\n",
      "Epoch [70/100], Loss: 7.5979e-03\n",
      "Epoch [80/100], Loss: 7.4041e-03\n",
      "Epoch [90/100], Loss: 7.2747e-03\n",
      "Epoch [100/100], Loss: 7.2065e-03\n",
      "#####--training model 151--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.7311e-04\n",
      "Epoch [20/100], Loss: 1.0321e-03\n",
      "Epoch [30/100], Loss: 1.2089e-03\n",
      "Epoch [40/100], Loss: 6.5908e-04\n",
      "Epoch [50/100], Loss: 5.2508e-04\n",
      "Epoch [60/100], Loss: 4.8468e-04\n",
      "Epoch [70/100], Loss: 4.5711e-04\n",
      "Epoch [80/100], Loss: 4.3845e-04\n",
      "Epoch [90/100], Loss: 4.2381e-04\n",
      "Epoch [100/100], Loss: 4.0876e-04\n",
      "#####--training model 152--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.3945e-04\n",
      "Epoch [20/100], Loss: 5.2392e-04\n",
      "Epoch [30/100], Loss: 5.0979e-04\n",
      "Epoch [40/100], Loss: 4.8781e-04\n",
      "Epoch [50/100], Loss: 4.3636e-04\n",
      "Epoch [60/100], Loss: 2.7007e-04\n",
      "Epoch [70/100], Loss: 1.8982e-04\n",
      "Epoch [80/100], Loss: 1.7736e-04\n",
      "Epoch [90/100], Loss: 1.8236e-04\n",
      "Epoch [100/100], Loss: 1.8891e-04\n",
      "#####--training model 153--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.9363e-04\n",
      "Epoch [20/100], Loss: 4.6998e-04\n",
      "Epoch [30/100], Loss: 8.5708e-05\n",
      "Epoch [40/100], Loss: 4.6366e-05\n",
      "Epoch [50/100], Loss: 1.7359e-05\n",
      "Epoch [60/100], Loss: 1.2087e-05\n",
      "Epoch [70/100], Loss: 1.2445e-05\n",
      "Epoch [80/100], Loss: 1.2836e-05\n",
      "Epoch [90/100], Loss: 1.3221e-05\n",
      "Epoch [100/100], Loss: 1.3548e-05\n",
      "#####--training model 154--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1395e-03\n",
      "Epoch [20/100], Loss: 2.2148e-03\n",
      "Epoch [30/100], Loss: 2.8597e-03\n",
      "Epoch [40/100], Loss: 2.8625e-03\n",
      "Epoch [50/100], Loss: 2.6840e-03\n",
      "Epoch [60/100], Loss: 2.3811e-03\n",
      "Epoch [70/100], Loss: 2.1444e-03\n",
      "Epoch [80/100], Loss: 2.0882e-03\n",
      "Epoch [90/100], Loss: 2.0987e-03\n",
      "Epoch [100/100], Loss: 2.0697e-03\n",
      "#####--training model 155--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.5411e-04\n",
      "Epoch [20/100], Loss: 1.5571e-03\n",
      "Epoch [30/100], Loss: 1.8258e-03\n",
      "Epoch [40/100], Loss: 1.1385e-03\n",
      "Epoch [50/100], Loss: 6.1896e-04\n",
      "Epoch [60/100], Loss: 4.3981e-04\n",
      "Epoch [70/100], Loss: 3.8478e-04\n",
      "Epoch [80/100], Loss: 3.6322e-04\n",
      "Epoch [90/100], Loss: 3.5219e-04\n",
      "Epoch [100/100], Loss: 3.4548e-04\n",
      "#####--training model 156--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0311e-03\n",
      "Epoch [20/100], Loss: 4.5926e-04\n",
      "Epoch [30/100], Loss: 1.5578e-04\n",
      "Epoch [40/100], Loss: 1.3441e-04\n",
      "Epoch [50/100], Loss: 1.2999e-04\n",
      "Epoch [60/100], Loss: 1.2514e-04\n",
      "Epoch [70/100], Loss: 1.2106e-04\n",
      "Epoch [80/100], Loss: 1.1750e-04\n",
      "Epoch [90/100], Loss: 1.1371e-04\n",
      "Epoch [100/100], Loss: 1.0924e-04\n",
      "#####--training model 157--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.8866e-05\n",
      "Epoch [20/100], Loss: 5.7161e-05\n",
      "Epoch [30/100], Loss: 5.7804e-05\n",
      "Epoch [40/100], Loss: 5.8664e-05\n",
      "Epoch [50/100], Loss: 6.0058e-05\n",
      "Epoch [60/100], Loss: 6.3434e-05\n",
      "Epoch [70/100], Loss: 6.8899e-05\n",
      "Epoch [80/100], Loss: 2.9432e-05\n",
      "Epoch [90/100], Loss: 4.2981e-05\n",
      "Epoch [100/100], Loss: 5.2277e-05\n",
      "#####--training model 158--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4637e-02\n",
      "Epoch [20/100], Loss: 8.2018e-03\n",
      "Epoch [30/100], Loss: 5.1844e-03\n",
      "Epoch [40/100], Loss: 3.0435e-03\n",
      "Epoch [50/100], Loss: 2.5653e-03\n",
      "Epoch [60/100], Loss: 2.9053e-03\n",
      "Epoch [70/100], Loss: 3.2938e-03\n",
      "Epoch [80/100], Loss: 3.5958e-03\n",
      "Epoch [90/100], Loss: 3.6786e-03\n",
      "Epoch [100/100], Loss: 3.6328e-03\n",
      "#####--training model 159--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.1170e-03\n",
      "Epoch [20/100], Loss: 3.0855e-03\n",
      "Epoch [30/100], Loss: 3.4766e-03\n",
      "Epoch [40/100], Loss: 3.7189e-03\n",
      "Epoch [50/100], Loss: 3.5771e-03\n",
      "Epoch [60/100], Loss: 3.3935e-03\n",
      "Epoch [70/100], Loss: 3.1630e-03\n",
      "Epoch [80/100], Loss: 2.9486e-03\n",
      "Epoch [90/100], Loss: 2.8332e-03\n",
      "Epoch [100/100], Loss: 2.7850e-03\n",
      "#####--training model 160--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1206e-03\n",
      "Epoch [20/100], Loss: 1.1719e-03\n",
      "Epoch [30/100], Loss: 1.2539e-03\n",
      "Epoch [40/100], Loss: 2.0690e-03\n",
      "Epoch [50/100], Loss: 1.3487e-03\n",
      "Epoch [60/100], Loss: 1.3588e-03\n",
      "Epoch [70/100], Loss: 1.4530e-03\n",
      "Epoch [80/100], Loss: 1.5300e-03\n",
      "Epoch [90/100], Loss: 1.5679e-03\n",
      "Epoch [100/100], Loss: 1.5520e-03\n",
      "#####--training model 161--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.1362e-02\n",
      "Epoch [20/100], Loss: 1.9213e-02\n",
      "Epoch [30/100], Loss: 1.3314e-02\n",
      "Epoch [40/100], Loss: 1.0241e-02\n",
      "Epoch [50/100], Loss: 5.2752e-03\n",
      "Epoch [60/100], Loss: 2.5120e-03\n",
      "Epoch [70/100], Loss: 1.8727e-03\n",
      "Epoch [80/100], Loss: 1.7568e-03\n",
      "Epoch [90/100], Loss: 1.7323e-03\n",
      "Epoch [100/100], Loss: 1.6728e-03\n",
      "#####--training model 162--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.2906e-04\n",
      "Epoch [20/100], Loss: 1.6774e-04\n",
      "Epoch [30/100], Loss: 1.0456e-04\n",
      "Epoch [40/100], Loss: 6.0794e-05\n",
      "Epoch [50/100], Loss: 2.6090e-05\n",
      "Epoch [60/100], Loss: 1.4654e-05\n",
      "Epoch [70/100], Loss: 1.3275e-05\n",
      "Epoch [80/100], Loss: 1.1739e-05\n",
      "Epoch [90/100], Loss: 1.0103e-05\n",
      "Epoch [100/100], Loss: 8.8971e-06\n",
      "#####--training model 163--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7901e-04\n",
      "Epoch [20/100], Loss: 8.9443e-05\n",
      "Epoch [30/100], Loss: 6.3166e-05\n",
      "Epoch [40/100], Loss: 5.2806e-05\n",
      "Epoch [50/100], Loss: 4.8491e-05\n",
      "Epoch [60/100], Loss: 4.6698e-05\n",
      "Epoch [70/100], Loss: 4.5797e-05\n",
      "Epoch [80/100], Loss: 4.5088e-05\n",
      "Epoch [90/100], Loss: 4.4379e-05\n",
      "Epoch [100/100], Loss: 4.3693e-05\n",
      "#####--training model 164--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.0279e-03\n",
      "Epoch [20/100], Loss: 9.3100e-03\n",
      "Epoch [30/100], Loss: 7.9555e-03\n",
      "Epoch [40/100], Loss: 6.6263e-03\n",
      "Epoch [50/100], Loss: 6.3850e-03\n",
      "Epoch [60/100], Loss: 6.5457e-03\n",
      "Epoch [70/100], Loss: 6.6709e-03\n",
      "Epoch [80/100], Loss: 6.7867e-03\n",
      "Epoch [90/100], Loss: 6.8837e-03\n",
      "Epoch [100/100], Loss: 6.9438e-03\n",
      "#####--training model 165--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.7111e-03\n",
      "Epoch [20/100], Loss: 1.2065e-03\n",
      "Epoch [30/100], Loss: 1.0954e-03\n",
      "Epoch [40/100], Loss: 1.0146e-03\n",
      "Epoch [50/100], Loss: 9.5964e-04\n",
      "Epoch [60/100], Loss: 9.3267e-04\n",
      "Epoch [70/100], Loss: 9.1925e-04\n",
      "Epoch [80/100], Loss: 9.0561e-04\n",
      "Epoch [90/100], Loss: 8.8056e-04\n",
      "Epoch [100/100], Loss: 8.6312e-04\n",
      "#####--training model 166--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0076e-04\n",
      "Epoch [20/100], Loss: 1.1842e-04\n",
      "Epoch [30/100], Loss: 9.7146e-05\n",
      "Epoch [40/100], Loss: 9.1577e-05\n",
      "Epoch [50/100], Loss: 9.4642e-05\n",
      "Epoch [60/100], Loss: 1.0618e-04\n",
      "Epoch [70/100], Loss: 1.3818e-04\n",
      "Epoch [80/100], Loss: 1.4951e-04\n",
      "Epoch [90/100], Loss: 9.0087e-05\n",
      "Epoch [100/100], Loss: 7.0433e-05\n",
      "#####--training model 167--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.3647e-04\n",
      "Epoch [20/100], Loss: 9.8651e-04\n",
      "Epoch [30/100], Loss: 7.7043e-04\n",
      "Epoch [40/100], Loss: 5.5399e-04\n",
      "Epoch [50/100], Loss: 4.5439e-04\n",
      "Epoch [60/100], Loss: 4.2495e-04\n",
      "Epoch [70/100], Loss: 4.5143e-04\n",
      "Epoch [80/100], Loss: 4.5764e-04\n",
      "Epoch [90/100], Loss: 4.3719e-04\n",
      "Epoch [100/100], Loss: 4.0391e-04\n",
      "#####--training model 168--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3764e-04\n",
      "Epoch [20/100], Loss: 4.9910e-05\n",
      "Epoch [30/100], Loss: 2.5720e-05\n",
      "Epoch [40/100], Loss: 1.5401e-05\n",
      "Epoch [50/100], Loss: 1.0009e-05\n",
      "Epoch [60/100], Loss: 6.8410e-06\n",
      "Epoch [70/100], Loss: 4.8336e-06\n",
      "Epoch [80/100], Loss: 3.4948e-06\n",
      "Epoch [90/100], Loss: 2.5690e-06\n",
      "Epoch [100/100], Loss: 1.9116e-06\n",
      "#####--training model 169--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1722e-04\n",
      "Epoch [20/100], Loss: 8.0551e-05\n",
      "Epoch [30/100], Loss: 4.2769e-04\n",
      "Epoch [40/100], Loss: 6.6434e-04\n",
      "Epoch [50/100], Loss: 6.1493e-04\n",
      "Epoch [60/100], Loss: 5.4348e-04\n",
      "Epoch [70/100], Loss: 4.8153e-04\n",
      "Epoch [80/100], Loss: 4.3438e-04\n",
      "Epoch [90/100], Loss: 3.9933e-04\n",
      "Epoch [100/100], Loss: 3.7240e-04\n",
      "#####--training model 170--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.8322e-05\n",
      "Epoch [20/100], Loss: 4.2822e-05\n",
      "Epoch [30/100], Loss: 3.4928e-05\n",
      "Epoch [40/100], Loss: 3.6651e-05\n",
      "Epoch [50/100], Loss: 7.5580e-04\n",
      "Epoch [60/100], Loss: 5.4611e-03\n",
      "Epoch [70/100], Loss: 4.4693e-03\n",
      "Epoch [80/100], Loss: 5.2270e-03\n",
      "Epoch [90/100], Loss: 3.5503e-03\n",
      "Epoch [100/100], Loss: 3.5453e-03\n",
      "#####--training model 171--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.1711e-04\n",
      "Epoch [20/100], Loss: 4.2700e-04\n",
      "Epoch [30/100], Loss: 3.7713e-04\n",
      "Epoch [40/100], Loss: 1.8654e-04\n",
      "Epoch [50/100], Loss: 1.0323e-04\n",
      "Epoch [60/100], Loss: 9.0181e-05\n",
      "Epoch [70/100], Loss: 8.5795e-05\n",
      "Epoch [80/100], Loss: 8.0113e-05\n",
      "Epoch [90/100], Loss: 7.4639e-05\n",
      "Epoch [100/100], Loss: 7.0968e-05\n",
      "#####--training model 172--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4689e-04\n",
      "Epoch [20/100], Loss: 1.1037e-05\n",
      "Epoch [30/100], Loss: 5.3876e-06\n",
      "Epoch [40/100], Loss: 1.8321e-05\n",
      "Epoch [50/100], Loss: 2.7303e-05\n",
      "Epoch [60/100], Loss: 3.9800e-05\n",
      "Epoch [70/100], Loss: 5.4828e-05\n",
      "Epoch [80/100], Loss: 6.7056e-05\n",
      "Epoch [90/100], Loss: 7.4092e-05\n",
      "Epoch [100/100], Loss: 7.6776e-05\n",
      "#####--training model 173--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0229e-03\n",
      "Epoch [20/100], Loss: 1.0344e-03\n",
      "Epoch [30/100], Loss: 1.0447e-03\n",
      "Epoch [40/100], Loss: 1.0511e-03\n",
      "Epoch [50/100], Loss: 6.0365e-04\n",
      "Epoch [60/100], Loss: 4.3540e-04\n",
      "Epoch [70/100], Loss: 2.5974e-04\n",
      "Epoch [80/100], Loss: 1.7757e-04\n",
      "Epoch [90/100], Loss: 1.3647e-04\n",
      "Epoch [100/100], Loss: 1.1611e-04\n",
      "#####--training model 174--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.6930e-04\n",
      "Epoch [20/100], Loss: 8.2894e-04\n",
      "Epoch [30/100], Loss: 1.2227e-03\n",
      "Epoch [40/100], Loss: 8.7938e-04\n",
      "Epoch [50/100], Loss: 6.5563e-04\n",
      "Epoch [60/100], Loss: 5.0369e-04\n",
      "Epoch [70/100], Loss: 4.2054e-04\n",
      "Epoch [80/100], Loss: 3.7740e-04\n",
      "Epoch [90/100], Loss: 3.5450e-04\n",
      "Epoch [100/100], Loss: 3.4110e-04\n",
      "#####--training model 175--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2434e-03\n",
      "Epoch [20/100], Loss: 1.2525e-03\n",
      "Epoch [30/100], Loss: 1.2846e-03\n",
      "Epoch [40/100], Loss: 1.3379e-03\n",
      "Epoch [50/100], Loss: 1.1823e-03\n",
      "Epoch [60/100], Loss: 1.0109e-03\n",
      "Epoch [70/100], Loss: 9.6886e-04\n",
      "Epoch [80/100], Loss: 9.3220e-04\n",
      "Epoch [90/100], Loss: 8.8266e-04\n",
      "Epoch [100/100], Loss: 8.1256e-04\n",
      "#####--training model 176--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4986e-03\n",
      "Epoch [20/100], Loss: 1.4352e-03\n",
      "Epoch [30/100], Loss: 5.4628e-04\n",
      "Epoch [40/100], Loss: 4.8132e-04\n",
      "Epoch [50/100], Loss: 3.8677e-04\n",
      "Epoch [60/100], Loss: 3.2299e-04\n",
      "Epoch [70/100], Loss: 2.7945e-04\n",
      "Epoch [80/100], Loss: 2.5330e-04\n",
      "Epoch [90/100], Loss: 2.3763e-04\n",
      "Epoch [100/100], Loss: 2.2518e-04\n",
      "#####--training model 177--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.6990e-05\n",
      "Epoch [20/100], Loss: 1.5154e-04\n",
      "Epoch [30/100], Loss: 1.6138e-04\n",
      "Epoch [40/100], Loss: 1.3472e-04\n",
      "Epoch [50/100], Loss: 9.6898e-05\n",
      "Epoch [60/100], Loss: 6.0471e-05\n",
      "Epoch [70/100], Loss: 3.1934e-05\n",
      "Epoch [80/100], Loss: 1.4334e-05\n",
      "Epoch [90/100], Loss: 5.9278e-06\n",
      "Epoch [100/100], Loss: 4.3433e-06\n",
      "#####--training model 178--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9352e-04\n",
      "Epoch [20/100], Loss: 2.9458e-04\n",
      "Epoch [30/100], Loss: 1.8032e-04\n",
      "Epoch [40/100], Loss: 7.3770e-05\n",
      "Epoch [50/100], Loss: 9.8654e-05\n",
      "Epoch [60/100], Loss: 4.1116e-05\n",
      "Epoch [70/100], Loss: 1.6468e-05\n",
      "Epoch [80/100], Loss: 6.2881e-06\n",
      "Epoch [90/100], Loss: 2.2898e-06\n",
      "Epoch [100/100], Loss: 1.2971e-06\n",
      "#####--training model 179--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.7570e-04\n",
      "Epoch [20/100], Loss: 2.4488e-04\n",
      "Epoch [30/100], Loss: 2.4704e-04\n",
      "Epoch [40/100], Loss: 2.5332e-04\n",
      "Epoch [50/100], Loss: 2.6832e-04\n",
      "Epoch [60/100], Loss: 2.9698e-04\n",
      "Epoch [70/100], Loss: 2.1585e-04\n",
      "Epoch [80/100], Loss: 2.5352e-04\n",
      "Epoch [90/100], Loss: 2.5761e-04\n",
      "Epoch [100/100], Loss: 2.5450e-04\n",
      "#####--training model 180--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3636e-03\n",
      "Epoch [20/100], Loss: 2.1941e-03\n",
      "Epoch [30/100], Loss: 2.7954e-03\n",
      "Epoch [40/100], Loss: 2.7670e-03\n",
      "Epoch [50/100], Loss: 2.9103e-03\n",
      "Epoch [60/100], Loss: 3.0870e-03\n",
      "Epoch [70/100], Loss: 3.3215e-03\n",
      "Epoch [80/100], Loss: 3.6072e-03\n",
      "Epoch [90/100], Loss: 3.9037e-03\n",
      "Epoch [100/100], Loss: 4.2148e-03\n",
      "#####--training model 181--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0412e-03\n",
      "Epoch [20/100], Loss: 1.0710e-03\n",
      "Epoch [30/100], Loss: 1.1379e-03\n",
      "Epoch [40/100], Loss: 1.3582e-03\n",
      "Epoch [50/100], Loss: 2.0096e-03\n",
      "Epoch [60/100], Loss: 2.4422e-03\n",
      "Epoch [70/100], Loss: 2.5443e-03\n",
      "Epoch [80/100], Loss: 2.5214e-03\n",
      "Epoch [90/100], Loss: 2.4267e-03\n",
      "Epoch [100/100], Loss: 2.4250e-03\n",
      "#####--training model 182--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7892e-02\n",
      "Epoch [20/100], Loss: 2.0131e-02\n",
      "Epoch [30/100], Loss: 2.5722e-02\n",
      "Epoch [40/100], Loss: 2.8811e-02\n",
      "Epoch [50/100], Loss: 2.9620e-02\n",
      "Epoch [60/100], Loss: 2.9538e-02\n",
      "Epoch [70/100], Loss: 2.9176e-02\n",
      "Epoch [80/100], Loss: 2.8768e-02\n",
      "Epoch [90/100], Loss: 2.8345e-02\n",
      "Epoch [100/100], Loss: 2.7889e-02\n",
      "#####--training model 183--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8575e-04\n",
      "Epoch [20/100], Loss: 1.9368e-04\n",
      "Epoch [30/100], Loss: 1.8257e-04\n",
      "Epoch [40/100], Loss: 1.8699e-04\n",
      "Epoch [50/100], Loss: 1.8860e-04\n",
      "Epoch [60/100], Loss: 2.0269e-04\n",
      "Epoch [70/100], Loss: 2.4443e-04\n",
      "Epoch [80/100], Loss: 2.2864e-04\n",
      "Epoch [90/100], Loss: 2.4850e-04\n",
      "Epoch [100/100], Loss: 2.7498e-04\n",
      "#####--training model 184--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.7123e-03\n",
      "Epoch [20/100], Loss: 5.4314e-05\n",
      "Epoch [30/100], Loss: 4.2624e-05\n",
      "Epoch [40/100], Loss: 1.9880e-04\n",
      "Epoch [50/100], Loss: 1.6357e-04\n",
      "Epoch [60/100], Loss: 1.5431e-04\n",
      "Epoch [70/100], Loss: 1.6244e-04\n",
      "Epoch [80/100], Loss: 1.7409e-04\n",
      "Epoch [90/100], Loss: 1.8593e-04\n",
      "Epoch [100/100], Loss: 1.9695e-04\n",
      "#####--training model 185--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.4955e-06\n",
      "Epoch [20/100], Loss: 6.2588e-06\n",
      "Epoch [30/100], Loss: 1.1530e-05\n",
      "Epoch [40/100], Loss: 1.7439e-05\n",
      "Epoch [50/100], Loss: 1.4586e-05\n",
      "Epoch [60/100], Loss: 1.6980e-05\n",
      "Epoch [70/100], Loss: 1.8625e-05\n",
      "Epoch [80/100], Loss: 1.8282e-05\n",
      "Epoch [90/100], Loss: 1.4949e-05\n",
      "Epoch [100/100], Loss: 1.2524e-05\n",
      "#####--training model 186--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.6811e-06\n",
      "Epoch [20/100], Loss: 7.0362e-06\n",
      "Epoch [30/100], Loss: 7.0435e-06\n",
      "Epoch [40/100], Loss: 7.0869e-06\n",
      "Epoch [50/100], Loss: 7.1543e-06\n",
      "Epoch [60/100], Loss: 7.2523e-06\n",
      "Epoch [70/100], Loss: 7.3975e-06\n",
      "Epoch [80/100], Loss: 7.7823e-06\n",
      "Epoch [90/100], Loss: 1.1660e-05\n",
      "Epoch [100/100], Loss: 1.7513e-05\n",
      "#####--training model 187--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9269e-02\n",
      "Epoch [20/100], Loss: 2.8337e-03\n",
      "Epoch [30/100], Loss: 1.0767e-03\n",
      "Epoch [40/100], Loss: 3.1138e-04\n",
      "Epoch [50/100], Loss: 2.0022e-04\n",
      "Epoch [60/100], Loss: 1.9525e-04\n",
      "Epoch [70/100], Loss: 2.0487e-04\n",
      "Epoch [80/100], Loss: 2.1525e-04\n",
      "Epoch [90/100], Loss: 2.2342e-04\n",
      "Epoch [100/100], Loss: 2.2843e-04\n",
      "#####--training model 188--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.6545e-03\n",
      "Epoch [20/100], Loss: 1.6818e-03\n",
      "Epoch [30/100], Loss: 1.4436e-03\n",
      "Epoch [40/100], Loss: 1.2549e-03\n",
      "Epoch [50/100], Loss: 1.1094e-03\n",
      "Epoch [60/100], Loss: 1.0465e-03\n",
      "Epoch [70/100], Loss: 1.0103e-03\n",
      "Epoch [80/100], Loss: 1.0032e-03\n",
      "Epoch [90/100], Loss: 1.0132e-03\n",
      "Epoch [100/100], Loss: 6.8769e-04\n",
      "#####--training model 189--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3652e-04\n",
      "Epoch [20/100], Loss: 9.5320e-05\n",
      "Epoch [30/100], Loss: 5.7932e-05\n",
      "Epoch [40/100], Loss: 4.2095e-05\n",
      "Epoch [50/100], Loss: 3.3945e-05\n",
      "Epoch [60/100], Loss: 2.9393e-05\n",
      "Epoch [70/100], Loss: 2.6821e-05\n",
      "Epoch [80/100], Loss: 2.5434e-05\n",
      "Epoch [90/100], Loss: 2.4762e-05\n",
      "Epoch [100/100], Loss: 2.4510e-05\n",
      "#####--training model 190--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9158e-04\n",
      "Epoch [20/100], Loss: 2.2179e-04\n",
      "Epoch [30/100], Loss: 3.2128e-04\n",
      "Epoch [40/100], Loss: 1.4349e-04\n",
      "Epoch [50/100], Loss: 7.4390e-05\n",
      "Epoch [60/100], Loss: 1.7521e-04\n",
      "Epoch [70/100], Loss: 3.8641e-04\n",
      "Epoch [80/100], Loss: 5.4057e-04\n",
      "Epoch [90/100], Loss: 6.2366e-04\n",
      "Epoch [100/100], Loss: 6.6957e-04\n",
      "#####--training model 191--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6508e-03\n",
      "Epoch [20/100], Loss: 9.6275e-04\n",
      "Epoch [30/100], Loss: 1.8099e-04\n",
      "Epoch [40/100], Loss: 1.9564e-04\n",
      "Epoch [50/100], Loss: 2.5716e-04\n",
      "Epoch [60/100], Loss: 3.0046e-04\n",
      "Epoch [70/100], Loss: 3.3299e-04\n",
      "Epoch [80/100], Loss: 3.5211e-04\n",
      "Epoch [90/100], Loss: 3.6659e-04\n",
      "Epoch [100/100], Loss: 3.7931e-04\n",
      "#####--training model 192--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.8078e-04\n",
      "Epoch [20/100], Loss: 1.8434e-04\n",
      "Epoch [30/100], Loss: 2.0299e-04\n",
      "Epoch [40/100], Loss: 2.3612e-04\n",
      "Epoch [50/100], Loss: 3.0272e-04\n",
      "Epoch [60/100], Loss: 5.1690e-04\n",
      "Epoch [70/100], Loss: 7.0300e-04\n",
      "Epoch [80/100], Loss: 7.3275e-04\n",
      "Epoch [90/100], Loss: 7.4742e-04\n",
      "Epoch [100/100], Loss: 7.5922e-04\n",
      "#####--training model 193--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.2202e-02\n",
      "Epoch [20/100], Loss: 6.2774e-02\n",
      "Epoch [30/100], Loss: 6.2899e-02\n",
      "Epoch [40/100], Loss: 6.2948e-02\n",
      "Epoch [50/100], Loss: 6.2589e-02\n",
      "Epoch [60/100], Loss: 5.4510e-02\n",
      "Epoch [70/100], Loss: 2.7003e-02\n",
      "Epoch [80/100], Loss: 2.4752e-02\n",
      "Epoch [90/100], Loss: 2.4567e-02\n",
      "Epoch [100/100], Loss: 2.8260e-02\n",
      "#####--training model 194--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8878e-03\n",
      "Epoch [20/100], Loss: 3.5843e-03\n",
      "Epoch [30/100], Loss: 2.9225e-03\n",
      "Epoch [40/100], Loss: 1.9058e-03\n",
      "Epoch [50/100], Loss: 1.4544e-03\n",
      "Epoch [60/100], Loss: 1.2087e-03\n",
      "Epoch [70/100], Loss: 1.0352e-03\n",
      "Epoch [80/100], Loss: 9.0529e-04\n",
      "Epoch [90/100], Loss: 8.0575e-04\n",
      "Epoch [100/100], Loss: 7.2251e-04\n",
      "#####--training model 195--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.2753e-07\n",
      "Epoch [20/100], Loss: 6.8545e-06\n",
      "Epoch [30/100], Loss: 1.1650e-05\n",
      "Epoch [40/100], Loss: 6.9623e-06\n",
      "Epoch [50/100], Loss: 1.3973e-05\n",
      "Epoch [60/100], Loss: 3.0161e-05\n",
      "Epoch [70/100], Loss: 4.4742e-05\n",
      "Epoch [80/100], Loss: 5.0673e-05\n",
      "Epoch [90/100], Loss: 5.2797e-05\n",
      "Epoch [100/100], Loss: 5.3611e-05\n",
      "#####--training model 196--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.1301e-03\n",
      "Epoch [20/100], Loss: 1.3797e-03\n",
      "Epoch [30/100], Loss: 7.8812e-04\n",
      "Epoch [40/100], Loss: 5.2237e-04\n",
      "Epoch [50/100], Loss: 4.1492e-04\n",
      "Epoch [60/100], Loss: 4.4810e-04\n",
      "Epoch [70/100], Loss: 4.1771e-04\n",
      "Epoch [80/100], Loss: 3.7632e-04\n",
      "Epoch [90/100], Loss: 3.3295e-04\n",
      "Epoch [100/100], Loss: 2.8900e-04\n",
      "#####--training model 197--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5805e-04\n",
      "Epoch [20/100], Loss: 2.0242e-04\n",
      "Epoch [30/100], Loss: 1.9878e-04\n",
      "Epoch [40/100], Loss: 2.0108e-04\n",
      "Epoch [50/100], Loss: 2.0450e-04\n",
      "Epoch [60/100], Loss: 2.1008e-04\n",
      "Epoch [70/100], Loss: 2.3218e-04\n",
      "Epoch [80/100], Loss: 2.3883e-04\n",
      "Epoch [90/100], Loss: 2.2270e-04\n",
      "Epoch [100/100], Loss: 2.1010e-04\n",
      "#####--training model 198--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.5495e-03\n",
      "Epoch [20/100], Loss: 4.8038e-03\n",
      "Epoch [30/100], Loss: 1.5734e-03\n",
      "Epoch [40/100], Loss: 1.0328e-03\n",
      "Epoch [50/100], Loss: 8.9399e-04\n",
      "Epoch [60/100], Loss: 7.9762e-04\n",
      "Epoch [70/100], Loss: 7.0850e-04\n",
      "Epoch [80/100], Loss: 6.2698e-04\n",
      "Epoch [90/100], Loss: 5.6756e-04\n",
      "Epoch [100/100], Loss: 5.3647e-04\n",
      "#####--training model 199--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.8921e-03\n",
      "Epoch [20/100], Loss: 7.5668e-03\n",
      "Epoch [30/100], Loss: 6.9439e-03\n",
      "Epoch [40/100], Loss: 2.5423e-03\n",
      "Epoch [50/100], Loss: 2.5919e-03\n",
      "Epoch [60/100], Loss: 1.6470e-03\n",
      "Epoch [70/100], Loss: 1.0035e-03\n",
      "Epoch [80/100], Loss: 8.9691e-04\n",
      "Epoch [90/100], Loss: 8.7578e-04\n",
      "Epoch [100/100], Loss: 8.6830e-04\n",
      "#####--training model 200--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5397e-03\n",
      "Epoch [20/100], Loss: 5.5708e-04\n",
      "Epoch [30/100], Loss: 5.2576e-04\n",
      "Epoch [40/100], Loss: 4.5435e-04\n",
      "Epoch [50/100], Loss: 3.5184e-04\n",
      "Epoch [60/100], Loss: 2.3313e-04\n",
      "Epoch [70/100], Loss: 1.2065e-04\n",
      "Epoch [80/100], Loss: 3.8115e-05\n",
      "Epoch [90/100], Loss: 1.4222e-06\n",
      "Epoch [100/100], Loss: 1.2792e-05\n",
      "#####--training model 201--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1479e-03\n",
      "Epoch [20/100], Loss: 7.6712e-04\n",
      "Epoch [30/100], Loss: 5.5321e-04\n",
      "Epoch [40/100], Loss: 3.6916e-04\n",
      "Epoch [50/100], Loss: 2.7193e-04\n",
      "Epoch [60/100], Loss: 2.1781e-04\n",
      "Epoch [70/100], Loss: 1.6653e-04\n",
      "Epoch [80/100], Loss: 1.3856e-04\n",
      "Epoch [90/100], Loss: 1.2254e-04\n",
      "Epoch [100/100], Loss: 1.1350e-04\n",
      "#####--training model 202--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.9451e-04\n",
      "Epoch [20/100], Loss: 7.6114e-04\n",
      "Epoch [30/100], Loss: 9.1320e-04\n",
      "Epoch [40/100], Loss: 1.2815e-03\n",
      "Epoch [50/100], Loss: 1.1741e-03\n",
      "Epoch [60/100], Loss: 9.9694e-04\n",
      "Epoch [70/100], Loss: 9.2303e-04\n",
      "Epoch [80/100], Loss: 9.0203e-04\n",
      "Epoch [90/100], Loss: 8.8403e-04\n",
      "Epoch [100/100], Loss: 8.5943e-04\n",
      "#####--training model 203--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0745e-02\n",
      "Epoch [20/100], Loss: 2.0732e-02\n",
      "Epoch [30/100], Loss: 1.9880e-02\n",
      "Epoch [40/100], Loss: 1.9287e-02\n",
      "Epoch [50/100], Loss: 1.8423e-02\n",
      "Epoch [60/100], Loss: 1.6959e-02\n",
      "Epoch [70/100], Loss: 1.5280e-02\n",
      "Epoch [80/100], Loss: 1.3803e-02\n",
      "Epoch [90/100], Loss: 1.2963e-02\n",
      "Epoch [100/100], Loss: 1.2597e-02\n",
      "#####--training model 204--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3916e-04\n",
      "Epoch [20/100], Loss: 3.0554e-04\n",
      "Epoch [30/100], Loss: 3.0283e-04\n",
      "Epoch [40/100], Loss: 3.0092e-04\n",
      "Epoch [50/100], Loss: 2.9857e-04\n",
      "Epoch [60/100], Loss: 2.9547e-04\n",
      "Epoch [70/100], Loss: 2.9102e-04\n",
      "Epoch [80/100], Loss: 2.8412e-04\n",
      "Epoch [90/100], Loss: 2.7008e-04\n",
      "Epoch [100/100], Loss: 2.3964e-04\n",
      "#####--training model 205--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.7669e-03\n",
      "Epoch [20/100], Loss: 5.9946e-03\n",
      "Epoch [30/100], Loss: 4.2662e-03\n",
      "Epoch [40/100], Loss: 3.6268e-03\n",
      "Epoch [50/100], Loss: 3.3916e-03\n",
      "Epoch [60/100], Loss: 3.2695e-03\n",
      "Epoch [70/100], Loss: 3.2045e-03\n",
      "Epoch [80/100], Loss: 3.1564e-03\n",
      "Epoch [90/100], Loss: 3.1088e-03\n",
      "Epoch [100/100], Loss: 3.0628e-03\n",
      "#####--training model 206--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9011e-04\n",
      "Epoch [20/100], Loss: 1.6250e-04\n",
      "Epoch [30/100], Loss: 1.3187e-04\n",
      "Epoch [40/100], Loss: 1.2346e-04\n",
      "Epoch [50/100], Loss: 1.2159e-04\n",
      "Epoch [60/100], Loss: 1.2120e-04\n",
      "Epoch [70/100], Loss: 1.2103e-04\n",
      "Epoch [80/100], Loss: 1.2097e-04\n",
      "Epoch [90/100], Loss: 1.2136e-04\n",
      "Epoch [100/100], Loss: 1.2396e-04\n",
      "#####--training model 207--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7979e-03\n",
      "Epoch [20/100], Loss: 2.9527e-03\n",
      "Epoch [30/100], Loss: 3.3643e-03\n",
      "Epoch [40/100], Loss: 3.1716e-03\n",
      "Epoch [50/100], Loss: 2.9730e-03\n",
      "Epoch [60/100], Loss: 2.8676e-03\n",
      "Epoch [70/100], Loss: 2.8056e-03\n",
      "Epoch [80/100], Loss: 2.7536e-03\n",
      "Epoch [90/100], Loss: 2.7108e-03\n",
      "Epoch [100/100], Loss: 2.6690e-03\n",
      "#####--training model 208--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3472e-02\n",
      "Epoch [20/100], Loss: 1.2826e-02\n",
      "Epoch [30/100], Loss: 9.6810e-03\n",
      "Epoch [40/100], Loss: 7.7773e-03\n",
      "Epoch [50/100], Loss: 7.0328e-03\n",
      "Epoch [60/100], Loss: 6.6725e-03\n",
      "Epoch [70/100], Loss: 6.3857e-03\n",
      "Epoch [80/100], Loss: 6.1113e-03\n",
      "Epoch [90/100], Loss: 5.8372e-03\n",
      "Epoch [100/100], Loss: 5.5640e-03\n",
      "#####--training model 209--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7735e-02\n",
      "Epoch [20/100], Loss: 1.3457e-02\n",
      "Epoch [30/100], Loss: 9.9652e-03\n",
      "Epoch [40/100], Loss: 7.9056e-03\n",
      "Epoch [50/100], Loss: 6.9696e-03\n",
      "Epoch [60/100], Loss: 6.4887e-03\n",
      "Epoch [70/100], Loss: 6.1904e-03\n",
      "Epoch [80/100], Loss: 6.0265e-03\n",
      "Epoch [90/100], Loss: 5.9733e-03\n",
      "Epoch [100/100], Loss: 5.9910e-03\n",
      "#####--training model 210--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.8557e-05\n",
      "Epoch [20/100], Loss: 3.8708e-05\n",
      "Epoch [30/100], Loss: 2.2769e-05\n",
      "Epoch [40/100], Loss: 1.5385e-05\n",
      "Epoch [50/100], Loss: 1.1294e-05\n",
      "Epoch [60/100], Loss: 8.7635e-06\n",
      "Epoch [70/100], Loss: 7.0895e-06\n",
      "Epoch [80/100], Loss: 5.9362e-06\n",
      "Epoch [90/100], Loss: 5.1247e-06\n",
      "Epoch [100/100], Loss: 4.5513e-06\n",
      "#####--training model 211--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.5859e-02\n",
      "Epoch [20/100], Loss: 2.1018e-03\n",
      "Epoch [30/100], Loss: 1.9718e-03\n",
      "Epoch [40/100], Loss: 1.8337e-03\n",
      "Epoch [50/100], Loss: 1.5982e-03\n",
      "Epoch [60/100], Loss: 6.3099e-04\n",
      "Epoch [70/100], Loss: 1.9806e-03\n",
      "Epoch [80/100], Loss: 1.7063e-03\n",
      "Epoch [90/100], Loss: 2.3336e-03\n",
      "Epoch [100/100], Loss: 2.0312e-03\n",
      "#####--training model 212--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1027e-03\n",
      "Epoch [20/100], Loss: 1.0841e-03\n",
      "Epoch [30/100], Loss: 6.9008e-04\n",
      "Epoch [40/100], Loss: 3.8826e-04\n",
      "Epoch [50/100], Loss: 2.6800e-04\n",
      "Epoch [60/100], Loss: 1.9704e-04\n",
      "Epoch [70/100], Loss: 1.3833e-04\n",
      "Epoch [80/100], Loss: 9.7552e-05\n",
      "Epoch [90/100], Loss: 8.1088e-05\n",
      "Epoch [100/100], Loss: 7.2013e-05\n",
      "#####--training model 213--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.1731e-03\n",
      "Epoch [20/100], Loss: 1.0686e-03\n",
      "Epoch [30/100], Loss: 5.4003e-04\n",
      "Epoch [40/100], Loss: 4.4881e-04\n",
      "Epoch [50/100], Loss: 3.7297e-04\n",
      "Epoch [60/100], Loss: 3.1223e-04\n",
      "Epoch [70/100], Loss: 2.7801e-04\n",
      "Epoch [80/100], Loss: 2.8002e-04\n",
      "Epoch [90/100], Loss: 2.6210e-04\n",
      "Epoch [100/100], Loss: 2.2410e-04\n",
      "#####--training model 214--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.2129e-02\n",
      "Epoch [20/100], Loss: 5.0441e-03\n",
      "Epoch [30/100], Loss: 3.5877e-03\n",
      "Epoch [40/100], Loss: 2.7272e-03\n",
      "Epoch [50/100], Loss: 1.6930e-03\n",
      "Epoch [60/100], Loss: 4.8217e-04\n",
      "Epoch [70/100], Loss: 1.7852e-04\n",
      "Epoch [80/100], Loss: 4.0717e-04\n",
      "Epoch [90/100], Loss: 4.7557e-04\n",
      "Epoch [100/100], Loss: 4.9675e-04\n",
      "#####--training model 215--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.6116e-02\n",
      "Epoch [20/100], Loss: 1.3570e-03\n",
      "Epoch [30/100], Loss: 6.8730e-04\n",
      "Epoch [40/100], Loss: 2.9712e-04\n",
      "Epoch [50/100], Loss: 2.6829e-04\n",
      "Epoch [60/100], Loss: 5.5563e-04\n",
      "Epoch [70/100], Loss: 4.0443e-04\n",
      "Epoch [80/100], Loss: 2.0446e-04\n",
      "Epoch [90/100], Loss: 1.2474e-04\n",
      "Epoch [100/100], Loss: 1.1773e-04\n",
      "#####--training model 216--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2829e-04\n",
      "Epoch [20/100], Loss: 4.4256e-05\n",
      "Epoch [30/100], Loss: 2.1191e-05\n",
      "Epoch [40/100], Loss: 1.2152e-05\n",
      "Epoch [50/100], Loss: 7.6852e-06\n",
      "Epoch [60/100], Loss: 5.1562e-06\n",
      "Epoch [70/100], Loss: 3.5971e-06\n",
      "Epoch [80/100], Loss: 2.5781e-06\n",
      "Epoch [90/100], Loss: 1.8836e-06\n",
      "Epoch [100/100], Loss: 1.3954e-06\n",
      "#####--training model 217--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.1767e-02\n",
      "Epoch [20/100], Loss: 3.0775e-03\n",
      "Epoch [30/100], Loss: 2.1699e-03\n",
      "Epoch [40/100], Loss: 1.7577e-03\n",
      "Epoch [50/100], Loss: 1.3719e-03\n",
      "Epoch [60/100], Loss: 9.9374e-04\n",
      "Epoch [70/100], Loss: 6.6926e-04\n",
      "Epoch [80/100], Loss: 4.2637e-04\n",
      "Epoch [90/100], Loss: 2.6996e-04\n",
      "Epoch [100/100], Loss: 2.0391e-04\n",
      "#####--training model 218--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7220e-04\n",
      "Epoch [20/100], Loss: 3.3870e-04\n",
      "Epoch [30/100], Loss: 5.1768e-04\n",
      "Epoch [40/100], Loss: 5.9279e-04\n",
      "Epoch [50/100], Loss: 5.9004e-04\n",
      "Epoch [60/100], Loss: 5.6093e-04\n",
      "Epoch [70/100], Loss: 5.3953e-04\n",
      "Epoch [80/100], Loss: 5.3757e-04\n",
      "Epoch [90/100], Loss: 5.5374e-04\n",
      "Epoch [100/100], Loss: 5.8353e-04\n",
      "#####--training model 219--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5118e-04\n",
      "Epoch [20/100], Loss: 5.6303e-05\n",
      "Epoch [30/100], Loss: 2.9967e-05\n",
      "Epoch [40/100], Loss: 1.8577e-05\n",
      "Epoch [50/100], Loss: 1.2531e-05\n",
      "Epoch [60/100], Loss: 8.9170e-06\n",
      "Epoch [70/100], Loss: 6.5840e-06\n",
      "Epoch [80/100], Loss: 4.9963e-06\n",
      "Epoch [90/100], Loss: 3.8738e-06\n",
      "Epoch [100/100], Loss: 3.0577e-06\n",
      "#####--training model 220--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8102e-03\n",
      "Epoch [20/100], Loss: 1.3718e-03\n",
      "Epoch [30/100], Loss: 1.3221e-03\n",
      "Epoch [40/100], Loss: 1.4440e-03\n",
      "Epoch [50/100], Loss: 1.7910e-03\n",
      "Epoch [60/100], Loss: 2.4189e-03\n",
      "Epoch [70/100], Loss: 3.0738e-03\n",
      "Epoch [80/100], Loss: 3.4582e-03\n",
      "Epoch [90/100], Loss: 3.5486e-03\n",
      "Epoch [100/100], Loss: 3.4417e-03\n",
      "#####--training model 221--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2353e-03\n",
      "Epoch [20/100], Loss: 2.8120e-03\n",
      "Epoch [30/100], Loss: 3.7537e-03\n",
      "Epoch [40/100], Loss: 3.2318e-03\n",
      "Epoch [50/100], Loss: 2.8349e-03\n",
      "Epoch [60/100], Loss: 2.5011e-03\n",
      "Epoch [70/100], Loss: 2.2504e-03\n",
      "Epoch [80/100], Loss: 2.1160e-03\n",
      "Epoch [90/100], Loss: 2.0316e-03\n",
      "Epoch [100/100], Loss: 1.9600e-03\n",
      "#####--training model 222--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8855e-03\n",
      "Epoch [20/100], Loss: 1.9231e-03\n",
      "Epoch [30/100], Loss: 1.8091e-03\n",
      "Epoch [40/100], Loss: 1.3132e-03\n",
      "Epoch [50/100], Loss: 9.1475e-04\n",
      "Epoch [60/100], Loss: 7.1238e-04\n",
      "Epoch [70/100], Loss: 5.6695e-04\n",
      "Epoch [80/100], Loss: 4.6127e-04\n",
      "Epoch [90/100], Loss: 3.9947e-04\n",
      "Epoch [100/100], Loss: 3.6293e-04\n",
      "#####--training model 223--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.8380e-02\n",
      "Epoch [20/100], Loss: 8.9744e-03\n",
      "Epoch [30/100], Loss: 5.1335e-03\n",
      "Epoch [40/100], Loss: 5.1843e-03\n",
      "Epoch [50/100], Loss: 5.4421e-03\n",
      "Epoch [60/100], Loss: 5.6518e-03\n",
      "Epoch [70/100], Loss: 5.7901e-03\n",
      "Epoch [80/100], Loss: 5.6834e-03\n",
      "Epoch [90/100], Loss: 5.5127e-03\n",
      "Epoch [100/100], Loss: 5.3682e-03\n",
      "#####--training model 224--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.0285e-02\n",
      "Epoch [20/100], Loss: 6.5986e-02\n",
      "Epoch [30/100], Loss: 7.7969e-02\n",
      "Epoch [40/100], Loss: 8.1268e-02\n",
      "Epoch [50/100], Loss: 8.3595e-02\n",
      "Epoch [60/100], Loss: 8.6519e-02\n",
      "Epoch [70/100], Loss: 8.4876e-02\n",
      "Epoch [80/100], Loss: 8.0266e-02\n",
      "Epoch [90/100], Loss: 7.2708e-02\n",
      "Epoch [100/100], Loss: 6.3237e-02\n",
      "#####--training model 225--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0309e-02\n",
      "Epoch [20/100], Loss: 6.0427e-03\n",
      "Epoch [30/100], Loss: 5.6164e-03\n",
      "Epoch [40/100], Loss: 4.8540e-03\n",
      "Epoch [50/100], Loss: 4.2386e-03\n",
      "Epoch [60/100], Loss: 3.7414e-03\n",
      "Epoch [70/100], Loss: 3.3663e-03\n",
      "Epoch [80/100], Loss: 3.0691e-03\n",
      "Epoch [90/100], Loss: 2.8260e-03\n",
      "Epoch [100/100], Loss: 2.6497e-03\n",
      "#####--training model 226--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4139e-04\n",
      "Epoch [20/100], Loss: 4.3118e-04\n",
      "Epoch [30/100], Loss: 1.8529e-03\n",
      "Epoch [40/100], Loss: 1.8500e-03\n",
      "Epoch [50/100], Loss: 1.2371e-03\n",
      "Epoch [60/100], Loss: 8.7240e-04\n",
      "Epoch [70/100], Loss: 7.2067e-04\n",
      "Epoch [80/100], Loss: 6.8197e-04\n",
      "Epoch [90/100], Loss: 6.9670e-04\n",
      "Epoch [100/100], Loss: 7.4269e-04\n",
      "#####--training model 227--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.5199e-03\n",
      "Epoch [20/100], Loss: 3.5838e-03\n",
      "Epoch [30/100], Loss: 4.7256e-03\n",
      "Epoch [40/100], Loss: 6.4294e-03\n",
      "Epoch [50/100], Loss: 6.5936e-03\n",
      "Epoch [60/100], Loss: 6.1519e-03\n",
      "Epoch [70/100], Loss: 5.7994e-03\n",
      "Epoch [80/100], Loss: 5.5633e-03\n",
      "Epoch [90/100], Loss: 5.4149e-03\n",
      "Epoch [100/100], Loss: 5.3306e-03\n",
      "#####--training model 228--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.8430e-03\n",
      "Epoch [20/100], Loss: 2.1987e-03\n",
      "Epoch [30/100], Loss: 1.3869e-03\n",
      "Epoch [40/100], Loss: 8.6871e-04\n",
      "Epoch [50/100], Loss: 7.2015e-04\n",
      "Epoch [60/100], Loss: 6.2575e-04\n",
      "Epoch [70/100], Loss: 5.2671e-04\n",
      "Epoch [80/100], Loss: 4.6761e-04\n",
      "Epoch [90/100], Loss: 4.2703e-04\n",
      "Epoch [100/100], Loss: 3.9283e-04\n",
      "#####--training model 229--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.7514e-05\n",
      "Epoch [20/100], Loss: 3.7962e-05\n",
      "Epoch [30/100], Loss: 2.1265e-05\n",
      "Epoch [40/100], Loss: 1.3954e-05\n",
      "Epoch [50/100], Loss: 1.0029e-05\n",
      "Epoch [60/100], Loss: 7.6612e-06\n",
      "Epoch [70/100], Loss: 6.1259e-06\n",
      "Epoch [80/100], Loss: 5.0848e-06\n",
      "Epoch [90/100], Loss: 4.3610e-06\n",
      "Epoch [100/100], Loss: 3.8539e-06\n",
      "#####--training model 230--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2507e-03\n",
      "Epoch [20/100], Loss: 1.2404e-03\n",
      "Epoch [30/100], Loss: 1.2873e-03\n",
      "Epoch [40/100], Loss: 1.8886e-03\n",
      "Epoch [50/100], Loss: 2.5109e-03\n",
      "Epoch [60/100], Loss: 3.0445e-03\n",
      "Epoch [70/100], Loss: 3.3293e-03\n",
      "Epoch [80/100], Loss: 3.4437e-03\n",
      "Epoch [90/100], Loss: 3.4749e-03\n",
      "Epoch [100/100], Loss: 3.5102e-03\n",
      "#####--training model 231--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6915e-04\n",
      "Epoch [20/100], Loss: 2.3244e-04\n",
      "Epoch [30/100], Loss: 1.8161e-04\n",
      "Epoch [40/100], Loss: 8.9596e-05\n",
      "Epoch [50/100], Loss: 5.6907e-05\n",
      "Epoch [60/100], Loss: 5.5670e-05\n",
      "Epoch [70/100], Loss: 6.0030e-05\n",
      "Epoch [80/100], Loss: 6.1495e-05\n",
      "Epoch [90/100], Loss: 5.9357e-05\n",
      "Epoch [100/100], Loss: 5.4854e-05\n",
      "#####--training model 232--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.1571e-03\n",
      "Epoch [20/100], Loss: 1.8520e-03\n",
      "Epoch [30/100], Loss: 1.3643e-03\n",
      "Epoch [40/100], Loss: 1.0799e-03\n",
      "Epoch [50/100], Loss: 8.9332e-04\n",
      "Epoch [60/100], Loss: 8.0171e-04\n",
      "Epoch [70/100], Loss: 7.6063e-04\n",
      "Epoch [80/100], Loss: 7.3736e-04\n",
      "Epoch [90/100], Loss: 7.2006e-04\n",
      "Epoch [100/100], Loss: 7.0435e-04\n",
      "#####--training model 233--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8661e-02\n",
      "Epoch [20/100], Loss: 2.3404e-02\n",
      "Epoch [30/100], Loss: 1.9426e-02\n",
      "Epoch [40/100], Loss: 1.6271e-02\n",
      "Epoch [50/100], Loss: 1.3835e-02\n",
      "Epoch [60/100], Loss: 1.2827e-02\n",
      "Epoch [70/100], Loss: 1.2375e-02\n",
      "Epoch [80/100], Loss: 1.2031e-02\n",
      "Epoch [90/100], Loss: 1.1663e-02\n",
      "Epoch [100/100], Loss: 1.1240e-02\n",
      "#####--training model 234--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2881e-02\n",
      "Epoch [20/100], Loss: 6.4703e-03\n",
      "Epoch [30/100], Loss: 5.4106e-03\n",
      "Epoch [40/100], Loss: 5.4412e-03\n",
      "Epoch [50/100], Loss: 5.6763e-03\n",
      "Epoch [60/100], Loss: 5.9915e-03\n",
      "Epoch [70/100], Loss: 6.2167e-03\n",
      "Epoch [80/100], Loss: 6.3090e-03\n",
      "Epoch [90/100], Loss: 6.3017e-03\n",
      "Epoch [100/100], Loss: 6.2384e-03\n",
      "#####--training model 235--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.0797e-04\n",
      "Epoch [20/100], Loss: 2.8851e-04\n",
      "Epoch [30/100], Loss: 1.6498e-04\n",
      "Epoch [40/100], Loss: 9.2821e-05\n",
      "Epoch [50/100], Loss: 5.2054e-05\n",
      "Epoch [60/100], Loss: 3.0693e-05\n",
      "Epoch [70/100], Loss: 2.0632e-05\n",
      "Epoch [80/100], Loss: 1.5723e-05\n",
      "Epoch [90/100], Loss: 1.3547e-05\n",
      "Epoch [100/100], Loss: 1.3013e-05\n",
      "#####--training model 236--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9650e-03\n",
      "Epoch [20/100], Loss: 2.9968e-03\n",
      "Epoch [30/100], Loss: 2.8104e-03\n",
      "Epoch [40/100], Loss: 2.9406e-03\n",
      "Epoch [50/100], Loss: 3.0462e-03\n",
      "Epoch [60/100], Loss: 3.1139e-03\n",
      "Epoch [70/100], Loss: 3.1499e-03\n",
      "Epoch [80/100], Loss: 3.1516e-03\n",
      "Epoch [90/100], Loss: 3.1428e-03\n",
      "Epoch [100/100], Loss: 3.1410e-03\n",
      "#####--training model 237--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6552e-03\n",
      "Epoch [20/100], Loss: 1.7342e-03\n",
      "Epoch [30/100], Loss: 1.8964e-03\n",
      "Epoch [40/100], Loss: 7.9761e-04\n",
      "Epoch [50/100], Loss: 6.0385e-04\n",
      "Epoch [60/100], Loss: 6.4167e-04\n",
      "Epoch [70/100], Loss: 6.3352e-04\n",
      "Epoch [80/100], Loss: 6.0191e-04\n",
      "Epoch [90/100], Loss: 5.8063e-04\n",
      "Epoch [100/100], Loss: 5.6258e-04\n",
      "#####--training model 238--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7043e-02\n",
      "Epoch [20/100], Loss: 1.6331e-02\n",
      "Epoch [30/100], Loss: 1.6784e-02\n",
      "Epoch [40/100], Loss: 1.9101e-02\n",
      "Epoch [50/100], Loss: 1.9553e-02\n",
      "Epoch [60/100], Loss: 2.0287e-02\n",
      "Epoch [70/100], Loss: 2.0944e-02\n",
      "Epoch [80/100], Loss: 2.1192e-02\n",
      "Epoch [90/100], Loss: 2.1406e-02\n",
      "Epoch [100/100], Loss: 2.1568e-02\n",
      "#####--training model 239--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.5511e-02\n",
      "Epoch [20/100], Loss: 3.9409e-02\n",
      "Epoch [30/100], Loss: 1.9431e-04\n",
      "Epoch [40/100], Loss: 8.1924e-04\n",
      "Epoch [50/100], Loss: 1.3503e-03\n",
      "Epoch [60/100], Loss: 1.4660e-03\n",
      "Epoch [70/100], Loss: 1.3545e-03\n",
      "Epoch [80/100], Loss: 1.1243e-03\n",
      "Epoch [90/100], Loss: 8.6935e-04\n",
      "Epoch [100/100], Loss: 6.7761e-04\n",
      "#####--training model 240--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3749e-03\n",
      "Epoch [20/100], Loss: 9.3770e-03\n",
      "Epoch [30/100], Loss: 6.0230e-03\n",
      "Epoch [40/100], Loss: 3.5931e-03\n",
      "Epoch [50/100], Loss: 2.2025e-03\n",
      "Epoch [60/100], Loss: 1.7324e-03\n",
      "Epoch [70/100], Loss: 1.6394e-03\n",
      "Epoch [80/100], Loss: 1.6592e-03\n",
      "Epoch [90/100], Loss: 1.6889e-03\n",
      "Epoch [100/100], Loss: 1.7035e-03\n",
      "#####--training model 241--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.3399e-05\n",
      "Epoch [20/100], Loss: 1.9095e-04\n",
      "Epoch [30/100], Loss: 1.4806e-04\n",
      "Epoch [40/100], Loss: 1.0001e-04\n",
      "Epoch [50/100], Loss: 9.1378e-05\n",
      "Epoch [60/100], Loss: 9.0255e-05\n",
      "Epoch [70/100], Loss: 9.2453e-05\n",
      "Epoch [80/100], Loss: 9.0910e-05\n",
      "Epoch [90/100], Loss: 8.3000e-05\n",
      "Epoch [100/100], Loss: 7.1859e-05\n",
      "#####--training model 242--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4617e-03\n",
      "Epoch [20/100], Loss: 2.3322e-03\n",
      "Epoch [30/100], Loss: 1.4727e-03\n",
      "Epoch [40/100], Loss: 1.3506e-03\n",
      "Epoch [50/100], Loss: 1.4514e-03\n",
      "Epoch [60/100], Loss: 1.8235e-03\n",
      "Epoch [70/100], Loss: 1.7796e-03\n",
      "Epoch [80/100], Loss: 1.7103e-03\n",
      "Epoch [90/100], Loss: 1.6515e-03\n",
      "Epoch [100/100], Loss: 1.5994e-03\n",
      "#####--training model 243--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.7752e-04\n",
      "Epoch [20/100], Loss: 2.8926e-04\n",
      "Epoch [30/100], Loss: 3.2080e-04\n",
      "Epoch [40/100], Loss: 4.9724e-04\n",
      "Epoch [50/100], Loss: 2.5612e-04\n",
      "Epoch [60/100], Loss: 1.9208e-04\n",
      "Epoch [70/100], Loss: 1.3618e-04\n",
      "Epoch [80/100], Loss: 9.0061e-05\n",
      "Epoch [90/100], Loss: 6.9101e-05\n",
      "Epoch [100/100], Loss: 8.8244e-05\n",
      "#####--training model 244--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.4589e-04\n",
      "Epoch [20/100], Loss: 9.6683e-04\n",
      "Epoch [30/100], Loss: 9.8871e-04\n",
      "Epoch [40/100], Loss: 1.0174e-03\n",
      "Epoch [50/100], Loss: 1.0050e-03\n",
      "Epoch [60/100], Loss: 9.5898e-04\n",
      "Epoch [70/100], Loss: 9.0014e-04\n",
      "Epoch [80/100], Loss: 8.5088e-04\n",
      "Epoch [90/100], Loss: 8.1421e-04\n",
      "Epoch [100/100], Loss: 7.8462e-04\n",
      "#####--training model 245--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.2662e-04\n",
      "Epoch [20/100], Loss: 4.0965e-04\n",
      "Epoch [30/100], Loss: 1.4654e-04\n",
      "Epoch [40/100], Loss: 1.0026e-04\n",
      "Epoch [50/100], Loss: 9.6755e-05\n",
      "Epoch [60/100], Loss: 1.2225e-04\n",
      "Epoch [70/100], Loss: 1.4105e-04\n",
      "Epoch [80/100], Loss: 1.5069e-04\n",
      "Epoch [90/100], Loss: 1.5458e-04\n",
      "Epoch [100/100], Loss: 1.5552e-04\n",
      "#####--training model 246--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0418e-04\n",
      "Epoch [20/100], Loss: 1.8706e-05\n",
      "Epoch [30/100], Loss: 2.6371e-05\n",
      "Epoch [40/100], Loss: 3.0913e-05\n",
      "Epoch [50/100], Loss: 2.1354e-05\n",
      "Epoch [60/100], Loss: 1.0150e-05\n",
      "Epoch [70/100], Loss: 7.7483e-06\n",
      "Epoch [80/100], Loss: 1.7853e-05\n",
      "Epoch [90/100], Loss: 4.6012e-05\n",
      "Epoch [100/100], Loss: 1.3539e-04\n",
      "#####--training model 247--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5596e-02\n",
      "Epoch [20/100], Loss: 8.2592e-04\n",
      "Epoch [30/100], Loss: 9.7086e-04\n",
      "Epoch [40/100], Loss: 8.4281e-04\n",
      "Epoch [50/100], Loss: 9.5212e-04\n",
      "Epoch [60/100], Loss: 1.1090e-03\n",
      "Epoch [70/100], Loss: 1.2356e-03\n",
      "Epoch [80/100], Loss: 1.3147e-03\n",
      "Epoch [90/100], Loss: 1.3563e-03\n",
      "Epoch [100/100], Loss: 1.3676e-03\n",
      "#####--training model 248--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.3886e-02\n",
      "Epoch [20/100], Loss: 4.1575e-02\n",
      "Epoch [30/100], Loss: 3.8816e-04\n",
      "Epoch [40/100], Loss: 1.6833e-04\n",
      "Epoch [50/100], Loss: 2.2960e-04\n",
      "Epoch [60/100], Loss: 2.8816e-04\n",
      "Epoch [70/100], Loss: 2.5113e-04\n",
      "Epoch [80/100], Loss: 1.6970e-04\n",
      "Epoch [90/100], Loss: 2.8620e-04\n",
      "Epoch [100/100], Loss: 4.3562e-04\n",
      "#####--training model 249--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.1648e-03\n",
      "Epoch [20/100], Loss: 5.1122e-03\n",
      "Epoch [30/100], Loss: 4.9629e-03\n",
      "Epoch [40/100], Loss: 5.4643e-03\n",
      "Epoch [50/100], Loss: 5.6874e-03\n",
      "Epoch [60/100], Loss: 5.8868e-03\n",
      "Epoch [70/100], Loss: 5.9938e-03\n",
      "Epoch [80/100], Loss: 6.0782e-03\n",
      "Epoch [90/100], Loss: 6.1568e-03\n",
      "Epoch [100/100], Loss: 6.2104e-03\n",
      "#####--training model 250--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8733e-03\n",
      "Epoch [20/100], Loss: 3.9885e-03\n",
      "Epoch [30/100], Loss: 1.4210e-03\n",
      "Epoch [40/100], Loss: 1.4135e-03\n",
      "Epoch [50/100], Loss: 1.4918e-03\n",
      "Epoch [60/100], Loss: 1.5569e-03\n",
      "Epoch [70/100], Loss: 1.6117e-03\n",
      "Epoch [80/100], Loss: 1.6239e-03\n",
      "Epoch [90/100], Loss: 1.6360e-03\n",
      "Epoch [100/100], Loss: 1.6610e-03\n",
      "#####--training model 251--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.8186e-04\n",
      "Epoch [20/100], Loss: 5.7119e-04\n",
      "Epoch [30/100], Loss: 5.8122e-04\n",
      "Epoch [40/100], Loss: 6.2363e-04\n",
      "Epoch [50/100], Loss: 6.3154e-04\n",
      "Epoch [60/100], Loss: 6.5328e-04\n",
      "Epoch [70/100], Loss: 6.8169e-04\n",
      "Epoch [80/100], Loss: 7.0865e-04\n",
      "Epoch [90/100], Loss: 7.3424e-04\n",
      "Epoch [100/100], Loss: 7.5696e-04\n",
      "#####--training model 252--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2167e-04\n",
      "Epoch [20/100], Loss: 1.2329e-04\n",
      "Epoch [30/100], Loss: 9.8445e-05\n",
      "Epoch [40/100], Loss: 9.1213e-05\n",
      "Epoch [50/100], Loss: 9.2026e-05\n",
      "Epoch [60/100], Loss: 9.6167e-05\n",
      "Epoch [70/100], Loss: 1.0225e-04\n",
      "Epoch [80/100], Loss: 1.0391e-04\n",
      "Epoch [90/100], Loss: 9.1638e-05\n",
      "Epoch [100/100], Loss: 4.7329e-05\n",
      "#####--training model 253--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8923e-03\n",
      "Epoch [20/100], Loss: 3.0743e-03\n",
      "Epoch [30/100], Loss: 2.7387e-03\n",
      "Epoch [40/100], Loss: 2.1778e-03\n",
      "Epoch [50/100], Loss: 1.7157e-03\n",
      "Epoch [60/100], Loss: 1.3794e-03\n",
      "Epoch [70/100], Loss: 1.1747e-03\n",
      "Epoch [80/100], Loss: 1.0748e-03\n",
      "Epoch [90/100], Loss: 1.0233e-03\n",
      "Epoch [100/100], Loss: 9.9247e-04\n",
      "#####--training model 254--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9112e-03\n",
      "Epoch [20/100], Loss: 2.2006e-03\n",
      "Epoch [30/100], Loss: 2.2271e-03\n",
      "Epoch [40/100], Loss: 2.2319e-03\n",
      "Epoch [50/100], Loss: 2.1143e-03\n",
      "Epoch [60/100], Loss: 1.9802e-03\n",
      "Epoch [70/100], Loss: 1.8757e-03\n",
      "Epoch [80/100], Loss: 1.8171e-03\n",
      "Epoch [90/100], Loss: 1.8061e-03\n",
      "Epoch [100/100], Loss: 1.8377e-03\n",
      "#####--training model 255--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.9559e-03\n",
      "Epoch [20/100], Loss: 3.7033e-03\n",
      "Epoch [30/100], Loss: 2.9042e-03\n",
      "Epoch [40/100], Loss: 2.3554e-03\n",
      "Epoch [50/100], Loss: 2.0246e-03\n",
      "Epoch [60/100], Loss: 1.6680e-03\n",
      "Epoch [70/100], Loss: 1.1201e-03\n",
      "Epoch [80/100], Loss: 7.9602e-04\n",
      "Epoch [90/100], Loss: 6.7045e-04\n",
      "Epoch [100/100], Loss: 5.7520e-04\n",
      "#####--training model 256--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.7224e-04\n",
      "Epoch [20/100], Loss: 5.6636e-04\n",
      "Epoch [30/100], Loss: 1.0875e-03\n",
      "Epoch [40/100], Loss: 1.1010e-03\n",
      "Epoch [50/100], Loss: 1.0372e-03\n",
      "Epoch [60/100], Loss: 1.0305e-03\n",
      "Epoch [70/100], Loss: 1.0450e-03\n",
      "Epoch [80/100], Loss: 1.0597e-03\n",
      "Epoch [90/100], Loss: 1.0678e-03\n",
      "Epoch [100/100], Loss: 1.0712e-03\n",
      "#####--training model 257--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.3190e-03\n",
      "Epoch [20/100], Loss: 5.0324e-03\n",
      "Epoch [30/100], Loss: 3.3590e-03\n",
      "Epoch [40/100], Loss: 2.5687e-03\n",
      "Epoch [50/100], Loss: 2.1658e-03\n",
      "Epoch [60/100], Loss: 1.5933e-03\n",
      "Epoch [70/100], Loss: 9.1785e-04\n",
      "Epoch [80/100], Loss: 5.3493e-04\n",
      "Epoch [90/100], Loss: 3.9296e-04\n",
      "Epoch [100/100], Loss: 3.2711e-04\n",
      "#####--training model 258--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.8484e-04\n",
      "Epoch [20/100], Loss: 6.7517e-04\n",
      "Epoch [30/100], Loss: 7.0556e-04\n",
      "Epoch [40/100], Loss: 4.7151e-04\n",
      "Epoch [50/100], Loss: 3.3405e-04\n",
      "Epoch [60/100], Loss: 2.4464e-04\n",
      "Epoch [70/100], Loss: 1.1147e-04\n",
      "Epoch [80/100], Loss: 7.4638e-05\n",
      "Epoch [90/100], Loss: 9.4180e-05\n",
      "Epoch [100/100], Loss: 1.1414e-04\n",
      "#####--training model 259--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4326e-02\n",
      "Epoch [20/100], Loss: 3.7540e-03\n",
      "Epoch [30/100], Loss: 3.3056e-03\n",
      "Epoch [40/100], Loss: 2.8612e-03\n",
      "Epoch [50/100], Loss: 2.7222e-03\n",
      "Epoch [60/100], Loss: 2.6619e-03\n",
      "Epoch [70/100], Loss: 2.6162e-03\n",
      "Epoch [80/100], Loss: 2.5873e-03\n",
      "Epoch [90/100], Loss: 2.5706e-03\n",
      "Epoch [100/100], Loss: 2.5607e-03\n",
      "#####--training model 260--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.2752e-03\n",
      "Epoch [20/100], Loss: 3.2213e-03\n",
      "Epoch [30/100], Loss: 1.6356e-03\n",
      "Epoch [40/100], Loss: 1.3550e-03\n",
      "Epoch [50/100], Loss: 1.3474e-03\n",
      "Epoch [60/100], Loss: 1.1985e-03\n",
      "Epoch [70/100], Loss: 1.0489e-03\n",
      "Epoch [80/100], Loss: 9.1837e-04\n",
      "Epoch [90/100], Loss: 8.0244e-04\n",
      "Epoch [100/100], Loss: 6.9268e-04\n",
      "#####--training model 261--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1623e-03\n",
      "Epoch [20/100], Loss: 8.9491e-05\n",
      "Epoch [30/100], Loss: 1.5374e-04\n",
      "Epoch [40/100], Loss: 2.8144e-04\n",
      "Epoch [50/100], Loss: 4.0974e-04\n",
      "Epoch [60/100], Loss: 4.6208e-04\n",
      "Epoch [70/100], Loss: 4.8042e-04\n",
      "Epoch [80/100], Loss: 4.8821e-04\n",
      "Epoch [90/100], Loss: 4.8752e-04\n",
      "Epoch [100/100], Loss: 4.8270e-04\n",
      "#####--training model 262--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.3771e-03\n",
      "Epoch [20/100], Loss: 7.9666e-03\n",
      "Epoch [30/100], Loss: 1.0935e-02\n",
      "Epoch [40/100], Loss: 9.3583e-03\n",
      "Epoch [50/100], Loss: 7.2417e-03\n",
      "Epoch [60/100], Loss: 4.9621e-03\n",
      "Epoch [70/100], Loss: 2.8892e-03\n",
      "Epoch [80/100], Loss: 1.4802e-03\n",
      "Epoch [90/100], Loss: 8.0057e-04\n",
      "Epoch [100/100], Loss: 5.3859e-04\n",
      "#####--training model 263--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.6632e-03\n",
      "Epoch [20/100], Loss: 7.0665e-03\n",
      "Epoch [30/100], Loss: 6.3885e-03\n",
      "Epoch [40/100], Loss: 5.0517e-03\n",
      "Epoch [50/100], Loss: 4.2896e-03\n",
      "Epoch [60/100], Loss: 3.8075e-03\n",
      "Epoch [70/100], Loss: 3.5122e-03\n",
      "Epoch [80/100], Loss: 3.3205e-03\n",
      "Epoch [90/100], Loss: 3.1751e-03\n",
      "Epoch [100/100], Loss: 3.0519e-03\n",
      "#####--training model 264--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6922e-04\n",
      "Epoch [20/100], Loss: 1.1089e-04\n",
      "Epoch [30/100], Loss: 3.3361e-05\n",
      "Epoch [40/100], Loss: 6.3465e-06\n",
      "Epoch [50/100], Loss: 3.1878e-06\n",
      "Epoch [60/100], Loss: 1.0793e-05\n",
      "Epoch [70/100], Loss: 1.7212e-05\n",
      "Epoch [80/100], Loss: 2.1343e-05\n",
      "Epoch [90/100], Loss: 2.3388e-05\n",
      "Epoch [100/100], Loss: 2.4262e-05\n",
      "#####--training model 265--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4383e-02\n",
      "Epoch [20/100], Loss: 1.8358e-02\n",
      "Epoch [30/100], Loss: 1.2378e-02\n",
      "Epoch [40/100], Loss: 8.5502e-03\n",
      "Epoch [50/100], Loss: 6.9490e-03\n",
      "Epoch [60/100], Loss: 6.6095e-03\n",
      "Epoch [70/100], Loss: 6.5602e-03\n",
      "Epoch [80/100], Loss: 6.5013e-03\n",
      "Epoch [90/100], Loss: 6.4455e-03\n",
      "Epoch [100/100], Loss: 6.3784e-03\n",
      "#####--training model 266--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6199e-06\n",
      "Epoch [20/100], Loss: 2.2011e-04\n",
      "Epoch [30/100], Loss: 7.4819e-04\n",
      "Epoch [40/100], Loss: 3.4905e-04\n",
      "Epoch [50/100], Loss: 2.6228e-04\n",
      "Epoch [60/100], Loss: 3.3997e-04\n",
      "Epoch [70/100], Loss: 5.3721e-04\n",
      "Epoch [80/100], Loss: 7.4960e-04\n",
      "Epoch [90/100], Loss: 7.8224e-04\n",
      "Epoch [100/100], Loss: 7.4401e-04\n",
      "#####--training model 267--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5187e-02\n",
      "Epoch [20/100], Loss: 2.6297e-02\n",
      "Epoch [30/100], Loss: 2.7965e-02\n",
      "Epoch [40/100], Loss: 2.8279e-02\n",
      "Epoch [50/100], Loss: 2.8049e-02\n",
      "Epoch [60/100], Loss: 2.8005e-02\n",
      "Epoch [70/100], Loss: 2.7988e-02\n",
      "Epoch [80/100], Loss: 2.7969e-02\n",
      "Epoch [90/100], Loss: 2.7940e-02\n",
      "Epoch [100/100], Loss: 2.7930e-02\n",
      "#####--training model 268--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5420e-03\n",
      "Epoch [20/100], Loss: 7.9633e-03\n",
      "Epoch [30/100], Loss: 6.4667e-03\n",
      "Epoch [40/100], Loss: 4.8047e-03\n",
      "Epoch [50/100], Loss: 4.1105e-03\n",
      "Epoch [60/100], Loss: 4.0320e-03\n",
      "Epoch [70/100], Loss: 4.0780e-03\n",
      "Epoch [80/100], Loss: 4.1130e-03\n",
      "Epoch [90/100], Loss: 4.1235e-03\n",
      "Epoch [100/100], Loss: 4.1227e-03\n",
      "#####--training model 269--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6103e-03\n",
      "Epoch [20/100], Loss: 1.3019e-03\n",
      "Epoch [30/100], Loss: 8.3907e-04\n",
      "Epoch [40/100], Loss: 5.1183e-04\n",
      "Epoch [50/100], Loss: 3.0744e-04\n",
      "Epoch [60/100], Loss: 1.7547e-04\n",
      "Epoch [70/100], Loss: 9.4892e-05\n",
      "Epoch [80/100], Loss: 5.7327e-05\n",
      "Epoch [90/100], Loss: 4.2848e-05\n",
      "Epoch [100/100], Loss: 3.6359e-05\n",
      "#####--training model 270--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0655e-02\n",
      "Epoch [20/100], Loss: 2.4146e-05\n",
      "Epoch [30/100], Loss: 1.4270e-04\n",
      "Epoch [40/100], Loss: 1.8284e-04\n",
      "Epoch [50/100], Loss: 2.0017e-04\n",
      "Epoch [60/100], Loss: 1.8743e-04\n",
      "Epoch [70/100], Loss: 1.5011e-04\n",
      "Epoch [80/100], Loss: 1.2718e-04\n",
      "Epoch [90/100], Loss: 1.1627e-04\n",
      "Epoch [100/100], Loss: 1.0896e-04\n",
      "#####--training model 271--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.2979e-03\n",
      "Epoch [20/100], Loss: 1.6299e-03\n",
      "Epoch [30/100], Loss: 1.3538e-03\n",
      "Epoch [40/100], Loss: 1.1038e-03\n",
      "Epoch [50/100], Loss: 8.7822e-04\n",
      "Epoch [60/100], Loss: 7.4910e-04\n",
      "Epoch [70/100], Loss: 6.9534e-04\n",
      "Epoch [80/100], Loss: 6.7252e-04\n",
      "Epoch [90/100], Loss: 6.5719e-04\n",
      "Epoch [100/100], Loss: 6.4003e-04\n",
      "#####--training model 272--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2797e-02\n",
      "Epoch [20/100], Loss: 1.3482e-02\n",
      "Epoch [30/100], Loss: 1.2738e-02\n",
      "Epoch [40/100], Loss: 1.2891e-02\n",
      "Epoch [50/100], Loss: 1.3416e-02\n",
      "Epoch [60/100], Loss: 1.3721e-02\n",
      "Epoch [70/100], Loss: 1.3654e-02\n",
      "Epoch [80/100], Loss: 1.3615e-02\n",
      "Epoch [90/100], Loss: 1.3623e-02\n",
      "Epoch [100/100], Loss: 1.3625e-02\n",
      "#####--training model 273--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2979e-03\n",
      "Epoch [20/100], Loss: 1.4900e-03\n",
      "Epoch [30/100], Loss: 1.7505e-03\n",
      "Epoch [40/100], Loss: 1.9279e-03\n",
      "Epoch [50/100], Loss: 2.0251e-03\n",
      "Epoch [60/100], Loss: 2.0872e-03\n",
      "Epoch [70/100], Loss: 2.1371e-03\n",
      "Epoch [80/100], Loss: 2.1831e-03\n",
      "Epoch [90/100], Loss: 2.2252e-03\n",
      "Epoch [100/100], Loss: 2.2615e-03\n",
      "#####--training model 274--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.4514e-04\n",
      "Epoch [20/100], Loss: 3.2465e-03\n",
      "Epoch [30/100], Loss: 2.3984e-03\n",
      "Epoch [40/100], Loss: 9.9703e-04\n",
      "Epoch [50/100], Loss: 6.6798e-04\n",
      "Epoch [60/100], Loss: 6.5005e-04\n",
      "Epoch [70/100], Loss: 6.7957e-04\n",
      "Epoch [80/100], Loss: 7.1206e-04\n",
      "Epoch [90/100], Loss: 7.2389e-04\n",
      "Epoch [100/100], Loss: 7.2249e-04\n",
      "#####--training model 275--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.0414e-02\n",
      "Epoch [20/100], Loss: 3.0170e-02\n",
      "Epoch [30/100], Loss: 1.9350e-02\n",
      "Epoch [40/100], Loss: 9.9766e-03\n",
      "Epoch [50/100], Loss: 2.0257e-03\n",
      "Epoch [60/100], Loss: 1.3569e-04\n",
      "Epoch [70/100], Loss: 5.6482e-05\n",
      "Epoch [80/100], Loss: 1.8305e-04\n",
      "Epoch [90/100], Loss: 2.7459e-04\n",
      "Epoch [100/100], Loss: 2.1740e-04\n",
      "#####--training model 276--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0774e-02\n",
      "Epoch [20/100], Loss: 2.3883e-03\n",
      "Epoch [30/100], Loss: 2.3670e-03\n",
      "Epoch [40/100], Loss: 2.5268e-03\n",
      "Epoch [50/100], Loss: 2.4287e-03\n",
      "Epoch [60/100], Loss: 2.1246e-03\n",
      "Epoch [70/100], Loss: 1.9939e-03\n",
      "Epoch [80/100], Loss: 1.9631e-03\n",
      "Epoch [90/100], Loss: 1.9941e-03\n",
      "Epoch [100/100], Loss: 2.0566e-03\n",
      "#####--training model 277--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3406e-03\n",
      "Epoch [20/100], Loss: 2.6754e-04\n",
      "Epoch [30/100], Loss: 2.8308e-04\n",
      "Epoch [40/100], Loss: 2.6493e-04\n",
      "Epoch [50/100], Loss: 2.6698e-04\n",
      "Epoch [60/100], Loss: 2.8388e-04\n",
      "Epoch [70/100], Loss: 3.0368e-04\n",
      "Epoch [80/100], Loss: 3.1318e-04\n",
      "Epoch [90/100], Loss: 3.1566e-04\n",
      "Epoch [100/100], Loss: 3.2548e-04\n",
      "#####--training model 278--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.7165e-02\n",
      "Epoch [20/100], Loss: 4.3543e-02\n",
      "Epoch [30/100], Loss: 1.2531e-02\n",
      "Epoch [40/100], Loss: 1.6393e-03\n",
      "Epoch [50/100], Loss: 6.2941e-04\n",
      "Epoch [60/100], Loss: 6.0477e-04\n",
      "Epoch [70/100], Loss: 6.5692e-04\n",
      "Epoch [80/100], Loss: 6.2529e-04\n",
      "Epoch [90/100], Loss: 5.0538e-04\n",
      "Epoch [100/100], Loss: 3.6308e-04\n",
      "#####--training model 279--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2595e-04\n",
      "Epoch [20/100], Loss: 4.9802e-05\n",
      "Epoch [30/100], Loss: 2.7560e-05\n",
      "Epoch [40/100], Loss: 1.7663e-05\n",
      "Epoch [50/100], Loss: 1.2310e-05\n",
      "Epoch [60/100], Loss: 9.0640e-06\n",
      "Epoch [70/100], Loss: 6.9457e-06\n",
      "Epoch [80/100], Loss: 5.4923e-06\n",
      "Epoch [90/100], Loss: 4.4599e-06\n",
      "Epoch [100/100], Loss: 3.7092e-06\n",
      "#####--training model 280--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0817e-04\n",
      "Epoch [20/100], Loss: 8.5088e-05\n",
      "Epoch [30/100], Loss: 1.1903e-04\n",
      "Epoch [40/100], Loss: 2.0240e-04\n",
      "Epoch [50/100], Loss: 2.6966e-04\n",
      "Epoch [60/100], Loss: 2.9912e-04\n",
      "Epoch [70/100], Loss: 3.1810e-04\n",
      "Epoch [80/100], Loss: 3.3965e-04\n",
      "Epoch [90/100], Loss: 3.6112e-04\n",
      "Epoch [100/100], Loss: 3.7883e-04\n",
      "#####--training model 281--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.5008e-04\n",
      "Epoch [20/100], Loss: 5.1162e-04\n",
      "Epoch [30/100], Loss: 5.0175e-04\n",
      "Epoch [40/100], Loss: 4.9335e-04\n",
      "Epoch [50/100], Loss: 4.8591e-04\n",
      "Epoch [60/100], Loss: 4.7994e-04\n",
      "Epoch [70/100], Loss: 4.7586e-04\n",
      "Epoch [80/100], Loss: 4.7186e-04\n",
      "Epoch [90/100], Loss: 4.6934e-04\n",
      "Epoch [100/100], Loss: 4.5739e-04\n",
      "#####--training model 282--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5043e-02\n",
      "Epoch [20/100], Loss: 2.0139e-02\n",
      "Epoch [30/100], Loss: 2.0646e-02\n",
      "Epoch [40/100], Loss: 1.8070e-02\n",
      "Epoch [50/100], Loss: 1.5279e-02\n",
      "Epoch [60/100], Loss: 1.2969e-02\n",
      "Epoch [70/100], Loss: 1.1319e-02\n",
      "Epoch [80/100], Loss: 1.0267e-02\n",
      "Epoch [90/100], Loss: 9.6300e-03\n",
      "Epoch [100/100], Loss: 9.2227e-03\n",
      "#####--training model 283--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7571e-03\n",
      "Epoch [20/100], Loss: 1.7898e-03\n",
      "Epoch [30/100], Loss: 1.2299e-03\n",
      "Epoch [40/100], Loss: 1.0939e-03\n",
      "Epoch [50/100], Loss: 1.0607e-03\n",
      "Epoch [60/100], Loss: 1.0191e-03\n",
      "Epoch [70/100], Loss: 1.0019e-03\n",
      "Epoch [80/100], Loss: 9.8937e-04\n",
      "Epoch [90/100], Loss: 9.6453e-04\n",
      "Epoch [100/100], Loss: 9.2452e-04\n",
      "#####--training model 284--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3367e-03\n",
      "Epoch [20/100], Loss: 7.4878e-04\n",
      "Epoch [30/100], Loss: 2.7778e-04\n",
      "Epoch [40/100], Loss: 2.2565e-04\n",
      "Epoch [50/100], Loss: 2.0038e-04\n",
      "Epoch [60/100], Loss: 1.9063e-04\n",
      "Epoch [70/100], Loss: 2.3198e-04\n",
      "Epoch [80/100], Loss: 2.9140e-04\n",
      "Epoch [90/100], Loss: 3.0285e-04\n",
      "Epoch [100/100], Loss: 2.7453e-04\n",
      "#####--training model 285--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7837e-04\n",
      "Epoch [20/100], Loss: 6.5475e-05\n",
      "Epoch [30/100], Loss: 3.3922e-05\n",
      "Epoch [40/100], Loss: 2.0717e-05\n",
      "Epoch [50/100], Loss: 1.3942e-05\n",
      "Epoch [60/100], Loss: 9.9459e-06\n",
      "Epoch [70/100], Loss: 7.3741e-06\n",
      "Epoch [80/100], Loss: 5.6231e-06\n",
      "Epoch [90/100], Loss: 4.3881e-06\n",
      "Epoch [100/100], Loss: 3.4974e-06\n",
      "#####--training model 286--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.3233e-04\n",
      "Epoch [20/100], Loss: 2.3861e-04\n",
      "Epoch [30/100], Loss: 2.3004e-04\n",
      "Epoch [40/100], Loss: 2.3304e-04\n",
      "Epoch [50/100], Loss: 2.1241e-04\n",
      "Epoch [60/100], Loss: 1.8994e-04\n",
      "Epoch [70/100], Loss: 1.8121e-04\n",
      "Epoch [80/100], Loss: 1.8313e-04\n",
      "Epoch [90/100], Loss: 1.9113e-04\n",
      "Epoch [100/100], Loss: 2.0311e-04\n",
      "#####--training model 287--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.8304e-03\n",
      "Epoch [20/100], Loss: 1.7903e-03\n",
      "Epoch [30/100], Loss: 1.2797e-03\n",
      "Epoch [40/100], Loss: 1.0750e-03\n",
      "Epoch [50/100], Loss: 8.8476e-04\n",
      "Epoch [60/100], Loss: 7.2676e-04\n",
      "Epoch [70/100], Loss: 6.1800e-04\n",
      "Epoch [80/100], Loss: 5.5961e-04\n",
      "Epoch [90/100], Loss: 5.4278e-04\n",
      "Epoch [100/100], Loss: 5.5889e-04\n",
      "#####--training model 288--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4459e-04\n",
      "Epoch [20/100], Loss: 5.3616e-05\n",
      "Epoch [30/100], Loss: 2.8765e-05\n",
      "Epoch [40/100], Loss: 1.7946e-05\n",
      "Epoch [50/100], Loss: 1.2177e-05\n",
      "Epoch [60/100], Loss: 8.7174e-06\n",
      "Epoch [70/100], Loss: 6.4802e-06\n",
      "Epoch [80/100], Loss: 4.9555e-06\n",
      "Epoch [90/100], Loss: 3.8769e-06\n",
      "Epoch [100/100], Loss: 3.0927e-06\n",
      "#####--training model 289--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2383e-03\n",
      "Epoch [20/100], Loss: 9.1067e-04\n",
      "Epoch [30/100], Loss: 9.0535e-04\n",
      "Epoch [40/100], Loss: 9.3790e-04\n",
      "Epoch [50/100], Loss: 9.4644e-04\n",
      "Epoch [60/100], Loss: 9.5251e-04\n",
      "Epoch [70/100], Loss: 9.5918e-04\n",
      "Epoch [80/100], Loss: 9.6510e-04\n",
      "Epoch [90/100], Loss: 9.6930e-04\n",
      "Epoch [100/100], Loss: 9.7301e-04\n",
      "#####--training model 290--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.4422e-03\n",
      "Epoch [20/100], Loss: 1.5919e-03\n",
      "Epoch [30/100], Loss: 1.1647e-03\n",
      "Epoch [40/100], Loss: 7.4962e-04\n",
      "Epoch [50/100], Loss: 5.2794e-04\n",
      "Epoch [60/100], Loss: 4.6092e-04\n",
      "Epoch [70/100], Loss: 4.5632e-04\n",
      "Epoch [80/100], Loss: 4.6693e-04\n",
      "Epoch [90/100], Loss: 4.6989e-04\n",
      "Epoch [100/100], Loss: 4.6086e-04\n",
      "#####--training model 291--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.1178e-02\n",
      "Epoch [20/100], Loss: 1.3889e-02\n",
      "Epoch [30/100], Loss: 1.0772e-02\n",
      "Epoch [40/100], Loss: 8.7652e-03\n",
      "Epoch [50/100], Loss: 7.2189e-03\n",
      "Epoch [60/100], Loss: 6.2652e-03\n",
      "Epoch [70/100], Loss: 5.6392e-03\n",
      "Epoch [80/100], Loss: 5.0735e-03\n",
      "Epoch [90/100], Loss: 4.5266e-03\n",
      "Epoch [100/100], Loss: 4.0031e-03\n",
      "#####--training model 292--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.3892e-04\n",
      "Epoch [20/100], Loss: 3.3248e-04\n",
      "Epoch [30/100], Loss: 2.2054e-04\n",
      "Epoch [40/100], Loss: 1.9269e-04\n",
      "Epoch [50/100], Loss: 1.7728e-04\n",
      "Epoch [60/100], Loss: 1.9363e-04\n",
      "Epoch [70/100], Loss: 2.1651e-04\n",
      "Epoch [80/100], Loss: 2.2965e-04\n",
      "Epoch [90/100], Loss: 2.3787e-04\n",
      "Epoch [100/100], Loss: 2.3843e-04\n",
      "#####--training model 293--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9000e-03\n",
      "Epoch [20/100], Loss: 2.9598e-03\n",
      "Epoch [30/100], Loss: 3.2759e-03\n",
      "Epoch [40/100], Loss: 3.4519e-03\n",
      "Epoch [50/100], Loss: 3.5829e-03\n",
      "Epoch [60/100], Loss: 3.7360e-03\n",
      "Epoch [70/100], Loss: 3.8858e-03\n",
      "Epoch [80/100], Loss: 3.9798e-03\n",
      "Epoch [90/100], Loss: 4.0318e-03\n",
      "Epoch [100/100], Loss: 4.0692e-03\n",
      "#####--training model 294--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.4918e-03\n",
      "Epoch [20/100], Loss: 7.4586e-03\n",
      "Epoch [30/100], Loss: 9.6541e-03\n",
      "Epoch [40/100], Loss: 9.1474e-03\n",
      "Epoch [50/100], Loss: 6.3668e-03\n",
      "Epoch [60/100], Loss: 3.8275e-03\n",
      "Epoch [70/100], Loss: 3.1339e-03\n",
      "Epoch [80/100], Loss: 2.9787e-03\n",
      "Epoch [90/100], Loss: 2.7370e-03\n",
      "Epoch [100/100], Loss: 2.1729e-03\n",
      "#####--training model 295--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.0115e-03\n",
      "Epoch [20/100], Loss: 5.7188e-03\n",
      "Epoch [30/100], Loss: 5.4108e-03\n",
      "Epoch [40/100], Loss: 4.4076e-03\n",
      "Epoch [50/100], Loss: 3.5787e-03\n",
      "Epoch [60/100], Loss: 3.1139e-03\n",
      "Epoch [70/100], Loss: 2.9421e-03\n",
      "Epoch [80/100], Loss: 2.8651e-03\n",
      "Epoch [90/100], Loss: 2.7929e-03\n",
      "Epoch [100/100], Loss: 2.7172e-03\n",
      "#####--training model 296--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.0694e-03\n",
      "Epoch [20/100], Loss: 4.7511e-03\n",
      "Epoch [30/100], Loss: 2.6929e-03\n",
      "Epoch [40/100], Loss: 1.7352e-03\n",
      "Epoch [50/100], Loss: 1.3014e-03\n",
      "Epoch [60/100], Loss: 1.1817e-03\n",
      "Epoch [70/100], Loss: 1.2383e-03\n",
      "Epoch [80/100], Loss: 1.3472e-03\n",
      "Epoch [90/100], Loss: 1.4425e-03\n",
      "Epoch [100/100], Loss: 1.4972e-03\n",
      "#####--training model 297--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.5083e-04\n",
      "Epoch [20/100], Loss: 5.1614e-04\n",
      "Epoch [30/100], Loss: 4.7640e-04\n",
      "Epoch [40/100], Loss: 4.2520e-04\n",
      "Epoch [50/100], Loss: 4.5233e-04\n",
      "Epoch [60/100], Loss: 5.0477e-04\n",
      "Epoch [70/100], Loss: 5.4789e-04\n",
      "Epoch [80/100], Loss: 5.8590e-04\n",
      "Epoch [90/100], Loss: 6.2930e-04\n",
      "Epoch [100/100], Loss: 6.8445e-04\n",
      "#####--training model 298--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.8698e-04\n",
      "Epoch [20/100], Loss: 8.7604e-04\n",
      "Epoch [30/100], Loss: 9.1499e-04\n",
      "Epoch [40/100], Loss: 3.0025e-04\n",
      "Epoch [50/100], Loss: 1.8641e-04\n",
      "Epoch [60/100], Loss: 2.0930e-04\n",
      "Epoch [70/100], Loss: 2.2123e-04\n",
      "Epoch [80/100], Loss: 2.3022e-04\n",
      "Epoch [90/100], Loss: 2.3657e-04\n",
      "Epoch [100/100], Loss: 2.2494e-04\n",
      "#####--training model 299--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.5255e-04\n",
      "Epoch [20/100], Loss: 1.2271e-04\n",
      "Epoch [30/100], Loss: 1.5865e-04\n",
      "Epoch [40/100], Loss: 1.3819e-04\n",
      "Epoch [50/100], Loss: 7.9849e-05\n",
      "Epoch [60/100], Loss: 5.4226e-05\n",
      "Epoch [70/100], Loss: 4.2610e-05\n",
      "Epoch [80/100], Loss: 4.0579e-05\n",
      "Epoch [90/100], Loss: 4.4543e-05\n",
      "Epoch [100/100], Loss: 5.1011e-05\n",
      "#####--training model 300--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4965e-03\n",
      "Epoch [20/100], Loss: 1.6296e-03\n",
      "Epoch [30/100], Loss: 1.7552e-03\n",
      "Epoch [40/100], Loss: 1.8689e-03\n",
      "Epoch [50/100], Loss: 1.9869e-03\n",
      "Epoch [60/100], Loss: 2.1056e-03\n",
      "Epoch [70/100], Loss: 2.2190e-03\n",
      "Epoch [80/100], Loss: 2.3186e-03\n",
      "Epoch [90/100], Loss: 2.3940e-03\n",
      "Epoch [100/100], Loss: 2.4417e-03\n",
      "#####--training model 301--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.6155e-05\n",
      "Epoch [20/100], Loss: 7.0064e-05\n",
      "Epoch [30/100], Loss: 7.5436e-05\n",
      "Epoch [40/100], Loss: 5.6294e-05\n",
      "Epoch [50/100], Loss: 2.0701e-05\n",
      "Epoch [60/100], Loss: 3.6234e-05\n",
      "Epoch [70/100], Loss: 5.1797e-05\n",
      "Epoch [80/100], Loss: 4.2188e-05\n",
      "Epoch [90/100], Loss: 3.4248e-05\n",
      "Epoch [100/100], Loss: 2.8181e-05\n",
      "#####--training model 302--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.1477e-03\n",
      "Epoch [20/100], Loss: 2.0682e-03\n",
      "Epoch [30/100], Loss: 1.9911e-03\n",
      "Epoch [40/100], Loss: 1.8802e-03\n",
      "Epoch [50/100], Loss: 1.6839e-03\n",
      "Epoch [60/100], Loss: 1.4591e-03\n",
      "Epoch [70/100], Loss: 7.8581e-04\n",
      "Epoch [80/100], Loss: 4.6012e-04\n",
      "Epoch [90/100], Loss: 3.2966e-04\n",
      "Epoch [100/100], Loss: 2.2110e-04\n",
      "#####--training model 303--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9105e-04\n",
      "Epoch [20/100], Loss: 2.3614e-04\n",
      "Epoch [30/100], Loss: 2.3132e-04\n",
      "Epoch [40/100], Loss: 2.3003e-04\n",
      "Epoch [50/100], Loss: 2.2872e-04\n",
      "Epoch [60/100], Loss: 2.2729e-04\n",
      "Epoch [70/100], Loss: 2.2571e-04\n",
      "Epoch [80/100], Loss: 2.2391e-04\n",
      "Epoch [90/100], Loss: 2.2158e-04\n",
      "Epoch [100/100], Loss: 2.1648e-04\n",
      "#####--training model 304--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9482e-04\n",
      "Epoch [20/100], Loss: 7.3722e-05\n",
      "Epoch [30/100], Loss: 4.0593e-05\n",
      "Epoch [40/100], Loss: 2.6315e-05\n",
      "Epoch [50/100], Loss: 1.8726e-05\n",
      "Epoch [60/100], Loss: 1.4178e-05\n",
      "Epoch [70/100], Loss: 1.1241e-05\n",
      "Epoch [80/100], Loss: 9.2526e-06\n",
      "Epoch [90/100], Loss: 7.8685e-06\n",
      "Epoch [100/100], Loss: 6.8944e-06\n",
      "#####--training model 305--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1783e-03\n",
      "Epoch [20/100], Loss: 1.2063e-03\n",
      "Epoch [30/100], Loss: 1.2343e-03\n",
      "Epoch [40/100], Loss: 1.2630e-03\n",
      "Epoch [50/100], Loss: 1.2940e-03\n",
      "Epoch [60/100], Loss: 1.3293e-03\n",
      "Epoch [70/100], Loss: 1.3671e-03\n",
      "Epoch [80/100], Loss: 1.4301e-03\n",
      "Epoch [90/100], Loss: 1.5912e-03\n",
      "Epoch [100/100], Loss: 9.7560e-04\n",
      "#####--training model 306--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9046e-04\n",
      "Epoch [20/100], Loss: 1.7331e-04\n",
      "Epoch [30/100], Loss: 1.4571e-04\n",
      "Epoch [40/100], Loss: 1.3967e-04\n",
      "Epoch [50/100], Loss: 1.4013e-04\n",
      "Epoch [60/100], Loss: 1.4397e-04\n",
      "Epoch [70/100], Loss: 1.5940e-04\n",
      "Epoch [80/100], Loss: 1.8103e-04\n",
      "Epoch [90/100], Loss: 1.9706e-04\n",
      "Epoch [100/100], Loss: 2.0654e-04\n",
      "#####--training model 307--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9667e-03\n",
      "Epoch [20/100], Loss: 2.0802e-03\n",
      "Epoch [30/100], Loss: 2.2362e-03\n",
      "Epoch [40/100], Loss: 2.6255e-03\n",
      "Epoch [50/100], Loss: 1.7555e-03\n",
      "Epoch [60/100], Loss: 1.0402e-03\n",
      "Epoch [70/100], Loss: 6.9557e-04\n",
      "Epoch [80/100], Loss: 5.1982e-04\n",
      "Epoch [90/100], Loss: 4.2784e-04\n",
      "Epoch [100/100], Loss: 3.9890e-04\n",
      "#####--training model 308--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.1515e-02\n",
      "Epoch [20/100], Loss: 7.2423e-02\n",
      "Epoch [30/100], Loss: 7.2123e-02\n",
      "Epoch [40/100], Loss: 1.7215e-02\n",
      "Epoch [50/100], Loss: 7.5775e-03\n",
      "Epoch [60/100], Loss: 8.3842e-03\n",
      "Epoch [70/100], Loss: 8.4742e-03\n",
      "Epoch [80/100], Loss: 7.9045e-03\n",
      "Epoch [90/100], Loss: 6.8795e-03\n",
      "Epoch [100/100], Loss: 5.4776e-03\n",
      "#####--training model 309--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0906e-04\n",
      "Epoch [20/100], Loss: 8.7044e-05\n",
      "Epoch [30/100], Loss: 8.5523e-05\n",
      "Epoch [40/100], Loss: 8.5045e-05\n",
      "Epoch [50/100], Loss: 8.4540e-05\n",
      "Epoch [60/100], Loss: 8.3968e-05\n",
      "Epoch [70/100], Loss: 8.3300e-05\n",
      "Epoch [80/100], Loss: 8.2499e-05\n",
      "Epoch [90/100], Loss: 8.1424e-05\n",
      "Epoch [100/100], Loss: 7.9378e-05\n",
      "#####--training model 310--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.1024e-04\n",
      "Epoch [20/100], Loss: 4.0313e-05\n",
      "Epoch [30/100], Loss: 2.3884e-04\n",
      "Epoch [40/100], Loss: 4.5618e-04\n",
      "Epoch [50/100], Loss: 4.8150e-04\n",
      "Epoch [60/100], Loss: 3.9866e-04\n",
      "Epoch [70/100], Loss: 3.4878e-04\n",
      "Epoch [80/100], Loss: 3.1592e-04\n",
      "Epoch [90/100], Loss: 2.9078e-04\n",
      "Epoch [100/100], Loss: 2.7321e-04\n",
      "#####--training model 311--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3358e-03\n",
      "Epoch [20/100], Loss: 1.3600e-03\n",
      "Epoch [30/100], Loss: 1.3811e-03\n",
      "Epoch [40/100], Loss: 1.3893e-03\n",
      "Epoch [50/100], Loss: 6.4981e-04\n",
      "Epoch [60/100], Loss: 5.4475e-04\n",
      "Epoch [70/100], Loss: 4.5907e-04\n",
      "Epoch [80/100], Loss: 3.9991e-04\n",
      "Epoch [90/100], Loss: 3.4979e-04\n",
      "Epoch [100/100], Loss: 3.0586e-04\n",
      "#####--training model 312--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.8048e-04\n",
      "Epoch [20/100], Loss: 7.2708e-05\n",
      "Epoch [30/100], Loss: 4.2202e-05\n",
      "Epoch [40/100], Loss: 2.8884e-05\n",
      "Epoch [50/100], Loss: 2.1792e-05\n",
      "Epoch [60/100], Loss: 1.7583e-05\n",
      "Epoch [70/100], Loss: 1.4935e-05\n",
      "Epoch [80/100], Loss: 1.3232e-05\n",
      "Epoch [90/100], Loss: 1.2148e-05\n",
      "Epoch [100/100], Loss: 1.1485e-05\n",
      "#####--training model 313--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5424e-04\n",
      "Epoch [20/100], Loss: 6.6086e-05\n",
      "Epoch [30/100], Loss: 4.0631e-05\n",
      "Epoch [40/100], Loss: 2.9475e-05\n",
      "Epoch [50/100], Loss: 2.3658e-05\n",
      "Epoch [60/100], Loss: 2.0401e-05\n",
      "Epoch [70/100], Loss: 1.8571e-05\n",
      "Epoch [80/100], Loss: 1.7612e-05\n",
      "Epoch [90/100], Loss: 1.7190e-05\n",
      "Epoch [100/100], Loss: 1.7101e-05\n",
      "#####--training model 314--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0867e-04\n",
      "Epoch [20/100], Loss: 1.1682e-04\n",
      "Epoch [30/100], Loss: 9.8051e-05\n",
      "Epoch [40/100], Loss: 9.4439e-05\n",
      "Epoch [50/100], Loss: 9.4835e-05\n",
      "Epoch [60/100], Loss: 9.9230e-05\n",
      "Epoch [70/100], Loss: 1.2323e-04\n",
      "Epoch [80/100], Loss: 1.3391e-04\n",
      "Epoch [90/100], Loss: 1.0616e-04\n",
      "Epoch [100/100], Loss: 8.5086e-05\n",
      "#####--training model 315--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.1212e-03\n",
      "Epoch [20/100], Loss: 2.4903e-03\n",
      "Epoch [30/100], Loss: 2.3978e-03\n",
      "Epoch [40/100], Loss: 2.3567e-03\n",
      "Epoch [50/100], Loss: 2.3147e-03\n",
      "Epoch [60/100], Loss: 2.2696e-03\n",
      "Epoch [70/100], Loss: 2.2290e-03\n",
      "Epoch [80/100], Loss: 2.1779e-03\n",
      "Epoch [90/100], Loss: 2.1019e-03\n",
      "Epoch [100/100], Loss: 2.0061e-03\n",
      "#####--training model 316--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.4478e-05\n",
      "Epoch [20/100], Loss: 2.5907e-05\n",
      "Epoch [30/100], Loss: 1.7567e-05\n",
      "Epoch [40/100], Loss: 1.6359e-05\n",
      "Epoch [50/100], Loss: 1.6345e-05\n",
      "Epoch [60/100], Loss: 1.6410e-05\n",
      "Epoch [70/100], Loss: 1.6905e-05\n",
      "Epoch [80/100], Loss: 1.8054e-05\n",
      "Epoch [90/100], Loss: 2.3462e-05\n",
      "Epoch [100/100], Loss: 1.2199e-05\n",
      "#####--training model 317--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5415e-02\n",
      "Epoch [20/100], Loss: 1.5416e-02\n",
      "Epoch [30/100], Loss: 1.5405e-02\n",
      "Epoch [40/100], Loss: 1.5385e-02\n",
      "Epoch [50/100], Loss: 1.5346e-02\n",
      "Epoch [60/100], Loss: 1.5242e-02\n",
      "Epoch [70/100], Loss: 1.4803e-02\n",
      "Epoch [80/100], Loss: 1.3565e-02\n",
      "Epoch [90/100], Loss: 1.3878e-02\n",
      "Epoch [100/100], Loss: 1.3868e-02\n",
      "#####--training model 318--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1222e-03\n",
      "Epoch [20/100], Loss: 1.3160e-03\n",
      "Epoch [30/100], Loss: 1.3797e-03\n",
      "Epoch [40/100], Loss: 1.3988e-03\n",
      "Epoch [50/100], Loss: 1.4004e-03\n",
      "Epoch [60/100], Loss: 1.3902e-03\n",
      "Epoch [70/100], Loss: 1.3664e-03\n",
      "Epoch [80/100], Loss: 1.3102e-03\n",
      "Epoch [90/100], Loss: 1.1992e-03\n",
      "Epoch [100/100], Loss: 1.2373e-03\n",
      "#####--training model 319--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8165e-04\n",
      "Epoch [20/100], Loss: 3.3234e-04\n",
      "Epoch [30/100], Loss: 3.3317e-04\n",
      "Epoch [40/100], Loss: 3.3550e-04\n",
      "Epoch [50/100], Loss: 3.3826e-04\n",
      "Epoch [60/100], Loss: 3.4144e-04\n",
      "Epoch [70/100], Loss: 3.4509e-04\n",
      "Epoch [80/100], Loss: 3.4935e-04\n",
      "Epoch [90/100], Loss: 3.5485e-04\n",
      "Epoch [100/100], Loss: 3.6304e-04\n",
      "#####--training model 320--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0323e-04\n",
      "Epoch [20/100], Loss: 2.3120e-04\n",
      "Epoch [30/100], Loss: 2.2429e-04\n",
      "Epoch [40/100], Loss: 2.2373e-04\n",
      "Epoch [50/100], Loss: 2.2370e-04\n",
      "Epoch [60/100], Loss: 2.2338e-04\n",
      "Epoch [70/100], Loss: 2.2396e-04\n",
      "Epoch [80/100], Loss: 2.2008e-04\n",
      "Epoch [90/100], Loss: 1.5842e-04\n",
      "Epoch [100/100], Loss: 1.2794e-04\n",
      "#####--training model 321--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.8683e-04\n",
      "Epoch [20/100], Loss: 9.8455e-05\n",
      "Epoch [30/100], Loss: 7.4938e-05\n",
      "Epoch [40/100], Loss: 6.6449e-05\n",
      "Epoch [50/100], Loss: 6.3495e-05\n",
      "Epoch [60/100], Loss: 6.2653e-05\n",
      "Epoch [70/100], Loss: 6.2447e-05\n",
      "Epoch [80/100], Loss: 6.2364e-05\n",
      "Epoch [90/100], Loss: 6.2293e-05\n",
      "Epoch [100/100], Loss: 6.2232e-05\n",
      "#####--training model 322--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4726e-03\n",
      "Epoch [20/100], Loss: 1.4667e-03\n",
      "Epoch [30/100], Loss: 1.4663e-03\n",
      "Epoch [40/100], Loss: 1.4631e-03\n",
      "Epoch [50/100], Loss: 1.0409e-03\n",
      "Epoch [60/100], Loss: 6.2621e-04\n",
      "Epoch [70/100], Loss: 1.3186e-04\n",
      "Epoch [80/100], Loss: 5.6597e-05\n",
      "Epoch [90/100], Loss: 8.5662e-05\n",
      "Epoch [100/100], Loss: 1.0717e-04\n",
      "#####--training model 323--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1772e-04\n",
      "Epoch [20/100], Loss: 1.2526e-04\n",
      "Epoch [30/100], Loss: 1.4562e-04\n",
      "Epoch [40/100], Loss: 6.1302e-05\n",
      "Epoch [50/100], Loss: 4.4815e-05\n",
      "Epoch [60/100], Loss: 6.3608e-05\n",
      "Epoch [70/100], Loss: 7.0823e-05\n",
      "Epoch [80/100], Loss: 7.3839e-05\n",
      "Epoch [90/100], Loss: 7.5099e-05\n",
      "Epoch [100/100], Loss: 7.4923e-05\n",
      "#####--training model 324--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.4205e-04\n",
      "Epoch [20/100], Loss: 3.6392e-04\n",
      "Epoch [30/100], Loss: 3.6858e-04\n",
      "Epoch [40/100], Loss: 4.3355e-04\n",
      "Epoch [50/100], Loss: 4.6553e-04\n",
      "Epoch [60/100], Loss: 3.0507e-04\n",
      "Epoch [70/100], Loss: 2.6255e-04\n",
      "Epoch [80/100], Loss: 2.0332e-04\n",
      "Epoch [90/100], Loss: 1.8400e-04\n",
      "Epoch [100/100], Loss: 1.1396e-04\n",
      "#####--training model 325--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.3343e-03\n",
      "Epoch [20/100], Loss: 4.2796e-03\n",
      "Epoch [30/100], Loss: 3.8871e-03\n",
      "Epoch [40/100], Loss: 2.6283e-03\n",
      "Epoch [50/100], Loss: 1.9528e-03\n",
      "Epoch [60/100], Loss: 1.6433e-03\n",
      "Epoch [70/100], Loss: 1.4849e-03\n",
      "Epoch [80/100], Loss: 1.3926e-03\n",
      "Epoch [90/100], Loss: 1.3210e-03\n",
      "Epoch [100/100], Loss: 1.2481e-03\n",
      "#####--training model 326--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.7691e-04\n",
      "Epoch [20/100], Loss: 2.6238e-04\n",
      "Epoch [30/100], Loss: 2.6649e-04\n",
      "Epoch [40/100], Loss: 2.7378e-04\n",
      "Epoch [50/100], Loss: 2.9066e-04\n",
      "Epoch [60/100], Loss: 1.3629e-04\n",
      "Epoch [70/100], Loss: 7.3944e-05\n",
      "Epoch [80/100], Loss: 4.2492e-05\n",
      "Epoch [90/100], Loss: 2.0990e-05\n",
      "Epoch [100/100], Loss: 1.2650e-05\n",
      "#####--training model 327--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4528e-04\n",
      "Epoch [20/100], Loss: 6.5192e-05\n",
      "Epoch [30/100], Loss: 4.2428e-05\n",
      "Epoch [40/100], Loss: 3.2444e-05\n",
      "Epoch [50/100], Loss: 2.7310e-05\n",
      "Epoch [60/100], Loss: 2.4540e-05\n",
      "Epoch [70/100], Loss: 2.3084e-05\n",
      "Epoch [80/100], Loss: 2.2373e-05\n",
      "Epoch [90/100], Loss: 2.2041e-05\n",
      "Epoch [100/100], Loss: 2.1855e-05\n",
      "#####--training model 328--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.9720e-03\n",
      "Epoch [20/100], Loss: 5.0699e-03\n",
      "Epoch [30/100], Loss: 5.0786e-03\n",
      "Epoch [40/100], Loss: 5.0802e-03\n",
      "Epoch [50/100], Loss: 5.0672e-03\n",
      "Epoch [60/100], Loss: 4.9964e-03\n",
      "Epoch [70/100], Loss: 4.4425e-03\n",
      "Epoch [80/100], Loss: 3.2221e-03\n",
      "Epoch [90/100], Loss: 3.5068e-03\n",
      "Epoch [100/100], Loss: 3.5887e-03\n",
      "#####--training model 329--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.3972e-04\n",
      "Epoch [20/100], Loss: 4.1600e-04\n",
      "Epoch [30/100], Loss: 4.4347e-04\n",
      "Epoch [40/100], Loss: 5.0511e-04\n",
      "Epoch [50/100], Loss: 6.7517e-04\n",
      "Epoch [60/100], Loss: 6.2043e-04\n",
      "Epoch [70/100], Loss: 4.6020e-04\n",
      "Epoch [80/100], Loss: 3.3848e-04\n",
      "Epoch [90/100], Loss: 3.3185e-04\n",
      "Epoch [100/100], Loss: 3.6059e-04\n",
      "#####--training model 330--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5641e-03\n",
      "Epoch [20/100], Loss: 2.2812e-03\n",
      "Epoch [30/100], Loss: 1.8196e-03\n",
      "Epoch [40/100], Loss: 1.4291e-03\n",
      "Epoch [50/100], Loss: 1.1418e-03\n",
      "Epoch [60/100], Loss: 9.3044e-04\n",
      "Epoch [70/100], Loss: 7.4894e-04\n",
      "Epoch [80/100], Loss: 5.3532e-04\n",
      "Epoch [90/100], Loss: 3.1571e-04\n",
      "Epoch [100/100], Loss: 2.1858e-04\n",
      "#####--training model 331--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6001e-01\n",
      "Epoch [20/100], Loss: 1.3279e-02\n",
      "Epoch [30/100], Loss: 1.0768e-02\n",
      "Epoch [40/100], Loss: 1.0671e-02\n",
      "Epoch [50/100], Loss: 1.0874e-02\n",
      "Epoch [60/100], Loss: 1.1552e-02\n",
      "Epoch [70/100], Loss: 1.2264e-02\n",
      "Epoch [80/100], Loss: 1.6232e-02\n",
      "Epoch [90/100], Loss: 1.3347e-02\n",
      "Epoch [100/100], Loss: 1.3832e-02\n",
      "#####--training model 332--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.5829e-04\n",
      "Epoch [20/100], Loss: 9.1639e-04\n",
      "Epoch [30/100], Loss: 1.3770e-03\n",
      "Epoch [40/100], Loss: 1.0906e-03\n",
      "Epoch [50/100], Loss: 7.7934e-04\n",
      "Epoch [60/100], Loss: 5.9408e-04\n",
      "Epoch [70/100], Loss: 4.4844e-04\n",
      "Epoch [80/100], Loss: 3.3594e-04\n",
      "Epoch [90/100], Loss: 2.5862e-04\n",
      "Epoch [100/100], Loss: 2.0307e-04\n",
      "#####--training model 333--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4664e-03\n",
      "Epoch [20/100], Loss: 1.4269e-03\n",
      "Epoch [30/100], Loss: 1.1054e-03\n",
      "Epoch [40/100], Loss: 6.0965e-04\n",
      "Epoch [50/100], Loss: 5.1486e-04\n",
      "Epoch [60/100], Loss: 4.5387e-04\n",
      "Epoch [70/100], Loss: 4.4668e-04\n",
      "Epoch [80/100], Loss: 4.6137e-04\n",
      "Epoch [90/100], Loss: 4.7530e-04\n",
      "Epoch [100/100], Loss: 4.8636e-04\n",
      "#####--training model 334--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0177e-03\n",
      "Epoch [20/100], Loss: 2.1657e-03\n",
      "Epoch [30/100], Loss: 3.2457e-03\n",
      "Epoch [40/100], Loss: 1.8125e-03\n",
      "Epoch [50/100], Loss: 1.3214e-03\n",
      "Epoch [60/100], Loss: 1.1376e-03\n",
      "Epoch [70/100], Loss: 1.0470e-03\n",
      "Epoch [80/100], Loss: 9.8833e-04\n",
      "Epoch [90/100], Loss: 9.4396e-04\n",
      "Epoch [100/100], Loss: 9.0778e-04\n",
      "#####--training model 335--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7568e-04\n",
      "Epoch [20/100], Loss: 7.7247e-05\n",
      "Epoch [30/100], Loss: 5.1390e-05\n",
      "Epoch [40/100], Loss: 4.1104e-05\n",
      "Epoch [50/100], Loss: 3.6577e-05\n",
      "Epoch [60/100], Loss: 3.4722e-05\n",
      "Epoch [70/100], Loss: 3.4150e-05\n",
      "Epoch [80/100], Loss: 3.4120e-05\n",
      "Epoch [90/100], Loss: 3.4291e-05\n",
      "Epoch [100/100], Loss: 3.4582e-05\n",
      "#####--training model 336--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7551e-04\n",
      "Epoch [20/100], Loss: 6.1185e-05\n",
      "Epoch [30/100], Loss: 3.1115e-05\n",
      "Epoch [40/100], Loss: 1.8522e-05\n",
      "Epoch [50/100], Loss: 1.2006e-05\n",
      "Epoch [60/100], Loss: 8.1998e-06\n",
      "Epoch [70/100], Loss: 5.7964e-06\n",
      "Epoch [80/100], Loss: 4.1960e-06\n",
      "Epoch [90/100], Loss: 3.0894e-06\n",
      "Epoch [100/100], Loss: 2.3030e-06\n",
      "#####--training model 337--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0784e-04\n",
      "Epoch [20/100], Loss: 4.9637e-05\n",
      "Epoch [30/100], Loss: 3.5104e-05\n",
      "Epoch [40/100], Loss: 2.9944e-05\n",
      "Epoch [50/100], Loss: 2.7977e-05\n",
      "Epoch [60/100], Loss: 2.7320e-05\n",
      "Epoch [70/100], Loss: 2.7186e-05\n",
      "Epoch [80/100], Loss: 2.7223e-05\n",
      "Epoch [90/100], Loss: 2.7305e-05\n",
      "Epoch [100/100], Loss: 2.7404e-05\n",
      "#####--training model 338--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9282e-03\n",
      "Epoch [20/100], Loss: 1.8441e-03\n",
      "Epoch [30/100], Loss: 3.2721e-03\n",
      "Epoch [40/100], Loss: 3.9421e-03\n",
      "Epoch [50/100], Loss: 3.9312e-03\n",
      "Epoch [60/100], Loss: 3.7520e-03\n",
      "Epoch [70/100], Loss: 3.4552e-03\n",
      "Epoch [80/100], Loss: 3.2296e-03\n",
      "Epoch [90/100], Loss: 3.2061e-03\n",
      "Epoch [100/100], Loss: 3.2575e-03\n",
      "#####--training model 339--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9930e-04\n",
      "Epoch [20/100], Loss: 2.5176e-04\n",
      "Epoch [30/100], Loss: 2.5177e-04\n",
      "Epoch [40/100], Loss: 2.5554e-04\n",
      "Epoch [50/100], Loss: 2.6188e-04\n",
      "Epoch [60/100], Loss: 2.7150e-04\n",
      "Epoch [70/100], Loss: 2.8295e-04\n",
      "Epoch [80/100], Loss: 3.0153e-04\n",
      "Epoch [90/100], Loss: 3.3715e-04\n",
      "Epoch [100/100], Loss: 4.1616e-04\n",
      "#####--training model 340--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.3713e-03\n",
      "Epoch [20/100], Loss: 2.0691e-03\n",
      "Epoch [30/100], Loss: 2.0881e-03\n",
      "Epoch [40/100], Loss: 1.6616e-03\n",
      "Epoch [50/100], Loss: 1.2826e-03\n",
      "Epoch [60/100], Loss: 1.0221e-03\n",
      "Epoch [70/100], Loss: 8.5254e-04\n",
      "Epoch [80/100], Loss: 7.0387e-04\n",
      "Epoch [90/100], Loss: 5.9352e-04\n",
      "Epoch [100/100], Loss: 5.1828e-04\n",
      "#####--training model 341--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2848e-04\n",
      "Epoch [20/100], Loss: 4.3636e-05\n",
      "Epoch [30/100], Loss: 2.1937e-05\n",
      "Epoch [40/100], Loss: 1.3016e-05\n",
      "Epoch [50/100], Loss: 8.4348e-06\n",
      "Epoch [60/100], Loss: 5.7663e-06\n",
      "Epoch [70/100], Loss: 4.0821e-06\n",
      "Epoch [80/100], Loss: 2.9599e-06\n",
      "Epoch [90/100], Loss: 2.1830e-06\n",
      "Epoch [100/100], Loss: 1.6299e-06\n",
      "#####--training model 342--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.8670e-04\n",
      "Epoch [20/100], Loss: 4.7454e-04\n",
      "Epoch [30/100], Loss: 4.1579e-04\n",
      "Epoch [40/100], Loss: 5.0907e-04\n",
      "Epoch [50/100], Loss: 5.9234e-04\n",
      "Epoch [60/100], Loss: 6.5791e-04\n",
      "Epoch [70/100], Loss: 7.2089e-04\n",
      "Epoch [80/100], Loss: 7.7957e-04\n",
      "Epoch [90/100], Loss: 8.2515e-04\n",
      "Epoch [100/100], Loss: 8.6044e-04\n",
      "#####--training model 343--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4869e-04\n",
      "Epoch [20/100], Loss: 5.4316e-05\n",
      "Epoch [30/100], Loss: 2.8542e-05\n",
      "Epoch [40/100], Loss: 1.7496e-05\n",
      "Epoch [50/100], Loss: 1.1676e-05\n",
      "Epoch [60/100], Loss: 8.2197e-06\n",
      "Epoch [70/100], Loss: 6.0026e-06\n",
      "Epoch [80/100], Loss: 4.5024e-06\n",
      "Epoch [90/100], Loss: 3.4476e-06\n",
      "Epoch [100/100], Loss: 2.6848e-06\n",
      "#####--training model 344--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.4230e-03\n",
      "Epoch [20/100], Loss: 7.0398e-03\n",
      "Epoch [30/100], Loss: 7.2009e-03\n",
      "Epoch [40/100], Loss: 7.2392e-03\n",
      "Epoch [50/100], Loss: 7.2450e-03\n",
      "Epoch [60/100], Loss: 7.2410e-03\n",
      "Epoch [70/100], Loss: 7.2279e-03\n",
      "Epoch [80/100], Loss: 7.1697e-03\n",
      "Epoch [90/100], Loss: 7.0211e-03\n",
      "Epoch [100/100], Loss: 6.6380e-03\n",
      "#####--training model 345--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.4433e-03\n",
      "Epoch [20/100], Loss: 1.5913e-03\n",
      "Epoch [30/100], Loss: 1.6261e-03\n",
      "Epoch [40/100], Loss: 1.6510e-03\n",
      "Epoch [50/100], Loss: 1.6739e-03\n",
      "Epoch [60/100], Loss: 1.4718e-03\n",
      "Epoch [70/100], Loss: 5.6506e-04\n",
      "Epoch [80/100], Loss: 5.5316e-04\n",
      "Epoch [90/100], Loss: 2.9334e-04\n",
      "Epoch [100/100], Loss: 3.1240e-04\n",
      "#####--training model 346--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.2804e-03\n",
      "Epoch [20/100], Loss: 7.9314e-04\n",
      "Epoch [30/100], Loss: 5.8839e-04\n",
      "Epoch [40/100], Loss: 4.5208e-04\n",
      "Epoch [50/100], Loss: 3.7437e-04\n",
      "Epoch [60/100], Loss: 3.3879e-04\n",
      "Epoch [70/100], Loss: 3.1439e-04\n",
      "Epoch [80/100], Loss: 2.9655e-04\n",
      "Epoch [90/100], Loss: 2.8212e-04\n",
      "Epoch [100/100], Loss: 2.6914e-04\n",
      "#####--training model 347--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3898e-04\n",
      "Epoch [20/100], Loss: 3.2050e-04\n",
      "Epoch [30/100], Loss: 3.1415e-04\n",
      "Epoch [40/100], Loss: 8.5108e-05\n",
      "Epoch [50/100], Loss: 4.6837e-05\n",
      "Epoch [60/100], Loss: 1.8120e-05\n",
      "Epoch [70/100], Loss: 1.3901e-05\n",
      "Epoch [80/100], Loss: 1.4201e-05\n",
      "Epoch [90/100], Loss: 1.3405e-05\n",
      "Epoch [100/100], Loss: 1.7760e-05\n",
      "#####--training model 348--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5882e-02\n",
      "Epoch [20/100], Loss: 1.0612e-02\n",
      "Epoch [30/100], Loss: 8.6830e-03\n",
      "Epoch [40/100], Loss: 6.7968e-03\n",
      "Epoch [50/100], Loss: 5.2089e-03\n",
      "Epoch [60/100], Loss: 4.3793e-03\n",
      "Epoch [70/100], Loss: 4.0171e-03\n",
      "Epoch [80/100], Loss: 3.7972e-03\n",
      "Epoch [90/100], Loss: 3.6420e-03\n",
      "Epoch [100/100], Loss: 3.5270e-03\n",
      "#####--training model 349--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.1092e-04\n",
      "Epoch [20/100], Loss: 3.1346e-04\n",
      "Epoch [30/100], Loss: 2.4454e-04\n",
      "Epoch [40/100], Loss: 2.8086e-04\n",
      "Epoch [50/100], Loss: 2.5737e-04\n",
      "Epoch [60/100], Loss: 1.6958e-04\n",
      "Epoch [70/100], Loss: 7.7132e-05\n",
      "Epoch [80/100], Loss: 3.2310e-05\n",
      "Epoch [90/100], Loss: 2.0538e-05\n",
      "Epoch [100/100], Loss: 1.7756e-05\n",
      "#####--training model 350--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.9900e-03\n",
      "Epoch [20/100], Loss: 1.2980e-03\n",
      "Epoch [30/100], Loss: 5.7926e-04\n",
      "Epoch [40/100], Loss: 3.7636e-04\n",
      "Epoch [50/100], Loss: 2.6298e-04\n",
      "Epoch [60/100], Loss: 1.7962e-04\n",
      "Epoch [70/100], Loss: 1.4142e-04\n",
      "Epoch [80/100], Loss: 1.3598e-04\n",
      "Epoch [90/100], Loss: 1.3237e-04\n",
      "Epoch [100/100], Loss: 1.2700e-04\n",
      "#####--training model 351--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7951e-04\n",
      "Epoch [20/100], Loss: 1.7751e-04\n",
      "Epoch [30/100], Loss: 1.7671e-04\n",
      "Epoch [40/100], Loss: 2.0940e-04\n",
      "Epoch [50/100], Loss: 2.3610e-04\n",
      "Epoch [60/100], Loss: 2.5017e-04\n",
      "Epoch [70/100], Loss: 2.3645e-04\n",
      "Epoch [80/100], Loss: 2.2359e-04\n",
      "Epoch [90/100], Loss: 2.1625e-04\n",
      "Epoch [100/100], Loss: 2.1012e-04\n",
      "#####--training model 352--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.6897e-06\n",
      "Epoch [20/100], Loss: 3.4390e-04\n",
      "Epoch [30/100], Loss: 3.6217e-04\n",
      "Epoch [40/100], Loss: 3.7095e-04\n",
      "Epoch [50/100], Loss: 3.6875e-04\n",
      "Epoch [60/100], Loss: 3.7103e-04\n",
      "Epoch [70/100], Loss: 3.8026e-04\n",
      "Epoch [80/100], Loss: 3.8917e-04\n",
      "Epoch [90/100], Loss: 3.9472e-04\n",
      "Epoch [100/100], Loss: 3.9967e-04\n",
      "#####--training model 353--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.6962e-04\n",
      "Epoch [20/100], Loss: 2.8986e-04\n",
      "Epoch [30/100], Loss: 1.6522e-04\n",
      "Epoch [40/100], Loss: 2.1411e-04\n",
      "Epoch [50/100], Loss: 3.1648e-04\n",
      "Epoch [60/100], Loss: 3.1682e-04\n",
      "Epoch [70/100], Loss: 3.1599e-04\n",
      "Epoch [80/100], Loss: 3.4728e-04\n",
      "Epoch [90/100], Loss: 3.9160e-04\n",
      "Epoch [100/100], Loss: 4.3701e-04\n",
      "#####--training model 354--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3586e-02\n",
      "Epoch [20/100], Loss: 1.4299e-02\n",
      "Epoch [30/100], Loss: 1.4458e-02\n",
      "Epoch [40/100], Loss: 1.4514e-02\n",
      "Epoch [50/100], Loss: 1.4548e-02\n",
      "Epoch [60/100], Loss: 1.4564e-02\n",
      "Epoch [70/100], Loss: 1.4566e-02\n",
      "Epoch [80/100], Loss: 1.4502e-02\n",
      "Epoch [90/100], Loss: 1.3677e-02\n",
      "Epoch [100/100], Loss: 1.1228e-02\n",
      "#####--training model 355--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3669e-03\n",
      "Epoch [20/100], Loss: 1.6698e-03\n",
      "Epoch [30/100], Loss: 1.4452e-03\n",
      "Epoch [40/100], Loss: 1.0176e-03\n",
      "Epoch [50/100], Loss: 6.4180e-04\n",
      "Epoch [60/100], Loss: 4.8302e-04\n",
      "Epoch [70/100], Loss: 4.3503e-04\n",
      "Epoch [80/100], Loss: 4.1670e-04\n",
      "Epoch [90/100], Loss: 4.0411e-04\n",
      "Epoch [100/100], Loss: 3.9039e-04\n",
      "#####--training model 356--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.2205e-04\n",
      "Epoch [20/100], Loss: 8.3480e-04\n",
      "Epoch [30/100], Loss: 8.9511e-04\n",
      "Epoch [40/100], Loss: 9.2804e-04\n",
      "Epoch [50/100], Loss: 1.0461e-03\n",
      "Epoch [60/100], Loss: 1.2482e-03\n",
      "Epoch [70/100], Loss: 1.4307e-03\n",
      "Epoch [80/100], Loss: 1.5396e-03\n",
      "Epoch [90/100], Loss: 1.5936e-03\n",
      "Epoch [100/100], Loss: 1.6218e-03\n",
      "#####--training model 357--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.1327e-04\n",
      "Epoch [20/100], Loss: 4.7967e-04\n",
      "Epoch [30/100], Loss: 1.8812e-04\n",
      "Epoch [40/100], Loss: 1.6098e-04\n",
      "Epoch [50/100], Loss: 3.2962e-04\n",
      "Epoch [60/100], Loss: 3.9699e-04\n",
      "Epoch [70/100], Loss: 4.4628e-04\n",
      "Epoch [80/100], Loss: 1.8657e-03\n",
      "Epoch [90/100], Loss: 1.2465e-03\n",
      "Epoch [100/100], Loss: 3.8199e-04\n",
      "#####--training model 358--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.8971e-05\n",
      "Epoch [20/100], Loss: 3.5514e-05\n",
      "Epoch [30/100], Loss: 5.9020e-05\n",
      "Epoch [40/100], Loss: 7.6771e-05\n",
      "Epoch [50/100], Loss: 8.7147e-05\n",
      "Epoch [60/100], Loss: 1.0477e-04\n",
      "Epoch [70/100], Loss: 1.2003e-04\n",
      "Epoch [80/100], Loss: 1.3008e-04\n",
      "Epoch [90/100], Loss: 1.3755e-04\n",
      "Epoch [100/100], Loss: 1.4470e-04\n",
      "#####--training model 359--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2527e-04\n",
      "Epoch [20/100], Loss: 4.5343e-05\n",
      "Epoch [30/100], Loss: 2.3339e-05\n",
      "Epoch [40/100], Loss: 1.3977e-05\n",
      "Epoch [50/100], Loss: 9.0938e-06\n",
      "Epoch [60/100], Loss: 6.2273e-06\n",
      "Epoch [70/100], Loss: 4.4110e-06\n",
      "Epoch [80/100], Loss: 3.1985e-06\n",
      "Epoch [90/100], Loss: 2.3584e-06\n",
      "Epoch [100/100], Loss: 1.7602e-06\n",
      "#####--training model 360--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4089e-05\n",
      "Epoch [20/100], Loss: 1.3990e-05\n",
      "Epoch [30/100], Loss: 1.4126e-05\n",
      "Epoch [40/100], Loss: 1.4262e-05\n",
      "Epoch [50/100], Loss: 1.4392e-05\n",
      "Epoch [60/100], Loss: 1.4507e-05\n",
      "Epoch [70/100], Loss: 1.4602e-05\n",
      "Epoch [80/100], Loss: 1.4672e-05\n",
      "Epoch [90/100], Loss: 1.4716e-05\n",
      "Epoch [100/100], Loss: 1.4734e-05\n",
      "#####--training model 361--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2353e-03\n",
      "Epoch [20/100], Loss: 2.2853e-03\n",
      "Epoch [30/100], Loss: 2.2957e-03\n",
      "Epoch [40/100], Loss: 2.3309e-03\n",
      "Epoch [50/100], Loss: 2.3681e-03\n",
      "Epoch [60/100], Loss: 2.3923e-03\n",
      "Epoch [70/100], Loss: 2.4143e-03\n",
      "Epoch [80/100], Loss: 2.4363e-03\n",
      "Epoch [90/100], Loss: 2.4594e-03\n",
      "Epoch [100/100], Loss: 2.4840e-03\n",
      "#####--training model 362--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.6310e-04\n",
      "Epoch [20/100], Loss: 2.4963e-04\n",
      "Epoch [30/100], Loss: 4.5859e-05\n",
      "Epoch [40/100], Loss: 1.4763e-05\n",
      "Epoch [50/100], Loss: 2.1627e-05\n",
      "Epoch [60/100], Loss: 3.5574e-05\n",
      "Epoch [70/100], Loss: 5.2808e-05\n",
      "Epoch [80/100], Loss: 7.7178e-05\n",
      "Epoch [90/100], Loss: 1.0670e-04\n",
      "Epoch [100/100], Loss: 1.3768e-04\n",
      "#####--training model 363--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3985e-04\n",
      "Epoch [20/100], Loss: 9.6472e-04\n",
      "Epoch [30/100], Loss: 3.0608e-03\n",
      "Epoch [40/100], Loss: 3.5468e-03\n",
      "Epoch [50/100], Loss: 3.8045e-03\n",
      "Epoch [60/100], Loss: 4.3069e-03\n",
      "Epoch [70/100], Loss: 7.6313e-03\n",
      "Epoch [80/100], Loss: 6.7727e-03\n",
      "Epoch [90/100], Loss: 5.6927e-03\n",
      "Epoch [100/100], Loss: 4.8676e-03\n",
      "#####--training model 364--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4346e-04\n",
      "Epoch [20/100], Loss: 5.2143e-05\n",
      "Epoch [30/100], Loss: 2.6851e-05\n",
      "Epoch [40/100], Loss: 1.6057e-05\n",
      "Epoch [50/100], Loss: 1.0415e-05\n",
      "Epoch [60/100], Loss: 7.1013e-06\n",
      "Epoch [70/100], Loss: 5.0047e-06\n",
      "Epoch [80/100], Loss: 3.6100e-06\n",
      "Epoch [90/100], Loss: 2.6482e-06\n",
      "Epoch [100/100], Loss: 1.9674e-06\n",
      "#####--training model 365--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.0996e-02\n",
      "Epoch [20/100], Loss: 6.1476e-02\n",
      "Epoch [30/100], Loss: 6.0269e-02\n",
      "Epoch [40/100], Loss: 6.0084e-02\n",
      "Epoch [50/100], Loss: 6.1389e-02\n",
      "Epoch [60/100], Loss: 6.3459e-02\n",
      "Epoch [70/100], Loss: 6.4885e-02\n",
      "Epoch [80/100], Loss: 6.5376e-02\n",
      "Epoch [90/100], Loss: 6.4945e-02\n",
      "Epoch [100/100], Loss: 6.3328e-02\n",
      "#####--training model 366--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.7799e-04\n",
      "Epoch [20/100], Loss: 1.1246e-04\n",
      "Epoch [30/100], Loss: 6.8029e-05\n",
      "Epoch [40/100], Loss: 5.0028e-05\n",
      "Epoch [50/100], Loss: 4.1098e-05\n",
      "Epoch [60/100], Loss: 3.6347e-05\n",
      "Epoch [70/100], Loss: 3.3877e-05\n",
      "Epoch [80/100], Loss: 3.2741e-05\n",
      "Epoch [90/100], Loss: 3.2357e-05\n",
      "Epoch [100/100], Loss: 3.2338e-05\n",
      "#####--training model 367--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.5743e-04\n",
      "Epoch [20/100], Loss: 4.4007e-04\n",
      "Epoch [30/100], Loss: 4.5360e-04\n",
      "Epoch [40/100], Loss: 4.9493e-04\n",
      "Epoch [50/100], Loss: 2.6553e-04\n",
      "Epoch [60/100], Loss: 1.8093e-04\n",
      "Epoch [70/100], Loss: 1.7064e-04\n",
      "Epoch [80/100], Loss: 1.6316e-04\n",
      "Epoch [90/100], Loss: 1.5163e-04\n",
      "Epoch [100/100], Loss: 1.2870e-04\n",
      "#####--training model 368--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.5005e-04\n",
      "Epoch [20/100], Loss: 1.1057e-03\n",
      "Epoch [30/100], Loss: 1.0453e-03\n",
      "Epoch [40/100], Loss: 1.0340e-03\n",
      "Epoch [50/100], Loss: 9.6026e-04\n",
      "Epoch [60/100], Loss: 9.0840e-04\n",
      "Epoch [70/100], Loss: 8.9032e-04\n",
      "Epoch [80/100], Loss: 8.9242e-04\n",
      "Epoch [90/100], Loss: 8.9910e-04\n",
      "Epoch [100/100], Loss: 8.9187e-04\n",
      "#####--training model 369--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3090e-03\n",
      "Epoch [20/100], Loss: 1.4402e-04\n",
      "Epoch [30/100], Loss: 2.6701e-04\n",
      "Epoch [40/100], Loss: 4.2441e-04\n",
      "Epoch [50/100], Loss: 5.6304e-04\n",
      "Epoch [60/100], Loss: 6.0156e-04\n",
      "Epoch [70/100], Loss: 6.0777e-04\n",
      "Epoch [80/100], Loss: 6.0390e-04\n",
      "Epoch [90/100], Loss: 5.9937e-04\n",
      "Epoch [100/100], Loss: 5.9812e-04\n",
      "#####--training model 370--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3134e-03\n",
      "Epoch [20/100], Loss: 1.3795e-03\n",
      "Epoch [30/100], Loss: 1.1031e-03\n",
      "Epoch [40/100], Loss: 7.8729e-04\n",
      "Epoch [50/100], Loss: 5.8704e-04\n",
      "Epoch [60/100], Loss: 4.4787e-04\n",
      "Epoch [70/100], Loss: 3.5294e-04\n",
      "Epoch [80/100], Loss: 2.8756e-04\n",
      "Epoch [90/100], Loss: 2.3936e-04\n",
      "Epoch [100/100], Loss: 1.9913e-04\n",
      "#####--training model 371--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.7816e-03\n",
      "Epoch [20/100], Loss: 3.8784e-03\n",
      "Epoch [30/100], Loss: 2.1554e-03\n",
      "Epoch [40/100], Loss: 1.4031e-03\n",
      "Epoch [50/100], Loss: 1.0355e-03\n",
      "Epoch [60/100], Loss: 7.6723e-04\n",
      "Epoch [70/100], Loss: 6.0658e-04\n",
      "Epoch [80/100], Loss: 5.1804e-04\n",
      "Epoch [90/100], Loss: 4.6028e-04\n",
      "Epoch [100/100], Loss: 4.1806e-04\n",
      "#####--training model 372--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.0927e-04\n",
      "Epoch [20/100], Loss: 1.2316e-03\n",
      "Epoch [30/100], Loss: 1.8860e-03\n",
      "Epoch [40/100], Loss: 1.9485e-03\n",
      "Epoch [50/100], Loss: 1.8102e-03\n",
      "Epoch [60/100], Loss: 1.7100e-03\n",
      "Epoch [70/100], Loss: 1.6565e-03\n",
      "Epoch [80/100], Loss: 1.6292e-03\n",
      "Epoch [90/100], Loss: 1.6145e-03\n",
      "Epoch [100/100], Loss: 1.6047e-03\n",
      "#####--training model 373--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8925e-04\n",
      "Epoch [20/100], Loss: 2.3943e-04\n",
      "Epoch [30/100], Loss: 2.3531e-04\n",
      "Epoch [40/100], Loss: 2.3721e-04\n",
      "Epoch [50/100], Loss: 2.4604e-04\n",
      "Epoch [60/100], Loss: 2.7462e-04\n",
      "Epoch [70/100], Loss: 2.9515e-04\n",
      "Epoch [80/100], Loss: 2.0647e-04\n",
      "Epoch [90/100], Loss: 1.8198e-04\n",
      "Epoch [100/100], Loss: 1.7573e-04\n",
      "#####--training model 374--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.7571e-03\n",
      "Epoch [20/100], Loss: 2.9639e-03\n",
      "Epoch [30/100], Loss: 1.2116e-03\n",
      "Epoch [40/100], Loss: 8.6419e-04\n",
      "Epoch [50/100], Loss: 7.8095e-04\n",
      "Epoch [60/100], Loss: 7.1947e-04\n",
      "Epoch [70/100], Loss: 6.2328e-04\n",
      "Epoch [80/100], Loss: 5.0906e-04\n",
      "Epoch [90/100], Loss: 4.1813e-04\n",
      "Epoch [100/100], Loss: 3.7026e-04\n",
      "#####--training model 375--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.0222e-04\n",
      "Epoch [20/100], Loss: 1.8745e-04\n",
      "Epoch [30/100], Loss: 4.9703e-05\n",
      "Epoch [40/100], Loss: 1.4161e-05\n",
      "Epoch [50/100], Loss: 8.4483e-06\n",
      "Epoch [60/100], Loss: 8.3284e-06\n",
      "Epoch [70/100], Loss: 8.8653e-06\n",
      "Epoch [80/100], Loss: 1.0307e-05\n",
      "Epoch [90/100], Loss: 1.3087e-05\n",
      "Epoch [100/100], Loss: 1.7004e-05\n",
      "#####--training model 376--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.7666e-04\n",
      "Epoch [20/100], Loss: 3.7220e-04\n",
      "Epoch [30/100], Loss: 1.8929e-04\n",
      "Epoch [40/100], Loss: 8.8980e-05\n",
      "Epoch [50/100], Loss: 6.3195e-05\n",
      "Epoch [60/100], Loss: 5.2823e-05\n",
      "Epoch [70/100], Loss: 5.1295e-05\n",
      "Epoch [80/100], Loss: 6.0890e-05\n",
      "Epoch [90/100], Loss: 7.6818e-05\n",
      "Epoch [100/100], Loss: 9.1033e-05\n",
      "#####--training model 377--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.7679e-02\n",
      "Epoch [20/100], Loss: 9.5357e-03\n",
      "Epoch [30/100], Loss: 1.0556e-02\n",
      "Epoch [40/100], Loss: 9.9087e-03\n",
      "Epoch [50/100], Loss: 8.2238e-03\n",
      "Epoch [60/100], Loss: 6.1645e-03\n",
      "Epoch [70/100], Loss: 4.1417e-03\n",
      "Epoch [80/100], Loss: 2.8410e-03\n",
      "Epoch [90/100], Loss: 2.0228e-03\n",
      "Epoch [100/100], Loss: 1.4583e-03\n",
      "#####--training model 378--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0778e-04\n",
      "Epoch [20/100], Loss: 7.0500e-04\n",
      "Epoch [30/100], Loss: 1.9364e-04\n",
      "Epoch [40/100], Loss: 3.0090e-04\n",
      "Epoch [50/100], Loss: 3.6363e-04\n",
      "Epoch [60/100], Loss: 3.0070e-04\n",
      "Epoch [70/100], Loss: 2.1344e-04\n",
      "Epoch [80/100], Loss: 1.3461e-04\n",
      "Epoch [90/100], Loss: 8.0278e-05\n",
      "Epoch [100/100], Loss: 5.1405e-05\n",
      "#####--training model 379--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.9771e-03\n",
      "Epoch [20/100], Loss: 3.4151e-03\n",
      "Epoch [30/100], Loss: 2.7289e-03\n",
      "Epoch [40/100], Loss: 2.1978e-03\n",
      "Epoch [50/100], Loss: 1.8976e-03\n",
      "Epoch [60/100], Loss: 1.8296e-03\n",
      "Epoch [70/100], Loss: 1.8227e-03\n",
      "Epoch [80/100], Loss: 1.8021e-03\n",
      "Epoch [90/100], Loss: 1.7850e-03\n",
      "Epoch [100/100], Loss: 1.7855e-03\n",
      "#####--training model 380--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4697e-03\n",
      "Epoch [20/100], Loss: 1.9956e-03\n",
      "Epoch [30/100], Loss: 2.0274e-03\n",
      "Epoch [40/100], Loss: 1.6531e-03\n",
      "Epoch [50/100], Loss: 1.0474e-03\n",
      "Epoch [60/100], Loss: 8.3812e-04\n",
      "Epoch [70/100], Loss: 7.2116e-04\n",
      "Epoch [80/100], Loss: 6.7028e-04\n",
      "Epoch [90/100], Loss: 6.8306e-04\n",
      "Epoch [100/100], Loss: 7.3247e-04\n",
      "#####--training model 381--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.7744e-03\n",
      "Epoch [20/100], Loss: 2.9071e-03\n",
      "Epoch [30/100], Loss: 3.1088e-03\n",
      "Epoch [40/100], Loss: 2.6035e-03\n",
      "Epoch [50/100], Loss: 2.1936e-03\n",
      "Epoch [60/100], Loss: 1.8903e-03\n",
      "Epoch [70/100], Loss: 1.6458e-03\n",
      "Epoch [80/100], Loss: 1.4414e-03\n",
      "Epoch [90/100], Loss: 1.2739e-03\n",
      "Epoch [100/100], Loss: 1.1432e-03\n",
      "#####--training model 382--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2389e-03\n",
      "Epoch [20/100], Loss: 1.2450e-03\n",
      "Epoch [30/100], Loss: 1.2635e-03\n",
      "Epoch [40/100], Loss: 1.2825e-03\n",
      "Epoch [50/100], Loss: 1.3774e-03\n",
      "Epoch [60/100], Loss: 1.5582e-03\n",
      "Epoch [70/100], Loss: 1.0937e-03\n",
      "Epoch [80/100], Loss: 8.8180e-04\n",
      "Epoch [90/100], Loss: 6.7587e-04\n",
      "Epoch [100/100], Loss: 5.4087e-04\n",
      "#####--training model 383--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3768e-02\n",
      "Epoch [20/100], Loss: 9.0547e-03\n",
      "Epoch [30/100], Loss: 4.8289e-03\n",
      "Epoch [40/100], Loss: 3.0101e-03\n",
      "Epoch [50/100], Loss: 2.5043e-03\n",
      "Epoch [60/100], Loss: 2.3602e-03\n",
      "Epoch [70/100], Loss: 2.3099e-03\n",
      "Epoch [80/100], Loss: 2.2706e-03\n",
      "Epoch [90/100], Loss: 2.2218e-03\n",
      "Epoch [100/100], Loss: 2.1677e-03\n",
      "#####--training model 384--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3662e-03\n",
      "Epoch [20/100], Loss: 1.4923e-03\n",
      "Epoch [30/100], Loss: 5.0116e-04\n",
      "Epoch [40/100], Loss: 2.8052e-04\n",
      "Epoch [50/100], Loss: 3.3572e-04\n",
      "Epoch [60/100], Loss: 5.0820e-04\n",
      "Epoch [70/100], Loss: 6.0776e-04\n",
      "Epoch [80/100], Loss: 6.0674e-04\n",
      "Epoch [90/100], Loss: 6.1663e-04\n",
      "Epoch [100/100], Loss: 6.2766e-04\n",
      "#####--training model 385--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.5824e-05\n",
      "Epoch [20/100], Loss: 2.1858e-03\n",
      "Epoch [30/100], Loss: 3.2918e-03\n",
      "Epoch [40/100], Loss: 3.1069e-03\n",
      "Epoch [50/100], Loss: 1.7384e-03\n",
      "Epoch [60/100], Loss: 6.4267e-04\n",
      "Epoch [70/100], Loss: 2.9573e-04\n",
      "Epoch [80/100], Loss: 2.0422e-04\n",
      "Epoch [90/100], Loss: 1.3837e-04\n",
      "Epoch [100/100], Loss: 8.1609e-05\n",
      "#####--training model 386--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.5384e-03\n",
      "Epoch [20/100], Loss: 2.9011e-03\n",
      "Epoch [30/100], Loss: 1.7739e-03\n",
      "Epoch [40/100], Loss: 1.1414e-03\n",
      "Epoch [50/100], Loss: 8.3801e-04\n",
      "Epoch [60/100], Loss: 6.6337e-04\n",
      "Epoch [70/100], Loss: 5.4877e-04\n",
      "Epoch [80/100], Loss: 4.6822e-04\n",
      "Epoch [90/100], Loss: 4.0793e-04\n",
      "Epoch [100/100], Loss: 3.6107e-04\n",
      "#####--training model 387--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.1834e-03\n",
      "Epoch [20/100], Loss: 3.8138e-03\n",
      "Epoch [30/100], Loss: 3.5435e-03\n",
      "Epoch [40/100], Loss: 2.8439e-03\n",
      "Epoch [50/100], Loss: 2.3396e-03\n",
      "Epoch [60/100], Loss: 1.9732e-03\n",
      "Epoch [70/100], Loss: 1.7351e-03\n",
      "Epoch [80/100], Loss: 1.6153e-03\n",
      "Epoch [90/100], Loss: 1.5660e-03\n",
      "Epoch [100/100], Loss: 1.5951e-03\n",
      "#####--training model 388--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1945e-03\n",
      "Epoch [20/100], Loss: 1.2749e-03\n",
      "Epoch [30/100], Loss: 1.4291e-03\n",
      "Epoch [40/100], Loss: 1.5213e-03\n",
      "Epoch [50/100], Loss: 1.6306e-03\n",
      "Epoch [60/100], Loss: 1.7231e-03\n",
      "Epoch [70/100], Loss: 1.7866e-03\n",
      "Epoch [80/100], Loss: 1.8299e-03\n",
      "Epoch [90/100], Loss: 1.8558e-03\n",
      "Epoch [100/100], Loss: 1.8660e-03\n",
      "#####--training model 389--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0953e-02\n",
      "Epoch [20/100], Loss: 6.5844e-03\n",
      "Epoch [30/100], Loss: 4.0868e-03\n",
      "Epoch [40/100], Loss: 2.7288e-03\n",
      "Epoch [50/100], Loss: 2.1504e-03\n",
      "Epoch [60/100], Loss: 2.0213e-03\n",
      "Epoch [70/100], Loss: 1.9289e-03\n",
      "Epoch [80/100], Loss: 1.8408e-03\n",
      "Epoch [90/100], Loss: 1.7722e-03\n",
      "Epoch [100/100], Loss: 1.7192e-03\n",
      "#####--training model 390--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5384e-03\n",
      "Epoch [20/100], Loss: 1.5312e-03\n",
      "Epoch [30/100], Loss: 1.5150e-03\n",
      "Epoch [40/100], Loss: 1.8414e-03\n",
      "Epoch [50/100], Loss: 1.7020e-03\n",
      "Epoch [60/100], Loss: 1.5952e-03\n",
      "Epoch [70/100], Loss: 1.7191e-03\n",
      "Epoch [80/100], Loss: 2.5304e-03\n",
      "Epoch [90/100], Loss: 2.2562e-03\n",
      "Epoch [100/100], Loss: 2.3908e-03\n",
      "#####--training model 391--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.3824e-04\n",
      "Epoch [20/100], Loss: 8.5511e-04\n",
      "Epoch [30/100], Loss: 7.7919e-04\n",
      "Epoch [40/100], Loss: 6.5933e-04\n",
      "Epoch [50/100], Loss: 6.6828e-04\n",
      "Epoch [60/100], Loss: 6.2478e-04\n",
      "Epoch [70/100], Loss: 5.7398e-04\n",
      "Epoch [80/100], Loss: 5.5077e-04\n",
      "Epoch [90/100], Loss: 5.4345e-04\n",
      "Epoch [100/100], Loss: 5.4386e-04\n",
      "#####--training model 392--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6185e-04\n",
      "Epoch [20/100], Loss: 8.2913e-04\n",
      "Epoch [30/100], Loss: 1.9341e-04\n",
      "Epoch [40/100], Loss: 3.3048e-05\n",
      "Epoch [50/100], Loss: 8.7552e-05\n",
      "Epoch [60/100], Loss: 1.8039e-04\n",
      "Epoch [70/100], Loss: 2.1546e-04\n",
      "Epoch [80/100], Loss: 2.0791e-04\n",
      "Epoch [90/100], Loss: 1.8537e-04\n",
      "Epoch [100/100], Loss: 1.6058e-04\n",
      "#####--training model 393--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.7939e-04\n",
      "Epoch [20/100], Loss: 2.9473e-04\n",
      "Epoch [30/100], Loss: 3.2471e-04\n",
      "Epoch [40/100], Loss: 5.9099e-04\n",
      "Epoch [50/100], Loss: 1.2501e-03\n",
      "Epoch [60/100], Loss: 7.0316e-04\n",
      "Epoch [70/100], Loss: 4.3021e-04\n",
      "Epoch [80/100], Loss: 3.7641e-04\n",
      "Epoch [90/100], Loss: 3.3725e-04\n",
      "Epoch [100/100], Loss: 3.1179e-04\n",
      "#####--training model 394--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.8656e-03\n",
      "Epoch [20/100], Loss: 6.2509e-03\n",
      "Epoch [30/100], Loss: 5.4578e-03\n",
      "Epoch [40/100], Loss: 5.0118e-03\n",
      "Epoch [50/100], Loss: 4.9861e-03\n",
      "Epoch [60/100], Loss: 5.2882e-03\n",
      "Epoch [70/100], Loss: 5.5048e-03\n",
      "Epoch [80/100], Loss: 5.5183e-03\n",
      "Epoch [90/100], Loss: 5.4950e-03\n",
      "Epoch [100/100], Loss: 5.4741e-03\n",
      "#####--training model 395--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8303e-03\n",
      "Epoch [20/100], Loss: 3.0301e-03\n",
      "Epoch [30/100], Loss: 3.7917e-03\n",
      "Epoch [40/100], Loss: 2.5330e-03\n",
      "Epoch [50/100], Loss: 2.6603e-03\n",
      "Epoch [60/100], Loss: 2.1864e-03\n",
      "Epoch [70/100], Loss: 1.7525e-03\n",
      "Epoch [80/100], Loss: 1.5081e-03\n",
      "Epoch [90/100], Loss: 1.3641e-03\n",
      "Epoch [100/100], Loss: 1.2740e-03\n",
      "#####--training model 396--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6397e-04\n",
      "Epoch [20/100], Loss: 5.9576e-05\n",
      "Epoch [30/100], Loss: 3.0641e-05\n",
      "Epoch [40/100], Loss: 1.8326e-05\n",
      "Epoch [50/100], Loss: 1.1910e-05\n",
      "Epoch [60/100], Loss: 8.1477e-06\n",
      "Epoch [70/100], Loss: 5.7668e-06\n",
      "Epoch [80/100], Loss: 4.1788e-06\n",
      "Epoch [90/100], Loss: 3.0795e-06\n",
      "Epoch [100/100], Loss: 2.2973e-06\n",
      "#####--training model 397--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.7599e-04\n",
      "Epoch [20/100], Loss: 6.9774e-04\n",
      "Epoch [30/100], Loss: 7.2067e-04\n",
      "Epoch [40/100], Loss: 7.4778e-04\n",
      "Epoch [50/100], Loss: 7.8803e-04\n",
      "Epoch [60/100], Loss: 8.8129e-04\n",
      "Epoch [70/100], Loss: 1.1217e-03\n",
      "Epoch [80/100], Loss: 1.0664e-03\n",
      "Epoch [90/100], Loss: 9.0288e-04\n",
      "Epoch [100/100], Loss: 7.9948e-04\n",
      "#####--training model 398--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0408e-03\n",
      "Epoch [20/100], Loss: 4.1297e-04\n",
      "Epoch [30/100], Loss: 4.1336e-04\n",
      "Epoch [40/100], Loss: 2.8741e-04\n",
      "Epoch [50/100], Loss: 2.7726e-04\n",
      "Epoch [60/100], Loss: 3.3224e-04\n",
      "Epoch [70/100], Loss: 3.7721e-04\n",
      "Epoch [80/100], Loss: 3.7014e-04\n",
      "Epoch [90/100], Loss: 3.2645e-04\n",
      "Epoch [100/100], Loss: 3.0574e-04\n",
      "#####--training model 399--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7243e-02\n",
      "Epoch [20/100], Loss: 1.6427e-02\n",
      "Epoch [30/100], Loss: 1.3082e-02\n",
      "Epoch [40/100], Loss: 1.1193e-02\n",
      "Epoch [50/100], Loss: 8.6751e-03\n",
      "Epoch [60/100], Loss: 7.2292e-03\n",
      "Epoch [70/100], Loss: 6.5021e-03\n",
      "Epoch [80/100], Loss: 5.8424e-03\n",
      "Epoch [90/100], Loss: 5.1241e-03\n",
      "Epoch [100/100], Loss: 4.4058e-03\n",
      "#####--training model 400--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7688e-02\n",
      "Epoch [20/100], Loss: 1.8474e-02\n",
      "Epoch [30/100], Loss: 1.8627e-02\n",
      "Epoch [40/100], Loss: 1.8653e-02\n",
      "Epoch [50/100], Loss: 1.8563e-02\n",
      "Epoch [60/100], Loss: 1.8910e-03\n",
      "Epoch [70/100], Loss: 2.5289e-03\n",
      "Epoch [80/100], Loss: 1.9761e-03\n",
      "Epoch [90/100], Loss: 1.8057e-03\n",
      "Epoch [100/100], Loss: 1.8254e-03\n",
      "#####--training model 401--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.6855e-04\n",
      "Epoch [20/100], Loss: 4.6065e-04\n",
      "Epoch [30/100], Loss: 4.5997e-04\n",
      "Epoch [40/100], Loss: 5.2292e-04\n",
      "Epoch [50/100], Loss: 5.7769e-04\n",
      "Epoch [60/100], Loss: 5.6155e-04\n",
      "Epoch [70/100], Loss: 5.5380e-04\n",
      "Epoch [80/100], Loss: 5.5593e-04\n",
      "Epoch [90/100], Loss: 5.6226e-04\n",
      "Epoch [100/100], Loss: 5.6563e-04\n",
      "#####--training model 402--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0451e-02\n",
      "Epoch [20/100], Loss: 2.0286e-04\n",
      "Epoch [30/100], Loss: 6.1933e-05\n",
      "Epoch [40/100], Loss: 1.2025e-04\n",
      "Epoch [50/100], Loss: 1.4856e-04\n",
      "Epoch [60/100], Loss: 1.7143e-04\n",
      "Epoch [70/100], Loss: 1.8630e-04\n",
      "Epoch [80/100], Loss: 1.9214e-04\n",
      "Epoch [90/100], Loss: 1.9127e-04\n",
      "Epoch [100/100], Loss: 1.8662e-04\n",
      "#####--training model 403--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8157e-02\n",
      "Epoch [20/100], Loss: 2.4510e-02\n",
      "Epoch [30/100], Loss: 1.5168e-03\n",
      "Epoch [40/100], Loss: 1.3567e-03\n",
      "Epoch [50/100], Loss: 1.6979e-03\n",
      "Epoch [60/100], Loss: 1.8987e-03\n",
      "Epoch [70/100], Loss: 1.8479e-03\n",
      "Epoch [80/100], Loss: 1.7391e-03\n",
      "Epoch [90/100], Loss: 1.6543e-03\n",
      "Epoch [100/100], Loss: 1.5952e-03\n",
      "#####--training model 404--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4613e-04\n",
      "Epoch [20/100], Loss: 6.9882e-05\n",
      "Epoch [30/100], Loss: 5.3194e-05\n",
      "Epoch [40/100], Loss: 4.8283e-05\n",
      "Epoch [50/100], Loss: 4.6948e-05\n",
      "Epoch [60/100], Loss: 4.6638e-05\n",
      "Epoch [70/100], Loss: 4.6518e-05\n",
      "Epoch [80/100], Loss: 4.6397e-05\n",
      "Epoch [90/100], Loss: 4.6251e-05\n",
      "Epoch [100/100], Loss: 4.6078e-05\n",
      "#####--training model 405--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.5472e-04\n",
      "Epoch [20/100], Loss: 5.1850e-04\n",
      "Epoch [30/100], Loss: 5.3422e-04\n",
      "Epoch [40/100], Loss: 5.7681e-04\n",
      "Epoch [50/100], Loss: 6.2559e-04\n",
      "Epoch [60/100], Loss: 5.4084e-04\n",
      "Epoch [70/100], Loss: 4.7417e-04\n",
      "Epoch [80/100], Loss: 3.8377e-04\n",
      "Epoch [90/100], Loss: 3.2730e-04\n",
      "Epoch [100/100], Loss: 2.8970e-04\n",
      "#####--training model 406--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3176e-04\n",
      "Epoch [20/100], Loss: 2.8373e-04\n",
      "Epoch [30/100], Loss: 2.9399e-04\n",
      "Epoch [40/100], Loss: 3.1315e-04\n",
      "Epoch [50/100], Loss: 3.4288e-04\n",
      "Epoch [60/100], Loss: 3.7427e-04\n",
      "Epoch [70/100], Loss: 4.0012e-04\n",
      "Epoch [80/100], Loss: 4.2239e-04\n",
      "Epoch [90/100], Loss: 4.3911e-04\n",
      "Epoch [100/100], Loss: 4.5109e-04\n",
      "#####--training model 407--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.1956e-05\n",
      "Epoch [20/100], Loss: 1.9612e-04\n",
      "Epoch [30/100], Loss: 4.0136e-04\n",
      "Epoch [40/100], Loss: 4.4149e-04\n",
      "Epoch [50/100], Loss: 4.3921e-04\n",
      "Epoch [60/100], Loss: 4.6590e-04\n",
      "Epoch [70/100], Loss: 5.2504e-04\n",
      "Epoch [80/100], Loss: 6.3495e-04\n",
      "Epoch [90/100], Loss: 8.1997e-04\n",
      "Epoch [100/100], Loss: 9.8844e-04\n",
      "#####--training model 408--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0248e-04\n",
      "Epoch [20/100], Loss: 3.7498e-05\n",
      "Epoch [30/100], Loss: 2.0513e-05\n",
      "Epoch [40/100], Loss: 1.2793e-05\n",
      "Epoch [50/100], Loss: 8.5521e-06\n",
      "Epoch [60/100], Loss: 5.9683e-06\n",
      "Epoch [70/100], Loss: 4.2863e-06\n",
      "Epoch [80/100], Loss: 3.1405e-06\n",
      "Epoch [90/100], Loss: 2.3342e-06\n",
      "Epoch [100/100], Loss: 1.7531e-06\n",
      "#####--training model 409--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2652e-03\n",
      "Epoch [20/100], Loss: 1.0690e-03\n",
      "Epoch [30/100], Loss: 8.6669e-04\n",
      "Epoch [40/100], Loss: 7.7193e-04\n",
      "Epoch [50/100], Loss: 6.9370e-04\n",
      "Epoch [60/100], Loss: 6.4202e-04\n",
      "Epoch [70/100], Loss: 6.1516e-04\n",
      "Epoch [80/100], Loss: 6.0169e-04\n",
      "Epoch [90/100], Loss: 5.9474e-04\n",
      "Epoch [100/100], Loss: 5.9004e-04\n",
      "#####--training model 410--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.5865e-04\n",
      "Epoch [20/100], Loss: 4.4269e-04\n",
      "Epoch [30/100], Loss: 4.5183e-04\n",
      "Epoch [40/100], Loss: 4.6446e-04\n",
      "Epoch [50/100], Loss: 4.8266e-04\n",
      "Epoch [60/100], Loss: 5.1270e-04\n",
      "Epoch [70/100], Loss: 6.1128e-04\n",
      "Epoch [80/100], Loss: 9.0718e-04\n",
      "Epoch [90/100], Loss: 8.6715e-04\n",
      "Epoch [100/100], Loss: 6.3736e-04\n",
      "#####--training model 411--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.2600e-04\n",
      "Epoch [20/100], Loss: 9.4786e-04\n",
      "Epoch [30/100], Loss: 9.9833e-04\n",
      "Epoch [40/100], Loss: 1.5421e-03\n",
      "Epoch [50/100], Loss: 1.6960e-03\n",
      "Epoch [60/100], Loss: 1.7097e-03\n",
      "Epoch [70/100], Loss: 1.7233e-03\n",
      "Epoch [80/100], Loss: 1.5589e-03\n",
      "Epoch [90/100], Loss: 1.4509e-03\n",
      "Epoch [100/100], Loss: 1.3870e-03\n",
      "#####--training model 412--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.2006e-03\n",
      "Epoch [20/100], Loss: 7.4724e-03\n",
      "Epoch [30/100], Loss: 6.6580e-03\n",
      "Epoch [40/100], Loss: 3.2512e-03\n",
      "Epoch [50/100], Loss: 2.3265e-03\n",
      "Epoch [60/100], Loss: 1.5084e-03\n",
      "Epoch [70/100], Loss: 9.5576e-04\n",
      "Epoch [80/100], Loss: 7.9350e-04\n",
      "Epoch [90/100], Loss: 7.5832e-04\n",
      "Epoch [100/100], Loss: 7.5247e-04\n",
      "#####--training model 413--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5209e-04\n",
      "Epoch [20/100], Loss: 1.2086e-04\n",
      "Epoch [30/100], Loss: 8.8519e-05\n",
      "Epoch [40/100], Loss: 7.6767e-05\n",
      "Epoch [50/100], Loss: 7.2794e-05\n",
      "Epoch [60/100], Loss: 7.2422e-05\n",
      "Epoch [70/100], Loss: 7.5002e-05\n",
      "Epoch [80/100], Loss: 8.7612e-05\n",
      "Epoch [90/100], Loss: 7.7734e-05\n",
      "Epoch [100/100], Loss: 9.5754e-05\n",
      "#####--training model 414--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.8474e-03\n",
      "Epoch [20/100], Loss: 4.2254e-03\n",
      "Epoch [30/100], Loss: 4.9256e-03\n",
      "Epoch [40/100], Loss: 5.1145e-03\n",
      "Epoch [50/100], Loss: 5.0524e-03\n",
      "Epoch [60/100], Loss: 5.1084e-03\n",
      "Epoch [70/100], Loss: 5.2876e-03\n",
      "Epoch [80/100], Loss: 5.2762e-03\n",
      "Epoch [90/100], Loss: 5.0880e-03\n",
      "Epoch [100/100], Loss: 4.7452e-03\n",
      "#####--training model 415--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3633e-03\n",
      "Epoch [20/100], Loss: 3.6680e-03\n",
      "Epoch [30/100], Loss: 3.6344e-03\n",
      "Epoch [40/100], Loss: 3.4911e-03\n",
      "Epoch [50/100], Loss: 3.4155e-03\n",
      "Epoch [60/100], Loss: 3.3901e-03\n",
      "Epoch [70/100], Loss: 3.3843e-03\n",
      "Epoch [80/100], Loss: 3.3585e-03\n",
      "Epoch [90/100], Loss: 3.2103e-03\n",
      "Epoch [100/100], Loss: 2.9160e-03\n",
      "#####--training model 416--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8720e-04\n",
      "Epoch [20/100], Loss: 3.1760e-04\n",
      "Epoch [30/100], Loss: 3.2374e-04\n",
      "Epoch [40/100], Loss: 3.5969e-04\n",
      "Epoch [50/100], Loss: 2.7289e-04\n",
      "Epoch [60/100], Loss: 3.0688e-04\n",
      "Epoch [70/100], Loss: 1.8735e-04\n",
      "Epoch [80/100], Loss: 1.3872e-04\n",
      "Epoch [90/100], Loss: 1.1213e-04\n",
      "Epoch [100/100], Loss: 1.0676e-04\n",
      "#####--training model 417--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.4845e-04\n",
      "Epoch [20/100], Loss: 8.3959e-04\n",
      "Epoch [30/100], Loss: 7.0369e-04\n",
      "Epoch [40/100], Loss: 4.7228e-04\n",
      "Epoch [50/100], Loss: 2.6253e-04\n",
      "Epoch [60/100], Loss: 1.4868e-04\n",
      "Epoch [70/100], Loss: 1.0670e-04\n",
      "Epoch [80/100], Loss: 9.0137e-05\n",
      "Epoch [90/100], Loss: 7.9584e-05\n",
      "Epoch [100/100], Loss: 7.0091e-05\n",
      "#####--training model 418--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6830e-04\n",
      "Epoch [20/100], Loss: 1.9150e-04\n",
      "Epoch [30/100], Loss: 1.8067e-04\n",
      "Epoch [40/100], Loss: 1.8088e-04\n",
      "Epoch [50/100], Loss: 1.8486e-04\n",
      "Epoch [60/100], Loss: 1.9291e-04\n",
      "Epoch [70/100], Loss: 2.0846e-04\n",
      "Epoch [80/100], Loss: 2.6379e-04\n",
      "Epoch [90/100], Loss: 2.2767e-04\n",
      "Epoch [100/100], Loss: 2.0334e-04\n",
      "#####--training model 419--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9782e-04\n",
      "Epoch [20/100], Loss: 1.1703e-04\n",
      "Epoch [30/100], Loss: 9.7618e-05\n",
      "Epoch [40/100], Loss: 9.2094e-05\n",
      "Epoch [50/100], Loss: 9.0458e-05\n",
      "Epoch [60/100], Loss: 8.9574e-05\n",
      "Epoch [70/100], Loss: 8.8673e-05\n",
      "Epoch [80/100], Loss: 8.7644e-05\n",
      "Epoch [90/100], Loss: 8.6489e-05\n",
      "Epoch [100/100], Loss: 8.5231e-05\n",
      "#####--training model 420--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4053e-03\n",
      "Epoch [20/100], Loss: 2.7301e-04\n",
      "Epoch [30/100], Loss: 2.7669e-04\n",
      "Epoch [40/100], Loss: 2.6485e-04\n",
      "Epoch [50/100], Loss: 2.2489e-04\n",
      "Epoch [60/100], Loss: 1.6793e-04\n",
      "Epoch [70/100], Loss: 1.1458e-04\n",
      "Epoch [80/100], Loss: 7.8866e-05\n",
      "Epoch [90/100], Loss: 5.6280e-05\n",
      "Epoch [100/100], Loss: 4.0572e-05\n",
      "#####--training model 421--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.8439e-04\n",
      "Epoch [20/100], Loss: 4.4286e-04\n",
      "Epoch [30/100], Loss: 5.1421e-04\n",
      "Epoch [40/100], Loss: 6.8151e-04\n",
      "Epoch [50/100], Loss: 4.8081e-04\n",
      "Epoch [60/100], Loss: 4.1615e-04\n",
      "Epoch [70/100], Loss: 3.8277e-04\n",
      "Epoch [80/100], Loss: 3.5895e-04\n",
      "Epoch [90/100], Loss: 3.3717e-04\n",
      "Epoch [100/100], Loss: 3.1582e-04\n",
      "#####--training model 422--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.1918e-03\n",
      "Epoch [20/100], Loss: 3.0248e-03\n",
      "Epoch [30/100], Loss: 2.8596e-03\n",
      "Epoch [40/100], Loss: 1.2385e-03\n",
      "Epoch [50/100], Loss: 1.0300e-03\n",
      "Epoch [60/100], Loss: 1.3672e-03\n",
      "Epoch [70/100], Loss: 8.8931e-04\n",
      "Epoch [80/100], Loss: 7.3015e-04\n",
      "Epoch [90/100], Loss: 6.7856e-04\n",
      "Epoch [100/100], Loss: 6.5322e-04\n",
      "#####--training model 423--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.6988e-04\n",
      "Epoch [20/100], Loss: 8.4291e-04\n",
      "Epoch [30/100], Loss: 9.1029e-04\n",
      "Epoch [40/100], Loss: 9.3657e-04\n",
      "Epoch [50/100], Loss: 9.3705e-04\n",
      "Epoch [60/100], Loss: 8.0083e-04\n",
      "Epoch [70/100], Loss: 9.3789e-04\n",
      "Epoch [80/100], Loss: 1.0273e-03\n",
      "Epoch [90/100], Loss: 1.0865e-03\n",
      "Epoch [100/100], Loss: 1.0336e-03\n",
      "#####--training model 424--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2038e-04\n",
      "Epoch [20/100], Loss: 1.7857e-04\n",
      "Epoch [30/100], Loss: 1.7540e-04\n",
      "Epoch [40/100], Loss: 1.7443e-04\n",
      "Epoch [50/100], Loss: 1.7557e-04\n",
      "Epoch [60/100], Loss: 1.6218e-04\n",
      "Epoch [70/100], Loss: 9.7008e-05\n",
      "Epoch [80/100], Loss: 7.9665e-05\n",
      "Epoch [90/100], Loss: 6.3686e-05\n",
      "Epoch [100/100], Loss: 5.7133e-05\n",
      "#####--training model 425--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.7200e-03\n",
      "Epoch [20/100], Loss: 2.2832e-03\n",
      "Epoch [30/100], Loss: 2.1815e-03\n",
      "Epoch [40/100], Loss: 2.1951e-03\n",
      "Epoch [50/100], Loss: 2.2037e-03\n",
      "Epoch [60/100], Loss: 2.0859e-03\n",
      "Epoch [70/100], Loss: 1.6366e-03\n",
      "Epoch [80/100], Loss: 1.4574e-03\n",
      "Epoch [90/100], Loss: 1.4354e-03\n",
      "Epoch [100/100], Loss: 1.4415e-03\n",
      "#####--training model 426--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4998e-03\n",
      "Epoch [20/100], Loss: 1.5365e-03\n",
      "Epoch [30/100], Loss: 1.6480e-03\n",
      "Epoch [40/100], Loss: 2.5302e-03\n",
      "Epoch [50/100], Loss: 2.1904e-03\n",
      "Epoch [60/100], Loss: 1.8727e-03\n",
      "Epoch [70/100], Loss: 1.9087e-03\n",
      "Epoch [80/100], Loss: 1.9633e-03\n",
      "Epoch [90/100], Loss: 2.0165e-03\n",
      "Epoch [100/100], Loss: 2.0628e-03\n",
      "#####--training model 427--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7851e-04\n",
      "Epoch [20/100], Loss: 7.7588e-05\n",
      "Epoch [30/100], Loss: 4.8666e-05\n",
      "Epoch [40/100], Loss: 3.6977e-05\n",
      "Epoch [50/100], Loss: 3.1848e-05\n",
      "Epoch [60/100], Loss: 2.9945e-05\n",
      "Epoch [70/100], Loss: 2.9731e-05\n",
      "Epoch [80/100], Loss: 3.2856e-05\n",
      "Epoch [90/100], Loss: 3.4119e-05\n",
      "Epoch [100/100], Loss: 4.6836e-05\n",
      "#####--training model 428--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8017e-04\n",
      "Epoch [20/100], Loss: 2.4154e-04\n",
      "Epoch [30/100], Loss: 2.4251e-04\n",
      "Epoch [40/100], Loss: 2.4768e-04\n",
      "Epoch [50/100], Loss: 2.6182e-04\n",
      "Epoch [60/100], Loss: 2.9109e-04\n",
      "Epoch [70/100], Loss: 3.3754e-04\n",
      "Epoch [80/100], Loss: 3.2445e-04\n",
      "Epoch [90/100], Loss: 2.6027e-04\n",
      "Epoch [100/100], Loss: 1.8529e-04\n",
      "#####--training model 429--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0906e-02\n",
      "Epoch [20/100], Loss: 1.1822e-02\n",
      "Epoch [30/100], Loss: 1.2789e-02\n",
      "Epoch [40/100], Loss: 1.3445e-02\n",
      "Epoch [50/100], Loss: 1.4186e-02\n",
      "Epoch [60/100], Loss: 1.5017e-02\n",
      "Epoch [70/100], Loss: 1.5787e-02\n",
      "Epoch [80/100], Loss: 1.6370e-02\n",
      "Epoch [90/100], Loss: 1.6590e-02\n",
      "Epoch [100/100], Loss: 1.6268e-02\n",
      "#####--training model 430--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.7792e-03\n",
      "Epoch [20/100], Loss: 5.0551e-03\n",
      "Epoch [30/100], Loss: 5.4957e-03\n",
      "Epoch [40/100], Loss: 6.3456e-03\n",
      "Epoch [50/100], Loss: 7.0208e-03\n",
      "Epoch [60/100], Loss: 7.2654e-03\n",
      "Epoch [70/100], Loss: 7.3724e-03\n",
      "Epoch [80/100], Loss: 7.4205e-03\n",
      "Epoch [90/100], Loss: 7.4414e-03\n",
      "Epoch [100/100], Loss: 7.4597e-03\n",
      "#####--training model 431--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.3988e-03\n",
      "Epoch [20/100], Loss: 1.4508e-03\n",
      "Epoch [30/100], Loss: 1.0345e-03\n",
      "Epoch [40/100], Loss: 9.0041e-04\n",
      "Epoch [50/100], Loss: 9.4936e-04\n",
      "Epoch [60/100], Loss: 9.0414e-04\n",
      "Epoch [70/100], Loss: 7.0558e-04\n",
      "Epoch [80/100], Loss: 5.3520e-04\n",
      "Epoch [90/100], Loss: 4.4999e-04\n",
      "Epoch [100/100], Loss: 3.4514e-04\n",
      "#####--training model 432--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3987e-04\n",
      "Epoch [20/100], Loss: 5.1876e-05\n",
      "Epoch [30/100], Loss: 2.6885e-05\n",
      "Epoch [40/100], Loss: 1.6142e-05\n",
      "Epoch [50/100], Loss: 1.0514e-05\n",
      "Epoch [60/100], Loss: 7.2032e-06\n",
      "Epoch [70/100], Loss: 5.1035e-06\n",
      "Epoch [80/100], Loss: 3.7010e-06\n",
      "Epoch [90/100], Loss: 2.7289e-06\n",
      "Epoch [100/100], Loss: 2.0368e-06\n",
      "#####--training model 433--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4965e-04\n",
      "Epoch [20/100], Loss: 1.3344e-04\n",
      "Epoch [30/100], Loss: 1.0235e-04\n",
      "Epoch [40/100], Loss: 9.1958e-05\n",
      "Epoch [50/100], Loss: 8.8897e-05\n",
      "Epoch [60/100], Loss: 8.8359e-05\n",
      "Epoch [70/100], Loss: 8.8509e-05\n",
      "Epoch [80/100], Loss: 8.8915e-05\n",
      "Epoch [90/100], Loss: 8.9805e-05\n",
      "Epoch [100/100], Loss: 9.2943e-05\n",
      "#####--training model 434--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.1528e-04\n",
      "Epoch [20/100], Loss: 5.3630e-04\n",
      "Epoch [30/100], Loss: 4.0737e-04\n",
      "Epoch [40/100], Loss: 1.6863e-04\n",
      "Epoch [50/100], Loss: 6.2141e-05\n",
      "Epoch [60/100], Loss: 4.9742e-05\n",
      "Epoch [70/100], Loss: 4.5882e-05\n",
      "Epoch [80/100], Loss: 4.3378e-05\n",
      "Epoch [90/100], Loss: 4.1408e-05\n",
      "Epoch [100/100], Loss: 3.9704e-05\n",
      "#####--training model 435--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6490e-01\n",
      "Epoch [20/100], Loss: 1.5458e-01\n",
      "Epoch [30/100], Loss: 1.4402e-01\n",
      "Epoch [40/100], Loss: 1.2574e-01\n",
      "Epoch [50/100], Loss: 1.0822e-01\n",
      "Epoch [60/100], Loss: 9.5160e-02\n",
      "Epoch [70/100], Loss: 8.4679e-02\n",
      "Epoch [80/100], Loss: 7.4526e-02\n",
      "Epoch [90/100], Loss: 6.8855e-02\n",
      "Epoch [100/100], Loss: 6.5728e-02\n",
      "#####--training model 436--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8128e-03\n",
      "Epoch [20/100], Loss: 4.1740e-03\n",
      "Epoch [30/100], Loss: 4.2469e-03\n",
      "Epoch [40/100], Loss: 4.2590e-03\n",
      "Epoch [50/100], Loss: 4.2608e-03\n",
      "Epoch [60/100], Loss: 4.2615e-03\n",
      "Epoch [70/100], Loss: 4.2619e-03\n",
      "Epoch [80/100], Loss: 4.2617e-03\n",
      "Epoch [90/100], Loss: 4.2585e-03\n",
      "Epoch [100/100], Loss: 4.2389e-03\n",
      "#####--training model 437--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0347e-03\n",
      "Epoch [20/100], Loss: 1.7219e-03\n",
      "Epoch [30/100], Loss: 1.0026e-03\n",
      "Epoch [40/100], Loss: 1.0749e-03\n",
      "Epoch [50/100], Loss: 1.1869e-03\n",
      "Epoch [60/100], Loss: 1.2674e-03\n",
      "Epoch [70/100], Loss: 1.3145e-03\n",
      "Epoch [80/100], Loss: 1.3477e-03\n",
      "Epoch [90/100], Loss: 1.3692e-03\n",
      "Epoch [100/100], Loss: 1.3830e-03\n",
      "#####--training model 438--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4581e-02\n",
      "Epoch [20/100], Loss: 2.7408e-02\n",
      "Epoch [30/100], Loss: 3.0521e-02\n",
      "Epoch [40/100], Loss: 3.3981e-02\n",
      "Epoch [50/100], Loss: 3.6108e-02\n",
      "Epoch [60/100], Loss: 3.7269e-02\n",
      "Epoch [70/100], Loss: 3.7806e-02\n",
      "Epoch [80/100], Loss: 3.7992e-02\n",
      "Epoch [90/100], Loss: 3.8026e-02\n",
      "Epoch [100/100], Loss: 3.7992e-02\n",
      "#####--training model 439--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.0593e-03\n",
      "Epoch [20/100], Loss: 4.3117e-03\n",
      "Epoch [30/100], Loss: 1.7749e-03\n",
      "Epoch [40/100], Loss: 1.3210e-03\n",
      "Epoch [50/100], Loss: 1.0631e-03\n",
      "Epoch [60/100], Loss: 9.0560e-04\n",
      "Epoch [70/100], Loss: 8.4468e-04\n",
      "Epoch [80/100], Loss: 8.2127e-04\n",
      "Epoch [90/100], Loss: 8.1362e-04\n",
      "Epoch [100/100], Loss: 8.0892e-04\n",
      "#####--training model 440--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.6700e-03\n",
      "Epoch [20/100], Loss: 5.7544e-03\n",
      "Epoch [30/100], Loss: 3.8677e-03\n",
      "Epoch [40/100], Loss: 2.8566e-03\n",
      "Epoch [50/100], Loss: 2.4736e-03\n",
      "Epoch [60/100], Loss: 2.3402e-03\n",
      "Epoch [70/100], Loss: 2.2596e-03\n",
      "Epoch [80/100], Loss: 2.1144e-03\n",
      "Epoch [90/100], Loss: 1.8874e-03\n",
      "Epoch [100/100], Loss: 1.6394e-03\n",
      "#####--training model 441--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9996e-03\n",
      "Epoch [20/100], Loss: 2.6738e-03\n",
      "Epoch [30/100], Loss: 2.6642e-03\n",
      "Epoch [40/100], Loss: 2.8306e-03\n",
      "Epoch [50/100], Loss: 2.9450e-03\n",
      "Epoch [60/100], Loss: 2.9782e-03\n",
      "Epoch [70/100], Loss: 2.9653e-03\n",
      "Epoch [80/100], Loss: 2.9160e-03\n",
      "Epoch [90/100], Loss: 2.8356e-03\n",
      "Epoch [100/100], Loss: 2.7219e-03\n",
      "#####--training model 442--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8815e-04\n",
      "Epoch [20/100], Loss: 1.5461e-04\n",
      "Epoch [30/100], Loss: 1.2380e-04\n",
      "Epoch [40/100], Loss: 1.1968e-04\n",
      "Epoch [50/100], Loss: 1.5381e-04\n",
      "Epoch [60/100], Loss: 2.4356e-04\n",
      "Epoch [70/100], Loss: 1.9988e-04\n",
      "Epoch [80/100], Loss: 1.2881e-04\n",
      "Epoch [90/100], Loss: 9.4097e-05\n",
      "Epoch [100/100], Loss: 7.8898e-05\n",
      "#####--training model 443--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1515e-03\n",
      "Epoch [20/100], Loss: 1.1178e-03\n",
      "Epoch [30/100], Loss: 1.1606e-03\n",
      "Epoch [40/100], Loss: 1.2260e-03\n",
      "Epoch [50/100], Loss: 1.2566e-03\n",
      "Epoch [60/100], Loss: 1.2661e-03\n",
      "Epoch [70/100], Loss: 1.2688e-03\n",
      "Epoch [80/100], Loss: 1.2729e-03\n",
      "Epoch [90/100], Loss: 1.2787e-03\n",
      "Epoch [100/100], Loss: 1.2839e-03\n",
      "#####--training model 444--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.2051e-02\n",
      "Epoch [20/100], Loss: 1.7599e-02\n",
      "Epoch [30/100], Loss: 1.2272e-02\n",
      "Epoch [40/100], Loss: 7.8224e-03\n",
      "Epoch [50/100], Loss: 5.9161e-03\n",
      "Epoch [60/100], Loss: 5.1749e-03\n",
      "Epoch [70/100], Loss: 4.5701e-03\n",
      "Epoch [80/100], Loss: 3.8417e-03\n",
      "Epoch [90/100], Loss: 3.1360e-03\n",
      "Epoch [100/100], Loss: 2.5665e-03\n",
      "#####--training model 445--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0145e-03\n",
      "Epoch [20/100], Loss: 9.5661e-04\n",
      "Epoch [30/100], Loss: 4.2494e-03\n",
      "Epoch [40/100], Loss: 3.1346e-03\n",
      "Epoch [50/100], Loss: 1.9919e-03\n",
      "Epoch [60/100], Loss: 1.8939e-03\n",
      "Epoch [70/100], Loss: 2.1552e-03\n",
      "Epoch [80/100], Loss: 2.3860e-03\n",
      "Epoch [90/100], Loss: 2.4401e-03\n",
      "Epoch [100/100], Loss: 2.4016e-03\n",
      "#####--training model 446--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8874e-05\n",
      "Epoch [20/100], Loss: 4.4728e-05\n",
      "Epoch [30/100], Loss: 3.4451e-05\n",
      "Epoch [40/100], Loss: 7.1707e-05\n",
      "Epoch [50/100], Loss: 1.0365e-03\n",
      "Epoch [60/100], Loss: 3.0579e-04\n",
      "Epoch [70/100], Loss: 1.4533e-04\n",
      "Epoch [80/100], Loss: 7.1943e-05\n",
      "Epoch [90/100], Loss: 5.0777e-05\n",
      "Epoch [100/100], Loss: 3.9651e-05\n",
      "#####--training model 447--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6507e-04\n",
      "Epoch [20/100], Loss: 2.7045e-04\n",
      "Epoch [30/100], Loss: 2.7010e-04\n",
      "Epoch [40/100], Loss: 1.9428e-03\n",
      "Epoch [50/100], Loss: 2.2061e-03\n",
      "Epoch [60/100], Loss: 2.0770e-03\n",
      "Epoch [70/100], Loss: 1.9414e-03\n",
      "Epoch [80/100], Loss: 1.8456e-03\n",
      "Epoch [90/100], Loss: 1.7862e-03\n",
      "Epoch [100/100], Loss: 1.7544e-03\n",
      "#####--training model 448--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1401e-04\n",
      "Epoch [20/100], Loss: 1.4968e-03\n",
      "Epoch [30/100], Loss: 3.0480e-03\n",
      "Epoch [40/100], Loss: 4.1277e-03\n",
      "Epoch [50/100], Loss: 4.9433e-03\n",
      "Epoch [60/100], Loss: 5.1142e-03\n",
      "Epoch [70/100], Loss: 5.4305e-03\n",
      "Epoch [80/100], Loss: 5.8370e-03\n",
      "Epoch [90/100], Loss: 6.2769e-03\n",
      "Epoch [100/100], Loss: 6.6703e-03\n",
      "#####--training model 449--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.6741e-03\n",
      "Epoch [20/100], Loss: 3.0406e-03\n",
      "Epoch [30/100], Loss: 2.4932e-03\n",
      "Epoch [40/100], Loss: 1.9559e-03\n",
      "Epoch [50/100], Loss: 1.3674e-03\n",
      "Epoch [60/100], Loss: 8.0912e-04\n",
      "Epoch [70/100], Loss: 5.6093e-04\n",
      "Epoch [80/100], Loss: 4.6166e-04\n",
      "Epoch [90/100], Loss: 4.0806e-04\n",
      "Epoch [100/100], Loss: 3.7961e-04\n",
      "#####--training model 450--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.7911e-02\n",
      "Epoch [20/100], Loss: 9.4477e-02\n",
      "Epoch [30/100], Loss: 1.1780e-02\n",
      "Epoch [40/100], Loss: 6.2014e-03\n",
      "Epoch [50/100], Loss: 2.9942e-03\n",
      "Epoch [60/100], Loss: 1.1711e-03\n",
      "Epoch [70/100], Loss: 8.6267e-04\n",
      "Epoch [80/100], Loss: 9.4067e-04\n",
      "Epoch [90/100], Loss: 1.0983e-03\n",
      "Epoch [100/100], Loss: 1.2028e-03\n",
      "#####--training model 451--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2623e-04\n",
      "Epoch [20/100], Loss: 4.6705e-05\n",
      "Epoch [30/100], Loss: 2.4172e-05\n",
      "Epoch [40/100], Loss: 1.4502e-05\n",
      "Epoch [50/100], Loss: 9.4418e-06\n",
      "Epoch [60/100], Loss: 6.4669e-06\n",
      "Epoch [70/100], Loss: 4.5809e-06\n",
      "Epoch [80/100], Loss: 3.3215e-06\n",
      "Epoch [90/100], Loss: 2.4489e-06\n",
      "Epoch [100/100], Loss: 1.8275e-06\n",
      "#####--training model 452--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3090e-04\n",
      "Epoch [20/100], Loss: 5.9386e-05\n",
      "Epoch [30/100], Loss: 3.6034e-05\n",
      "Epoch [40/100], Loss: 2.5298e-05\n",
      "Epoch [50/100], Loss: 1.9503e-05\n",
      "Epoch [60/100], Loss: 1.6084e-05\n",
      "Epoch [70/100], Loss: 1.3983e-05\n",
      "Epoch [80/100], Loss: 1.2692e-05\n",
      "Epoch [90/100], Loss: 1.1935e-05\n",
      "Epoch [100/100], Loss: 1.1533e-05\n",
      "#####--training model 453--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6829e-03\n",
      "Epoch [20/100], Loss: 2.0562e-03\n",
      "Epoch [30/100], Loss: 3.0160e-03\n",
      "Epoch [40/100], Loss: 2.5745e-03\n",
      "Epoch [50/100], Loss: 2.2210e-03\n",
      "Epoch [60/100], Loss: 2.1084e-03\n",
      "Epoch [70/100], Loss: 2.0928e-03\n",
      "Epoch [80/100], Loss: 2.0985e-03\n",
      "Epoch [90/100], Loss: 2.0484e-03\n",
      "Epoch [100/100], Loss: 1.9461e-03\n",
      "#####--training model 454--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4953e-03\n",
      "Epoch [20/100], Loss: 1.6027e-03\n",
      "Epoch [30/100], Loss: 2.0528e-03\n",
      "Epoch [40/100], Loss: 1.8749e-03\n",
      "Epoch [50/100], Loss: 1.1912e-03\n",
      "Epoch [60/100], Loss: 9.1574e-04\n",
      "Epoch [70/100], Loss: 7.0299e-04\n",
      "Epoch [80/100], Loss: 4.1354e-04\n",
      "Epoch [90/100], Loss: 2.4633e-04\n",
      "Epoch [100/100], Loss: 1.9324e-04\n",
      "#####--training model 455--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4240e-03\n",
      "Epoch [20/100], Loss: 1.2684e-02\n",
      "Epoch [30/100], Loss: 2.4259e-02\n",
      "Epoch [40/100], Loss: 3.0948e-02\n",
      "Epoch [50/100], Loss: 3.4643e-02\n",
      "Epoch [60/100], Loss: 3.4684e-02\n",
      "Epoch [70/100], Loss: 3.1163e-02\n",
      "Epoch [80/100], Loss: 2.1705e-02\n",
      "Epoch [90/100], Loss: 1.2490e-02\n",
      "Epoch [100/100], Loss: 8.9092e-03\n",
      "#####--training model 456--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4739e-04\n",
      "Epoch [20/100], Loss: 5.1828e-05\n",
      "Epoch [30/100], Loss: 2.6285e-05\n",
      "Epoch [40/100], Loss: 1.5608e-05\n",
      "Epoch [50/100], Loss: 1.0100e-05\n",
      "Epoch [60/100], Loss: 6.8904e-06\n",
      "Epoch [70/100], Loss: 4.8673e-06\n",
      "Epoch [80/100], Loss: 3.5218e-06\n",
      "Epoch [90/100], Loss: 2.5923e-06\n",
      "Epoch [100/100], Loss: 1.9320e-06\n",
      "#####--training model 457--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9988e-03\n",
      "Epoch [20/100], Loss: 2.4726e-03\n",
      "Epoch [30/100], Loss: 1.8014e-03\n",
      "Epoch [40/100], Loss: 1.9123e-03\n",
      "Epoch [50/100], Loss: 2.0262e-03\n",
      "Epoch [60/100], Loss: 2.1263e-03\n",
      "Epoch [70/100], Loss: 2.2184e-03\n",
      "Epoch [80/100], Loss: 2.3164e-03\n",
      "Epoch [90/100], Loss: 2.4145e-03\n",
      "Epoch [100/100], Loss: 2.5062e-03\n",
      "#####--training model 458--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5462e-04\n",
      "Epoch [20/100], Loss: 9.7534e-05\n",
      "Epoch [30/100], Loss: 5.5494e-05\n",
      "Epoch [40/100], Loss: 3.7376e-05\n",
      "Epoch [50/100], Loss: 2.7742e-05\n",
      "Epoch [60/100], Loss: 2.2001e-05\n",
      "Epoch [70/100], Loss: 1.8352e-05\n",
      "Epoch [80/100], Loss: 1.5959e-05\n",
      "Epoch [90/100], Loss: 1.4385e-05\n",
      "Epoch [100/100], Loss: 1.3372e-05\n",
      "#####--training model 459--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3679e-04\n",
      "Epoch [20/100], Loss: 2.7999e-04\n",
      "Epoch [30/100], Loss: 2.8960e-04\n",
      "Epoch [40/100], Loss: 2.8700e-04\n",
      "Epoch [50/100], Loss: 2.7868e-04\n",
      "Epoch [60/100], Loss: 2.4869e-04\n",
      "Epoch [70/100], Loss: 2.0603e-04\n",
      "Epoch [80/100], Loss: 2.9063e-04\n",
      "Epoch [90/100], Loss: 3.5539e-04\n",
      "Epoch [100/100], Loss: 3.7410e-04\n",
      "#####--training model 460--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.4371e-04\n",
      "Epoch [20/100], Loss: 4.7272e-04\n",
      "Epoch [30/100], Loss: 4.6818e-04\n",
      "Epoch [40/100], Loss: 4.6236e-04\n",
      "Epoch [50/100], Loss: 4.5468e-04\n",
      "Epoch [60/100], Loss: 4.4305e-04\n",
      "Epoch [70/100], Loss: 4.2476e-04\n",
      "Epoch [80/100], Loss: 4.0172e-04\n",
      "Epoch [90/100], Loss: 5.6956e-04\n",
      "Epoch [100/100], Loss: 4.8694e-04\n",
      "#####--training model 461--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.3408e-03\n",
      "Epoch [20/100], Loss: 7.3680e-03\n",
      "Epoch [30/100], Loss: 1.6623e-03\n",
      "Epoch [40/100], Loss: 6.9198e-04\n",
      "Epoch [50/100], Loss: 2.6838e-04\n",
      "Epoch [60/100], Loss: 2.1268e-04\n",
      "Epoch [70/100], Loss: 1.9488e-04\n",
      "Epoch [80/100], Loss: 1.8419e-04\n",
      "Epoch [90/100], Loss: 1.7727e-04\n",
      "Epoch [100/100], Loss: 1.7245e-04\n",
      "#####--training model 462--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6405e-02\n",
      "Epoch [20/100], Loss: 1.6671e-02\n",
      "Epoch [30/100], Loss: 1.3772e-02\n",
      "Epoch [40/100], Loss: 1.5101e-02\n",
      "Epoch [50/100], Loss: 1.6712e-02\n",
      "Epoch [60/100], Loss: 1.7950e-02\n",
      "Epoch [70/100], Loss: 1.8668e-02\n",
      "Epoch [80/100], Loss: 1.9117e-02\n",
      "Epoch [90/100], Loss: 1.9410e-02\n",
      "Epoch [100/100], Loss: 1.9602e-02\n",
      "#####--training model 463--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.8919e-02\n",
      "Epoch [20/100], Loss: 9.4734e-02\n",
      "Epoch [30/100], Loss: 8.7337e-02\n",
      "Epoch [40/100], Loss: 7.7767e-02\n",
      "Epoch [50/100], Loss: 6.7189e-02\n",
      "Epoch [60/100], Loss: 5.7106e-02\n",
      "Epoch [70/100], Loss: 4.8441e-02\n",
      "Epoch [80/100], Loss: 4.1587e-02\n",
      "Epoch [90/100], Loss: 3.6330e-02\n",
      "Epoch [100/100], Loss: 3.2060e-02\n",
      "#####--training model 464--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5264e-04\n",
      "Epoch [20/100], Loss: 1.5460e-04\n",
      "Epoch [30/100], Loss: 1.6319e-04\n",
      "Epoch [40/100], Loss: 1.6028e-04\n",
      "Epoch [50/100], Loss: 1.8874e-04\n",
      "Epoch [60/100], Loss: 1.8007e-04\n",
      "Epoch [70/100], Loss: 1.7227e-04\n",
      "Epoch [80/100], Loss: 1.6731e-04\n",
      "Epoch [90/100], Loss: 1.6298e-04\n",
      "Epoch [100/100], Loss: 1.5995e-04\n",
      "#####--training model 465--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.8647e-03\n",
      "Epoch [20/100], Loss: 1.8187e-03\n",
      "Epoch [30/100], Loss: 1.7904e-03\n",
      "Epoch [40/100], Loss: 1.7766e-03\n",
      "Epoch [50/100], Loss: 1.7860e-03\n",
      "Epoch [60/100], Loss: 1.7171e-03\n",
      "Epoch [70/100], Loss: 5.5158e-04\n",
      "Epoch [80/100], Loss: 1.8652e-04\n",
      "Epoch [90/100], Loss: 1.0429e-04\n",
      "Epoch [100/100], Loss: 7.6685e-05\n",
      "#####--training model 466--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.1162e-03\n",
      "Epoch [20/100], Loss: 9.0231e-03\n",
      "Epoch [30/100], Loss: 8.9318e-03\n",
      "Epoch [40/100], Loss: 8.7904e-03\n",
      "Epoch [50/100], Loss: 8.4620e-03\n",
      "Epoch [60/100], Loss: 7.2078e-03\n",
      "Epoch [70/100], Loss: 4.5594e-03\n",
      "Epoch [80/100], Loss: 3.4250e-03\n",
      "Epoch [90/100], Loss: 3.3050e-03\n",
      "Epoch [100/100], Loss: 3.3380e-03\n",
      "#####--training model 467--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6193e-04\n",
      "Epoch [20/100], Loss: 1.1182e-04\n",
      "Epoch [30/100], Loss: 1.0920e-04\n",
      "Epoch [40/100], Loss: 1.0907e-04\n",
      "Epoch [50/100], Loss: 1.0895e-04\n",
      "Epoch [60/100], Loss: 1.0881e-04\n",
      "Epoch [70/100], Loss: 1.0866e-04\n",
      "Epoch [80/100], Loss: 1.0854e-04\n",
      "Epoch [90/100], Loss: 1.0850e-04\n",
      "Epoch [100/100], Loss: 1.0875e-04\n",
      "#####--training model 468--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.0495e-03\n",
      "Epoch [20/100], Loss: 1.3128e-03\n",
      "Epoch [30/100], Loss: 7.3092e-04\n",
      "Epoch [40/100], Loss: 5.7936e-04\n",
      "Epoch [50/100], Loss: 5.3853e-04\n",
      "Epoch [60/100], Loss: 4.8141e-04\n",
      "Epoch [70/100], Loss: 3.9719e-04\n",
      "Epoch [80/100], Loss: 3.3396e-04\n",
      "Epoch [90/100], Loss: 2.9821e-04\n",
      "Epoch [100/100], Loss: 2.8191e-04\n",
      "#####--training model 469--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.8912e-03\n",
      "Epoch [20/100], Loss: 9.4426e-03\n",
      "Epoch [30/100], Loss: 9.5678e-03\n",
      "Epoch [40/100], Loss: 9.6126e-03\n",
      "Epoch [50/100], Loss: 9.6345e-03\n",
      "Epoch [60/100], Loss: 9.6095e-03\n",
      "Epoch [70/100], Loss: 1.0379e-02\n",
      "Epoch [80/100], Loss: 1.5959e-03\n",
      "Epoch [90/100], Loss: 1.7003e-03\n",
      "Epoch [100/100], Loss: 1.6182e-03\n",
      "#####--training model 470--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1835e-03\n",
      "Epoch [20/100], Loss: 1.1804e-03\n",
      "Epoch [30/100], Loss: 1.1591e-03\n",
      "Epoch [40/100], Loss: 8.1753e-04\n",
      "Epoch [50/100], Loss: 8.4072e-04\n",
      "Epoch [60/100], Loss: 8.7270e-04\n",
      "Epoch [70/100], Loss: 9.0668e-04\n",
      "Epoch [80/100], Loss: 9.2455e-04\n",
      "Epoch [90/100], Loss: 9.3314e-04\n",
      "Epoch [100/100], Loss: 9.4165e-04\n",
      "#####--training model 471--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.9576e-04\n",
      "Epoch [20/100], Loss: 4.8816e-04\n",
      "Epoch [30/100], Loss: 5.0086e-04\n",
      "Epoch [40/100], Loss: 5.2915e-04\n",
      "Epoch [50/100], Loss: 5.7620e-04\n",
      "Epoch [60/100], Loss: 6.3796e-04\n",
      "Epoch [70/100], Loss: 7.0749e-04\n",
      "Epoch [80/100], Loss: 7.6485e-04\n",
      "Epoch [90/100], Loss: 7.9464e-04\n",
      "Epoch [100/100], Loss: 7.9559e-04\n",
      "#####--training model 472--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.0748e-03\n",
      "Epoch [20/100], Loss: 5.7589e-03\n",
      "Epoch [30/100], Loss: 4.0977e-03\n",
      "Epoch [40/100], Loss: 2.7190e-03\n",
      "Epoch [50/100], Loss: 2.5317e-03\n",
      "Epoch [60/100], Loss: 2.6304e-03\n",
      "Epoch [70/100], Loss: 2.6958e-03\n",
      "Epoch [80/100], Loss: 2.7366e-03\n",
      "Epoch [90/100], Loss: 2.7608e-03\n",
      "Epoch [100/100], Loss: 2.7742e-03\n",
      "#####--training model 473--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2106e-03\n",
      "Epoch [20/100], Loss: 1.2048e-03\n",
      "Epoch [30/100], Loss: 1.1962e-03\n",
      "Epoch [40/100], Loss: 1.1504e-03\n",
      "Epoch [50/100], Loss: 7.8705e-04\n",
      "Epoch [60/100], Loss: 7.6849e-04\n",
      "Epoch [70/100], Loss: 7.4050e-04\n",
      "Epoch [80/100], Loss: 6.6581e-04\n",
      "Epoch [90/100], Loss: 6.7713e-04\n",
      "Epoch [100/100], Loss: 6.8656e-04\n",
      "#####--training model 474--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.4039e-02\n",
      "Epoch [20/100], Loss: 5.1437e-02\n",
      "Epoch [30/100], Loss: 4.6681e-02\n",
      "Epoch [40/100], Loss: 4.6901e-02\n",
      "Epoch [50/100], Loss: 4.8338e-02\n",
      "Epoch [60/100], Loss: 4.9391e-02\n",
      "Epoch [70/100], Loss: 4.9841e-02\n",
      "Epoch [80/100], Loss: 4.9921e-02\n",
      "Epoch [90/100], Loss: 4.9816e-02\n",
      "Epoch [100/100], Loss: 4.9611e-02\n",
      "#####--training model 475--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3310e-02\n",
      "Epoch [20/100], Loss: 2.1875e-02\n",
      "Epoch [30/100], Loss: 2.2601e-02\n",
      "Epoch [40/100], Loss: 2.3540e-02\n",
      "Epoch [50/100], Loss: 2.3985e-02\n",
      "Epoch [60/100], Loss: 2.3969e-02\n",
      "Epoch [70/100], Loss: 2.3678e-02\n",
      "Epoch [80/100], Loss: 2.3346e-02\n",
      "Epoch [90/100], Loss: 2.3091e-02\n",
      "Epoch [100/100], Loss: 2.2871e-02\n",
      "#####--training model 476--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.0832e-04\n",
      "Epoch [20/100], Loss: 6.8649e-04\n",
      "Epoch [30/100], Loss: 3.8582e-04\n",
      "Epoch [40/100], Loss: 2.4962e-04\n",
      "Epoch [50/100], Loss: 2.0543e-04\n",
      "Epoch [60/100], Loss: 1.8195e-04\n",
      "Epoch [70/100], Loss: 1.6815e-04\n",
      "Epoch [80/100], Loss: 1.6095e-04\n",
      "Epoch [90/100], Loss: 1.5725e-04\n",
      "Epoch [100/100], Loss: 1.5328e-04\n",
      "#####--training model 477--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4206e-03\n",
      "Epoch [20/100], Loss: 4.2943e-03\n",
      "Epoch [30/100], Loss: 4.5353e-03\n",
      "Epoch [40/100], Loss: 4.8920e-03\n",
      "Epoch [50/100], Loss: 5.0539e-03\n",
      "Epoch [60/100], Loss: 5.0423e-03\n",
      "Epoch [70/100], Loss: 4.9710e-03\n",
      "Epoch [80/100], Loss: 4.8948e-03\n",
      "Epoch [90/100], Loss: 4.8210e-03\n",
      "Epoch [100/100], Loss: 4.7399e-03\n",
      "#####--training model 478--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3259e-04\n",
      "Epoch [20/100], Loss: 1.0535e-03\n",
      "Epoch [30/100], Loss: 6.4864e-05\n",
      "Epoch [40/100], Loss: 5.5664e-05\n",
      "Epoch [50/100], Loss: 5.6842e-05\n",
      "Epoch [60/100], Loss: 6.0867e-05\n",
      "Epoch [70/100], Loss: 5.9233e-05\n",
      "Epoch [80/100], Loss: 5.8844e-05\n",
      "Epoch [90/100], Loss: 6.0867e-05\n",
      "Epoch [100/100], Loss: 6.4482e-05\n",
      "#####--training model 479--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.9386e-04\n",
      "Epoch [20/100], Loss: 1.0378e-03\n",
      "Epoch [30/100], Loss: 1.1214e-03\n",
      "Epoch [40/100], Loss: 1.1699e-03\n",
      "Epoch [50/100], Loss: 5.4719e-04\n",
      "Epoch [60/100], Loss: 3.0284e-04\n",
      "Epoch [70/100], Loss: 1.1536e-04\n",
      "Epoch [80/100], Loss: 7.7419e-05\n",
      "Epoch [90/100], Loss: 6.3288e-05\n",
      "Epoch [100/100], Loss: 5.5767e-05\n",
      "#####--training model 480--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.2473e-03\n",
      "Epoch [20/100], Loss: 3.9351e-03\n",
      "Epoch [30/100], Loss: 3.4318e-03\n",
      "Epoch [40/100], Loss: 3.0825e-03\n",
      "Epoch [50/100], Loss: 2.8963e-03\n",
      "Epoch [60/100], Loss: 2.7702e-03\n",
      "Epoch [70/100], Loss: 2.6794e-03\n",
      "Epoch [80/100], Loss: 2.5823e-03\n",
      "Epoch [90/100], Loss: 2.4582e-03\n",
      "Epoch [100/100], Loss: 2.3090e-03\n",
      "#####--training model 481--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.3572e-02\n",
      "Epoch [20/100], Loss: 3.9383e-03\n",
      "Epoch [30/100], Loss: 4.0080e-03\n",
      "Epoch [40/100], Loss: 4.1844e-03\n",
      "Epoch [50/100], Loss: 4.4234e-03\n",
      "Epoch [60/100], Loss: 4.6573e-03\n",
      "Epoch [70/100], Loss: 4.9661e-03\n",
      "Epoch [80/100], Loss: 5.6400e-03\n",
      "Epoch [90/100], Loss: 6.2397e-03\n",
      "Epoch [100/100], Loss: 6.2780e-03\n",
      "#####--training model 482--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.6712e-04\n",
      "Epoch [20/100], Loss: 3.2609e-04\n",
      "Epoch [30/100], Loss: 3.2266e-04\n",
      "Epoch [40/100], Loss: 3.2105e-04\n",
      "Epoch [50/100], Loss: 3.1813e-04\n",
      "Epoch [60/100], Loss: 2.7876e-04\n",
      "Epoch [70/100], Loss: 2.3742e-04\n",
      "Epoch [80/100], Loss: 2.4939e-04\n",
      "Epoch [90/100], Loss: 2.2803e-04\n",
      "Epoch [100/100], Loss: 1.9803e-04\n",
      "#####--training model 483--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8819e-03\n",
      "Epoch [20/100], Loss: 2.5897e-03\n",
      "Epoch [30/100], Loss: 3.7203e-03\n",
      "Epoch [40/100], Loss: 4.4323e-03\n",
      "Epoch [50/100], Loss: 4.2256e-03\n",
      "Epoch [60/100], Loss: 3.1872e-03\n",
      "Epoch [70/100], Loss: 2.5680e-03\n",
      "Epoch [80/100], Loss: 2.4695e-03\n",
      "Epoch [90/100], Loss: 2.4007e-03\n",
      "Epoch [100/100], Loss: 2.3329e-03\n",
      "#####--training model 484--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.8648e-04\n",
      "Epoch [20/100], Loss: 9.2792e-04\n",
      "Epoch [30/100], Loss: 8.7447e-04\n",
      "Epoch [40/100], Loss: 8.0096e-04\n",
      "Epoch [50/100], Loss: 6.2403e-04\n",
      "Epoch [60/100], Loss: 1.8822e-04\n",
      "Epoch [70/100], Loss: 1.7591e-04\n",
      "Epoch [80/100], Loss: 1.6102e-04\n",
      "Epoch [90/100], Loss: 1.4882e-04\n",
      "Epoch [100/100], Loss: 1.3330e-04\n",
      "#####--training model 485--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4332e-03\n",
      "Epoch [20/100], Loss: 3.6308e-03\n",
      "Epoch [30/100], Loss: 1.5977e-03\n",
      "Epoch [40/100], Loss: 1.2465e-03\n",
      "Epoch [50/100], Loss: 9.7721e-04\n",
      "Epoch [60/100], Loss: 7.8580e-04\n",
      "Epoch [70/100], Loss: 6.8573e-04\n",
      "Epoch [80/100], Loss: 6.2982e-04\n",
      "Epoch [90/100], Loss: 6.0770e-04\n",
      "Epoch [100/100], Loss: 5.6133e-04\n",
      "#####--training model 486--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.7804e-03\n",
      "Epoch [20/100], Loss: 3.7014e-03\n",
      "Epoch [30/100], Loss: 3.5420e-03\n",
      "Epoch [40/100], Loss: 2.8502e-03\n",
      "Epoch [50/100], Loss: 1.8573e-03\n",
      "Epoch [60/100], Loss: 1.0828e-03\n",
      "Epoch [70/100], Loss: 8.7531e-04\n",
      "Epoch [80/100], Loss: 8.0824e-04\n",
      "Epoch [90/100], Loss: 7.6376e-04\n",
      "Epoch [100/100], Loss: 7.1403e-04\n",
      "#####--training model 487--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4068e-03\n",
      "Epoch [20/100], Loss: 5.2139e-03\n",
      "Epoch [30/100], Loss: 2.6706e-03\n",
      "Epoch [40/100], Loss: 5.2824e-04\n",
      "Epoch [50/100], Loss: 1.4809e-04\n",
      "Epoch [60/100], Loss: 1.4948e-04\n",
      "Epoch [70/100], Loss: 1.4636e-04\n",
      "Epoch [80/100], Loss: 1.2142e-04\n",
      "Epoch [90/100], Loss: 8.6307e-05\n",
      "Epoch [100/100], Loss: 5.7274e-05\n",
      "#####--training model 488--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.9994e-04\n",
      "Epoch [20/100], Loss: 4.0638e-04\n",
      "Epoch [30/100], Loss: 3.9175e-04\n",
      "Epoch [40/100], Loss: 3.8322e-04\n",
      "Epoch [50/100], Loss: 3.7404e-04\n",
      "Epoch [60/100], Loss: 3.6352e-04\n",
      "Epoch [70/100], Loss: 3.5118e-04\n",
      "Epoch [80/100], Loss: 3.3570e-04\n",
      "Epoch [90/100], Loss: 3.1424e-04\n",
      "Epoch [100/100], Loss: 2.7504e-04\n",
      "#####--training model 489--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4169e-03\n",
      "Epoch [20/100], Loss: 8.8992e-03\n",
      "Epoch [30/100], Loss: 5.7150e-03\n",
      "Epoch [40/100], Loss: 3.3847e-03\n",
      "Epoch [50/100], Loss: 2.3851e-03\n",
      "Epoch [60/100], Loss: 2.1977e-03\n",
      "Epoch [70/100], Loss: 2.3350e-03\n",
      "Epoch [80/100], Loss: 2.6100e-03\n",
      "Epoch [90/100], Loss: 2.8594e-03\n",
      "Epoch [100/100], Loss: 3.0204e-03\n",
      "#####--training model 490--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.7364e-03\n",
      "Epoch [20/100], Loss: 4.8820e-03\n",
      "Epoch [30/100], Loss: 3.3957e-03\n",
      "Epoch [40/100], Loss: 2.4664e-03\n",
      "Epoch [50/100], Loss: 2.0284e-03\n",
      "Epoch [60/100], Loss: 1.8068e-03\n",
      "Epoch [70/100], Loss: 1.6626e-03\n",
      "Epoch [80/100], Loss: 1.5421e-03\n",
      "Epoch [90/100], Loss: 1.4376e-03\n",
      "Epoch [100/100], Loss: 1.3470e-03\n",
      "#####--training model 491--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.6636e-03\n",
      "Epoch [20/100], Loss: 4.3746e-03\n",
      "Epoch [30/100], Loss: 3.6500e-03\n",
      "Epoch [40/100], Loss: 3.4867e-03\n",
      "Epoch [50/100], Loss: 3.4662e-03\n",
      "Epoch [60/100], Loss: 3.4672e-03\n",
      "Epoch [70/100], Loss: 3.4666e-03\n",
      "Epoch [80/100], Loss: 3.4615e-03\n",
      "Epoch [90/100], Loss: 3.4562e-03\n",
      "Epoch [100/100], Loss: 3.4559e-03\n",
      "#####--training model 492--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1849e-02\n",
      "Epoch [20/100], Loss: 1.2009e-02\n",
      "Epoch [30/100], Loss: 1.1920e-02\n",
      "Epoch [40/100], Loss: 6.8736e-03\n",
      "Epoch [50/100], Loss: 4.9812e-03\n",
      "Epoch [60/100], Loss: 3.6723e-03\n",
      "Epoch [70/100], Loss: 3.5246e-03\n",
      "Epoch [80/100], Loss: 3.4881e-03\n",
      "Epoch [90/100], Loss: 3.4908e-03\n",
      "Epoch [100/100], Loss: 3.5061e-03\n",
      "#####--training model 493--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9161e-03\n",
      "Epoch [20/100], Loss: 2.8333e-03\n",
      "Epoch [30/100], Loss: 2.6641e-03\n",
      "Epoch [40/100], Loss: 6.8026e-04\n",
      "Epoch [50/100], Loss: 4.8317e-04\n",
      "Epoch [60/100], Loss: 5.8535e-04\n",
      "Epoch [70/100], Loss: 7.0446e-04\n",
      "Epoch [80/100], Loss: 6.5973e-04\n",
      "Epoch [90/100], Loss: 6.2781e-04\n",
      "Epoch [100/100], Loss: 6.1414e-04\n",
      "#####--training model 494--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.4504e-03\n",
      "Epoch [20/100], Loss: 5.2584e-03\n",
      "Epoch [30/100], Loss: 3.4013e-03\n",
      "Epoch [40/100], Loss: 2.9129e-03\n",
      "Epoch [50/100], Loss: 2.7465e-03\n",
      "Epoch [60/100], Loss: 2.6265e-03\n",
      "Epoch [70/100], Loss: 2.4568e-03\n",
      "Epoch [80/100], Loss: 2.0912e-03\n",
      "Epoch [90/100], Loss: 1.2017e-03\n",
      "Epoch [100/100], Loss: 4.7436e-04\n",
      "#####--training model 495--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0321e-03\n",
      "Epoch [20/100], Loss: 9.0896e-04\n",
      "Epoch [30/100], Loss: 1.9693e-03\n",
      "Epoch [40/100], Loss: 3.1992e-03\n",
      "Epoch [50/100], Loss: 4.3679e-03\n",
      "Epoch [60/100], Loss: 5.3246e-03\n",
      "Epoch [70/100], Loss: 5.8635e-03\n",
      "Epoch [80/100], Loss: 6.0952e-03\n",
      "Epoch [90/100], Loss: 6.2613e-03\n",
      "Epoch [100/100], Loss: 6.4616e-03\n",
      "#####--training model 496--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.7320e-03\n",
      "Epoch [20/100], Loss: 8.5784e-03\n",
      "Epoch [30/100], Loss: 8.7510e-03\n",
      "Epoch [40/100], Loss: 7.3821e-03\n",
      "Epoch [50/100], Loss: 5.9624e-03\n",
      "Epoch [60/100], Loss: 5.0862e-03\n",
      "Epoch [70/100], Loss: 4.5940e-03\n",
      "Epoch [80/100], Loss: 4.3328e-03\n",
      "Epoch [90/100], Loss: 4.1967e-03\n",
      "Epoch [100/100], Loss: 4.1275e-03\n",
      "#####--training model 497--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4603e-04\n",
      "Epoch [20/100], Loss: 5.6743e-05\n",
      "Epoch [30/100], Loss: 3.0268e-05\n",
      "Epoch [40/100], Loss: 1.8602e-05\n",
      "Epoch [50/100], Loss: 1.2409e-05\n",
      "Epoch [60/100], Loss: 8.7289e-06\n",
      "Epoch [70/100], Loss: 6.3702e-06\n",
      "Epoch [80/100], Loss: 4.7756e-06\n",
      "Epoch [90/100], Loss: 3.6550e-06\n",
      "Epoch [100/100], Loss: 2.8447e-06\n",
      "#####--training model 498--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1296e-03\n",
      "Epoch [20/100], Loss: 1.1154e-03\n",
      "Epoch [30/100], Loss: 1.1089e-03\n",
      "Epoch [40/100], Loss: 1.0742e-03\n",
      "Epoch [50/100], Loss: 7.7313e-04\n",
      "Epoch [60/100], Loss: 6.7054e-04\n",
      "Epoch [70/100], Loss: 5.8193e-04\n",
      "Epoch [80/100], Loss: 4.0170e-04\n",
      "Epoch [90/100], Loss: 1.8548e-04\n",
      "Epoch [100/100], Loss: 7.1926e-05\n",
      "#####--training model 499--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0552e-04\n",
      "Epoch [20/100], Loss: 4.6383e-05\n",
      "Epoch [30/100], Loss: 9.9039e-05\n",
      "Epoch [40/100], Loss: 2.0779e-04\n",
      "Epoch [50/100], Loss: 3.0851e-04\n",
      "Epoch [60/100], Loss: 4.4705e-04\n",
      "Epoch [70/100], Loss: 5.6152e-04\n",
      "Epoch [80/100], Loss: 4.6886e-04\n",
      "Epoch [90/100], Loss: 4.0430e-04\n",
      "Epoch [100/100], Loss: 3.7411e-04\n",
      "#####--training model 500--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1382e-02\n",
      "Epoch [20/100], Loss: 7.8817e-03\n",
      "Epoch [30/100], Loss: 5.5337e-03\n",
      "Epoch [40/100], Loss: 3.7988e-03\n",
      "Epoch [50/100], Loss: 2.9904e-03\n",
      "Epoch [60/100], Loss: 2.4346e-03\n",
      "Epoch [70/100], Loss: 2.0851e-03\n",
      "Epoch [80/100], Loss: 1.8750e-03\n",
      "Epoch [90/100], Loss: 1.7374e-03\n",
      "Epoch [100/100], Loss: 1.6344e-03\n",
      "#####--training model 501--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.3453e-04\n",
      "Epoch [20/100], Loss: 4.7314e-04\n",
      "Epoch [30/100], Loss: 5.2264e-04\n",
      "Epoch [40/100], Loss: 7.9143e-04\n",
      "Epoch [50/100], Loss: 3.1618e-04\n",
      "Epoch [60/100], Loss: 1.5547e-04\n",
      "Epoch [70/100], Loss: 7.7991e-05\n",
      "Epoch [80/100], Loss: 5.4046e-05\n",
      "Epoch [90/100], Loss: 4.9014e-05\n",
      "Epoch [100/100], Loss: 4.7874e-05\n",
      "#####--training model 502--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3468e-04\n",
      "Epoch [20/100], Loss: 5.0821e-05\n",
      "Epoch [30/100], Loss: 2.7233e-05\n",
      "Epoch [40/100], Loss: 1.6923e-05\n",
      "Epoch [50/100], Loss: 1.1410e-05\n",
      "Epoch [60/100], Loss: 8.0979e-06\n",
      "Epoch [70/100], Loss: 5.9526e-06\n",
      "Epoch [80/100], Loss: 4.4893e-06\n",
      "Epoch [90/100], Loss: 3.4536e-06\n",
      "Epoch [100/100], Loss: 2.7003e-06\n",
      "#####--training model 503--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.0003e-02\n",
      "Epoch [20/100], Loss: 3.9817e-02\n",
      "Epoch [30/100], Loss: 3.9631e-02\n",
      "Epoch [40/100], Loss: 3.9366e-02\n",
      "Epoch [50/100], Loss: 3.8865e-02\n",
      "Epoch [60/100], Loss: 3.7636e-02\n",
      "Epoch [70/100], Loss: 2.8330e-02\n",
      "Epoch [80/100], Loss: 1.6516e-02\n",
      "Epoch [90/100], Loss: 1.2852e-02\n",
      "Epoch [100/100], Loss: 1.1733e-02\n",
      "#####--training model 504--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6357e-04\n",
      "Epoch [20/100], Loss: 5.7135e-05\n",
      "Epoch [30/100], Loss: 2.9155e-05\n",
      "Epoch [40/100], Loss: 1.7413e-05\n",
      "Epoch [50/100], Loss: 1.1315e-05\n",
      "Epoch [60/100], Loss: 7.7403e-06\n",
      "Epoch [70/100], Loss: 5.4773e-06\n",
      "Epoch [80/100], Loss: 3.9675e-06\n",
      "Epoch [90/100], Loss: 2.9222e-06\n",
      "Epoch [100/100], Loss: 2.1785e-06\n",
      "#####--training model 505--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1431e-03\n",
      "Epoch [20/100], Loss: 1.1438e-03\n",
      "Epoch [30/100], Loss: 1.1292e-03\n",
      "Epoch [40/100], Loss: 1.0896e-03\n",
      "Epoch [50/100], Loss: 9.8288e-04\n",
      "Epoch [60/100], Loss: 6.1908e-04\n",
      "Epoch [70/100], Loss: 6.1885e-04\n",
      "Epoch [80/100], Loss: 7.6347e-04\n",
      "Epoch [90/100], Loss: 7.6144e-04\n",
      "Epoch [100/100], Loss: 6.6162e-04\n",
      "#####--training model 506--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.1385e-02\n",
      "Epoch [20/100], Loss: 5.1858e-02\n",
      "Epoch [30/100], Loss: 5.1899e-02\n",
      "Epoch [40/100], Loss: 5.1883e-02\n",
      "Epoch [50/100], Loss: 5.1852e-02\n",
      "Epoch [60/100], Loss: 5.1802e-02\n",
      "Epoch [70/100], Loss: 5.1707e-02\n",
      "Epoch [80/100], Loss: 5.1508e-02\n",
      "Epoch [90/100], Loss: 5.1102e-02\n",
      "Epoch [100/100], Loss: 5.0325e-02\n",
      "#####--training model 507--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3993e-03\n",
      "Epoch [20/100], Loss: 1.4314e-03\n",
      "Epoch [30/100], Loss: 1.5274e-03\n",
      "Epoch [40/100], Loss: 1.4390e-03\n",
      "Epoch [50/100], Loss: 1.0736e-03\n",
      "Epoch [60/100], Loss: 9.2383e-04\n",
      "Epoch [70/100], Loss: 8.7016e-04\n",
      "Epoch [80/100], Loss: 8.5737e-04\n",
      "Epoch [90/100], Loss: 8.6330e-04\n",
      "Epoch [100/100], Loss: 8.6077e-04\n",
      "#####--training model 508--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.5298e-04\n",
      "Epoch [20/100], Loss: 5.8738e-04\n",
      "Epoch [30/100], Loss: 7.8425e-04\n",
      "Epoch [40/100], Loss: 1.0652e-03\n",
      "Epoch [50/100], Loss: 9.0835e-04\n",
      "Epoch [60/100], Loss: 7.8522e-04\n",
      "Epoch [70/100], Loss: 8.5815e-04\n",
      "Epoch [80/100], Loss: 9.8252e-04\n",
      "Epoch [90/100], Loss: 9.8757e-04\n",
      "Epoch [100/100], Loss: 9.9721e-04\n",
      "#####--training model 509--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2626e-04\n",
      "Epoch [20/100], Loss: 4.8435e-05\n",
      "Epoch [30/100], Loss: 2.9922e-05\n",
      "Epoch [40/100], Loss: 2.3534e-05\n",
      "Epoch [50/100], Loss: 2.1228e-05\n",
      "Epoch [60/100], Loss: 2.0466e-05\n",
      "Epoch [70/100], Loss: 2.0188e-05\n",
      "Epoch [80/100], Loss: 1.9989e-05\n",
      "Epoch [90/100], Loss: 1.9764e-05\n",
      "Epoch [100/100], Loss: 1.9496e-05\n",
      "#####--training model 510--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5187e-04\n",
      "Epoch [20/100], Loss: 1.8155e-04\n",
      "Epoch [30/100], Loss: 1.7949e-04\n",
      "Epoch [40/100], Loss: 1.9672e-04\n",
      "Epoch [50/100], Loss: 3.4694e-04\n",
      "Epoch [60/100], Loss: 5.9476e-04\n",
      "Epoch [70/100], Loss: 4.9245e-04\n",
      "Epoch [80/100], Loss: 3.9062e-04\n",
      "Epoch [90/100], Loss: 2.2433e-04\n",
      "Epoch [100/100], Loss: 1.0977e-04\n",
      "#####--training model 511--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8276e-04\n",
      "Epoch [20/100], Loss: 2.7530e-04\n",
      "Epoch [30/100], Loss: 2.5873e-04\n",
      "Epoch [40/100], Loss: 2.5371e-04\n",
      "Epoch [50/100], Loss: 2.5305e-04\n",
      "Epoch [60/100], Loss: 1.2534e-04\n",
      "Epoch [70/100], Loss: 6.5923e-05\n",
      "Epoch [80/100], Loss: 5.2271e-05\n",
      "Epoch [90/100], Loss: 4.1926e-05\n",
      "Epoch [100/100], Loss: 3.6752e-05\n",
      "#####--training model 512--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.0964e-03\n",
      "Epoch [20/100], Loss: 3.8001e-03\n",
      "Epoch [30/100], Loss: 2.0558e-03\n",
      "Epoch [40/100], Loss: 1.2182e-03\n",
      "Epoch [50/100], Loss: 1.0379e-03\n",
      "Epoch [60/100], Loss: 9.6432e-04\n",
      "Epoch [70/100], Loss: 9.2527e-04\n",
      "Epoch [80/100], Loss: 9.0376e-04\n",
      "Epoch [90/100], Loss: 8.6836e-04\n",
      "Epoch [100/100], Loss: 8.8489e-04\n",
      "#####--training model 513--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1482e-03\n",
      "Epoch [20/100], Loss: 1.2817e-03\n",
      "Epoch [30/100], Loss: 1.3280e-03\n",
      "Epoch [40/100], Loss: 1.3433e-03\n",
      "Epoch [50/100], Loss: 1.3471e-03\n",
      "Epoch [60/100], Loss: 1.3474e-03\n",
      "Epoch [70/100], Loss: 1.3471e-03\n",
      "Epoch [80/100], Loss: 1.3466e-03\n",
      "Epoch [90/100], Loss: 1.3458e-03\n",
      "Epoch [100/100], Loss: 1.3444e-03\n",
      "#####--training model 514--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.6941e-03\n",
      "Epoch [20/100], Loss: 7.3848e-03\n",
      "Epoch [30/100], Loss: 3.7024e-03\n",
      "Epoch [40/100], Loss: 2.3661e-03\n",
      "Epoch [50/100], Loss: 1.4497e-03\n",
      "Epoch [60/100], Loss: 1.1930e-03\n",
      "Epoch [70/100], Loss: 1.0838e-03\n",
      "Epoch [80/100], Loss: 1.0059e-03\n",
      "Epoch [90/100], Loss: 9.3890e-04\n",
      "Epoch [100/100], Loss: 8.8089e-04\n",
      "#####--training model 515--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2977e-04\n",
      "Epoch [20/100], Loss: 4.8188e-05\n",
      "Epoch [30/100], Loss: 2.5374e-05\n",
      "Epoch [40/100], Loss: 1.5567e-05\n",
      "Epoch [50/100], Loss: 1.0397e-05\n",
      "Epoch [60/100], Loss: 7.3268e-06\n",
      "Epoch [70/100], Loss: 5.3571e-06\n",
      "Epoch [80/100], Loss: 4.0242e-06\n",
      "Epoch [90/100], Loss: 3.0868e-06\n",
      "Epoch [100/100], Loss: 2.4088e-06\n",
      "#####--training model 516--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.5796e-04\n",
      "Epoch [20/100], Loss: 6.4867e-04\n",
      "Epoch [30/100], Loss: 6.2466e-04\n",
      "Epoch [40/100], Loss: 4.3650e-04\n",
      "Epoch [50/100], Loss: 4.5658e-04\n",
      "Epoch [60/100], Loss: 4.3228e-04\n",
      "Epoch [70/100], Loss: 4.1833e-04\n",
      "Epoch [80/100], Loss: 4.0690e-04\n",
      "Epoch [90/100], Loss: 3.9829e-04\n",
      "Epoch [100/100], Loss: 3.9295e-04\n",
      "#####--training model 517--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2474e-03\n",
      "Epoch [20/100], Loss: 2.2918e-03\n",
      "Epoch [30/100], Loss: 8.2570e-04\n",
      "Epoch [40/100], Loss: 6.1470e-04\n",
      "Epoch [50/100], Loss: 4.5640e-04\n",
      "Epoch [60/100], Loss: 3.7773e-04\n",
      "Epoch [70/100], Loss: 3.5129e-04\n",
      "Epoch [80/100], Loss: 3.4401e-04\n",
      "Epoch [90/100], Loss: 3.5677e-04\n",
      "Epoch [100/100], Loss: 3.9688e-04\n",
      "#####--training model 518--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5713e-03\n",
      "Epoch [20/100], Loss: 1.6790e-03\n",
      "Epoch [30/100], Loss: 2.3775e-03\n",
      "Epoch [40/100], Loss: 1.2502e-03\n",
      "Epoch [50/100], Loss: 1.1631e-03\n",
      "Epoch [60/100], Loss: 1.0899e-03\n",
      "Epoch [70/100], Loss: 9.9896e-04\n",
      "Epoch [80/100], Loss: 9.0289e-04\n",
      "Epoch [90/100], Loss: 8.1586e-04\n",
      "Epoch [100/100], Loss: 7.3102e-04\n",
      "#####--training model 519--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.3169e-04\n",
      "Epoch [20/100], Loss: 5.9011e-04\n",
      "Epoch [30/100], Loss: 6.4073e-04\n",
      "Epoch [40/100], Loss: 7.2957e-04\n",
      "Epoch [50/100], Loss: 6.1647e-04\n",
      "Epoch [60/100], Loss: 4.8161e-04\n",
      "Epoch [70/100], Loss: 3.7931e-04\n",
      "Epoch [80/100], Loss: 3.0113e-04\n",
      "Epoch [90/100], Loss: 2.3955e-04\n",
      "Epoch [100/100], Loss: 1.8581e-04\n",
      "#####--training model 520--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7709e-04\n",
      "Epoch [20/100], Loss: 7.2909e-05\n",
      "Epoch [30/100], Loss: 4.3690e-05\n",
      "Epoch [40/100], Loss: 3.1230e-05\n",
      "Epoch [50/100], Loss: 2.4911e-05\n",
      "Epoch [60/100], Loss: 2.1498e-05\n",
      "Epoch [70/100], Loss: 1.9686e-05\n",
      "Epoch [80/100], Loss: 1.8814e-05\n",
      "Epoch [90/100], Loss: 1.8472e-05\n",
      "Epoch [100/100], Loss: 1.8387e-05\n",
      "#####--training model 521--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.6092e-04\n",
      "Epoch [20/100], Loss: 4.3355e-04\n",
      "Epoch [30/100], Loss: 4.4064e-04\n",
      "Epoch [40/100], Loss: 4.4921e-04\n",
      "Epoch [50/100], Loss: 4.5861e-04\n",
      "Epoch [60/100], Loss: 4.6922e-04\n",
      "Epoch [70/100], Loss: 4.8255e-04\n",
      "Epoch [80/100], Loss: 5.0448e-04\n",
      "Epoch [90/100], Loss: 5.5096e-04\n",
      "Epoch [100/100], Loss: 6.1659e-04\n",
      "#####--training model 522--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.4743e-04\n",
      "Epoch [20/100], Loss: 6.7508e-04\n",
      "Epoch [30/100], Loss: 6.9873e-04\n",
      "Epoch [40/100], Loss: 7.2779e-04\n",
      "Epoch [50/100], Loss: 7.8732e-04\n",
      "Epoch [60/100], Loss: 1.0543e-03\n",
      "Epoch [70/100], Loss: 3.8550e-04\n",
      "Epoch [80/100], Loss: 1.3347e-04\n",
      "Epoch [90/100], Loss: 9.8562e-05\n",
      "Epoch [100/100], Loss: 8.8670e-05\n",
      "#####--training model 523--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.6832e-04\n",
      "Epoch [20/100], Loss: 1.0576e-03\n",
      "Epoch [30/100], Loss: 1.3221e-03\n",
      "Epoch [40/100], Loss: 9.8798e-04\n",
      "Epoch [50/100], Loss: 8.1047e-04\n",
      "Epoch [60/100], Loss: 7.3041e-04\n",
      "Epoch [70/100], Loss: 6.8668e-04\n",
      "Epoch [80/100], Loss: 6.4792e-04\n",
      "Epoch [90/100], Loss: 6.1806e-04\n",
      "Epoch [100/100], Loss: 5.9798e-04\n",
      "#####--training model 524--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4383e-04\n",
      "Epoch [20/100], Loss: 2.8499e-04\n",
      "Epoch [30/100], Loss: 2.8543e-04\n",
      "Epoch [40/100], Loss: 2.9181e-04\n",
      "Epoch [50/100], Loss: 3.0089e-04\n",
      "Epoch [60/100], Loss: 3.1110e-04\n",
      "Epoch [70/100], Loss: 3.3932e-04\n",
      "Epoch [80/100], Loss: 4.8713e-04\n",
      "Epoch [90/100], Loss: 5.1985e-04\n",
      "Epoch [100/100], Loss: 2.8915e-04\n",
      "#####--training model 525--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0903e-04\n",
      "Epoch [20/100], Loss: 2.1307e-04\n",
      "Epoch [30/100], Loss: 1.9714e-04\n",
      "Epoch [40/100], Loss: 1.9596e-04\n",
      "Epoch [50/100], Loss: 1.9707e-04\n",
      "Epoch [60/100], Loss: 1.9865e-04\n",
      "Epoch [70/100], Loss: 2.0075e-04\n",
      "Epoch [80/100], Loss: 2.0405e-04\n",
      "Epoch [90/100], Loss: 2.1096e-04\n",
      "Epoch [100/100], Loss: 2.1794e-04\n",
      "#####--training model 526--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6054e-03\n",
      "Epoch [20/100], Loss: 1.3980e-03\n",
      "Epoch [30/100], Loss: 8.9701e-04\n",
      "Epoch [40/100], Loss: 6.4186e-04\n",
      "Epoch [50/100], Loss: 2.9385e-04\n",
      "Epoch [60/100], Loss: 1.1854e-04\n",
      "Epoch [70/100], Loss: 8.1244e-05\n",
      "Epoch [80/100], Loss: 6.8712e-05\n",
      "Epoch [90/100], Loss: 6.2265e-05\n",
      "Epoch [100/100], Loss: 5.8767e-05\n",
      "#####--training model 527--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.6676e-03\n",
      "Epoch [20/100], Loss: 1.7268e-03\n",
      "Epoch [30/100], Loss: 1.9164e-03\n",
      "Epoch [40/100], Loss: 2.4846e-03\n",
      "Epoch [50/100], Loss: 2.1275e-03\n",
      "Epoch [60/100], Loss: 1.8113e-03\n",
      "Epoch [70/100], Loss: 1.7335e-03\n",
      "Epoch [80/100], Loss: 1.7574e-03\n",
      "Epoch [90/100], Loss: 1.6565e-03\n",
      "Epoch [100/100], Loss: 1.5316e-03\n",
      "#####--training model 528--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1767e-04\n",
      "Epoch [20/100], Loss: 4.2808e-05\n",
      "Epoch [30/100], Loss: 2.1974e-05\n",
      "Epoch [40/100], Loss: 1.3129e-05\n",
      "Epoch [50/100], Loss: 8.5282e-06\n",
      "Epoch [60/100], Loss: 5.8326e-06\n",
      "Epoch [70/100], Loss: 4.1274e-06\n",
      "Epoch [80/100], Loss: 2.9905e-06\n",
      "Epoch [90/100], Loss: 2.2035e-06\n",
      "Epoch [100/100], Loss: 1.6437e-06\n"
     ]
    }
   ],
   "source": [
    "folder_name  = 'models_od\\\\'\n",
    "\n",
    "for feature in range(num_features): \n",
    "\n",
    "    print('#####--training model %d--#####\\n' % feature)\n",
    "    \n",
    "    # Get model and optimizer\n",
    "    model = models[feature]\n",
    "    optimizer = optimizers[feature]\n",
    "\n",
    "    # Create training dataset and dataloader for current feature\n",
    "    train_loader = get_dataloader(np.expand_dims(trainX[:, :, feature], axis = 2), np.expand_dims(trainY[:, feature], axis = 1),\n",
    "                                   batch_size, num_workers, shuffle)\n",
    "    \n",
    "    # Train the model\n",
    "    loss = train(model, train_loader, epochs, criterion, optimizer)\n",
    "\n",
    "    # Save the model, we will get model outputs in a later loop\n",
    "    model_name = 'model_%d.pth' % feature\n",
    "    model_path = folder_name+model_name\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros((test_data.shape[0]-10, test_data.shape[1]))\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for i in range(529):\n",
    "    path = 'models_od\\\\model_%d.pth' % i\n",
    "    model = RNN(input_size, hidden_size, num_layers)\n",
    "    model.load_state_dict(torch.load(path, weights_only=True))\n",
    "    model.eval()\n",
    "\n",
    "    testX_i = np.expand_dims(testX[:, :, i], axis = 2)\n",
    "    testY_i = np.expand_dims(testY[:, i], axis = 1)\n",
    "\n",
    "    # Create test_loader\n",
    "    test_loader = get_dataloader(testX_i, testY_i,\n",
    "                                batch_size, num_workers, shuffle)\n",
    "\n",
    "    total_loss = 0.0 \n",
    "\n",
    "    model_outputs = [] # account for window size\n",
    "    test_loss = np.zeros((testY_i.shape[0], 1))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, targets) in enumerate(test_loader): \n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            model_outputs.append(outputs.flatten())\n",
    "\n",
    "\n",
    "    # Concatenate all outputs into a single tensor\n",
    "    model_outputs =  torch.cat(model_outputs, dim=0).numpy()\n",
    "\n",
    "    # Save the model_outputs\n",
    "    np.save('model_outputs_od\\\\geant_local_mse_od_%i.npy' % i, \n",
    "        model_outputs)\n",
    "\n",
    "    # Inverse normalize the prediction\n",
    "    inverse_preds = model_outputs * (max_vals_test[i] - min_vals_test[i]) + min_vals_test[i]\n",
    "\n",
    "    # Add inverse normalized predictions to largers matrix\n",
    "    predictions[:, i] = inverse_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_save_heatmap(test_data/1e5, predictions/1e5, num_nodes=23, save_path = 'Figs\\\\heat_maps',\n",
    "                          fig_name= 'inverse_normalized_model_predictions_local.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-10\n"
     ]
    }
   ],
   "source": [
    "# Compute MCF on inverse normalized predictions\n",
    "mlu_preds, Nans = mlu_on_preds(predictions, num_nodes=23, capacity = 1e7, topo='fc')\n",
    "\n",
    "if Nans: \n",
    "    print('NaN values in mlu_preds, ending program')\n",
    "\n",
    "# Save MLUs\n",
    "np.save('mlu_baseline\\\\mlu_preds_geant_local_mse.npy', mlu_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MCF baseline on original dataset\n",
    "mlu_gt = np.load('mlu_baseline\\\\mlu_baseline_geant_fc.npy')\n",
    "mlu_gt = mlu_gt[len(train_data):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mlu cdf and mlu comparison\n",
    "plot_and_save_ecdf(mlu_gt, mlu_preds, save_path = 'Figs\\\\ecdfs', fig_name='CDF_mlu_geant_local_mse.png')\n",
    "plot_and_save_mlu_compare(mlu_gt, mlu_preds, save_path='Figs\\\\mlu_compare', fig_name='mlu_compare_geant_local_mse.png')\n",
    "plot_and_save_pdf(mlu_gt, mlu_preds, save_path = 'Figs\\\\pdfs', fig_name='PDF_mlu_geant_local_mse.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all predictions\n",
    "for i in range(144):\n",
    "    plt.plot(test_data[10:, i], label = 'Original')\n",
    "    plt.plot(predictions[:, i], label = 'Prediction')\n",
    "    plt.xlabel('Time Index')\n",
    "    plt.ylabel('Traffic Demand (bps)')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.savefig('Figs\\\\od_pairs\\\\prediction_local_%d.png' % i, dpi = 300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example data\n",
    "data1 = np.random.normal(0, 1, 1000)\n",
    "data2 = np.random.normal(2, 0.5, 1000)\n",
    "data3 = np.random.normal(-1, 1.5, 1000)\n",
    "\n",
    "# Plot PDFs directly with seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.kdeplot(data1, label=\"Dataset 1\", color=\"blue\")\n",
    "sns.kdeplot(data2, label=\"Dataset 2\", color=\"green\")\n",
    "sns.kdeplot(data3, label=\"Dataset 3\", color=\"red\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Overlapping PDFs with KDE\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
