{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "from torch.autograd import *\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from utils import * \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Abilene Dataset\n",
    "data = read_abilene_data(read_week = True, week = 1)\n",
    "\n",
    "# Train Test Split \n",
    "train_data, test_data = train_test_split(data, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-wise min-max normalization (normalize each element over time)\n",
    "min_vals_train = train_data.min(axis=0)  # Shape (144,)\n",
    "max_vals_train = train_data.max(axis=0)  # Shape (144,)\n",
    "train_data_norm = (train_data - min_vals_train) / (max_vals_train - min_vals_train + 1e-8)  # Avoid division by zero\n",
    "\n",
    "# Feature-wise min-max normalization (normalize each element over time)\n",
    "min_vals_test = test_data.min(axis=0)  # Shape (144,)\n",
    "max_vals_test = test_data.max(axis=0)  # Shape (144,)\n",
    "test_data_norm = (test_data - min_vals_test) / (max_vals_test - min_vals_test + 1e-8)  # Avoid division by zero\n",
    "\n",
    "# Window the dataset\n",
    "trainX, trainY= create_dataset(train_data_norm, 10) \n",
    "testX, testY = create_dataset(test_data_norm, 10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyper parameters \n",
    "input_size = 1  # Each feature is treated as an individual time series\n",
    "hidden_size = 30\n",
    "num_layers = 1\n",
    "learn_rate = 0.001 \n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "num_features = 12 * 12  # Total number of features in the flattened traffic matrix\n",
    "shuffle = False #don't want to lose the time dependency\n",
    "num_workers = 0  # Number of subprocesses to use for data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a separate model for each feature in the traffic matrix\n",
    "models = [RNN(input_size, hidden_size, num_layers) for _ in range(num_features)]\n",
    "\n",
    "optimizers = [optim.Adam(model.parameters(), lr=learn_rate) for model in models]\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#####--training model 0--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9277e-03\n",
      "Epoch [20/100], Loss: 1.7751e-03\n",
      "Epoch [30/100], Loss: 1.8763e-03\n",
      "Epoch [40/100], Loss: 1.8977e-03\n",
      "Epoch [50/100], Loss: 1.9745e-03\n",
      "Epoch [60/100], Loss: 2.0441e-03\n",
      "Epoch [70/100], Loss: 2.0508e-03\n",
      "Epoch [80/100], Loss: 2.0749e-03\n",
      "Epoch [90/100], Loss: 2.1009e-03\n",
      "Epoch [100/100], Loss: 2.1158e-03\n",
      "#####--training model 1--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.6318e-04\n",
      "Epoch [20/100], Loss: 4.4587e-04\n",
      "Epoch [30/100], Loss: 2.2303e-04\n",
      "Epoch [40/100], Loss: 1.5327e-04\n",
      "Epoch [50/100], Loss: 1.5072e-04\n",
      "Epoch [60/100], Loss: 1.5415e-04\n",
      "Epoch [70/100], Loss: 1.5725e-04\n",
      "Epoch [80/100], Loss: 1.5595e-04\n",
      "Epoch [90/100], Loss: 1.5200e-04\n",
      "Epoch [100/100], Loss: 1.4579e-04\n",
      "#####--training model 2--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.4988e-04\n",
      "Epoch [20/100], Loss: 1.8327e-04\n",
      "Epoch [30/100], Loss: 1.4329e-04\n",
      "Epoch [40/100], Loss: 1.5857e-04\n",
      "Epoch [50/100], Loss: 1.5842e-04\n",
      "Epoch [60/100], Loss: 1.5711e-04\n",
      "Epoch [70/100], Loss: 1.5712e-04\n",
      "Epoch [80/100], Loss: 1.5743e-04\n",
      "Epoch [90/100], Loss: 1.5821e-04\n",
      "Epoch [100/100], Loss: 1.5824e-04\n",
      "#####--training model 3--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9159e-03\n",
      "Epoch [20/100], Loss: 1.7522e-03\n",
      "Epoch [30/100], Loss: 1.8126e-03\n",
      "Epoch [40/100], Loss: 1.8411e-03\n",
      "Epoch [50/100], Loss: 1.9068e-03\n",
      "Epoch [60/100], Loss: 1.9483e-03\n",
      "Epoch [70/100], Loss: 1.8429e-03\n",
      "Epoch [80/100], Loss: 1.7358e-03\n",
      "Epoch [90/100], Loss: 1.6960e-03\n",
      "Epoch [100/100], Loss: 1.6963e-03\n",
      "#####--training model 4--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9233e-03\n",
      "Epoch [20/100], Loss: 1.7964e-03\n",
      "Epoch [30/100], Loss: 1.8581e-03\n",
      "Epoch [40/100], Loss: 1.8950e-03\n",
      "Epoch [50/100], Loss: 2.0062e-03\n",
      "Epoch [60/100], Loss: 2.1520e-03\n",
      "Epoch [70/100], Loss: 2.2200e-03\n",
      "Epoch [80/100], Loss: 2.2314e-03\n",
      "Epoch [90/100], Loss: 2.2247e-03\n",
      "Epoch [100/100], Loss: 2.2072e-03\n",
      "#####--training model 5--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.7467e-03\n",
      "Epoch [20/100], Loss: 9.1611e-04\n",
      "Epoch [30/100], Loss: 6.6263e-04\n",
      "Epoch [40/100], Loss: 6.2261e-04\n",
      "Epoch [50/100], Loss: 6.3636e-04\n",
      "Epoch [60/100], Loss: 6.4576e-04\n",
      "Epoch [70/100], Loss: 6.2698e-04\n",
      "Epoch [80/100], Loss: 6.0169e-04\n",
      "Epoch [90/100], Loss: 5.9475e-04\n",
      "Epoch [100/100], Loss: 5.7151e-04\n",
      "#####--training model 6--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.9899e-04\n",
      "Epoch [20/100], Loss: 7.7172e-04\n",
      "Epoch [30/100], Loss: 7.2038e-04\n",
      "Epoch [40/100], Loss: 7.2746e-04\n",
      "Epoch [50/100], Loss: 7.2520e-04\n",
      "Epoch [60/100], Loss: 6.8236e-04\n",
      "Epoch [70/100], Loss: 6.4432e-04\n",
      "Epoch [80/100], Loss: 6.2971e-04\n",
      "Epoch [90/100], Loss: 6.3041e-04\n",
      "Epoch [100/100], Loss: 6.3643e-04\n",
      "#####--training model 7--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0886e-03\n",
      "Epoch [20/100], Loss: 9.4797e-04\n",
      "Epoch [30/100], Loss: 7.9938e-04\n",
      "Epoch [40/100], Loss: 7.3722e-04\n",
      "Epoch [50/100], Loss: 7.3275e-04\n",
      "Epoch [60/100], Loss: 7.4141e-04\n",
      "Epoch [70/100], Loss: 7.1608e-04\n",
      "Epoch [80/100], Loss: 7.0195e-04\n",
      "Epoch [90/100], Loss: 7.0303e-04\n",
      "Epoch [100/100], Loss: 7.0631e-04\n",
      "#####--training model 8--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.1587e-03\n",
      "Epoch [20/100], Loss: 2.3362e-03\n",
      "Epoch [30/100], Loss: 2.3830e-03\n",
      "Epoch [40/100], Loss: 2.4969e-03\n",
      "Epoch [50/100], Loss: 2.6925e-03\n",
      "Epoch [60/100], Loss: 2.5942e-03\n",
      "Epoch [70/100], Loss: 2.5677e-03\n",
      "Epoch [80/100], Loss: 2.5237e-03\n",
      "Epoch [90/100], Loss: 2.4667e-03\n",
      "Epoch [100/100], Loss: 2.4334e-03\n",
      "#####--training model 9--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3405e-03\n",
      "Epoch [20/100], Loss: 1.4191e-03\n",
      "Epoch [30/100], Loss: 1.4014e-03\n",
      "Epoch [40/100], Loss: 1.4139e-03\n",
      "Epoch [50/100], Loss: 1.4823e-03\n",
      "Epoch [60/100], Loss: 1.5762e-03\n",
      "Epoch [70/100], Loss: 1.6317e-03\n",
      "Epoch [80/100], Loss: 1.6151e-03\n",
      "Epoch [90/100], Loss: 1.5492e-03\n",
      "Epoch [100/100], Loss: 1.5526e-03\n",
      "#####--training model 10--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.7638e-03\n",
      "Epoch [20/100], Loss: 3.6717e-03\n",
      "Epoch [30/100], Loss: 3.6205e-03\n",
      "Epoch [40/100], Loss: 4.1114e-03\n",
      "Epoch [50/100], Loss: 4.7623e-03\n",
      "Epoch [60/100], Loss: 5.2104e-03\n",
      "Epoch [70/100], Loss: 5.2677e-03\n",
      "Epoch [80/100], Loss: 5.0771e-03\n",
      "Epoch [90/100], Loss: 4.9477e-03\n",
      "Epoch [100/100], Loss: 4.8997e-03\n",
      "#####--training model 11--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.0569e-04\n",
      "Epoch [20/100], Loss: 3.6784e-04\n",
      "Epoch [30/100], Loss: 3.3804e-04\n",
      "Epoch [40/100], Loss: 3.1545e-04\n",
      "Epoch [50/100], Loss: 2.6103e-04\n",
      "Epoch [60/100], Loss: 1.9178e-04\n",
      "Epoch [70/100], Loss: 1.3457e-04\n",
      "Epoch [80/100], Loss: 1.0802e-04\n",
      "Epoch [90/100], Loss: 1.0227e-04\n",
      "Epoch [100/100], Loss: 1.0420e-04\n",
      "#####--training model 12--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9167e-04\n",
      "Epoch [20/100], Loss: 1.9176e-04\n",
      "Epoch [30/100], Loss: 2.2327e-04\n",
      "Epoch [40/100], Loss: 1.9877e-04\n",
      "Epoch [50/100], Loss: 1.3464e-04\n",
      "Epoch [60/100], Loss: 8.9116e-05\n",
      "Epoch [70/100], Loss: 7.8360e-05\n",
      "Epoch [80/100], Loss: 7.5752e-05\n",
      "Epoch [90/100], Loss: 7.6807e-05\n",
      "Epoch [100/100], Loss: 7.9262e-05\n",
      "#####--training model 13--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.1812e-04\n",
      "Epoch [20/100], Loss: 2.1963e-04\n",
      "Epoch [30/100], Loss: 2.1986e-04\n",
      "Epoch [40/100], Loss: 2.2334e-04\n",
      "Epoch [50/100], Loss: 2.1897e-04\n",
      "Epoch [60/100], Loss: 2.0367e-04\n",
      "Epoch [70/100], Loss: 1.8339e-04\n",
      "Epoch [80/100], Loss: 1.6477e-04\n",
      "Epoch [90/100], Loss: 1.5079e-04\n",
      "Epoch [100/100], Loss: 1.3899e-04\n",
      "#####--training model 14--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.5618e-04\n",
      "Epoch [20/100], Loss: 2.3404e-04\n",
      "Epoch [30/100], Loss: 2.1729e-04\n",
      "Epoch [40/100], Loss: 2.0737e-04\n",
      "Epoch [50/100], Loss: 1.6775e-04\n",
      "Epoch [60/100], Loss: 1.2895e-04\n",
      "Epoch [70/100], Loss: 1.0990e-04\n",
      "Epoch [80/100], Loss: 1.0058e-04\n",
      "Epoch [90/100], Loss: 9.3593e-05\n",
      "Epoch [100/100], Loss: 8.4833e-05\n",
      "#####--training model 15--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.7554e-03\n",
      "Epoch [20/100], Loss: 3.8501e-03\n",
      "Epoch [30/100], Loss: 2.3070e-03\n",
      "Epoch [40/100], Loss: 1.1382e-03\n",
      "Epoch [50/100], Loss: 8.5726e-04\n",
      "Epoch [60/100], Loss: 6.2355e-04\n",
      "Epoch [70/100], Loss: 4.2842e-04\n",
      "Epoch [80/100], Loss: 3.4121e-04\n",
      "Epoch [90/100], Loss: 3.2617e-04\n",
      "Epoch [100/100], Loss: 3.3434e-04\n",
      "#####--training model 16--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.1733e-04\n",
      "Epoch [20/100], Loss: 4.0896e-04\n",
      "Epoch [30/100], Loss: 4.6694e-04\n",
      "Epoch [40/100], Loss: 3.8473e-04\n",
      "Epoch [50/100], Loss: 3.1096e-04\n",
      "Epoch [60/100], Loss: 2.7620e-04\n",
      "Epoch [70/100], Loss: 2.7236e-04\n",
      "Epoch [80/100], Loss: 2.7963e-04\n",
      "Epoch [90/100], Loss: 2.9635e-04\n",
      "Epoch [100/100], Loss: 3.2123e-04\n",
      "#####--training model 17--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5080e-04\n",
      "Epoch [20/100], Loss: 3.9210e-04\n",
      "Epoch [30/100], Loss: 5.0191e-04\n",
      "Epoch [40/100], Loss: 4.7221e-04\n",
      "Epoch [50/100], Loss: 3.8811e-04\n",
      "Epoch [60/100], Loss: 3.1325e-04\n",
      "Epoch [70/100], Loss: 2.6283e-04\n",
      "Epoch [80/100], Loss: 2.4036e-04\n",
      "Epoch [90/100], Loss: 2.3689e-04\n",
      "Epoch [100/100], Loss: 2.3972e-04\n",
      "#####--training model 18--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.3415e-05\n",
      "Epoch [20/100], Loss: 1.4899e-04\n",
      "Epoch [30/100], Loss: 7.3953e-05\n",
      "Epoch [40/100], Loss: 4.8931e-05\n",
      "Epoch [50/100], Loss: 4.6186e-05\n",
      "Epoch [60/100], Loss: 3.8855e-05\n",
      "Epoch [70/100], Loss: 3.6078e-05\n",
      "Epoch [80/100], Loss: 3.6984e-05\n",
      "Epoch [90/100], Loss: 3.9528e-05\n",
      "Epoch [100/100], Loss: 4.3386e-05\n",
      "#####--training model 19--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0594e-04\n",
      "Epoch [20/100], Loss: 2.4595e-04\n",
      "Epoch [30/100], Loss: 2.1419e-04\n",
      "Epoch [40/100], Loss: 1.6884e-04\n",
      "Epoch [50/100], Loss: 1.5406e-04\n",
      "Epoch [60/100], Loss: 1.3627e-04\n",
      "Epoch [70/100], Loss: 1.2526e-04\n",
      "Epoch [80/100], Loss: 1.2849e-04\n",
      "Epoch [90/100], Loss: 1.3571e-04\n",
      "Epoch [100/100], Loss: 1.4379e-04\n",
      "#####--training model 20--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0420e-02\n",
      "Epoch [20/100], Loss: 3.6811e-03\n",
      "Epoch [30/100], Loss: 2.5762e-03\n",
      "Epoch [40/100], Loss: 2.0020e-03\n",
      "Epoch [50/100], Loss: 1.6819e-03\n",
      "Epoch [60/100], Loss: 1.3850e-03\n",
      "Epoch [70/100], Loss: 1.1788e-03\n",
      "Epoch [80/100], Loss: 1.0874e-03\n",
      "Epoch [90/100], Loss: 1.0489e-03\n",
      "Epoch [100/100], Loss: 1.0277e-03\n",
      "#####--training model 21--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3068e-03\n",
      "Epoch [20/100], Loss: 3.1662e-03\n",
      "Epoch [30/100], Loss: 3.3770e-03\n",
      "Epoch [40/100], Loss: 3.6907e-03\n",
      "Epoch [50/100], Loss: 4.0066e-03\n",
      "Epoch [60/100], Loss: 4.2094e-03\n",
      "Epoch [70/100], Loss: 4.3857e-03\n",
      "Epoch [80/100], Loss: 4.6054e-03\n",
      "Epoch [90/100], Loss: 4.7958e-03\n",
      "Epoch [100/100], Loss: 4.8285e-03\n",
      "#####--training model 22--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4712e-03\n",
      "Epoch [20/100], Loss: 2.5553e-03\n",
      "Epoch [30/100], Loss: 2.7877e-03\n",
      "Epoch [40/100], Loss: 3.0679e-03\n",
      "Epoch [50/100], Loss: 3.3067e-03\n",
      "Epoch [60/100], Loss: 3.4456e-03\n",
      "Epoch [70/100], Loss: 3.5391e-03\n",
      "Epoch [80/100], Loss: 3.6220e-03\n",
      "Epoch [90/100], Loss: 3.6991e-03\n",
      "Epoch [100/100], Loss: 3.7746e-03\n",
      "#####--training model 23--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9268e-04\n",
      "Epoch [20/100], Loss: 1.0730e-04\n",
      "Epoch [30/100], Loss: 8.9393e-05\n",
      "Epoch [40/100], Loss: 7.5216e-05\n",
      "Epoch [50/100], Loss: 4.6759e-05\n",
      "Epoch [60/100], Loss: 1.8638e-05\n",
      "Epoch [70/100], Loss: 2.0781e-05\n",
      "Epoch [80/100], Loss: 3.8525e-05\n",
      "Epoch [90/100], Loss: 8.0242e-05\n",
      "Epoch [100/100], Loss: 1.7092e-04\n",
      "#####--training model 24--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.1144e-05\n",
      "Epoch [20/100], Loss: 1.4839e-05\n",
      "Epoch [30/100], Loss: 8.6931e-06\n",
      "Epoch [40/100], Loss: 7.8561e-06\n",
      "Epoch [50/100], Loss: 9.1135e-06\n",
      "Epoch [60/100], Loss: 2.7536e-05\n",
      "Epoch [70/100], Loss: 7.4944e-05\n",
      "Epoch [80/100], Loss: 1.5305e-04\n",
      "Epoch [90/100], Loss: 2.6676e-04\n",
      "Epoch [100/100], Loss: 3.5343e-04\n",
      "#####--training model 25--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.1486e-03\n",
      "Epoch [20/100], Loss: 1.8056e-03\n",
      "Epoch [30/100], Loss: 4.5281e-04\n",
      "Epoch [40/100], Loss: 5.0322e-05\n",
      "Epoch [50/100], Loss: 2.7541e-05\n",
      "Epoch [60/100], Loss: 6.7999e-05\n",
      "Epoch [70/100], Loss: 8.8212e-05\n",
      "Epoch [80/100], Loss: 9.8502e-05\n",
      "Epoch [90/100], Loss: 1.0519e-04\n",
      "Epoch [100/100], Loss: 1.0189e-04\n",
      "#####--training model 26--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0353e-04\n",
      "Epoch [20/100], Loss: 2.1693e-04\n",
      "Epoch [30/100], Loss: 2.3607e-04\n",
      "Epoch [40/100], Loss: 2.2339e-04\n",
      "Epoch [50/100], Loss: 2.1244e-04\n",
      "Epoch [60/100], Loss: 1.9267e-04\n",
      "Epoch [70/100], Loss: 1.7286e-04\n",
      "Epoch [80/100], Loss: 1.7547e-04\n",
      "Epoch [90/100], Loss: 2.0905e-04\n",
      "Epoch [100/100], Loss: 2.6244e-04\n",
      "#####--training model 27--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.6691e-04\n",
      "Epoch [20/100], Loss: 4.3920e-04\n",
      "Epoch [30/100], Loss: 4.4040e-04\n",
      "Epoch [40/100], Loss: 3.6658e-04\n",
      "Epoch [50/100], Loss: 2.9569e-04\n",
      "Epoch [60/100], Loss: 2.5055e-04\n",
      "Epoch [70/100], Loss: 2.3572e-04\n",
      "Epoch [80/100], Loss: 2.3729e-04\n",
      "Epoch [90/100], Loss: 2.4266e-04\n",
      "Epoch [100/100], Loss: 2.4963e-04\n",
      "#####--training model 28--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7136e-04\n",
      "Epoch [20/100], Loss: 2.8189e-04\n",
      "Epoch [30/100], Loss: 3.0249e-04\n",
      "Epoch [40/100], Loss: 2.8175e-04\n",
      "Epoch [50/100], Loss: 2.7614e-04\n",
      "Epoch [60/100], Loss: 2.6526e-04\n",
      "Epoch [70/100], Loss: 2.3743e-04\n",
      "Epoch [80/100], Loss: 2.1930e-04\n",
      "Epoch [90/100], Loss: 2.1493e-04\n",
      "Epoch [100/100], Loss: 2.1657e-04\n",
      "#####--training model 29--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.8029e-04\n",
      "Epoch [20/100], Loss: 1.8268e-04\n",
      "Epoch [30/100], Loss: 1.5617e-04\n",
      "Epoch [40/100], Loss: 1.4040e-04\n",
      "Epoch [50/100], Loss: 1.4904e-04\n",
      "Epoch [60/100], Loss: 1.7161e-04\n",
      "Epoch [70/100], Loss: 1.8194e-04\n",
      "Epoch [80/100], Loss: 1.8185e-04\n",
      "Epoch [90/100], Loss: 1.8786e-04\n",
      "Epoch [100/100], Loss: 1.9828e-04\n",
      "#####--training model 30--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.3003e-03\n",
      "Epoch [20/100], Loss: 3.3250e-03\n",
      "Epoch [30/100], Loss: 2.7526e-03\n",
      "Epoch [40/100], Loss: 2.1238e-03\n",
      "Epoch [50/100], Loss: 1.7562e-03\n",
      "Epoch [60/100], Loss: 1.5159e-03\n",
      "Epoch [70/100], Loss: 1.3157e-03\n",
      "Epoch [80/100], Loss: 1.1373e-03\n",
      "Epoch [90/100], Loss: 9.7903e-04\n",
      "Epoch [100/100], Loss: 8.5200e-04\n",
      "#####--training model 31--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.8412e-04\n",
      "Epoch [20/100], Loss: 2.4540e-04\n",
      "Epoch [30/100], Loss: 2.1485e-04\n",
      "Epoch [40/100], Loss: 1.9260e-04\n",
      "Epoch [50/100], Loss: 1.5980e-04\n",
      "Epoch [60/100], Loss: 1.2105e-04\n",
      "Epoch [70/100], Loss: 8.7428e-05\n",
      "Epoch [80/100], Loss: 6.7043e-05\n",
      "Epoch [90/100], Loss: 6.2324e-05\n",
      "Epoch [100/100], Loss: 6.2382e-05\n",
      "#####--training model 32--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1615e-03\n",
      "Epoch [20/100], Loss: 4.2483e-04\n",
      "Epoch [30/100], Loss: 3.6868e-04\n",
      "Epoch [40/100], Loss: 3.1513e-04\n",
      "Epoch [50/100], Loss: 2.8029e-04\n",
      "Epoch [60/100], Loss: 2.3981e-04\n",
      "Epoch [70/100], Loss: 1.8189e-04\n",
      "Epoch [80/100], Loss: 1.4351e-04\n",
      "Epoch [90/100], Loss: 1.3788e-04\n",
      "Epoch [100/100], Loss: 1.3642e-04\n",
      "#####--training model 33--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7909e-04\n",
      "Epoch [20/100], Loss: 6.3156e-05\n",
      "Epoch [30/100], Loss: 4.8886e-05\n",
      "Epoch [40/100], Loss: 4.3539e-05\n",
      "Epoch [50/100], Loss: 4.3389e-05\n",
      "Epoch [60/100], Loss: 4.4947e-05\n",
      "Epoch [70/100], Loss: 4.5700e-05\n",
      "Epoch [80/100], Loss: 4.3065e-05\n",
      "Epoch [90/100], Loss: 4.0620e-05\n",
      "Epoch [100/100], Loss: 4.0428e-05\n",
      "#####--training model 34--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.2764e-05\n",
      "Epoch [20/100], Loss: 6.6921e-05\n",
      "Epoch [30/100], Loss: 6.2853e-05\n",
      "Epoch [40/100], Loss: 7.0739e-05\n",
      "Epoch [50/100], Loss: 7.5576e-05\n",
      "Epoch [60/100], Loss: 6.8135e-05\n",
      "Epoch [70/100], Loss: 5.1726e-05\n",
      "Epoch [80/100], Loss: 3.7614e-05\n",
      "Epoch [90/100], Loss: 3.2935e-05\n",
      "Epoch [100/100], Loss: 3.4850e-05\n",
      "#####--training model 35--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.5661e-03\n",
      "Epoch [20/100], Loss: 4.7122e-03\n",
      "Epoch [30/100], Loss: 3.0098e-03\n",
      "Epoch [40/100], Loss: 2.4528e-03\n",
      "Epoch [50/100], Loss: 2.0286e-03\n",
      "Epoch [60/100], Loss: 1.6745e-03\n",
      "Epoch [70/100], Loss: 1.2804e-03\n",
      "Epoch [80/100], Loss: 1.0282e-03\n",
      "Epoch [90/100], Loss: 9.4112e-04\n",
      "Epoch [100/100], Loss: 8.7738e-04\n",
      "#####--training model 36--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.6928e-03\n",
      "Epoch [20/100], Loss: 9.2836e-04\n",
      "Epoch [30/100], Loss: 9.9293e-04\n",
      "Epoch [40/100], Loss: 1.0977e-03\n",
      "Epoch [50/100], Loss: 1.2455e-03\n",
      "Epoch [60/100], Loss: 1.4183e-03\n",
      "Epoch [70/100], Loss: 1.5566e-03\n",
      "Epoch [80/100], Loss: 1.6378e-03\n",
      "Epoch [90/100], Loss: 1.6649e-03\n",
      "Epoch [100/100], Loss: 1.6622e-03\n",
      "#####--training model 37--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.1677e-03\n",
      "Epoch [20/100], Loss: 1.2241e-03\n",
      "Epoch [30/100], Loss: 1.3678e-03\n",
      "Epoch [40/100], Loss: 1.5430e-03\n",
      "Epoch [50/100], Loss: 1.7577e-03\n",
      "Epoch [60/100], Loss: 1.9452e-03\n",
      "Epoch [70/100], Loss: 2.0504e-03\n",
      "Epoch [80/100], Loss: 2.0987e-03\n",
      "Epoch [90/100], Loss: 2.1084e-03\n",
      "Epoch [100/100], Loss: 2.0997e-03\n",
      "#####--training model 38--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.1543e-03\n",
      "Epoch [20/100], Loss: 3.0471e-03\n",
      "Epoch [30/100], Loss: 3.1128e-03\n",
      "Epoch [40/100], Loss: 3.2146e-03\n",
      "Epoch [50/100], Loss: 3.2967e-03\n",
      "Epoch [60/100], Loss: 3.3258e-03\n",
      "Epoch [70/100], Loss: 3.2639e-03\n",
      "Epoch [80/100], Loss: 3.1362e-03\n",
      "Epoch [90/100], Loss: 3.0312e-03\n",
      "Epoch [100/100], Loss: 2.9557e-03\n",
      "#####--training model 39--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.0155e-03\n",
      "Epoch [20/100], Loss: 2.0683e-03\n",
      "Epoch [30/100], Loss: 2.1389e-03\n",
      "Epoch [40/100], Loss: 2.2070e-03\n",
      "Epoch [50/100], Loss: 2.2266e-03\n",
      "Epoch [60/100], Loss: 2.1820e-03\n",
      "Epoch [70/100], Loss: 2.1169e-03\n",
      "Epoch [80/100], Loss: 1.9616e-03\n",
      "Epoch [90/100], Loss: 2.6234e-03\n",
      "Epoch [100/100], Loss: 3.0917e-03\n",
      "#####--training model 40--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0804e-02\n",
      "Epoch [20/100], Loss: 2.2334e-03\n",
      "Epoch [30/100], Loss: 1.1665e-03\n",
      "Epoch [40/100], Loss: 7.7661e-04\n",
      "Epoch [50/100], Loss: 5.6101e-04\n",
      "Epoch [60/100], Loss: 4.0132e-04\n",
      "Epoch [70/100], Loss: 2.8629e-04\n",
      "Epoch [80/100], Loss: 1.8548e-04\n",
      "Epoch [90/100], Loss: 1.1478e-04\n",
      "Epoch [100/100], Loss: 8.5320e-05\n",
      "#####--training model 41--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3226e-04\n",
      "Epoch [20/100], Loss: 3.9468e-04\n",
      "Epoch [30/100], Loss: 4.4447e-04\n",
      "Epoch [40/100], Loss: 3.6051e-04\n",
      "Epoch [50/100], Loss: 2.8453e-04\n",
      "Epoch [60/100], Loss: 2.1687e-04\n",
      "Epoch [70/100], Loss: 1.4448e-04\n",
      "Epoch [80/100], Loss: 9.9355e-05\n",
      "Epoch [90/100], Loss: 7.0595e-05\n",
      "Epoch [100/100], Loss: 5.1426e-05\n",
      "#####--training model 42--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8072e-04\n",
      "Epoch [20/100], Loss: 1.4973e-04\n",
      "Epoch [30/100], Loss: 1.7303e-04\n",
      "Epoch [40/100], Loss: 1.9971e-04\n",
      "Epoch [50/100], Loss: 1.8410e-04\n",
      "Epoch [60/100], Loss: 1.4334e-04\n",
      "Epoch [70/100], Loss: 1.0763e-04\n",
      "Epoch [80/100], Loss: 9.1550e-05\n",
      "Epoch [90/100], Loss: 8.4634e-05\n",
      "Epoch [100/100], Loss: 8.0470e-05\n",
      "#####--training model 43--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1157e-03\n",
      "Epoch [20/100], Loss: 1.3694e-03\n",
      "Epoch [30/100], Loss: 1.4587e-03\n",
      "Epoch [40/100], Loss: 1.4281e-03\n",
      "Epoch [50/100], Loss: 1.3230e-03\n",
      "Epoch [60/100], Loss: 1.1991e-03\n",
      "Epoch [70/100], Loss: 1.1142e-03\n",
      "Epoch [80/100], Loss: 1.0757e-03\n",
      "Epoch [90/100], Loss: 1.0603e-03\n",
      "Epoch [100/100], Loss: 1.0525e-03\n",
      "#####--training model 44--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0348e-03\n",
      "Epoch [20/100], Loss: 1.1496e-03\n",
      "Epoch [30/100], Loss: 1.2998e-03\n",
      "Epoch [40/100], Loss: 1.2961e-03\n",
      "Epoch [50/100], Loss: 1.1437e-03\n",
      "Epoch [60/100], Loss: 9.9815e-04\n",
      "Epoch [70/100], Loss: 9.2552e-04\n",
      "Epoch [80/100], Loss: 8.9462e-04\n",
      "Epoch [90/100], Loss: 8.8008e-04\n",
      "Epoch [100/100], Loss: 8.7215e-04\n",
      "#####--training model 45--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.1432e-03\n",
      "Epoch [20/100], Loss: 5.2725e-03\n",
      "Epoch [30/100], Loss: 5.4543e-03\n",
      "Epoch [40/100], Loss: 4.6932e-03\n",
      "Epoch [50/100], Loss: 2.2638e-03\n",
      "Epoch [60/100], Loss: 1.3994e-03\n",
      "Epoch [70/100], Loss: 1.0940e-03\n",
      "Epoch [80/100], Loss: 8.8076e-04\n",
      "Epoch [90/100], Loss: 6.8945e-04\n",
      "Epoch [100/100], Loss: 5.1300e-04\n",
      "#####--training model 46--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2400e-04\n",
      "Epoch [20/100], Loss: 1.6743e-04\n",
      "Epoch [30/100], Loss: 1.8492e-04\n",
      "Epoch [40/100], Loss: 1.8084e-04\n",
      "Epoch [50/100], Loss: 1.7088e-04\n",
      "Epoch [60/100], Loss: 1.5125e-04\n",
      "Epoch [70/100], Loss: 1.2130e-04\n",
      "Epoch [80/100], Loss: 9.2070e-05\n",
      "Epoch [90/100], Loss: 7.6426e-05\n",
      "Epoch [100/100], Loss: 8.2251e-05\n",
      "#####--training model 47--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5483e-04\n",
      "Epoch [20/100], Loss: 2.2080e-04\n",
      "Epoch [30/100], Loss: 2.5126e-04\n",
      "Epoch [40/100], Loss: 2.5406e-04\n",
      "Epoch [50/100], Loss: 2.2369e-04\n",
      "Epoch [60/100], Loss: 1.7956e-04\n",
      "Epoch [70/100], Loss: 1.6913e-04\n",
      "Epoch [80/100], Loss: 1.8282e-04\n",
      "Epoch [90/100], Loss: 1.9171e-04\n",
      "Epoch [100/100], Loss: 1.8968e-04\n",
      "#####--training model 48--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.7208e-04\n",
      "Epoch [20/100], Loss: 5.8314e-04\n",
      "Epoch [30/100], Loss: 7.5664e-04\n",
      "Epoch [40/100], Loss: 8.5484e-04\n",
      "Epoch [50/100], Loss: 8.7026e-04\n",
      "Epoch [60/100], Loss: 8.2013e-04\n",
      "Epoch [70/100], Loss: 7.3245e-04\n",
      "Epoch [80/100], Loss: 6.3906e-04\n",
      "Epoch [90/100], Loss: 5.6826e-04\n",
      "Epoch [100/100], Loss: 5.2489e-04\n",
      "#####--training model 49--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.9759e-04\n",
      "Epoch [20/100], Loss: 4.1914e-04\n",
      "Epoch [30/100], Loss: 5.1455e-04\n",
      "Epoch [40/100], Loss: 5.6322e-04\n",
      "Epoch [50/100], Loss: 6.3215e-04\n",
      "Epoch [60/100], Loss: 6.0066e-04\n",
      "Epoch [70/100], Loss: 5.3754e-04\n",
      "Epoch [80/100], Loss: 5.2029e-04\n",
      "Epoch [90/100], Loss: 5.1958e-04\n",
      "Epoch [100/100], Loss: 5.1813e-04\n",
      "#####--training model 50--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.7576e-02\n",
      "Epoch [20/100], Loss: 4.1606e-02\n",
      "Epoch [30/100], Loss: 3.0843e-02\n",
      "Epoch [40/100], Loss: 2.6766e-02\n",
      "Epoch [50/100], Loss: 2.5034e-02\n",
      "Epoch [60/100], Loss: 2.4292e-02\n",
      "Epoch [70/100], Loss: 2.4008e-02\n",
      "Epoch [80/100], Loss: 2.3591e-02\n",
      "Epoch [90/100], Loss: 2.2789e-02\n",
      "Epoch [100/100], Loss: 2.1969e-02\n",
      "#####--training model 51--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0995e-03\n",
      "Epoch [20/100], Loss: 1.3434e-03\n",
      "Epoch [30/100], Loss: 1.6399e-03\n",
      "Epoch [40/100], Loss: 1.5739e-03\n",
      "Epoch [50/100], Loss: 1.4015e-03\n",
      "Epoch [60/100], Loss: 1.2452e-03\n",
      "Epoch [70/100], Loss: 1.1293e-03\n",
      "Epoch [80/100], Loss: 1.0627e-03\n",
      "Epoch [90/100], Loss: 1.0306e-03\n",
      "Epoch [100/100], Loss: 1.0177e-03\n",
      "#####--training model 52--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.8179e-04\n",
      "Epoch [20/100], Loss: 1.2500e-03\n",
      "Epoch [30/100], Loss: 1.5165e-03\n",
      "Epoch [40/100], Loss: 1.5246e-03\n",
      "Epoch [50/100], Loss: 1.4114e-03\n",
      "Epoch [60/100], Loss: 1.2473e-03\n",
      "Epoch [70/100], Loss: 1.1278e-03\n",
      "Epoch [80/100], Loss: 1.0815e-03\n",
      "Epoch [90/100], Loss: 1.0676e-03\n",
      "Epoch [100/100], Loss: 1.0629e-03\n",
      "#####--training model 53--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.1572e-04\n",
      "Epoch [20/100], Loss: 3.4387e-04\n",
      "Epoch [30/100], Loss: 4.0080e-04\n",
      "Epoch [40/100], Loss: 4.4814e-04\n",
      "Epoch [50/100], Loss: 4.5762e-04\n",
      "Epoch [60/100], Loss: 4.3465e-04\n",
      "Epoch [70/100], Loss: 4.1746e-04\n",
      "Epoch [80/100], Loss: 4.0552e-04\n",
      "Epoch [90/100], Loss: 3.9489e-04\n",
      "Epoch [100/100], Loss: 3.8120e-04\n",
      "#####--training model 54--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0947e-04\n",
      "Epoch [20/100], Loss: 3.9532e-04\n",
      "Epoch [30/100], Loss: 3.8213e-04\n",
      "Epoch [40/100], Loss: 3.5360e-04\n",
      "Epoch [50/100], Loss: 3.2219e-04\n",
      "Epoch [60/100], Loss: 2.9477e-04\n",
      "Epoch [70/100], Loss: 2.7948e-04\n",
      "Epoch [80/100], Loss: 2.7096e-04\n",
      "Epoch [90/100], Loss: 2.6176e-04\n",
      "Epoch [100/100], Loss: 2.5013e-04\n",
      "#####--training model 55--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.2404e-03\n",
      "Epoch [20/100], Loss: 4.9832e-04\n",
      "Epoch [30/100], Loss: 5.0873e-04\n",
      "Epoch [40/100], Loss: 5.4257e-04\n",
      "Epoch [50/100], Loss: 5.8408e-04\n",
      "Epoch [60/100], Loss: 6.4403e-04\n",
      "Epoch [70/100], Loss: 6.8915e-04\n",
      "Epoch [80/100], Loss: 7.1731e-04\n",
      "Epoch [90/100], Loss: 7.3811e-04\n",
      "Epoch [100/100], Loss: 7.5646e-04\n",
      "#####--training model 56--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.6342e-04\n",
      "Epoch [20/100], Loss: 4.0174e-04\n",
      "Epoch [30/100], Loss: 4.0529e-04\n",
      "Epoch [40/100], Loss: 3.0399e-04\n",
      "Epoch [50/100], Loss: 2.2046e-04\n",
      "Epoch [60/100], Loss: 2.2703e-04\n",
      "Epoch [70/100], Loss: 2.7580e-04\n",
      "Epoch [80/100], Loss: 3.2445e-04\n",
      "Epoch [90/100], Loss: 3.5300e-04\n",
      "Epoch [100/100], Loss: 3.6067e-04\n",
      "#####--training model 57--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.5621e-04\n",
      "Epoch [20/100], Loss: 3.7834e-04\n",
      "Epoch [30/100], Loss: 2.9024e-04\n",
      "Epoch [40/100], Loss: 3.0539e-04\n",
      "Epoch [50/100], Loss: 2.9039e-04\n",
      "Epoch [60/100], Loss: 2.3583e-04\n",
      "Epoch [70/100], Loss: 1.7755e-04\n",
      "Epoch [80/100], Loss: 1.3930e-04\n",
      "Epoch [90/100], Loss: 1.3192e-04\n",
      "Epoch [100/100], Loss: 1.4396e-04\n",
      "#####--training model 58--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5111e-03\n",
      "Epoch [20/100], Loss: 1.2490e-03\n",
      "Epoch [30/100], Loss: 1.2795e-03\n",
      "Epoch [40/100], Loss: 1.3512e-03\n",
      "Epoch [50/100], Loss: 1.2879e-03\n",
      "Epoch [60/100], Loss: 1.1766e-03\n",
      "Epoch [70/100], Loss: 1.0979e-03\n",
      "Epoch [80/100], Loss: 1.0450e-03\n",
      "Epoch [90/100], Loss: 1.0032e-03\n",
      "Epoch [100/100], Loss: 9.6250e-04\n",
      "#####--training model 59--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5611e-03\n",
      "Epoch [20/100], Loss: 1.7020e-03\n",
      "Epoch [30/100], Loss: 1.9406e-03\n",
      "Epoch [40/100], Loss: 2.0889e-03\n",
      "Epoch [50/100], Loss: 2.0968e-03\n",
      "Epoch [60/100], Loss: 1.9910e-03\n",
      "Epoch [70/100], Loss: 1.8542e-03\n",
      "Epoch [80/100], Loss: 1.7384e-03\n",
      "Epoch [90/100], Loss: 1.6533e-03\n",
      "Epoch [100/100], Loss: 1.5898e-03\n",
      "#####--training model 60--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.8272e-03\n",
      "Epoch [20/100], Loss: 1.9408e-03\n",
      "Epoch [30/100], Loss: 9.8486e-04\n",
      "Epoch [40/100], Loss: 5.9197e-04\n",
      "Epoch [50/100], Loss: 4.3815e-04\n",
      "Epoch [60/100], Loss: 3.4501e-04\n",
      "Epoch [70/100], Loss: 7.0418e-04\n",
      "Epoch [80/100], Loss: 7.9637e-04\n",
      "Epoch [90/100], Loss: 8.2645e-04\n",
      "Epoch [100/100], Loss: 8.3998e-04\n",
      "#####--training model 61--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.5522e-03\n",
      "Epoch [20/100], Loss: 1.5977e-03\n",
      "Epoch [30/100], Loss: 1.2556e-03\n",
      "Epoch [40/100], Loss: 9.1439e-04\n",
      "Epoch [50/100], Loss: 4.9475e-04\n",
      "Epoch [60/100], Loss: 4.4503e-04\n",
      "Epoch [70/100], Loss: 5.1135e-04\n",
      "Epoch [80/100], Loss: 5.9066e-04\n",
      "Epoch [90/100], Loss: 6.2745e-04\n",
      "Epoch [100/100], Loss: 6.1131e-04\n",
      "#####--training model 62--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9779e-03\n",
      "Epoch [20/100], Loss: 9.9816e-04\n",
      "Epoch [30/100], Loss: 6.8142e-04\n",
      "Epoch [40/100], Loss: 4.0438e-04\n",
      "Epoch [50/100], Loss: 3.5857e-04\n",
      "Epoch [60/100], Loss: 3.6417e-04\n",
      "Epoch [70/100], Loss: 4.1089e-04\n",
      "Epoch [80/100], Loss: 4.3664e-04\n",
      "Epoch [90/100], Loss: 4.2157e-04\n",
      "Epoch [100/100], Loss: 3.9028e-04\n",
      "#####--training model 63--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1431e-02\n",
      "Epoch [20/100], Loss: 1.1364e-03\n",
      "Epoch [30/100], Loss: 8.5486e-04\n",
      "Epoch [40/100], Loss: 3.1773e-04\n",
      "Epoch [50/100], Loss: 2.3619e-04\n",
      "Epoch [60/100], Loss: 2.2279e-04\n",
      "Epoch [70/100], Loss: 2.4375e-04\n",
      "Epoch [80/100], Loss: 2.3507e-04\n",
      "Epoch [90/100], Loss: 1.9009e-04\n",
      "Epoch [100/100], Loss: 1.5657e-04\n",
      "#####--training model 64--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.3813e-03\n",
      "Epoch [20/100], Loss: 4.4550e-04\n",
      "Epoch [30/100], Loss: 1.6545e-04\n",
      "Epoch [40/100], Loss: 1.2111e-04\n",
      "Epoch [50/100], Loss: 1.0757e-04\n",
      "Epoch [60/100], Loss: 1.0239e-04\n",
      "Epoch [70/100], Loss: 7.7826e-05\n",
      "Epoch [80/100], Loss: 6.7053e-05\n",
      "Epoch [90/100], Loss: 6.5850e-05\n",
      "Epoch [100/100], Loss: 6.8415e-05\n",
      "#####--training model 65--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.4271e-02\n",
      "Epoch [20/100], Loss: 6.8045e-03\n",
      "Epoch [30/100], Loss: 1.0242e-03\n",
      "Epoch [40/100], Loss: 3.8521e-04\n",
      "Epoch [50/100], Loss: 9.3261e-04\n",
      "Epoch [60/100], Loss: 9.8921e-04\n",
      "Epoch [70/100], Loss: 9.6702e-04\n",
      "Epoch [80/100], Loss: 8.6381e-04\n",
      "Epoch [90/100], Loss: 6.5363e-04\n",
      "Epoch [100/100], Loss: 4.8451e-04\n",
      "#####--training model 66--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.7150e-03\n",
      "Epoch [20/100], Loss: 2.3591e-03\n",
      "Epoch [30/100], Loss: 1.5162e-03\n",
      "Epoch [40/100], Loss: 1.1582e-03\n",
      "Epoch [50/100], Loss: 9.5687e-04\n",
      "Epoch [60/100], Loss: 8.3532e-04\n",
      "Epoch [70/100], Loss: 7.6043e-04\n",
      "Epoch [80/100], Loss: 7.1110e-04\n",
      "Epoch [90/100], Loss: 6.7349e-04\n",
      "Epoch [100/100], Loss: 6.0272e-04\n",
      "#####--training model 67--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0311e-02\n",
      "Epoch [20/100], Loss: 2.6226e-03\n",
      "Epoch [30/100], Loss: 1.6472e-03\n",
      "Epoch [40/100], Loss: 1.2351e-03\n",
      "Epoch [50/100], Loss: 9.9251e-04\n",
      "Epoch [60/100], Loss: 7.7662e-04\n",
      "Epoch [70/100], Loss: 4.9310e-04\n",
      "Epoch [80/100], Loss: 3.7593e-04\n",
      "Epoch [90/100], Loss: 3.3821e-04\n",
      "Epoch [100/100], Loss: 3.2149e-04\n",
      "#####--training model 68--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9612e-02\n",
      "Epoch [20/100], Loss: 1.6919e-03\n",
      "Epoch [30/100], Loss: 1.2773e-03\n",
      "Epoch [40/100], Loss: 1.0629e-03\n",
      "Epoch [50/100], Loss: 8.1151e-04\n",
      "Epoch [60/100], Loss: 7.0577e-04\n",
      "Epoch [70/100], Loss: 4.8308e-04\n",
      "Epoch [80/100], Loss: 2.3723e-04\n",
      "Epoch [90/100], Loss: 2.6176e-04\n",
      "Epoch [100/100], Loss: 3.6193e-04\n",
      "#####--training model 69--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5802e-02\n",
      "Epoch [20/100], Loss: 1.6632e-03\n",
      "Epoch [30/100], Loss: 9.2739e-04\n",
      "Epoch [40/100], Loss: 5.1505e-04\n",
      "Epoch [50/100], Loss: 4.8551e-04\n",
      "Epoch [60/100], Loss: 2.5070e-04\n",
      "Epoch [70/100], Loss: 4.0588e-04\n",
      "Epoch [80/100], Loss: 5.1935e-04\n",
      "Epoch [90/100], Loss: 4.4374e-04\n",
      "Epoch [100/100], Loss: 4.0309e-04\n",
      "#####--training model 70--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1438e-03\n",
      "Epoch [20/100], Loss: 6.2935e-04\n",
      "Epoch [30/100], Loss: 4.5656e-04\n",
      "Epoch [40/100], Loss: 3.5041e-04\n",
      "Epoch [50/100], Loss: 2.6804e-04\n",
      "Epoch [60/100], Loss: 2.0922e-04\n",
      "Epoch [70/100], Loss: 1.7120e-04\n",
      "Epoch [80/100], Loss: 1.4676e-04\n",
      "Epoch [90/100], Loss: 1.3156e-04\n",
      "Epoch [100/100], Loss: 1.2559e-04\n",
      "#####--training model 71--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2224e-02\n",
      "Epoch [20/100], Loss: 3.2292e-03\n",
      "Epoch [30/100], Loss: 2.3413e-03\n",
      "Epoch [40/100], Loss: 1.9540e-03\n",
      "Epoch [50/100], Loss: 1.6828e-03\n",
      "Epoch [60/100], Loss: 1.4691e-03\n",
      "Epoch [70/100], Loss: 1.3098e-03\n",
      "Epoch [80/100], Loss: 1.2012e-03\n",
      "Epoch [90/100], Loss: 1.1509e-03\n",
      "Epoch [100/100], Loss: 1.1377e-03\n",
      "#####--training model 72--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1814e-02\n",
      "Epoch [20/100], Loss: 3.4456e-03\n",
      "Epoch [30/100], Loss: 2.3603e-03\n",
      "Epoch [40/100], Loss: 1.8293e-03\n",
      "Epoch [50/100], Loss: 1.4765e-03\n",
      "Epoch [60/100], Loss: 1.2260e-03\n",
      "Epoch [70/100], Loss: 1.0528e-03\n",
      "Epoch [80/100], Loss: 9.3474e-04\n",
      "Epoch [90/100], Loss: 8.5157e-04\n",
      "Epoch [100/100], Loss: 7.8933e-04\n",
      "#####--training model 73--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.4985e-03\n",
      "Epoch [20/100], Loss: 4.9399e-03\n",
      "Epoch [30/100], Loss: 3.7767e-03\n",
      "Epoch [40/100], Loss: 3.1310e-03\n",
      "Epoch [50/100], Loss: 2.6976e-03\n",
      "Epoch [60/100], Loss: 2.3715e-03\n",
      "Epoch [70/100], Loss: 2.0798e-03\n",
      "Epoch [80/100], Loss: 1.7965e-03\n",
      "Epoch [90/100], Loss: 1.5112e-03\n",
      "Epoch [100/100], Loss: 1.2310e-03\n",
      "#####--training model 74--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.5160e-03\n",
      "Epoch [20/100], Loss: 3.2638e-03\n",
      "Epoch [30/100], Loss: 2.4609e-03\n",
      "Epoch [40/100], Loss: 2.0352e-03\n",
      "Epoch [50/100], Loss: 1.8235e-03\n",
      "Epoch [60/100], Loss: 1.6600e-03\n",
      "Epoch [70/100], Loss: 1.5225e-03\n",
      "Epoch [80/100], Loss: 1.4031e-03\n",
      "Epoch [90/100], Loss: 1.2925e-03\n",
      "Epoch [100/100], Loss: 1.1838e-03\n",
      "#####--training model 75--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2482e-02\n",
      "Epoch [20/100], Loss: 1.2519e-02\n",
      "Epoch [30/100], Loss: 1.1534e-02\n",
      "Epoch [40/100], Loss: 9.6704e-03\n",
      "Epoch [50/100], Loss: 7.7848e-03\n",
      "Epoch [60/100], Loss: 6.5219e-03\n",
      "Epoch [70/100], Loss: 5.9494e-03\n",
      "Epoch [80/100], Loss: 5.6903e-03\n",
      "Epoch [90/100], Loss: 5.5690e-03\n",
      "Epoch [100/100], Loss: 5.5092e-03\n",
      "#####--training model 76--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5495e-02\n",
      "Epoch [20/100], Loss: 1.3632e-02\n",
      "Epoch [30/100], Loss: 1.1096e-02\n",
      "Epoch [40/100], Loss: 9.6310e-03\n",
      "Epoch [50/100], Loss: 8.5753e-03\n",
      "Epoch [60/100], Loss: 7.4744e-03\n",
      "Epoch [70/100], Loss: 6.3198e-03\n",
      "Epoch [80/100], Loss: 5.4156e-03\n",
      "Epoch [90/100], Loss: 4.8078e-03\n",
      "Epoch [100/100], Loss: 4.3409e-03\n",
      "#####--training model 77--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4385e-02\n",
      "Epoch [20/100], Loss: 1.3672e-02\n",
      "Epoch [30/100], Loss: 1.1208e-02\n",
      "Epoch [40/100], Loss: 9.1292e-03\n",
      "Epoch [50/100], Loss: 7.6180e-03\n",
      "Epoch [60/100], Loss: 6.7047e-03\n",
      "Epoch [70/100], Loss: 6.2055e-03\n",
      "Epoch [80/100], Loss: 5.8620e-03\n",
      "Epoch [90/100], Loss: 5.5625e-03\n",
      "Epoch [100/100], Loss: 5.2648e-03\n",
      "#####--training model 78--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.6480e-03\n",
      "Epoch [20/100], Loss: 8.2875e-03\n",
      "Epoch [30/100], Loss: 6.9954e-03\n",
      "Epoch [40/100], Loss: 5.7539e-03\n",
      "Epoch [50/100], Loss: 4.8840e-03\n",
      "Epoch [60/100], Loss: 4.2059e-03\n",
      "Epoch [70/100], Loss: 3.6034e-03\n",
      "Epoch [80/100], Loss: 3.1083e-03\n",
      "Epoch [90/100], Loss: 2.7832e-03\n",
      "Epoch [100/100], Loss: 2.5903e-03\n",
      "#####--training model 79--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2327e-02\n",
      "Epoch [20/100], Loss: 1.0649e-02\n",
      "Epoch [30/100], Loss: 8.8103e-03\n",
      "Epoch [40/100], Loss: 7.5285e-03\n",
      "Epoch [50/100], Loss: 6.6089e-03\n",
      "Epoch [60/100], Loss: 5.9004e-03\n",
      "Epoch [70/100], Loss: 5.1960e-03\n",
      "Epoch [80/100], Loss: 4.4550e-03\n",
      "Epoch [90/100], Loss: 3.9988e-03\n",
      "Epoch [100/100], Loss: 3.8200e-03\n",
      "#####--training model 80--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.7106e-03\n",
      "Epoch [20/100], Loss: 4.3605e-03\n",
      "Epoch [30/100], Loss: 3.5714e-03\n",
      "Epoch [40/100], Loss: 2.7524e-03\n",
      "Epoch [50/100], Loss: 1.6632e-03\n",
      "Epoch [60/100], Loss: 9.0657e-04\n",
      "Epoch [70/100], Loss: 5.2101e-04\n",
      "Epoch [80/100], Loss: 3.9774e-04\n",
      "Epoch [90/100], Loss: 4.3414e-04\n",
      "Epoch [100/100], Loss: 4.8539e-04\n",
      "#####--training model 81--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.0178e-03\n",
      "Epoch [20/100], Loss: 3.1095e-03\n",
      "Epoch [30/100], Loss: 2.5807e-03\n",
      "Epoch [40/100], Loss: 2.3769e-03\n",
      "Epoch [50/100], Loss: 2.2750e-03\n",
      "Epoch [60/100], Loss: 2.1694e-03\n",
      "Epoch [70/100], Loss: 1.9461e-03\n",
      "Epoch [80/100], Loss: 1.7558e-03\n",
      "Epoch [90/100], Loss: 1.6177e-03\n",
      "Epoch [100/100], Loss: 1.4460e-03\n",
      "#####--training model 82--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.5370e-03\n",
      "Epoch [20/100], Loss: 3.4402e-03\n",
      "Epoch [30/100], Loss: 2.8518e-03\n",
      "Epoch [40/100], Loss: 2.5551e-03\n",
      "Epoch [50/100], Loss: 2.4316e-03\n",
      "Epoch [60/100], Loss: 2.3557e-03\n",
      "Epoch [70/100], Loss: 2.2720e-03\n",
      "Epoch [80/100], Loss: 2.1753e-03\n",
      "Epoch [90/100], Loss: 1.9609e-03\n",
      "Epoch [100/100], Loss: 1.6601e-03\n",
      "#####--training model 83--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3591e-03\n",
      "Epoch [20/100], Loss: 7.2776e-04\n",
      "Epoch [30/100], Loss: 3.6608e-04\n",
      "Epoch [40/100], Loss: 1.9029e-04\n",
      "Epoch [50/100], Loss: 1.6710e-04\n",
      "Epoch [60/100], Loss: 1.7601e-04\n",
      "Epoch [70/100], Loss: 1.8709e-04\n",
      "Epoch [80/100], Loss: 1.9694e-04\n",
      "Epoch [90/100], Loss: 2.0529e-04\n",
      "Epoch [100/100], Loss: 2.1172e-04\n",
      "#####--training model 84--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.2150e-03\n",
      "Epoch [20/100], Loss: 1.2232e-03\n",
      "Epoch [30/100], Loss: 5.4818e-04\n",
      "Epoch [40/100], Loss: 2.7171e-04\n",
      "Epoch [50/100], Loss: 1.5421e-04\n",
      "Epoch [60/100], Loss: 1.1963e-04\n",
      "Epoch [70/100], Loss: 1.2792e-04\n",
      "Epoch [80/100], Loss: 1.4818e-04\n",
      "Epoch [90/100], Loss: 1.6335e-04\n",
      "Epoch [100/100], Loss: 1.7046e-04\n",
      "#####--training model 85--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5024e-02\n",
      "Epoch [20/100], Loss: 3.8862e-03\n",
      "Epoch [30/100], Loss: 2.8235e-03\n",
      "Epoch [40/100], Loss: 2.0884e-03\n",
      "Epoch [50/100], Loss: 1.6398e-03\n",
      "Epoch [60/100], Loss: 1.4070e-03\n",
      "Epoch [70/100], Loss: 1.2439e-03\n",
      "Epoch [80/100], Loss: 1.1305e-03\n",
      "Epoch [90/100], Loss: 1.0967e-03\n",
      "Epoch [100/100], Loss: 1.1481e-03\n",
      "#####--training model 86--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.1945e-03\n",
      "Epoch [20/100], Loss: 3.3859e-03\n",
      "Epoch [30/100], Loss: 2.4864e-03\n",
      "Epoch [40/100], Loss: 1.9191e-03\n",
      "Epoch [50/100], Loss: 1.5639e-03\n",
      "Epoch [60/100], Loss: 1.3282e-03\n",
      "Epoch [70/100], Loss: 1.1530e-03\n",
      "Epoch [80/100], Loss: 1.0154e-03\n",
      "Epoch [90/100], Loss: 9.1539e-04\n",
      "Epoch [100/100], Loss: 8.6068e-04\n",
      "#####--training model 87--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.1336e-03\n",
      "Epoch [20/100], Loss: 3.4125e-03\n",
      "Epoch [30/100], Loss: 2.4230e-03\n",
      "Epoch [40/100], Loss: 1.9199e-03\n",
      "Epoch [50/100], Loss: 1.6694e-03\n",
      "Epoch [60/100], Loss: 1.4994e-03\n",
      "Epoch [70/100], Loss: 1.3617e-03\n",
      "Epoch [80/100], Loss: 1.2542e-03\n",
      "Epoch [90/100], Loss: 1.1928e-03\n",
      "Epoch [100/100], Loss: 1.1802e-03\n",
      "#####--training model 88--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.0255e-03\n",
      "Epoch [20/100], Loss: 3.9317e-03\n",
      "Epoch [30/100], Loss: 3.0095e-03\n",
      "Epoch [40/100], Loss: 2.3252e-03\n",
      "Epoch [50/100], Loss: 1.9393e-03\n",
      "Epoch [60/100], Loss: 1.7091e-03\n",
      "Epoch [70/100], Loss: 1.5312e-03\n",
      "Epoch [80/100], Loss: 1.3797e-03\n",
      "Epoch [90/100], Loss: 1.2512e-03\n",
      "Epoch [100/100], Loss: 1.1510e-03\n",
      "#####--training model 89--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.3460e-03\n",
      "Epoch [20/100], Loss: 2.2831e-03\n",
      "Epoch [30/100], Loss: 1.6207e-03\n",
      "Epoch [40/100], Loss: 1.3894e-03\n",
      "Epoch [50/100], Loss: 1.3058e-03\n",
      "Epoch [60/100], Loss: 1.2364e-03\n",
      "Epoch [70/100], Loss: 1.1631e-03\n",
      "Epoch [80/100], Loss: 1.0904e-03\n",
      "Epoch [90/100], Loss: 1.0199e-03\n",
      "Epoch [100/100], Loss: 9.4440e-04\n",
      "#####--training model 90--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.2972e-03\n",
      "Epoch [20/100], Loss: 4.1752e-03\n",
      "Epoch [30/100], Loss: 3.7791e-03\n",
      "Epoch [40/100], Loss: 3.6443e-03\n",
      "Epoch [50/100], Loss: 3.3042e-03\n",
      "Epoch [60/100], Loss: 3.0065e-03\n",
      "Epoch [70/100], Loss: 2.8000e-03\n",
      "Epoch [80/100], Loss: 2.5998e-03\n",
      "Epoch [90/100], Loss: 2.3282e-03\n",
      "Epoch [100/100], Loss: 1.9495e-03\n",
      "#####--training model 91--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0778e-02\n",
      "Epoch [20/100], Loss: 7.4678e-03\n",
      "Epoch [30/100], Loss: 5.6198e-03\n",
      "Epoch [40/100], Loss: 4.9741e-03\n",
      "Epoch [50/100], Loss: 4.5260e-03\n",
      "Epoch [60/100], Loss: 3.9595e-03\n",
      "Epoch [70/100], Loss: 3.2842e-03\n",
      "Epoch [80/100], Loss: 2.0614e-03\n",
      "Epoch [90/100], Loss: 1.7025e-03\n",
      "Epoch [100/100], Loss: 1.4883e-03\n",
      "#####--training model 92--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2021e-02\n",
      "Epoch [20/100], Loss: 8.7236e-03\n",
      "Epoch [30/100], Loss: 6.4586e-03\n",
      "Epoch [40/100], Loss: 5.4789e-03\n",
      "Epoch [50/100], Loss: 4.9416e-03\n",
      "Epoch [60/100], Loss: 4.4395e-03\n",
      "Epoch [70/100], Loss: 3.9164e-03\n",
      "Epoch [80/100], Loss: 3.4032e-03\n",
      "Epoch [90/100], Loss: 2.9134e-03\n",
      "Epoch [100/100], Loss: 2.1900e-03\n",
      "#####--training model 93--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.1430e-03\n",
      "Epoch [20/100], Loss: 5.1881e-03\n",
      "Epoch [30/100], Loss: 3.5791e-03\n",
      "Epoch [40/100], Loss: 2.6108e-03\n",
      "Epoch [50/100], Loss: 2.2169e-03\n",
      "Epoch [60/100], Loss: 1.9289e-03\n",
      "Epoch [70/100], Loss: 1.7004e-03\n",
      "Epoch [80/100], Loss: 1.5490e-03\n",
      "Epoch [90/100], Loss: 1.4798e-03\n",
      "Epoch [100/100], Loss: 1.4764e-03\n",
      "#####--training model 94--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 9.5718e-03\n",
      "Epoch [20/100], Loss: 7.1559e-03\n",
      "Epoch [30/100], Loss: 5.1756e-03\n",
      "Epoch [40/100], Loss: 4.4701e-03\n",
      "Epoch [50/100], Loss: 4.0682e-03\n",
      "Epoch [60/100], Loss: 3.7246e-03\n",
      "Epoch [70/100], Loss: 3.3706e-03\n",
      "Epoch [80/100], Loss: 2.9896e-03\n",
      "Epoch [90/100], Loss: 2.5928e-03\n",
      "Epoch [100/100], Loss: 2.2112e-03\n",
      "#####--training model 95--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.7515e-02\n",
      "Epoch [20/100], Loss: 5.2232e-03\n",
      "Epoch [30/100], Loss: 1.9912e-03\n",
      "Epoch [40/100], Loss: 5.3148e-04\n",
      "Epoch [50/100], Loss: 3.0665e-04\n",
      "Epoch [60/100], Loss: 2.0872e-04\n",
      "Epoch [70/100], Loss: 1.4387e-04\n",
      "Epoch [80/100], Loss: 1.0404e-04\n",
      "Epoch [90/100], Loss: 8.3372e-05\n",
      "Epoch [100/100], Loss: 7.1355e-05\n",
      "#####--training model 96--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3485e-02\n",
      "Epoch [20/100], Loss: 1.3287e-02\n",
      "Epoch [30/100], Loss: 1.0369e-02\n",
      "Epoch [40/100], Loss: 5.3411e-03\n",
      "Epoch [50/100], Loss: 3.3891e-03\n",
      "Epoch [60/100], Loss: 1.9606e-03\n",
      "Epoch [70/100], Loss: 1.0705e-03\n",
      "Epoch [80/100], Loss: 8.1327e-04\n",
      "Epoch [90/100], Loss: 6.7592e-04\n",
      "Epoch [100/100], Loss: 5.4725e-04\n",
      "#####--training model 97--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.5316e-02\n",
      "Epoch [20/100], Loss: 1.3940e-02\n",
      "Epoch [30/100], Loss: 7.9799e-03\n",
      "Epoch [40/100], Loss: 5.2390e-03\n",
      "Epoch [50/100], Loss: 3.7182e-03\n",
      "Epoch [60/100], Loss: 2.6536e-03\n",
      "Epoch [70/100], Loss: 1.4595e-03\n",
      "Epoch [80/100], Loss: 9.7772e-04\n",
      "Epoch [90/100], Loss: 7.7734e-04\n",
      "Epoch [100/100], Loss: 6.6245e-04\n",
      "#####--training model 98--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.2242e-02\n",
      "Epoch [20/100], Loss: 2.7766e-03\n",
      "Epoch [30/100], Loss: 2.0945e-03\n",
      "Epoch [40/100], Loss: 1.9663e-03\n",
      "Epoch [50/100], Loss: 1.9414e-03\n",
      "Epoch [60/100], Loss: 1.9529e-03\n",
      "Epoch [70/100], Loss: 1.9811e-03\n",
      "Epoch [80/100], Loss: 1.9950e-03\n",
      "Epoch [90/100], Loss: 1.0481e-03\n",
      "Epoch [100/100], Loss: 1.2678e-03\n",
      "#####--training model 99--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.0105e-02\n",
      "Epoch [20/100], Loss: 3.1355e-03\n",
      "Epoch [30/100], Loss: 2.4422e-03\n",
      "Epoch [40/100], Loss: 2.2030e-03\n",
      "Epoch [50/100], Loss: 2.1525e-03\n",
      "Epoch [60/100], Loss: 2.1410e-03\n",
      "Epoch [70/100], Loss: 2.1178e-03\n",
      "Epoch [80/100], Loss: 2.0747e-03\n",
      "Epoch [90/100], Loss: 1.9585e-03\n",
      "Epoch [100/100], Loss: 1.0533e-03\n",
      "#####--training model 100--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0246e-02\n",
      "Epoch [20/100], Loss: 9.2391e-03\n",
      "Epoch [30/100], Loss: 8.5549e-03\n",
      "Epoch [40/100], Loss: 7.5342e-03\n",
      "Epoch [50/100], Loss: 6.5839e-03\n",
      "Epoch [60/100], Loss: 5.9906e-03\n",
      "Epoch [70/100], Loss: 5.6164e-03\n",
      "Epoch [80/100], Loss: 5.3383e-03\n",
      "Epoch [90/100], Loss: 5.0794e-03\n",
      "Epoch [100/100], Loss: 4.8178e-03\n",
      "#####--training model 101--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.4449e-02\n",
      "Epoch [20/100], Loss: 1.0463e-02\n",
      "Epoch [30/100], Loss: 8.6064e-03\n",
      "Epoch [40/100], Loss: 7.5289e-03\n",
      "Epoch [50/100], Loss: 6.8479e-03\n",
      "Epoch [60/100], Loss: 6.2131e-03\n",
      "Epoch [70/100], Loss: 5.4784e-03\n",
      "Epoch [80/100], Loss: 4.7155e-03\n",
      "Epoch [90/100], Loss: 4.2653e-03\n",
      "Epoch [100/100], Loss: 4.1215e-03\n",
      "#####--training model 102--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.1038e-02\n",
      "Epoch [20/100], Loss: 7.7123e-03\n",
      "Epoch [30/100], Loss: 5.8702e-03\n",
      "Epoch [40/100], Loss: 4.9170e-03\n",
      "Epoch [50/100], Loss: 4.3731e-03\n",
      "Epoch [60/100], Loss: 3.9914e-03\n",
      "Epoch [70/100], Loss: 3.6458e-03\n",
      "Epoch [80/100], Loss: 3.2548e-03\n",
      "Epoch [90/100], Loss: 2.7783e-03\n",
      "Epoch [100/100], Loss: 2.2455e-03\n",
      "#####--training model 103--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2079e-02\n",
      "Epoch [20/100], Loss: 8.4633e-03\n",
      "Epoch [30/100], Loss: 7.0073e-03\n",
      "Epoch [40/100], Loss: 6.4357e-03\n",
      "Epoch [50/100], Loss: 5.9605e-03\n",
      "Epoch [60/100], Loss: 5.3106e-03\n",
      "Epoch [70/100], Loss: 4.6770e-03\n",
      "Epoch [80/100], Loss: 4.2353e-03\n",
      "Epoch [90/100], Loss: 3.9248e-03\n",
      "Epoch [100/100], Loss: 3.6689e-03\n",
      "#####--training model 104--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0871e-02\n",
      "Epoch [20/100], Loss: 8.7039e-03\n",
      "Epoch [30/100], Loss: 7.2867e-03\n",
      "Epoch [40/100], Loss: 6.5396e-03\n",
      "Epoch [50/100], Loss: 5.8000e-03\n",
      "Epoch [60/100], Loss: 5.1384e-03\n",
      "Epoch [70/100], Loss: 4.5711e-03\n",
      "Epoch [80/100], Loss: 4.0859e-03\n",
      "Epoch [90/100], Loss: 3.7263e-03\n",
      "Epoch [100/100], Loss: 3.4646e-03\n",
      "#####--training model 105--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2332e-02\n",
      "Epoch [20/100], Loss: 9.0428e-03\n",
      "Epoch [30/100], Loss: 3.5834e-03\n",
      "Epoch [40/100], Loss: 2.1709e-03\n",
      "Epoch [50/100], Loss: 1.4752e-03\n",
      "Epoch [60/100], Loss: 1.1181e-03\n",
      "Epoch [70/100], Loss: 8.9624e-04\n",
      "Epoch [80/100], Loss: 6.8719e-04\n",
      "Epoch [90/100], Loss: 4.9574e-04\n",
      "Epoch [100/100], Loss: 3.6779e-04\n",
      "#####--training model 106--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.2903e-03\n",
      "Epoch [20/100], Loss: 6.3198e-03\n",
      "Epoch [30/100], Loss: 5.4144e-03\n",
      "Epoch [40/100], Loss: 4.6956e-03\n",
      "Epoch [50/100], Loss: 4.2216e-03\n",
      "Epoch [60/100], Loss: 3.9352e-03\n",
      "Epoch [70/100], Loss: 3.6862e-03\n",
      "Epoch [80/100], Loss: 3.4054e-03\n",
      "Epoch [90/100], Loss: 3.1207e-03\n",
      "Epoch [100/100], Loss: 2.8576e-03\n",
      "#####--training model 107--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.6363e-03\n",
      "Epoch [20/100], Loss: 6.4195e-03\n",
      "Epoch [30/100], Loss: 5.1698e-03\n",
      "Epoch [40/100], Loss: 4.3084e-03\n",
      "Epoch [50/100], Loss: 3.8868e-03\n",
      "Epoch [60/100], Loss: 3.6388e-03\n",
      "Epoch [70/100], Loss: 3.3885e-03\n",
      "Epoch [80/100], Loss: 3.0899e-03\n",
      "Epoch [90/100], Loss: 2.7580e-03\n",
      "Epoch [100/100], Loss: 2.4252e-03\n",
      "#####--training model 108--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.1689e-03\n",
      "Epoch [20/100], Loss: 2.7495e-03\n",
      "Epoch [30/100], Loss: 2.1088e-03\n",
      "Epoch [40/100], Loss: 1.6661e-03\n",
      "Epoch [50/100], Loss: 1.4313e-03\n",
      "Epoch [60/100], Loss: 1.2815e-03\n",
      "Epoch [70/100], Loss: 1.1377e-03\n",
      "Epoch [80/100], Loss: 9.8068e-04\n",
      "Epoch [90/100], Loss: 7.9874e-04\n",
      "Epoch [100/100], Loss: 5.6633e-04\n",
      "#####--training model 109--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.9534e-03\n",
      "Epoch [20/100], Loss: 4.5562e-03\n",
      "Epoch [30/100], Loss: 3.3991e-03\n",
      "Epoch [40/100], Loss: 2.6789e-03\n",
      "Epoch [50/100], Loss: 2.1890e-03\n",
      "Epoch [60/100], Loss: 1.8426e-03\n",
      "Epoch [70/100], Loss: 1.5813e-03\n",
      "Epoch [80/100], Loss: 1.3685e-03\n",
      "Epoch [90/100], Loss: 1.1837e-03\n",
      "Epoch [100/100], Loss: 1.0164e-03\n",
      "#####--training model 110--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.9339e-02\n",
      "Epoch [20/100], Loss: 4.7349e-03\n",
      "Epoch [30/100], Loss: 2.8247e-03\n",
      "Epoch [40/100], Loss: 2.3443e-03\n",
      "Epoch [50/100], Loss: 2.0142e-03\n",
      "Epoch [60/100], Loss: 1.7247e-03\n",
      "Epoch [70/100], Loss: 1.5164e-03\n",
      "Epoch [80/100], Loss: 1.3925e-03\n",
      "Epoch [90/100], Loss: 1.3237e-03\n",
      "Epoch [100/100], Loss: 1.2813e-03\n",
      "#####--training model 111--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0735e-02\n",
      "Epoch [20/100], Loss: 7.6206e-03\n",
      "Epoch [30/100], Loss: 6.3278e-03\n",
      "Epoch [40/100], Loss: 5.3146e-03\n",
      "Epoch [50/100], Loss: 4.3986e-03\n",
      "Epoch [60/100], Loss: 3.4856e-03\n",
      "Epoch [70/100], Loss: 2.5791e-03\n",
      "Epoch [80/100], Loss: 1.8682e-03\n",
      "Epoch [90/100], Loss: 1.5334e-03\n",
      "Epoch [100/100], Loss: 1.3008e-03\n",
      "#####--training model 112--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3400e-02\n",
      "Epoch [20/100], Loss: 8.2894e-03\n",
      "Epoch [30/100], Loss: 6.3394e-03\n",
      "Epoch [40/100], Loss: 5.2400e-03\n",
      "Epoch [50/100], Loss: 4.4547e-03\n",
      "Epoch [60/100], Loss: 3.7742e-03\n",
      "Epoch [70/100], Loss: 3.0858e-03\n",
      "Epoch [80/100], Loss: 2.4375e-03\n",
      "Epoch [90/100], Loss: 1.9566e-03\n",
      "Epoch [100/100], Loss: 1.6528e-03\n",
      "#####--training model 113--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.8837e-03\n",
      "Epoch [20/100], Loss: 5.0782e-03\n",
      "Epoch [30/100], Loss: 4.2591e-03\n",
      "Epoch [40/100], Loss: 3.5662e-03\n",
      "Epoch [50/100], Loss: 3.0875e-03\n",
      "Epoch [60/100], Loss: 2.7447e-03\n",
      "Epoch [70/100], Loss: 2.4832e-03\n",
      "Epoch [80/100], Loss: 2.2781e-03\n",
      "Epoch [90/100], Loss: 2.1115e-03\n",
      "Epoch [100/100], Loss: 1.9619e-03\n",
      "#####--training model 114--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.0804e-03\n",
      "Epoch [20/100], Loss: 5.4051e-03\n",
      "Epoch [30/100], Loss: 4.2944e-03\n",
      "Epoch [40/100], Loss: 3.5877e-03\n",
      "Epoch [50/100], Loss: 3.0715e-03\n",
      "Epoch [60/100], Loss: 2.6296e-03\n",
      "Epoch [70/100], Loss: 2.2424e-03\n",
      "Epoch [80/100], Loss: 1.8915e-03\n",
      "Epoch [90/100], Loss: 1.4925e-03\n",
      "Epoch [100/100], Loss: 9.6671e-04\n",
      "#####--training model 115--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.9629e-04\n",
      "Epoch [20/100], Loss: 4.1851e-04\n",
      "Epoch [30/100], Loss: 5.0438e-04\n",
      "Epoch [40/100], Loss: 5.3919e-04\n",
      "Epoch [50/100], Loss: 5.6908e-04\n",
      "Epoch [60/100], Loss: 5.8853e-04\n",
      "Epoch [70/100], Loss: 5.9455e-04\n",
      "Epoch [80/100], Loss: 5.9532e-04\n",
      "Epoch [90/100], Loss: 5.9953e-04\n",
      "Epoch [100/100], Loss: 6.0370e-04\n",
      "#####--training model 116--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.1541e-03\n",
      "Epoch [20/100], Loss: 1.9910e-03\n",
      "Epoch [30/100], Loss: 1.5060e-03\n",
      "Epoch [40/100], Loss: 1.2848e-03\n",
      "Epoch [50/100], Loss: 1.1682e-03\n",
      "Epoch [60/100], Loss: 1.0851e-03\n",
      "Epoch [70/100], Loss: 1.0177e-03\n",
      "Epoch [80/100], Loss: 9.6206e-04\n",
      "Epoch [90/100], Loss: 9.1644e-04\n",
      "Epoch [100/100], Loss: 8.8977e-04\n",
      "#####--training model 117--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.2546e-03\n",
      "Epoch [20/100], Loss: 2.0925e-03\n",
      "Epoch [30/100], Loss: 1.3534e-03\n",
      "Epoch [40/100], Loss: 1.0703e-03\n",
      "Epoch [50/100], Loss: 9.0437e-04\n",
      "Epoch [60/100], Loss: 7.9247e-04\n",
      "Epoch [70/100], Loss: 7.2301e-04\n",
      "Epoch [80/100], Loss: 6.9231e-04\n",
      "Epoch [90/100], Loss: 6.9296e-04\n",
      "Epoch [100/100], Loss: 7.1776e-04\n",
      "#####--training model 118--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.9024e-03\n",
      "Epoch [20/100], Loss: 1.2169e-03\n",
      "Epoch [30/100], Loss: 7.0672e-04\n",
      "Epoch [40/100], Loss: 6.1135e-04\n",
      "Epoch [50/100], Loss: 5.4366e-04\n",
      "Epoch [60/100], Loss: 4.5963e-04\n",
      "Epoch [70/100], Loss: 3.9226e-04\n",
      "Epoch [80/100], Loss: 3.6071e-04\n",
      "Epoch [90/100], Loss: 3.2635e-04\n",
      "Epoch [100/100], Loss: 3.0375e-04\n",
      "#####--training model 119--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.5879e-03\n",
      "Epoch [20/100], Loss: 1.4189e-03\n",
      "Epoch [30/100], Loss: 8.6356e-04\n",
      "Epoch [40/100], Loss: 7.1352e-04\n",
      "Epoch [50/100], Loss: 6.1858e-04\n",
      "Epoch [60/100], Loss: 5.4208e-04\n",
      "Epoch [70/100], Loss: 4.8189e-04\n",
      "Epoch [80/100], Loss: 4.3397e-04\n",
      "Epoch [90/100], Loss: 3.9317e-04\n",
      "Epoch [100/100], Loss: 3.6656e-04\n",
      "#####--training model 120--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.4985e-03\n",
      "Epoch [20/100], Loss: 2.1109e-03\n",
      "Epoch [30/100], Loss: 1.6481e-03\n",
      "Epoch [40/100], Loss: 1.3445e-03\n",
      "Epoch [50/100], Loss: 1.2007e-03\n",
      "Epoch [60/100], Loss: 1.1156e-03\n",
      "Epoch [70/100], Loss: 1.0368e-03\n",
      "Epoch [80/100], Loss: 9.4211e-04\n",
      "Epoch [90/100], Loss: 8.1623e-04\n",
      "Epoch [100/100], Loss: 6.9946e-04\n",
      "#####--training model 121--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6314e-03\n",
      "Epoch [20/100], Loss: 1.3274e-03\n",
      "Epoch [30/100], Loss: 6.6214e-04\n",
      "Epoch [40/100], Loss: 3.4847e-04\n",
      "Epoch [50/100], Loss: 1.4267e-04\n",
      "Epoch [60/100], Loss: 1.9153e-05\n",
      "Epoch [70/100], Loss: 5.8331e-06\n",
      "Epoch [80/100], Loss: 9.0314e-06\n",
      "Epoch [90/100], Loss: 1.2913e-05\n",
      "Epoch [100/100], Loss: 1.5489e-05\n",
      "#####--training model 122--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.6490e-03\n",
      "Epoch [20/100], Loss: 2.5347e-03\n",
      "Epoch [30/100], Loss: 2.0196e-03\n",
      "Epoch [40/100], Loss: 8.8414e-04\n",
      "Epoch [50/100], Loss: 3.1593e-04\n",
      "Epoch [60/100], Loss: 3.2018e-05\n",
      "Epoch [70/100], Loss: 5.3514e-06\n",
      "Epoch [80/100], Loss: 1.5131e-05\n",
      "Epoch [90/100], Loss: 1.8189e-05\n",
      "Epoch [100/100], Loss: 1.9578e-05\n",
      "#####--training model 123--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.1800e-03\n",
      "Epoch [20/100], Loss: 5.2807e-04\n",
      "Epoch [30/100], Loss: 9.7466e-05\n",
      "Epoch [40/100], Loss: 4.1289e-05\n",
      "Epoch [50/100], Loss: 1.0714e-04\n",
      "Epoch [60/100], Loss: 1.3270e-04\n",
      "Epoch [70/100], Loss: 1.3096e-04\n",
      "Epoch [80/100], Loss: 1.2225e-04\n",
      "Epoch [90/100], Loss: 1.0710e-04\n",
      "Epoch [100/100], Loss: 8.7052e-05\n",
      "#####--training model 124--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.8490e-03\n",
      "Epoch [20/100], Loss: 4.9745e-04\n",
      "Epoch [30/100], Loss: 1.7531e-04\n",
      "Epoch [40/100], Loss: 6.3687e-05\n",
      "Epoch [50/100], Loss: 2.2654e-05\n",
      "Epoch [60/100], Loss: 5.5517e-05\n",
      "Epoch [70/100], Loss: 7.2307e-05\n",
      "Epoch [80/100], Loss: 6.8265e-05\n",
      "Epoch [90/100], Loss: 5.8128e-05\n",
      "Epoch [100/100], Loss: 4.8691e-05\n",
      "#####--training model 125--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.6589e-02\n",
      "Epoch [20/100], Loss: 5.2890e-02\n",
      "Epoch [30/100], Loss: 3.7505e-02\n",
      "Epoch [40/100], Loss: 2.5694e-02\n",
      "Epoch [50/100], Loss: 1.9476e-02\n",
      "Epoch [60/100], Loss: 1.6712e-02\n",
      "Epoch [70/100], Loss: 1.5597e-02\n",
      "Epoch [80/100], Loss: 1.4770e-02\n",
      "Epoch [90/100], Loss: 1.3908e-02\n",
      "Epoch [100/100], Loss: 1.3007e-02\n",
      "#####--training model 126--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.2425e-03\n",
      "Epoch [20/100], Loss: 1.2017e-03\n",
      "Epoch [30/100], Loss: 1.1274e-03\n",
      "Epoch [40/100], Loss: 7.3827e-04\n",
      "Epoch [50/100], Loss: 2.6562e-04\n",
      "Epoch [60/100], Loss: 3.6531e-05\n",
      "Epoch [70/100], Loss: 8.0640e-05\n",
      "Epoch [80/100], Loss: 8.0373e-05\n",
      "Epoch [90/100], Loss: 7.1214e-05\n",
      "Epoch [100/100], Loss: 6.3809e-05\n",
      "#####--training model 127--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0221e-03\n",
      "Epoch [20/100], Loss: 1.0153e-03\n",
      "Epoch [30/100], Loss: 8.4047e-04\n",
      "Epoch [40/100], Loss: 3.1515e-04\n",
      "Epoch [50/100], Loss: 1.7732e-04\n",
      "Epoch [60/100], Loss: 4.0600e-05\n",
      "Epoch [70/100], Loss: 9.5209e-05\n",
      "Epoch [80/100], Loss: 9.0202e-05\n",
      "Epoch [90/100], Loss: 7.8482e-05\n",
      "Epoch [100/100], Loss: 6.5045e-05\n",
      "#####--training model 128--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 4.5181e-03\n",
      "Epoch [20/100], Loss: 3.6029e-04\n",
      "Epoch [30/100], Loss: 5.2350e-04\n",
      "Epoch [40/100], Loss: 5.6151e-04\n",
      "Epoch [50/100], Loss: 5.0116e-04\n",
      "Epoch [60/100], Loss: 4.1240e-04\n",
      "Epoch [70/100], Loss: 3.4373e-04\n",
      "Epoch [80/100], Loss: 2.9881e-04\n",
      "Epoch [90/100], Loss: 2.6946e-04\n",
      "Epoch [100/100], Loss: 2.5343e-04\n",
      "#####--training model 129--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.8093e-03\n",
      "Epoch [20/100], Loss: 4.1057e-04\n",
      "Epoch [30/100], Loss: 1.4732e-04\n",
      "Epoch [40/100], Loss: 2.0666e-04\n",
      "Epoch [50/100], Loss: 2.9022e-04\n",
      "Epoch [60/100], Loss: 3.2849e-04\n",
      "Epoch [70/100], Loss: 3.1622e-04\n",
      "Epoch [80/100], Loss: 2.8650e-04\n",
      "Epoch [90/100], Loss: 2.5662e-04\n",
      "Epoch [100/100], Loss: 2.3353e-04\n",
      "#####--training model 130--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.8684e-03\n",
      "Epoch [20/100], Loss: 1.3850e-03\n",
      "Epoch [30/100], Loss: 9.3906e-04\n",
      "Epoch [40/100], Loss: 7.8912e-04\n",
      "Epoch [50/100], Loss: 6.7509e-04\n",
      "Epoch [60/100], Loss: 6.2806e-04\n",
      "Epoch [70/100], Loss: 6.2203e-04\n",
      "Epoch [80/100], Loss: 6.2743e-04\n",
      "Epoch [90/100], Loss: 6.3499e-04\n",
      "Epoch [100/100], Loss: 6.4278e-04\n",
      "#####--training model 131--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 8.7768e-04\n",
      "Epoch [20/100], Loss: 8.7682e-04\n",
      "Epoch [30/100], Loss: 8.7510e-04\n",
      "Epoch [40/100], Loss: 8.6567e-04\n",
      "Epoch [50/100], Loss: 8.0875e-04\n",
      "Epoch [60/100], Loss: 3.8976e-04\n",
      "Epoch [70/100], Loss: 9.5433e-05\n",
      "Epoch [80/100], Loss: 3.4897e-05\n",
      "Epoch [90/100], Loss: 1.0599e-04\n",
      "Epoch [100/100], Loss: 5.0433e-05\n",
      "#####--training model 132--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.1953e-03\n",
      "Epoch [20/100], Loss: 2.5820e-04\n",
      "Epoch [30/100], Loss: 6.4904e-04\n",
      "Epoch [40/100], Loss: 8.9206e-04\n",
      "Epoch [50/100], Loss: 8.5823e-04\n",
      "Epoch [60/100], Loss: 7.3589e-04\n",
      "Epoch [70/100], Loss: 6.0936e-04\n",
      "Epoch [80/100], Loss: 5.1830e-04\n",
      "Epoch [90/100], Loss: 4.5670e-04\n",
      "Epoch [100/100], Loss: 4.1228e-04\n",
      "#####--training model 133--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.2956e-04\n",
      "Epoch [20/100], Loss: 2.4362e-03\n",
      "Epoch [30/100], Loss: 2.1732e-03\n",
      "Epoch [40/100], Loss: 1.5573e-03\n",
      "Epoch [50/100], Loss: 1.2023e-03\n",
      "Epoch [60/100], Loss: 1.0667e-03\n",
      "Epoch [70/100], Loss: 1.0317e-03\n",
      "Epoch [80/100], Loss: 1.0301e-03\n",
      "Epoch [90/100], Loss: 1.0278e-03\n",
      "Epoch [100/100], Loss: 1.0249e-03\n",
      "#####--training model 134--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 2.3929e-03\n",
      "Epoch [20/100], Loss: 2.1645e-03\n",
      "Epoch [30/100], Loss: 1.5951e-03\n",
      "Epoch [40/100], Loss: 1.2105e-03\n",
      "Epoch [50/100], Loss: 9.6628e-04\n",
      "Epoch [60/100], Loss: 8.3187e-04\n",
      "Epoch [70/100], Loss: 7.7237e-04\n",
      "Epoch [80/100], Loss: 7.4654e-04\n",
      "Epoch [90/100], Loss: 7.2177e-04\n",
      "Epoch [100/100], Loss: 6.9517e-04\n",
      "#####--training model 135--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 6.5515e-04\n",
      "Epoch [20/100], Loss: 3.7601e-04\n",
      "Epoch [30/100], Loss: 1.3475e-04\n",
      "Epoch [40/100], Loss: 3.6283e-05\n",
      "Epoch [50/100], Loss: 1.4483e-05\n",
      "Epoch [60/100], Loss: 1.9331e-05\n",
      "Epoch [70/100], Loss: 3.4256e-05\n",
      "Epoch [80/100], Loss: 5.2147e-05\n",
      "Epoch [90/100], Loss: 6.3630e-05\n",
      "Epoch [100/100], Loss: 6.8847e-05\n",
      "#####--training model 136--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.3674e-03\n",
      "Epoch [20/100], Loss: 1.3815e-03\n",
      "Epoch [30/100], Loss: 1.3761e-03\n",
      "Epoch [40/100], Loss: 4.4602e-04\n",
      "Epoch [50/100], Loss: 1.3954e-05\n",
      "Epoch [60/100], Loss: 1.9243e-05\n",
      "Epoch [70/100], Loss: 1.2848e-05\n",
      "Epoch [80/100], Loss: 2.0205e-05\n",
      "Epoch [90/100], Loss: 4.0696e-05\n",
      "Epoch [100/100], Loss: 7.6527e-05\n",
      "#####--training model 137--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0391e-03\n",
      "Epoch [20/100], Loss: 9.9911e-04\n",
      "Epoch [30/100], Loss: 3.8617e-04\n",
      "Epoch [40/100], Loss: 1.5816e-04\n",
      "Epoch [50/100], Loss: 5.8916e-07\n",
      "Epoch [60/100], Loss: 1.3755e-06\n",
      "Epoch [70/100], Loss: 1.0581e-05\n",
      "Epoch [80/100], Loss: 3.1382e-05\n",
      "Epoch [90/100], Loss: 4.1188e-05\n",
      "Epoch [100/100], Loss: 3.3204e-05\n",
      "#####--training model 138--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 7.6432e-04\n",
      "Epoch [20/100], Loss: 7.9673e-04\n",
      "Epoch [30/100], Loss: 7.9645e-04\n",
      "Epoch [40/100], Loss: 3.2949e-04\n",
      "Epoch [50/100], Loss: 3.6758e-05\n",
      "Epoch [60/100], Loss: 3.1697e-04\n",
      "Epoch [70/100], Loss: 3.1889e-04\n",
      "Epoch [80/100], Loss: 2.9480e-04\n",
      "Epoch [90/100], Loss: 2.9065e-04\n",
      "Epoch [100/100], Loss: 2.9011e-04\n",
      "#####--training model 139--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 5.8563e-04\n",
      "Epoch [20/100], Loss: 5.5760e-04\n",
      "Epoch [30/100], Loss: 9.1047e-05\n",
      "Epoch [40/100], Loss: 1.9385e-05\n",
      "Epoch [50/100], Loss: 2.5901e-05\n",
      "Epoch [60/100], Loss: 6.5313e-05\n",
      "Epoch [70/100], Loss: 1.0127e-04\n",
      "Epoch [80/100], Loss: 1.3776e-04\n",
      "Epoch [90/100], Loss: 1.6509e-04\n",
      "Epoch [100/100], Loss: 1.5195e-04\n",
      "#####--training model 140--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.7791e-03\n",
      "Epoch [20/100], Loss: 2.9681e-03\n",
      "Epoch [30/100], Loss: 2.3185e-03\n",
      "Epoch [40/100], Loss: 1.6562e-03\n",
      "Epoch [50/100], Loss: 1.1643e-03\n",
      "Epoch [60/100], Loss: 9.3860e-04\n",
      "Epoch [70/100], Loss: 8.7573e-04\n",
      "Epoch [80/100], Loss: 8.8972e-04\n",
      "Epoch [90/100], Loss: 9.1495e-04\n",
      "Epoch [100/100], Loss: 8.4924e-04\n",
      "#####--training model 141--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.7131e-03\n",
      "Epoch [20/100], Loss: 3.6715e-03\n",
      "Epoch [30/100], Loss: 3.6036e-03\n",
      "Epoch [40/100], Loss: 1.9333e-03\n",
      "Epoch [50/100], Loss: 6.7425e-04\n",
      "Epoch [60/100], Loss: 5.3605e-04\n",
      "Epoch [70/100], Loss: 5.4984e-04\n",
      "Epoch [80/100], Loss: 5.9351e-04\n",
      "Epoch [90/100], Loss: 6.2674e-04\n",
      "Epoch [100/100], Loss: 6.4509e-04\n",
      "#####--training model 142--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 3.0126e-03\n",
      "Epoch [20/100], Loss: 2.9124e-03\n",
      "Epoch [30/100], Loss: 2.3235e-03\n",
      "Epoch [40/100], Loss: 9.8773e-04\n",
      "Epoch [50/100], Loss: 5.1992e-04\n",
      "Epoch [60/100], Loss: 3.7779e-04\n",
      "Epoch [70/100], Loss: 3.9604e-04\n",
      "Epoch [80/100], Loss: 4.0966e-04\n",
      "Epoch [90/100], Loss: 4.1767e-04\n",
      "Epoch [100/100], Loss: 4.2364e-04\n",
      "#####--training model 143--#####\n",
      "\n",
      "-----Begin Training------\n",
      "Epoch [10/100], Loss: 1.0102e-02\n",
      "Epoch [20/100], Loss: 2.8792e-03\n",
      "Epoch [30/100], Loss: 1.6579e-03\n",
      "Epoch [40/100], Loss: 1.1312e-03\n",
      "Epoch [50/100], Loss: 8.5028e-04\n",
      "Epoch [60/100], Loss: 6.3310e-04\n",
      "Epoch [70/100], Loss: 4.7095e-04\n",
      "Epoch [80/100], Loss: 3.7670e-04\n",
      "Epoch [90/100], Loss: 3.2513e-04\n",
      "Epoch [100/100], Loss: 3.1103e-04\n"
     ]
    }
   ],
   "source": [
    "folder_name  = 'models_od\\\\'\n",
    "\n",
    "for feature in range(num_features): \n",
    "\n",
    "    print('#####--training model %d--#####\\n' % feature)\n",
    "    \n",
    "    # Get model and optimizer\n",
    "    model = models[feature]\n",
    "    optimizer = optimizers[feature]\n",
    "\n",
    "    # Create training dataset and dataloader for current feature\n",
    "    train_loader = get_dataloader(np.expand_dims(trainX[:, :, feature], axis = 2), np.expand_dims(trainY[:, feature], axis = 1),\n",
    "                                   batch_size, num_workers, shuffle)\n",
    "    \n",
    "    # Train the model\n",
    "    loss = train(model, train_loader, epochs, criterion, optimizer)\n",
    "\n",
    "    # Save the model, we will get model outputs in a later loop\n",
    "    model_name = 'model_%d.pth' % feature\n",
    "    model_path = folder_name+model_name\n",
    "\n",
    "    torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.zeros((test_data.shape[0]-10, test_data.shape[1]))\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for i in range(144):\n",
    "    path = 'models_od\\\\model_%d.pth' % i\n",
    "    model = RNN(input_size, hidden_size, num_layers)\n",
    "    model.load_state_dict(torch.load(path, weights_only=True))\n",
    "    model.eval()\n",
    "\n",
    "    testX_i = np.expand_dims(testX[:, :, i], axis = 2)\n",
    "    testY_i = np.expand_dims(testY[:, i], axis = 1)\n",
    "\n",
    "    # Create test_loader\n",
    "    test_loader = get_dataloader(testX_i, testY_i,\n",
    "                                batch_size, num_workers, shuffle)\n",
    "\n",
    "    total_loss = 0.0 \n",
    "\n",
    "    model_outputs = [] # account for window size\n",
    "    test_loss = np.zeros((testY_i.shape[0], 1))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (inputs, targets) in enumerate(test_loader): \n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            model_outputs.append(outputs.flatten())\n",
    "\n",
    "\n",
    "    # Concatenate all outputs into a single tensor\n",
    "    model_outputs =  torch.cat(model_outputs, dim=0).numpy()\n",
    "\n",
    "    # Save the model_outputs\n",
    "    np.save('model_outputs_od\\\\abilene_local_mse_od_%i.npy' % i, \n",
    "        model_outputs)\n",
    "\n",
    "    # Inverse normalize the prediction\n",
    "    inverse_preds = model_outputs * (max_vals_test[i] - min_vals_test[i]) + min_vals_test[i]\n",
    "\n",
    "    # Add inverse normalized predictions to largers matrix\n",
    "    predictions[:, i] = inverse_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_save_heatmap(test_data, predictions, num_nodes=12, save_path = 'Figs\\\\heat_maps',\n",
    "                          fig_name= 'inverse_normalized_model_predictions_local.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-09-10\n"
     ]
    }
   ],
   "source": [
    "# Compute MCF on inverse normalized predictions\n",
    "mlu_preds, Nans = mlu_on_preds(predictions, topo='abilene')\n",
    "\n",
    "if Nans: \n",
    "    print('NaN values in mlu_preds, ending program')\n",
    "\n",
    "# Save MLUs\n",
    "np.save('mlu_baseline\\\\mlu_preds_abilene_local_mse.npy', mlu_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MCF baseline on original dataset\n",
    "mlu_gt = np.load('mlu_baseline\\\\mlu_baseline_abilene.npy')\n",
    "mlu_gt = mlu_gt[len(train_data):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mlu cdf and mlu comparison\n",
    "plot_and_save_ecdf(mlu_gt, mlu_preds, save_path = 'Figs\\\\ecdfs', fig_name='CDF_mlu_abilene_local_mse.png')\n",
    "plot_and_save_mlu_compare(mlu_gt, mlu_preds, save_path='Figs\\\\mlu_compare', fig_name='mlu_compare_abilene_local_mse.png')\n",
    "plot_and_save_pdf(mlu_gt, mlu_preds, save_path = 'Figs\\\\pdfs', fig_name='PDF_mlu_abilene_local_mse.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all predictions\n",
    "for i in range(144):\n",
    "    plt.plot(test_data[10:, i], label = 'Original')\n",
    "    plt.plot(predictions[:, i], label = 'Prediction')\n",
    "    plt.xlabel('Time Index')\n",
    "    plt.ylabel('Traffic Demand (bps)')\n",
    "    plt.legend(loc = 'upper right')\n",
    "    plt.savefig('Figs\\\\od_pairs\\\\prediction_local_%d.png' % i, dpi = 300, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
